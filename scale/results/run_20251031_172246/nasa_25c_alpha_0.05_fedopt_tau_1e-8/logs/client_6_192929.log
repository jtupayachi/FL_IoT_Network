[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c17f65bc-36db-462f-a9cf-7ce44547e3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116e67b9-4061-4747-8eec-6781de7ceb24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f435af7-0c15-426c-9c54-2fadf5c44ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d9ffa28-43f4-4a82-800c-72684a3f3d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43fb68f9-1da1-4e81-a2ef-6b64344c50da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda6750e-af19-4982-ad6a-46c8047ec9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61391943-9347-4a09-88d6-45ce4d4eff50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ccad62-dcf4-40b5-a064-8271bf55f38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bab3298f-8501-431a-bbbc-73abe962aae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92649298-b026-4771-88e3-064c04a7a31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f577e462-2eef-4b3d-b312-4d7df789f482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13b19dd-7e64-4f36-9bcc-cad047a9d34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca82964e-e331-4939-b2c7-cec1c11a09ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e749c59-897f-4b41-9726-f3a6468b2b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed445fc9-148c-4dfd-bf66-9bb519b92fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba375b12-16d9-4649-bf79-4fea9ba62a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e9bdfe-f560-46ea-9548-069766e42703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebaae023-685e-42e3-ae01-55a6e3fb5adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b473923-0ff0-4e9c-8107-0daa2a8f0782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2986ff5-2cef-467a-8bee-583c31a50f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9df805-cc76-4f30-b729-377cec551eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14d5d96-bfef-4511-90b1-5a36e90666f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c3956cb-31ab-49d7-acef-db877187a75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5b53f0-0a5e-4fd7-9976-8b7032355f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1ef2d6-862f-4cd2-a1b9-9dd5b845dc39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5c0ba3-2b73-4da5-885f-ed8226006d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11620a5f-2dca-4d81-bf74-8c30350b8644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466f0897-e5fa-4230-9ef1-ae6a426fcac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012b8cae-15b0-4e17-ab90-9546ede3f835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 253ffd97-6f1c-43d7-9190-347ce81179e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62be6fb-4d66-4e50-b908-c7087fede650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65aa8f3-75a1-45f1-9cfc-edd3ba34683e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72b1b35-4cab-4578-870c-cac656b3dbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1a485f-b26e-4d4f-ac51-2085c2c2427e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7647b20-9a24-4409-b27e-596775566729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b42f33-ad63-4e3c-8f7d-ad088aca7e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c42cac-9648-4ab0-8860-8d1278461b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca6724f-79b0-4233-8177-693260cbe96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b9a3f53-ab09-41f7-ad84-12ecef07271f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852e55aa-672c-440e-b747-bc2d9630bf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4592142-4d67-4e79-ae1f-96c1adafc170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce55eebb-78da-4994-bbe9-ede2dbf5bd5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10ee438-1ecb-4e97-af40-bca06a103bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6b4f3c-add3-47ae-903a-1c98df34080a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e23198b-7770-4f26-868e-e3087191fd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94bf6ddc-2fdd-4e8a-a500-67b9b358257f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7edc91e6-69aa-4c9b-92e0-109e776c064a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cbc3455-8230-424b-b443-9a69565effd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef6f4f0-77a0-4bce-9152-d3ace94d24ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b9a8139-d328-4c58-9cb7-d58a3cd3fff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ad763f-22c2-49b6-b46f-b5757f5827ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82bbff7b-21b6-453f-81ac-dfc58aa40f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a279f85-d61d-4cdc-8d68-cc9fd68c1e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e272b60-fd29-40f2-a1b9-8f145cfd1e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29dddf81-8eb6-4e77-a319-ec667209ca93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f83734-8ecb-416d-8f34-d6d1ea46b393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d373b718-5d4a-41bc-a7d5-feb52112852a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9ef8c44-56fb-45e0-b1c8-472da726459e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a94964-b901-4c10-944c-fc6df553852e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843a211b-ced4-41f7-827f-13590b45fd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407f3334-ee92-4dc8-9140-38de4ea94457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f148a133-c051-48ce-93ac-efb8060a786b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32143250-24b1-42f2-b00e-0a690b43b6e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4df8fd-8bf7-4a21-ae42-60064c2d4684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 838b58bf-297f-4104-b78d-2fae646ad19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3c7285-3f41-4371-bc18-f52b288c4a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5648c0b3-fdef-4438-b501-1868e7567bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03111ba5-ef94-40ce-9520-6a5b96ea2975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a020cff-bd87-42d6-9962-d48f3075cfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297ba725-ea7d-4c84-864d-c5621599305b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3f102c-9e7c-42c5-b012-24cc9752d3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30780153-b5a2-480c-a61a-b40095c68f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4449dbf7-8e0c-4407-9fdb-725131bc55fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2c63b37-9d86-4eaa-b4db-d434803a9a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ca5e37-3638-414d-97de-68c0556b31e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2640f6-0bbe-4db6-988d-9661526175fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b98d68-e132-40c8-a9b5-fd5619f7395b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0c14c2-a50b-41a1-9fc0-62b2d6b10555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad174a7-0888-4b14-95b2-3a274d1678dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ca36e2-3e43-41d6-aee6-ea4bf156607c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68c5301-1fc0-4f22-afee-d736372675f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158c8253-fd50-4a5a-9ea0-4f89e5ae8060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a1e130-b183-45f2-8394-6a1a6e6251ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b99291-7d35-4b52-a114-7821a9865e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af963e5-5987-46ae-98e8-dbf7e53b1531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44715bf-e4cd-48fe-aaa3-2b486f771fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d06d4732-6597-409d-8612-ddbdef511556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2ae802-9b9e-47dd-b439-6984f4d4a7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1b8ac3-e320-49bf-ad98-f051b2bbf81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8f9429-910c-4efd-8b2a-f69c78bf3eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450a0c6c-9c6b-4e70-a319-f008c50827d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0397f1ac-1dbb-430d-8863-34a40f10371b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484e15d1-5c14-41ea-8b92-821150757b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34b43e9-35db-4c00-af8c-99984f6ae332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46300cb3-1761-4077-bbbc-f066dc97c5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1c4c64-202a-465d-8023-298e9f67c8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 838cfc4f-6234-4f56-9a86-f44a6f9c4301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339a66f1-2935-4f15-8f50-08e0c94d3669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211e37d9-a479-4e3e-ac7f-5cf5f414b7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26de1d2-cce4-480a-86f9-4f6a1cc89775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946fb937-dcc0-419a-a7a5-fc6d2e050c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a4843d-8dad-4530-b460-a2fc1c4267eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c403fabf-84db-4ec6-b42b-c977360eca09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0314d82-295e-461d-9c35-5d4ab550dc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d3f2ea-1233-4005-a79f-93becc6604cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81105654-5785-44fb-a61d-b015b07576bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010fc957-ed39-4d70-bcad-547ba1c37b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad32bf59-d154-44fb-b8c0-9977f3eb230f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a89b8c-1fc7-481b-99ee-2762ad7b78bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e97ec92-f5eb-4fbe-b914-f9c21523b54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8bcbe30-b1c6-486b-97c6-ecb8603bacf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f95e92a1-ea33-45d6-be56-ebc17c34bc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3214c93b-bc8f-4e31-880b-ce407d602710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e47d220-a8e9-4d24-b85d-cd5db865b2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddb52831-6924-4f97-ad31-35529b40febb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a76464-6fbc-4861-a02e-0134d6fb21ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c88d300-0e6f-4348-9514-291c9f2286a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e772f16-65ad-4ce9-aa7e-8b4a86c0bd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f18d51-7fc7-4aeb-8653-2511c29b1459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086254b8-f34e-4294-b7c9-a02da738af92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5372d24-860e-4c06-bb9d-7927d25e8790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ccb556f-60a7-4fa8-b53b-c6bea72472ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 352d75b8-27d7-431b-aec0-7cc6f2f97021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18b01b3e-ee67-4a45-80fa-beffc6d8f9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b201063-8993-462a-9e5d-9748fb516a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81760634-80a1-48f8-927a-ff136000e796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4206f3da-fa52-43ac-ae5d-ae3dbc85b6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14357d0-8b07-4abf-91aa-5d442d1adb2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 189c7671-aa24-4cfd-a1c1-c16c7c1283a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c6ef22-f643-4189-acae-950d59d01d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27bf49c3-cc06-4c0b-8a14-a4cacc84d00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d773cb-888e-4c0d-ab3c-2561fd8ad98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c7214a-7229-499e-ba1d-b6769416ed3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc7a9670-3af8-4a4b-8bf6-315ca656a2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea5efcb-92ab-4849-9cad-c4cbeb6cc41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94a7470-8a8c-4f91-9ba5-1fc929348991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eca2eb9-9de0-4039-8c3c-63c4343f50f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f87602-6414-4e68-a4aa-06df5f3665ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27bf4f45-0d2a-442e-ba9f-1fbc4af31d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e379cf-df1b-4bb9-b05f-3a80800bb323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5abf0a88-e4dd-472e-b01b-35885e7fd83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8b3b70-052d-44f9-b56e-992e6e6cb7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c588ce-290c-4d41-bfe5-90ab3da488b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9649953a-fde4-4194-8d53-3bbcbbbb2533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669591d6-76c0-44f9-96b6-f0f2f45d1e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a06ff750-d376-4337-b423-71ec1c2a3c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e661849d-ea13-46a1-bedc-1686145429e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d7a25b-524d-4d85-97fb-60770018901b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b506c59-1b7e-43c7-8cda-dfcccb0f0d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2159dbe0-57f2-4c53-8cf8-1804e6aa3d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5d53ac-24e6-4daa-916c-3c2a239694bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0991b65d-16f2-49e6-b732-5ccefb4355c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d5cbcf-920e-4961-ba82-66a8fc159372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6844f551-eb15-492e-b8fa-d5ed77b9f874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5cd9c00-7596-456f-8b1f-1f38151fd377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a432841-d34a-4a09-b56e-eee6962f0def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b76770-2ca4-430d-8d86-a0eef066940e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5205b955-a8ea-4515-8984-59b2923d1fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a24d35-cf56-4137-9c4c-176efa40fec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029aeae0-1607-4ae8-83a1-0db2d3d8cc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55629e0f-0672-4f75-8e42-227e74b088f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee07dfca-b0bf-47c9-a5db-d8774c822296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f9b20b1-10ce-4ec2-a006-34309113def3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42766ec1-8a4b-4712-bdd8-2cf82e8cb073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04370bb5-3eb8-42a6-98d3-65e7977fa88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8785797-d744-42f8-99a7-ebd320ae6b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4242b1-ed0c-4425-97d8-dc181e6c4d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7efcbe4-7a00-48b2-a55b-0f0273918ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838e8317-d3a9-4f8a-9191-9d6ea210f414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72cac649-0179-49ca-b7dd-e31c90ec1b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90737fe5-8037-434f-bad3-5109b30d5268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79be8e7f-514d-4716-9ae9-799ae479697f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c9f46c9-624a-4ac3-9f95-6467fb357492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6351dbcd-66cf-445e-870b-7e7e2a8c3030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c79756-1db1-4c12-b12b-468af2fb9575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02804f5f-ffd2-4e57-bd84-82f0cb9e88c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 362b118a-a59c-4bcf-a4e9-400ecac0d6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed23832a-9ed8-4ff5-85cc-d0b8a573cc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c070b3-b45b-4f26-8e77-6e435414bf65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004a3b38-c5b3-4bba-a713-01c28f8b3232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eaaec15-1ce6-462e-afed-7e499da5050b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e498868f-b8c8-439f-9e8c-13c29d428e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad5afd5-31b0-4ec9-a599-38f2774dcef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4d3f4d-3962-4a21-8afa-2771d92cf4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f04f80-0a07-4bbb-993f-8be2df26e6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247c7d7f-141c-4a13-ab5f-4b551bbb3fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52001cd3-2a58-4cc1-9491-1915dbd67080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18a101e-d050-4656-b3c8-97230d3d6270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b71157c-69a7-4312-84d7-d1cb771f5c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e584ee0-7763-49dd-99c6-0524a4f99db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac86c8d8-f256-45d3-b8b8-53ec26cadf01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b95cc7-f9c7-46a4-8ac6-1b87d00f776a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 296c1230-c884-4649-afb7-2187de1300a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1680cad3-1047-46f1-be2d-adfd2182e1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d429a6d8-4acd-4330-aac6-69132e13fc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b75e265-b09c-4471-a8c8-d965fcfb6ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47664daf-13b8-4c57-a7dd-09e54c4bdc1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b2f5837-e060-4ae6-8a33-bc10a9b00af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de53ee30-8fc0-409c-9f7f-78cff7975ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed691a5a-6600-461b-bea9-500a490ec273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc0d01e-3822-4765-87dc-63fe51f68e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8fef641-1916-41c9-bcba-1969f59ab3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d9aee8c-ffa4-471a-a0b6-ca51d2814938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3749e97c-e640-4808-ba17-87206c9379a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104186c3-c51a-4497-ab4f-45dd6628d37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712ecfa1-7cc8-45db-a9d7-7b3437358183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a553649-d749-4aac-a611-4fe290140370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607b21c5-ec5f-40d8-a50e-d20c544d8d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b5107b-7c47-44ca-ba52-bf850804a26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cea83d-70ad-42c4-9a45-310d7dcbe95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57299bfa-475c-4934-b755-a89cbc6675b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8962ece-9bb8-44e5-bea7-d9dbf1b32c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6338fb5-c986-43a9-bd83-0d86e24b53e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4264a775-6eb5-44fb-be5c-5f7f7d76c7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0276204-bb7c-4f10-8eba-fe7ec5dfced2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128bbe8c-1c94-4d38-8371-37c085709cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595d9e34-0be0-460d-a692-8acd54398dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c04d0eb-69cf-4f67-b18d-517c50fce887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84077780-e0c9-4b67-bf89-f3b6957f4d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ba77ce-1b3d-4b59-9302-569ad850759c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88183066-4e5e-4525-a58d-b38905410285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3937c33-7985-4c8b-91a0-30f7af99ed9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79dfd372-ef41-4ca5-9913-ab08038e8bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80407382-e1e9-4ebc-8fcc-d0492676cc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e5dec39-360e-4a1b-a63d-cfd47bea9ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d024523b-f419-44cd-b47d-e8f18eb40de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c162804-6e49-46c9-9eb0-71ac5aef80c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42310c4e-fabb-4f28-b7f5-7deaa589d3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 116070be-b30a-4115-83ce-2eb09accb4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa6f585-ac2a-4f44-b2cc-931062182bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8adbcca8-c5ad-4eae-9a8f-49bdc2d18918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48091d2e-627e-48e2-b1df-0732a4055a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5401ca8-1d46-45fd-a3d6-df3661181327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2a63e6-a432-4609-be85-8f9a5182998c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 731b5407-092c-48ff-a151-54d9c9ab4435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113b8c1d-4fa8-4904-9c13-090edab6e372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb91a3b6-49cd-435b-82b6-1441cdf7a032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e4474e-8d17-41c1-ac9a-bf8c40bb5656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537f15e6-7e83-45c9-88cb-d91b1324ccaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85774c27-9d6e-4265-bdbd-edadadf198cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be96c87-7d8c-45df-950b-357d103e0d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b1f54e-a1f3-4c53-bf77-ce26b624ea69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcc67b2-071c-4031-b5cd-a7ea40682226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ce1f28-681c-463c-a62f-d17b9725d528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2de9f76-1ce3-4fa0-a973-19e4521d6505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fecd9f6-87f8-4e00-afac-5acb7bfdaa44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202c5ec6-a543-4cb0-98da-59bfacf1aab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d5d6bea-f400-4197-8d1d-974311468d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f949a05-5067-468e-9a96-4874feb7729f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78a423a-28b6-4e6b-a0da-e5177f094b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446b75e8-fd99-488d-a6d1-891c0795bbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8befcc51-fcf0-4caf-b98e-8c7060acf21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b87e08f-d78d-4a22-a4fb-8e8302768305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7198510-9a55-4af3-87c2-ec777563dd28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a977d9-1ac5-44ce-b8d0-7df016f2f283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6876e76a-b8d7-45ee-bf85-4146a581ffff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8800ee69-94fc-42ec-b174-e056438d1fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ca82ac6-ee63-4284-977a-7f6685b93fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f0b230-2886-4a9b-8f0d-af0dc2fd1778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6358f95-0bf0-4353-8e5c-257ec4aa36ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57cc0033-3ba7-469b-9250-a2217785ce5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0676ec6-23af-4507-9051-7336f410b5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a05074c-a38b-4eff-9941-e58a4a58dadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af37c380-ecc4-40f3-ba1e-372fe6e7dc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9770ab99-5046-4bdc-afb5-d47073b46848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7cec69e-dd6a-434c-a623-1287733dbaf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038994d6-28a2-46e6-828c-6bc4391fa2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac55bdee-dd0f-4a7b-b521-d9ec10b307d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97e37df-2f79-48ab-978b-073dd32abdb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326df989-3191-49b4-ac45-480228454cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a41ca3-f635-420c-b06f-85345c1009f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a616a44-cc47-4119-a3b0-86d388107a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada3d093-743a-462f-bf1a-75f1461e78a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12604f51-307f-4a2e-b21c-98de7444710b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e208269a-e784-4662-ae20-6215ff4db21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f6aa4f-e6df-4307-a2ae-7e5f8de014d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f49e9cd-f1cb-4aac-834a-0d6328c1639e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2d09bda-56b1-4b26-b298-cf8b6e899fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739ddf98-0ecc-496f-85c9-0b5b51d6f5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e26052-6ba7-4ed5-84a8-718318ea7d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6881e93d-00a1-45ba-bb22-7010ffacef7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23be06e-cb43-49be-917a-54b8d478e860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f96b2e0-5bd2-4cea-8d17-c98cc1024423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df85a80d-21e4-4600-9166-aa2f933896f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c9e10b-d145-47c8-9bff-89f72d3b3743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc49288-2093-4904-821a-e889d1f18b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 058198a7-700c-43cf-b55f-a231a16dab3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011acb83-ac1a-463f-89b9-3cc1f2733f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5bcdf1-505b-44d5-a4b6-159568e74103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3236e0e-4a40-43e9-a142-c96c222a08c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2f0ed16-a5d3-404d-a1ff-7117f4a726f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92b2d6f-4a37-48f4-8e38-f78b2e70278d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d923334-9b1c-43b4-8a56-70aae27aeb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef36ecc9-3ba5-4af0-995d-065d35786d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc5648bd-032d-45d2-96a5-6a7c94bf50e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac7d556-1957-46d9-95ea-00ec10cd2e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd2cbc3-fa4a-4506-9253-c4301517b037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6407ef87-6727-471d-bc96-fc7efb7357d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53492d57-8344-4c28-8d7b-625d44659497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a74e60-a8c6-413e-9e2a-806b0a4e38a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b28d31-5191-4ca0-a3a4-3a8ae2bdde97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce084d8c-c6a4-448e-8ef7-1769690d2254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c974ae7-e051-483e-81e7-59db6bf8d457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08264af-16ca-4e86-9111-8bd57e783489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20409ae0-0a02-445e-a28d-eb27d47b59ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2184b9db-5232-454b-a84e-84204a7cbd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7c7d7d-af9c-44ad-9271-c835fbdf9815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08693ee6-c09d-4b8a-8fd7-0a7687e4f433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbd4c36-3dad-46b6-bd79-33446a85a095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52ab652-8052-4cda-8d38-96c3df99c867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a73c0d-16a9-4174-8e9a-1db5c998b84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cad80b7-fcad-4155-b14a-1713c29fe07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e864896-0dab-4641-a469-282c8f8dffcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51fda67-1376-444a-b9a0-b105fcbfb57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d119f0b-212f-48c7-b40d-f83a4746d4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054df633-bd1b-469d-9f1e-c1c5c862dfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1be656c-f2e3-4c70-97ac-172cc6a6c04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0d6445-ae5f-48ee-9dba-66c613dcc952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb72242-a80a-4d09-8400-fe922093ec3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dab43a9-b737-455e-a00a-9c91d94b610d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce89f416-c8d2-49b5-b0a2-aca5eec74c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab273aa-eeee-4482-9898-c472af82dc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fbc713c-5cd7-4219-b17a-d008c18c6d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b075ba07-d996-43cc-9f09-a2e3b6f170a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f24147b-7053-4306-8997-598e2a59a8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a74d66-1230-400d-9211-090125de7323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab576b7b-5bdc-475b-aac7-2360e6590579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41044c0-6a02-48ef-8d59-b5e9e47fc0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f3760f-c68b-49c4-b8c4-3c6ef65d74d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc56ddcc-0019-4b77-9b31-548c461abadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd967268-f3cd-4ebb-abfe-f47184054e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95545e1f-7adb-4c1a-ab6a-368328d94a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397b183c-ab7e-4d31-89aa-daf0c0152fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f29e78e-731d-435b-9be4-3359d480f669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39982ad1-dfe4-4c1e-8dfe-733c3ef7d892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe58e09-ac77-408b-a368-e19a7fd99da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521825fe-f846-4461-b97b-8eb6cf41d227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef604d6b-f1de-43b0-9149-f119ef35709e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688e65be-cc96-41c6-bef6-064ecd9fc4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4639e16-e6ed-440e-9b07-cedcc905545b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af79c055-e32e-4dd0-9120-fca817d58063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e76c842-c72e-400f-ba55-5064302784b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe80c9eb-5d78-4d3c-83d8-c47aefe3b981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aaefc6b-ded0-4d44-a545-ebb99b7aa0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde27e2d-7e04-41c0-aca1-f4f4f2c74194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e34313d-e824-4eb2-bd79-d899464df403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4a1bdf-2257-4c64-a31d-2079c189b3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66adc2f0-3cdc-406d-a9d7-4c146b4b32af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7df3ca5-4405-443a-b1cf-b2aa8ed25368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90f7012-2b76-400c-ad4d-a08adfa11a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37cac4e6-1918-4a01-8eb7-90385d535c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6460cd3c-3d5d-4660-8dca-404f7a988c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92fac9ed-cc56-4800-9c8b-cc15f82307a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21558bd-d169-4ee5-8c5e-f7b13f2d3f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8469138-862b-48ae-88a6-dbeefb74fce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 127a5aa8-2f05-4edc-9e24-2c21b4f2be3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e552ae59-657f-4b3a-bc15-dd869177969d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194a1237-e452-4479-b850-00dd4739ee11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c485c5bb-1e53-4193-b6b0-4df7e849439c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b0c3e8-46ca-415d-9041-76dfb5a85358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9f9260-4655-4ba1-b305-4939a8e1679a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28bbe184-3ba5-4b0a-a23f-ad04e3a76015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f0b5ad-f9a3-493d-a2c3-b2c832ddadec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926fcf78-cb4f-4b94-8b95-fd240e8bf156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07da337e-882d-4962-876c-5d9978cb098a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c125a578-231c-40f9-b6c3-147311aa600b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 429a6bbb-a9af-4422-b202-afa6f7fcdafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 584569f6-cd05-4861-b497-e37a92621b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8852b25-ceba-4dd5-9bfb-a00e2ac92dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af5f31e-21b8-4e6c-b2ea-918e66d7f15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d3c388-ff9f-4c8f-b48c-7bb57275dcf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d56dfd-7407-4de8-9eff-8d492d476753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe716169-ff32-425e-a3e7-e937b89cd514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bb57e1c-1954-42db-b878-00e78796a058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf6b351-7faf-486c-9e79-4352165f90a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d23f010-6e80-4275-bd0f-ed6e61a2c938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58cd238-9457-4392-b1e1-6c9a8382b3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f319a4e-3d2c-4dc0-9706-7b4219eac223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5683df9d-3cf2-456c-b981-93fc19e09fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23c4b581-bbb1-41e8-927f-720c19f97e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912203f9-0686-4093-9e2d-78ad6c38d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1654f91-14c4-43c8-8720-70c0d53c0a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f38d80-f9d2-4c7e-8122-5942608a32db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c2390c-5635-447b-b754-ad3d43582480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92cacdb3-12f5-4ea7-9759-3f1e4e745901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eb23dc7-e407-4adc-9352-a597c081f86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ebeb42-f323-4a19-96ca-4ff8e2f9cb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dad313a-6269-471e-9671-481470e81b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a60aff2-7a63-4331-af00-592e7f7afb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf88018-602a-4030-899b-a8da8411280b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326b13f7-8ee6-4552-94b7-550b29c677e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21fe1bdb-dc11-4bd5-a5c4-cf6d441502ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82fc3d3-9212-40b8-b2c0-f8233a2656db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 999e4247-364c-40a6-b24b-6dfb61a76964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c960526-4f07-4875-b532-ad5bb9d6e2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a425d38-92c1-4065-8770-27318c71a8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980be8b3-a396-491d-83c8-61e793b96afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c812b62b-37e7-4cf9-9736-51563678a6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ec73651-8082-4c8e-87f7-3913fffea184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12fdefd1-e1b9-4711-a60a-dd2df93c5320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7115fbc4-3f14-4855-92eb-2d8200ede47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d709118-2f0f-4de3-8800-c0440313e03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476a867f-b7bd-4d4a-8446-f61279af2e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537f1736-1d10-4ac5-83f9-49e2eff42278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a3365b-dd7c-47dc-b28f-08a39dd0338c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e24019-d150-415f-a26b-64beee6794e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb171a9-9aac-4c89-82f6-42e603bc1492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a71b1a4-6848-4286-9b4a-59ef8a8f401c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d6e38f-85f9-40a6-ac13-08d159157348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3116bf-c2fd-4bc1-a869-cdc18a2edee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fcd2de0-4c2a-4c61-bf49-4853a2f8fa98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c5815b-9c33-4b3c-abcc-836361e401ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7be0ff-f4ca-4020-8c39-10423e1d0d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e71636-ba38-4120-8613-1200ace1f732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b64b56-33a5-4ef6-88c2-8cdd8e3c2292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae78c3b-ee09-4248-ae70-ad63c43ee7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b02bfc9-4449-4d91-b945-e21b9f0d8775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0875d4cf-dc6e-4b60-81da-bef5b41c1fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7589b9-c840-4541-bc39-eb52e5958d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c5e67c-cdf7-49d2-9dfb-1f91fbfe13b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb7a07e-6734-4b8f-b095-8d2a4208ca08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa936c1-1b4e-4183-96ca-da51899d1014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98beb16c-7081-49a6-b384-96b008ae121e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37eda49c-72b8-474f-9930-60bec04f5238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfecd640-fa66-4695-bd68-68b0de228c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977e3eb3-3153-482f-a588-c39d0a77be03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1968a2b3-0fe9-442d-aad7-9986b8600044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992ab3d8-112d-4208-b62c-15ae5fcbdcd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece135f5-1ead-4842-bd93-439b6e98fc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e58feaa-370d-4854-bd85-d1960366c6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdea0d3b-7f35-4db6-b1e4-bef72d0af079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e88ae790-5e83-44fe-8a24-151d18dba539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03622634-3d80-47a3-b9ed-399c5128beff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161c100b-9e67-4ab3-a57e-10d061a6a16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e4b65ba-cc30-4420-afdb-4630db76a057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75649495-cbf5-49f3-b0b9-9154aafd8497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4d43c1-3ab4-4265-a429-b7fc2abfd5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d727ffe6-4c80-47ed-a76a-5be4d9b153a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f12bad0e-6f7a-42c4-9a9f-3f2bc5f7a538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852c55fa-f38e-4afe-a2a4-c65220d845bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937c867f-9182-4734-bf2f-c6c12e8e7aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ea2376-ca0c-4cbf-a4d3-c2ebf5fe8618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f48804d-2950-4f39-9797-b7144200c33e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8233917-a3b2-4511-a754-ea7d0345bf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4e01c5-1a06-47d4-ac2e-d00246c27af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba5ad72a-00f0-4323-95cd-be1ca12fc23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7df11c88-44e9-48ff-a09d-8a105a8c7cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fbc810-3f15-4b47-b56a-3cc7cf87d69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3c80e2-3f24-4cca-84be-3bfc6caa4f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b122e0-e0de-483c-8c5d-f40bfae9d05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ae6ce5-63a3-47dd-9f2a-46fee6189adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d449b1-5317-4f07-8754-b30bef50a994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e602354-60ac-487f-bf94-a3cb742f0b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69547f00-1f6f-450a-ae5f-c20be129c976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 501f4735-db15-40f6-a8f0-6dfdfeaa964c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c292fb55-3a56-416d-b0fe-23c3f4d474b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d201796-2354-474c-b6f4-587c7e570a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f192635-3b8a-41ea-867d-83e5f404a4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e26c115-295a-41de-b93b-9f63edf79124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b187f92d-3741-4adf-b5d4-51f88ce52278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6123c76e-3846-490e-aa65-4068ee692993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7794ff2-3394-4fd7-bfc3-765fbbb9cac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dde0e31-e174-4e2f-b6d4-fc8d0c354103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7187a70b-9bfa-42a3-979c-639a6515291a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00d0e76-c03a-413e-8a06-d8f508bb7bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777e19dd-40f7-49b8-ad9e-a44939e99153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2ec27f-9a1d-4b65-96b9-6989b905907c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb05cc5-deba-420c-a8c5-421129771749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1141aabd-2dce-42f0-acb9-83f688c11469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103c8b3b-3485-4e4b-beb9-683bba5ad1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c4770e-427b-44d3-a1ec-e7d36988f6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0007c4a4-e187-493a-bd2a-8e98f481c8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab919fb-0334-4631-82f7-6381a7ea3781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cef90c-4c77-45e0-8c86-ce457bb5e033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0bffce7-741b-4cb6-94e7-cd94fa58212a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cec9b7f1-1432-4dc2-a390-959ca3069b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8d513f1-04be-4c05-b4ca-9a892a644687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce3bdfaf-e5b2-46cd-bdce-e70429f3aa77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690889c6-2957-4eef-adbf-a4c0e076ae1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f2b7c8-6c9c-4460-96e5-fd143a211c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83365ab-c040-4103-a81e-fd1665904af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e54aa6-0f0f-48c1-893e-b5a39eca776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe56d18-0acd-4b5a-ac99-a21517a14c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbd8119-074e-41df-ba1a-078e993d4a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64403233-8269-4f09-94b2-fa2ae555df2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf43d643-adf8-4da0-9043-d57775ecd45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 957d3293-6ca0-492d-a58c-b04ff5d72e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6442119-01d2-4667-937f-43233589f484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb8e66b6-1bf0-4fa7-aa63-7ec42ed0e759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5941dd-afb6-4792-b829-98502ae0feaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5068e4bc-6fe9-41df-887c-2b73d358d7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960dbb38-3fe2-4384-9592-2ae2f8078f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b55382-8fef-468a-afde-7645122140a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969748dc-0ee4-4f6c-8c7f-9ed0548d3d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e2e762-45ec-4d0a-94e4-facefcad5293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d08dc5-618b-4b43-93f8-a936f058403b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc01a298-06f5-4ac7-93bd-8bd00b1f1c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d81a77-cddc-446d-baa3-e5907101a061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25f098b-7691-4fc3-9606-dd87ab262f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0064246c-d1ed-4611-b152-27cae78907e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8db5b4b8-5847-4abc-ae65-dcc884f51292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a5a4fa-0165-4523-b06e-cfba0d257569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 076d43ec-37c0-46a3-a5f1-1379acf97250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9a8ca0-95a9-49b3-8b12-d1900b3852e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8cfe181-e380-4919-8def-47205c06b1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c73fef-405f-4b2e-91b3-4bd97e042b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ee5efb-94a6-4c71-b931-8c94638dd9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491f3f5d-dd61-44c3-b5f7-298bc10f245f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23179fb2-b2c2-4217-8bb9-e2a91ec2eee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9aa3147-7768-49c0-aa69-1acb844c6873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb59a02-4013-44cb-92da-73f145d87ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9266a28c-7690-4300-81ba-32d4e54d4f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f150fb50-a4db-4c44-8661-21e37a137571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80274312-7328-4289-a1b7-d2a47edcd4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd2f01c-1756-4c79-bc7b-50529e91b47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7d4379e-41f6-4e7a-9860-26b7ebc07950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbbf31e0-f1cc-4cc4-95aa-f9f3265d64b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd68a5f-0ed4-4a46-9a9a-79fd04b0872e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0493013-a2b0-4ceb-95e4-16590a4ea07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7069dd75-b5b4-42fb-b61e-ba749b4d06eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9cf48d7-9b77-46fe-9112-dc802a3380d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab28e931-9351-41f0-a868-6d63ebadde80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffeb5109-e131-48be-a8fb-aa10d4d4f764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ed4e907-95cd-4a43-be96-0811041b3c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5b3047-aa75-49be-b356-d55ada61c55a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(4759, 24), y=(4759,)
   Test:  X=(1190, 24), y=(1190,)

⚠️  Limiting training data: 4759 → 800 samples
⚠️  Limiting test data: 1190 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2403, R²: -0.0046

📊 Round 0 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 0 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2399, R²: -0.0002

📊 Round 0 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2401, R²: -0.0020

============================================================
🔄 Round 13 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0910 (↓), lr=0.001000
   • Epoch   2/100: train=0.0808, val=0.0906, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0803, val=0.0904 (↓), lr=0.001000
   • Epoch   4/100: train=0.0799, val=0.0903, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0796, val=0.0902, patience=2/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0783, val=0.0887 (↓), lr=0.001000
   • Epoch  21/100: train=0.0657, val=0.0834, patience=2/15, lr=0.001000
   📉 Epoch 30: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0550, val=0.0829, patience=7/15, lr=0.000500
   📉 Epoch 38: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 13 Summary - Client client_6
   Epochs: 39/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0622, RMSE=0.2493, R²=0.2140
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.1008
============================================================


============================================================
🔄 Round 14 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000250
   • Epoch   2/100: train=0.0824, val=0.0745, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0824, val=0.0747, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0823, val=0.0749, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0822, val=0.0750, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0819, val=0.0753, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 14 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0095
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0063
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0041

============================================================
🔄 Round 15 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0885 (↓), lr=0.000063
   • Epoch   2/100: train=0.0793, val=0.0885, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0791, val=0.0886, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 15 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0107
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0013
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 19 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0917 (↓), lr=0.000016
   • Epoch   2/100: train=0.0783, val=0.0917, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0782, val=0.0917, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0782, val=0.0917, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0782, val=0.0917, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0782, val=0.0917, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 19 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0107
   Val:   Loss=0.0917, RMSE=0.3027, R²=-0.0110
============================================================


============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000004
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0084
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0066
============================================================


============================================================
🔄 Round 21 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 21 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0092
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0041
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 28 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 28 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0076
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0017
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 29 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 29 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0068
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0143
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 31 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 31 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0097
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0028
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 33 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 33 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0079
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0095
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 36 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 36 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0083
   Val:   Loss=0.0893, RMSE=0.2987, R²=0.0081
============================================================


============================================================
🔄 Round 38 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 38 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0091
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0033
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 42 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 42 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0067
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0129
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 42 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 46 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 46 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0084
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0076
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 46 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 46 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 53 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 53 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0083
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0259
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 54 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 54 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0095
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0053
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 54 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 58 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 58 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0092
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0029
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 61 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 61 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0066
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0148
============================================================


============================================================
🔄 Round 62 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 62 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0075
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0169
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 64 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 64 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0079
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0020
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 70 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 70 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0088
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0062
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 70 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 73 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 73 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0059
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0007
============================================================


============================================================
🔄 Round 76 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 76 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0081
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0055
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 76 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 79 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 79 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0084
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0076
============================================================


============================================================
🔄 Round 80 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 80 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0079
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0101
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 81 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 81 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0082
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0003
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 83 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 83 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0092
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0035
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 84 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 84 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0072
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0127
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 86 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 86 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0076
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0068
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 89 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 89 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0072
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0126
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 91 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 91 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0089
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0052
============================================================


============================================================
🔄 Round 92 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 92 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0069
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0142
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 92 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 97 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 97 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0078
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0078
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 97 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 99 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 99 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0064
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0153
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 101 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 101 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0053
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0055
============================================================


============================================================
🔄 Round 102 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 102 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0084
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0073
============================================================


============================================================
🔄 Round 103 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 103 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0079
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0100
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 103 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 103 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 107 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 107 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0080
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0063
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 107 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 109 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 109 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0078
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0035
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 109 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 112 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 112 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0071
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0083
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0076
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0047
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 113 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 115 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 115 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0078
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0101
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 115 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 115 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 119 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 119 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0084
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0078
============================================================


============================================================
🔄 Round 120 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 120 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0085
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0073
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 124 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 124 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0088
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0060
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 127 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 127 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0084
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0075
============================================================


============================================================
🔄 Round 128 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 128 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0060
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0061
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 131 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 131 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0084
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0078
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 131 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 131 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 135 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 135 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0082
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0086
============================================================


============================================================
🔄 Round 136 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 136 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0063
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0133
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 136 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 143 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 143 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0100
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0020
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 144 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 144 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0087
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0028
============================================================


============================================================
🔄 Round 145 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 145 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0086
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0074
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 145 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 145 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 150 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 150 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0066
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0153
============================================================


============================================================
🔄 Round 151 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 151 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0079
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0099
============================================================


============================================================
🔄 Round 154 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 154 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0081
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0067
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 156 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 156 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0082
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0087
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 156 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 158 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 158 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0086
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0066
============================================================


============================================================
🔄 Round 159 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 159 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0080
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0075
============================================================


============================================================
🔄 Round 161 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 161 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0071
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0134
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 161 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 165 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 165 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0084
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0055
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 165 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 167 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 167 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0055
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0074
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 168 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 168 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0097
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0017
============================================================


============================================================
🔄 Round 169 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 169 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0089
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0194
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 172 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 172 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0087
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0053
============================================================


============================================================
🔄 Round 174 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 174 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0073
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0091
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 175 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 175 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0062
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0282
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 177 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 177 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0077
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0034
============================================================


============================================================
🔄 Round 179 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 179 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0088
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0052
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

📊 Round 179 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 182 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 182 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0075
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0114
============================================================


============================================================
🔄 Round 184 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 184 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0075
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0109
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0036

============================================================
🔄 Round 185 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 185 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0076
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0076
============================================================


============================================================
🔄 Round 188 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 188 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0076
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0083
============================================================


============================================================
🔄 Round 190 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 190 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0055
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0023
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 192 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 192 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0095
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0024
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 194 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 194 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0081
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0001
============================================================


============================================================
🔄 Round 197 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 197 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0077
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0108
============================================================


============================================================
🔄 Round 198 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 198 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0086
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0057
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 198 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 201 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 201 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0101
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0006
============================================================


============================================================
🔄 Round 202 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 202 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0068
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0153
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 204 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 204 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0083
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0020
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 206 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 206 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0088
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0059
============================================================


============================================================
🔄 Round 207 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 207 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0096
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0020
============================================================


============================================================
🔄 Round 208 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 208 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0090
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0028
============================================================


============================================================
🔄 Round 209 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 209 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0057
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0070
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 212 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 212 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0087
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0002
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 212 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 214 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 214 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0073
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0046
============================================================


============================================================
🔄 Round 216 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 216 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0096
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0535
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

📊 Round 216 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 222 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 222 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0070
   Val:   Loss=0.0991, RMSE=0.3148, R²=0.0122
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 228 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 228 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0083
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0001
============================================================


============================================================
🔄 Round 229 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 229 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0070
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0016
============================================================


============================================================
🔄 Round 230 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 230 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0083
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0059
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0037

============================================================
🔄 Round 234 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 234 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0055
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0204
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 234 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 234 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 234 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 241 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 241 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0090
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0039
============================================================


============================================================
🔄 Round 242 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 242 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0078
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0087
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 243 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 243 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0081
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0082
============================================================


============================================================
🔄 Round 246 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 246 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0088
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0067
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 246 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 246 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 252 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 252 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0049
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0034
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 255 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 255 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0076
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0082
============================================================


============================================================
🔄 Round 257 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 257 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0083
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0091
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 257 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 263 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 263 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0097
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0022
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 265 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 265 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0075
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0105
============================================================


============================================================
🔄 Round 266 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 266 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0092
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0054
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 267 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 267 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0074
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0060
============================================================


============================================================
🔄 Round 269 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 269 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0090
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0156
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 272 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 272 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0052
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0278
============================================================


============================================================
🔄 Round 273 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 273 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0087
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0072
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 273 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 280 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 280 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0074
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0029
============================================================


============================================================
🔄 Round 281 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 281 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0053
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0013
============================================================


============================================================
🔄 Round 282 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 282 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0096
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0063
============================================================


============================================================
🔄 Round 284 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 284 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0073
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0096
============================================================


============================================================
🔄 Round 285 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 285 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0077
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0112
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 288 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 288 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0087
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0011
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 288 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 292 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 292 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0066
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0073
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

📊 Round 292 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 295 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 295 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0081
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0067
============================================================


============================================================
🔄 Round 296 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 296 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0100
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0006
============================================================


============================================================
🔄 Round 297 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 297 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0064
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0165
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 298 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 298 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0096
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0037
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 298 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 298 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 303 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 303 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0080
   Val:   Loss=0.0677, RMSE=0.2603, R²=0.0105
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

📊 Round 303 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 303 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 303 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 303 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 311 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 311 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0083
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0046
============================================================


============================================================
🔄 Round 312 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 312 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0069
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0138
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 315 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 315 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0096
   Val:   Loss=0.0963, RMSE=0.3104, R²=0.0046
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 317 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 317 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0102
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0033
============================================================


============================================================
🔄 Round 318 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 318 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0103
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0052
============================================================


============================================================
🔄 Round 319 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 319 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0094
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0036
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 319 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

📊 Round 319 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 325 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 325 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0084
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0062
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

📊 Round 325 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 329 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 329 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0090
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0003
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 331 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 331 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0070
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0009
============================================================


============================================================
🔄 Round 333 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 333 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0079
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0065
============================================================


============================================================
🔄 Round 335 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 335 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0081
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0057
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

📊 Round 335 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 338 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 338 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0098
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0034
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 341 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 341 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0085
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0205
============================================================


============================================================
🔄 Round 342 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 342 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0105
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0115
============================================================


============================================================
🔄 Round 343 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 343 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0071
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0107
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 344 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 344 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0080
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0101
============================================================


============================================================
🔄 Round 345 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 345 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0066
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0099
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 345 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 345 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 345 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 345 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 358 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 358 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0072
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0126
============================================================


============================================================
🔄 Round 359 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 359 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0099
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0007
============================================================


============================================================
🔄 Round 360 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 360 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0083
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0076
============================================================


============================================================
🔄 Round 362 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 362 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0086
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0074
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 364 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 364 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0085
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0060
============================================================


============================================================
🔄 Round 366 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 366 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0063
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0174
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 369 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 369 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0068
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0028
============================================================


============================================================
🔄 Round 370 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 370 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0084
   Val:   Loss=0.0688, RMSE=0.2624, R²=-0.0015
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 372 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 372 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0078
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0043
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 375 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 375 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0075
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0037
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 375 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 375 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 378 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 378 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0109
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0204
============================================================


============================================================
🔄 Round 379 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 379 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0095
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0039
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 387 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 387 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0097
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0024
============================================================


============================================================
🔄 Round 388 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 388 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0070
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0140
============================================================


============================================================
🔄 Round 389 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 389 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0074
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0206
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 389 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 391 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 391 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0091
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0002
============================================================


============================================================
🔄 Round 392 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 392 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0067
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0112
============================================================


============================================================
🔄 Round 393 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 393 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0072
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0120
============================================================


============================================================
🔄 Round 394 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 394 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0089
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0060
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 394 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 397 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 397 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0051
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0218
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 400 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 400 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0088
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0254
============================================================


============================================================
🔄 Round 401 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 401 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0074
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0093
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 402 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 402 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0070
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0078
============================================================


============================================================
🔄 Round 403 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 403 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0076
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0045
============================================================


============================================================
🔄 Round 404 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 404 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0074
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0083
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0038

============================================================
🔄 Round 406 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 406 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0090
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0030
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0038

============================================================
🔄 Round 408 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 408 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0065
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0015
============================================================


============================================================
🔄 Round 411 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 411 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0089
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0031
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 415 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 415 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0091
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0014
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 417 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 417 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0086
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0078
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 417 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 417 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 425 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 425 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0103
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0006
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 425 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 425 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 425 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 430 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 430 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0082
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0094
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 430 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 433 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 433 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0082
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0099
============================================================


============================================================
🔄 Round 434 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 434 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0109
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0026
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 434 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 439 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 439 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0075
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0128
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 439 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 439 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 439 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 439 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 447 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 447 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0066
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0052
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 447 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 449 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 449 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0087
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0074
============================================================


============================================================
🔄 Round 450 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 450 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0071
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0052
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 451 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 451 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0082
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0095
============================================================


============================================================
🔄 Round 452 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 452 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0072
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0112
============================================================


============================================================
🔄 Round 453 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 453 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0068
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0135
============================================================


============================================================
🔄 Round 454 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 454 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0080
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0062
============================================================


============================================================
🔄 Round 455 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 455 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0073
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0060
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 457 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 457 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0101
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0066
============================================================


============================================================
🔄 Round 458 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 458 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0045
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0130
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 458 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 463 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 463 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0092
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0011
============================================================


============================================================
🔄 Round 464 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 464 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0069
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0126
============================================================


============================================================
🔄 Round 465 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 465 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0054
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0135
============================================================


============================================================
🔄 Round 466 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 466 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0085
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0043
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 466 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 472 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 472 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0073
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0125
============================================================


============================================================
🔄 Round 473 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 473 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0059
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0023
============================================================


============================================================
🔄 Round 474 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 474 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0062
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0155
============================================================


============================================================
🔄 Round 475 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 475 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0082
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0086
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 479 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 479 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0016
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0294
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 481 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 481 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0089
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0067
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 482 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 482 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0080
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0105
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 483 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 483 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0099
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0019
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 483 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 487 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 487 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0077
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0069
============================================================


============================================================
🔄 Round 488 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 488 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0079
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0096
============================================================


============================================================
🔄 Round 489 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 489 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0070
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0122
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 490 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 490 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0076
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0059
============================================================


============================================================
🔄 Round 491 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 491 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0080
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0073
============================================================


============================================================
🔄 Round 492 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 492 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0080
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0091
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 493 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 493 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0094
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0027
============================================================


============================================================
🔄 Round 494 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 494 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0083
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0056
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 496 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 496 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0088
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0112
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 496 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 496 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 504 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 504 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0086
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0080
============================================================


============================================================
🔄 Round 505 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 505 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0087
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0072
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 506 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 506 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0083
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0069
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 506 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 508 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 508 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0086
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0066
============================================================


============================================================
🔄 Round 509 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 509 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0077
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0114
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 509 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 514 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 514 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0062
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0083
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 521 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 521 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0067
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0056
============================================================


============================================================
🔄 Round 522 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 522 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0081
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0008
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 524 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 524 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0087
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0048
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 524 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 524 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 527 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 527 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0096
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0041
============================================================


============================================================
🔄 Round 529 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 529 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0089
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0036
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 530 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 530 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0094
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0049
============================================================


============================================================
🔄 Round 532 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 532 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0078
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0114
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 533 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 533 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0085
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0055
============================================================


============================================================
🔄 Round 534 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 534 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0098
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0000
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 534 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 534 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 534 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 540 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 540 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0070
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0050
============================================================


============================================================
🔄 Round 542 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 542 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0093
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0038
============================================================


============================================================
🔄 Round 543 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 543 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0079
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0070
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 543 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 543 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 547 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 547 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0068
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0072
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 547 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 551 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 551 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0074
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0132
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 552 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 552 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0094
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0048
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 552 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 558 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 558 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0092
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0014
============================================================


============================================================
🔄 Round 562 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 562 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0092
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0020
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 562 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 562 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 570 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 570 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0099
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0117
============================================================


============================================================
🔄 Round 572 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 572 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0093
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0053
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 572 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 576 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 576 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0080
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0103
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 576 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 578 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 578 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0081
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0094
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 580 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 580 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0086
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0076
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 583 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 583 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0077
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0091
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 586 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 586 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0093
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0051
============================================================


============================================================
🔄 Round 589 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 589 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0067
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0046
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 590 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 590 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0112
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0044
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 590 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 590 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

📊 Round 590 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0040

============================================================
🔄 Round 597 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 597 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0086
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0237
============================================================


============================================================
🔄 Round 598 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 598 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0079
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0109
============================================================


============================================================
🔄 Round 601 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 601 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0091
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0008
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 601 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 601 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 601 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

📊 Round 601 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 607 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 607 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0075
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0074
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 610 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 610 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0087
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0075
============================================================


============================================================
🔄 Round 611 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 611 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0073
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0128
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

============================================================
🔄 Round 615 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 615 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0085
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0078
============================================================


============================================================
🔄 Round 616 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 616 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0109
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0099
============================================================


============================================================
🔄 Round 617 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 617 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0084
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0083
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

============================================================
🔄 Round 619 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 619 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0094
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0004
============================================================


============================================================
🔄 Round 621 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 621 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0080
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0095
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 623 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 623 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0080
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0088
============================================================


============================================================
🔄 Round 624 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 624 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0095
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0014
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 624 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 629 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 629 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0088
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0071
============================================================


============================================================
🔄 Round 631 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 631 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0063
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0181
============================================================


============================================================
🔄 Round 632 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 632 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0074
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0102
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 635 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 635 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0066
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0109
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

📊 Round 635 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 639 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 639 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0098
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0161
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 641 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 641 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0088
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0070
============================================================


============================================================
🔄 Round 642 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 642 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0097
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0020
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

📊 Round 642 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 648 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 648 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0107
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0022
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 649 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 649 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0078
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0093
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

📊 Round 649 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

============================================================
🔄 Round 651 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 651 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0082
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0000
============================================================


============================================================
🔄 Round 652 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 652 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0091
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0036
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0039

============================================================
🔄 Round 653 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 653 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0089
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0062
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0038

============================================================
🔄 Round 654 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 654 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0097
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0040
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 655 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 655 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0067
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0153
============================================================


============================================================
🔄 Round 657 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 657 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0091
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0064
============================================================


============================================================
🔄 Round 659 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 659 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0079
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0002
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2394, R²: 0.0039

============================================================
🔄 Round 662 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 662 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0102
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0020
============================================================


============================================================
🔄 Round 663 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 663 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0077
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0113
============================================================


❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
