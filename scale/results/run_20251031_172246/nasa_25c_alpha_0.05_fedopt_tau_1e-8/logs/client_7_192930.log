[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06afbb8f-4fbc-4c37-8e61-31d34391c249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8cb2a60-3de0-4060-a621-a52517132b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1857211c-a888-42cb-80b2-41c77ef96788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54c6caf-b411-4a5e-b6e1-d0e2d5ab6f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac26203-3073-4a04-83c4-dec3b5b6399a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e6fd1c-5ecd-4605-93ff-99535ca22422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ee1e50-dea2-4759-ae88-e74e2cf6904f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e5c9b1-fd07-421d-912e-7f3dc0e03e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd259b0e-4600-4901-9539-3afb43f06345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac42e9cd-a2e7-4354-a896-412128358939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d369ac3-3289-4ad2-87b9-83a09c299f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e11748b-435b-413c-ad9c-5af94db5d6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd3e1c8-91da-43c3-adf7-b09b78bb9ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2632c088-e300-4479-af4f-06062206c215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f5b49a-4e49-4343-82b6-613fbbc70374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 755160bc-23be-4b3f-843e-940e1a3fc483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987685ba-799f-49ac-a523-d20a4543ff48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51743bd2-69f1-42c3-a861-7ffb87562440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9008ea8-7563-41ce-97b1-9f2aec1ea5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b54aa86-b731-4d53-a7b6-40a1539a849f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91444aba-2ea2-4bcf-a213-691025d15a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039a89bb-90ed-45ab-bd92-b28e051137b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30554026-e7de-4843-8d60-34655ddeb0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8c5933-a8c4-4bdb-872c-8257cf003838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd5c7da0-555e-4d95-bef6-87f5aacf218e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e02165a-a5bd-4ef2-8a80-2c8002d0d64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8d6515-390d-4b2a-a526-3d1fd2031663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186dbada-dfb1-4047-b301-c011d54bee39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af1ebcc-d70d-44cd-9778-c43854b7e50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e243f63-dfcd-494a-86d7-746832166008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 190386bd-d1f3-452f-9ac5-788e165e86c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27cf0c8b-b235-4257-b571-d3c696a4c102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca746c7-84d6-49cf-b0e1-387921dd5f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc5d52a-170d-4043-b126-61cc41927430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ab51e8c-05cf-4841-b251-9044aad2dbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f777e7e-3e4b-4da0-a213-41ae1cf50aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491a27f1-d992-4f84-a9c7-36d22ffeb7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce1a01a-ff80-4291-ae5e-a66a8ef14976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb9f312-4698-4cf5-ad50-09535e5601ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba95674-c5a9-4074-ac03-3a7c27539f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db11be47-5974-4b95-9d12-75da5589c1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c833ef89-65e5-47eb-b4b3-fcf17e9d9427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bbe8710-dbd1-48f6-a518-51f7062c03f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169e956e-1afb-4d13-abec-138a79dc7b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec48b3e3-beff-499c-b55d-d05ee4e09ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adacf01e-94ac-470c-a1d1-f1de371d476e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c089179e-7be6-49a0-965d-31086853f0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ca2e8c-dbbf-4e1f-bea2-a39f4a980429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df3487a2-7346-42c0-bc65-ea744a7ff0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message debdc7e5-551e-436e-b4ac-ef128ea0b2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49db0725-f348-47ff-804d-7849442e37f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3c6997-18a3-4df9-ae99-f6feb229ba93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e5e911-58a7-449a-9fd1-4cf74170131b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971af86c-6028-47eb-bb13-dfc1a3627819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21062bc4-3683-4676-aec0-7ec80525444b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9092e8e2-573b-4d9d-928f-2ededa7a12e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb72321d-c6fc-455e-ad95-15e0416f4961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5fef7c-1e81-46b4-9d18-eeeb0d652631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238bba7d-9d5e-423d-b029-85e5cba34a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af4e5c3c-f9e1-4b97-847f-b64f9ea6012f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dcde1a8-f202-4ee5-808d-e869befce071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3689681-c260-4cef-b854-fee823f4639c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a50b4ed-ed69-43db-8c87-6a665b346b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38aabecd-45f9-44f6-907e-340556f8007c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ebac11-2c09-4455-9c66-b30d24626f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170f06df-58ab-42a5-b610-1a8e5d372131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1312a34c-afb2-426d-861f-f14b0f666509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40cd90d1-74ee-4292-944d-caaa1fffd21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0887246-f59d-49b6-9962-d96173510bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5efa5a0-9cd1-490d-84ee-50365a935405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f13332-c663-44a8-b52b-33779a92ee91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3722516c-ed73-423f-bee0-4d963e85c0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa1405d2-afd3-4d28-b768-7a0c3a47ba98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac40f54-c72e-4dcf-ac01-8f3693d909b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d916af3-221b-4842-8720-1bb91c4d3c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f2c2019-9b51-4f71-9d93-0f97edd3f301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81242d17-2805-49ed-b271-fd747fedf653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99458004-7407-4e8d-9ce1-aa5b8639980e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4488ea91-8b4a-4b76-83e6-df1c2fa9fc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70e7420-4611-42e3-8a9f-818f041c683e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94275065-8c18-4080-830b-9feb633f5ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d8f065-5e54-43fb-8639-f2a4b6b4ddc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4c0a2f-02a9-45e0-8b56-1c41fa355528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b5804d7-eedf-499f-aef2-661f565ee60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41e30bd5-722d-4f5b-b993-686c47a8a981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73038e5c-b1f1-4795-812b-527ea221c941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08300b58-91e5-4175-bd3a-8fbe4bb83ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43f8fc00-6712-4b84-8cd8-ff0cd11edbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5a21c7-c936-418b-b590-2cdb48226eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03d0057-6c14-48e3-85bf-93138f12d8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4283c34-a7c3-401b-8219-749c7e3bf041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35777564-17eb-4f8b-87d6-8df6a94fba22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 776568b2-4d7f-4f44-9929-c7be8db166d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae00d83-fbc1-47e9-bcf9-f6ab61d32bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ca4967-610c-4b68-9887-7c3417d4ae87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4406f8f4-e60b-4ea7-985b-6fe6d1cbdd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31e9355-aec2-468d-b6b9-f0494c43f4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ef5afd-a73d-4703-bdf7-36c400241d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3df1b8c-1167-424f-9f24-e6a19ac7dfb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a75d6292-a97f-4cae-8d16-4452140dd754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3918bb4e-6508-49cd-92dc-62d594ee7421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82527b32-8fd9-4d45-b1bc-df6e15227036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ba3244-7a96-499f-99bb-1f5446cb92eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 295c1ab0-592d-4b12-a730-09d72fb93bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a70be179-8014-4429-bc8f-e481089f5c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d8cdfb-9035-49a3-b879-0e3edb5f3b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e05a1b6b-ef2c-4c45-9afc-9aa9d5d67716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46444513-f1e5-42d0-8e4a-5fce80a861ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57f4a03-fb12-4e55-a254-364a94ba18c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e96ef8-198c-48c8-a52e-95f90aa78ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7aaf70-a37f-48e2-81c6-59bc06d17a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f75f03-9051-450b-ba2b-467751947fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6a8f87-a5d2-46e0-aa0d-f78c01658fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3255bf91-3820-441a-b15d-6b4260d51c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4876ad-a092-446d-8fbe-b6728b136bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287ca943-12d1-42ba-845d-30c9e04686ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d4811b-c6f6-4508-af45-52f0e03a8896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa523d8-18b1-4393-9c51-23a8cd0f452b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263603bc-0964-4ca6-be04-f3886fe152c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6db3cf-1dd5-4bb0-95ee-f46d1758ec8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d514280-03e3-4e54-920f-e767692bcc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6327f4aa-2794-4be5-aba7-cedf6a2e2c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055a5855-a037-4230-b5d2-3e42f2bb57cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2af1aa-f9b0-4663-9a83-2af34397b43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 908fbbb5-060d-46cd-ab44-a214729ba97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5cf3f30-7073-4d62-97a4-ed1a789675bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3215a32-6037-4afd-a067-36d06d3aa041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235b0c52-2ab3-4c6e-a46c-ea03793aacc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce9144b-a49b-4e9c-a06a-76ceaf37fa8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab98ee2-9f8c-4629-9dfd-0b4196251f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05891cb4-dc20-4bba-a5ee-0199108e7451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87f1992-546e-4655-ac22-97744925d669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2214fd4-2f11-4077-8d56-6fe141ec37b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f47a856f-9b04-41bb-97bb-a07cd5511538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f47b4b28-4fb0-40f5-8c12-40c6a3f1f1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce74901-b13a-46c5-8e2b-ace2f2f9733b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763dc47a-96f4-40e2-90e1-a5fe1ab1bceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d3681b-474c-491f-9bea-b721626d3a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702c82d8-5724-4f46-b2f6-eceeda0327c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acaefc53-dd21-4825-8a8d-8294118a2db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff91d7a-40b1-4692-8505-260722bb0cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d95d733-ecc4-429e-9ba0-570e8aeb276e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4f0c7f-874e-47d1-85fd-714952325aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e21d6b4f-94c0-4a61-bb93-0d016c406b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72a1c9b-5c57-46d5-b111-4a92948baa5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 500ea060-2bb5-4c22-95a7-07ad35ced2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaced3e5-76f4-444c-aaa4-1096d1e336ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef88be5e-4ca7-4c93-9676-57cd09f17b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b24530-bbeb-4226-97ef-6894dc9df28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f67cd60d-6d47-42eb-90c0-6d79efa87a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30654837-639b-4f1b-9979-77630d72ea60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e78f1d-f6ce-4eb5-b38e-ccb8e0409112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025d7fb1-aeb1-4122-a773-e50aa06d926e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ccb3a35-1342-4455-8f8e-a0553b84f830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56081f94-6817-43eb-823b-87e4cda50d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3791494b-6a83-4ff3-b335-994af526176f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1acfe86-de19-406f-9ae5-e5de46a308df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1131dec0-c039-4206-9569-528f6315f44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a0b2eb-f02e-43a2-906d-1326c2bfdcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43158d72-cffd-44de-b9a5-76c66b1b0568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8daaf1-ec0c-4b19-b5ab-5ecb2ab54176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7591416c-4f54-4dad-9e2c-27cb56b9d11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f667a5-71e4-4d5b-b3be-8d8cc7503e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9ab8ad-f876-4a13-a26d-0ce8c480f154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e57f91-b593-4138-9504-3890a9bd43e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b6a0eb-80ba-4424-90f1-dc8f3d1422b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8615dfe-497c-42f2-9768-cd2f485c7f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d8fcc8-db7c-468e-a4bd-a2fd6d3a0b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e2e6a4-50f9-4b8a-a472-caaadcb328ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126894c7-ae1a-4f39-b328-37febcad429a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c433ea4-bdd6-4669-bf29-3b22458f9416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d9df24-3b83-4b8e-9749-75ae45a2173b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13af7fa5-0cad-493d-807c-a4d8a73122ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab889313-a0fe-4922-ac93-7d5876563434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759b7471-9606-479a-bb59-0f95437f7830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a205e4f-b4de-4a41-911f-41d1eb4d083c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca605ae8-2d99-4e83-8216-cd7e2bb576bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ac410d-6780-4e4d-aa3c-48d259aa4408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ae6af15-47cf-4727-a705-34fc786cc1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f980e03-8715-4e6a-81bd-16460d892975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e34e88-01a4-4dc2-8f11-307beaa880ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc58c2db-939a-4699-87f7-e1f12c86261d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3469e6c-0592-4e5c-85f9-943044b3f03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a600869-15f2-4d9d-9c26-7d2e8ce3ca1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5973527b-d7c9-4b01-afd7-9ceb4c42bce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e46d48-828c-471f-b4d6-b7b6570dfd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f8ec7e-7e88-40f1-9ac1-31d6a294d439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead6c205-72a1-4b43-bb57-b75ce623fdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aea99537-8bd0-4272-a001-bd6e6eb032fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777f0d5b-52b1-4cf0-ad61-bbf0c22152c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 842b9a33-54d0-44ff-9285-9002e59fdbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2e4356-389d-4e90-b538-efd28846980a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e96c18-3ac8-4376-ae3f-b0472690925d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10799197-a6f8-4305-9ec7-b39b7141a642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d71ab7-2dd0-420f-a71a-de2789e27222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea31c24-1257-4ce4-b8c1-c9b5f9ab275e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0faf0a30-a1cf-4360-b30a-03570d768f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f23948-6281-474a-8ceb-02486d83d1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ca4e9c-a6ec-4f2c-9c92-3e3ad268019c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2012eaf-9f43-416a-b7fa-7469f2b808af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4b8530-d3ee-4b27-b8a5-97d3e90ab461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a955dc-5afb-46ef-baa8-78827f5f60a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac9bb8e-a40e-4b8b-9b2f-bbb4868d5159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fc6e6c-d591-4dc6-897e-4e89e797d5e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be1f969-1fd3-4995-a3dc-2d8659b32547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288a68c2-c36d-4b8d-99c5-4c909420336e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2181b71-36d3-4861-be19-4f88f30f84db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd1ce46d-a057-4b1a-81c6-1bb53cdc067c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13bc5c0-1c4e-49a9-b052-215686f325a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0415a3db-991e-4feb-933c-c9d9368df73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3c7291-de7b-4387-bad3-c607a3f513c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0b6768-1e3f-4163-a59b-ab76ff5e7fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2f30df-de51-4140-b7dc-968e2cdcc452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ccc94e6-b6fb-4553-8c7f-fb8e57641c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff02cbb-2b3e-4397-9c6a-f0070a3be14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdff2ed7-1858-445d-ac2b-fcf4e68ff110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee7c171-7f74-4dec-b76a-a958763bbd35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4aabaf-078c-452a-8119-a1a267a692f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d12145-2433-4286-838c-a5242437f349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c196a678-9b5e-43b7-9ffb-d89c61f8f095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc11e350-1a42-4f0c-bb63-60f85096941c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde49602-f3fa-4b1a-9fd2-5ced40cc15e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68c2d34-4623-4ad0-9c0a-094e29d74d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79246e3a-c33d-4fe2-9349-9f3f51b2c3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb6314e6-2305-4227-a764-5f110abe9c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9373e334-f1aa-46f1-8ea1-fe4e80147eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f4dd19-6da9-4e15-99bd-01ff7751a5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02426403-1a4e-4c09-a4e7-0940fae70cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d90b56-7e92-4b78-8780-ef7009e002d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3cba0df-efa4-4e48-9764-f0f87583b903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a882ba7-740a-4e49-a281-92b35fdd58c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54162182-15dd-499f-a92d-7e52166f1ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698812a9-bfd5-480f-944e-ecf0c42421ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e41459-9c78-404e-bda7-7d0663d2dfda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55fdbd9c-c7a2-414f-8426-45c59c3191c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9cd11fb-e025-48cc-bdae-def9d03749da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46bb2cd6-30d4-4b40-8e88-2b4fce30cce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32a543b-ad5d-4e6b-9adc-0195ec8063df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b101e90-1df6-4a7e-bc2e-a614d8c7a8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7761b136-2b2c-48bd-a9aa-4ff4eb5ae433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc83a23-0eac-4ece-aa85-af839dcad8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883cc744-15ff-40cc-a5c8-ad48b7f42847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9295b958-327e-4864-8dca-b71acbe53059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0113344f-aa5e-41a1-974c-81501dc30a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 584a8f5b-aa3f-4773-a33e-f47f1634dcad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de1ab6f-84c7-46c1-bdce-47e533d07af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0185708a-3515-4bfc-a1fa-68eeee6e4ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 002a5eb9-4012-42ed-9ce5-97966d92db44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd3ac26-2f58-45ec-82ec-c50842c9bd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc0d85c-ff7a-47d4-8766-6561f5ecbded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6e32d8-4288-46b3-913f-bab329e82cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4bdaeb-5543-40f6-b883-5d3852222ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef23717-d403-4146-bccd-73fee5c712eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22fd1a13-5d61-4f07-9635-8bfa883880ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc0b4827-039c-42bd-903e-e34adbf3c51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1ef532-6610-4d2f-86b4-35658387c61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e29a62-eead-4c55-8070-71cd463061d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22ae348-de2d-4b0a-bfb5-dabac3fe184b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2092800f-6b08-4482-b8d9-f25495655b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2684be69-5d6f-431f-9126-e9f9b7d83ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cce02aa-f788-4ddc-b99b-a945c1f93a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090fd12e-2990-46fc-940c-a2349b6aaf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed465ac-50a3-41e2-bfdd-da2d2c00fe45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5ded11-3453-4f96-bf19-495933f8070f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ecb44d0-2d5f-4d65-976e-0108cbf740b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc99af7-8d7c-4756-9a2f-3a20800bf2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd93913b-c1cf-43dc-9b3f-bc3b092dddcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9596b292-014c-4ed3-aa9a-0d5694886e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b20bfee-273b-4daa-a7e8-8221c8c7d21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d863ad-25df-4af8-9224-89a82e957063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6379f2f7-43c3-4531-ac35-442afaff1636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f2a489-f01c-40f9-8a3a-c69c13b0333b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442c553c-346d-4cbe-b74c-8fd18d37e1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bd27c0-e08f-40b1-a948-750a1e8eb9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b59420e-03ca-44e1-b5a6-41fbe2439fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2667c0dc-9b6c-451f-8819-168163ffd5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d495a28-ca0e-4b53-9668-e14d76032d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb48304-7af3-4887-a59b-9ce2933b0121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8799391e-0b76-415d-acc0-b96b448b2d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19cf431-b6a0-4c55-9bdf-2a87e2758116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd94f67-a11b-4203-8a54-ff2264cdf69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b20678d-ac3c-43e8-a857-486f63eea779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d710dbd-824b-405b-ba4f-b748fe17124d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65dd92e8-3299-468d-99e0-d8c9a1580e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0568680a-f436-4d36-a660-74794154843a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d45385-329c-4266-aa05-552b05293e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81875ad-ac02-45de-b080-eceee6625e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6360db-8624-425c-abc3-9dd3ff7c1551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f671b3-be63-450c-acab-a934ba54d77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94ba090a-898b-4092-b00e-e42535df97d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6308ec37-4495-438a-a676-aabc58e1c43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6096ff67-fe62-4bf2-a161-263d5a066e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2d1d31-300e-4581-9c1f-2402bc6eefe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c2cab0-1269-4918-bc68-1297fbd14bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d49db5b-da17-4656-8470-b67c9a7c2520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf6fb4a-3009-4da6-8f05-794ec667e625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c4b61f-a1bf-4cb5-8c46-704dec5351cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8476bdf7-70ba-42aa-99b4-28cec8dd9fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d48d565-1bd7-4bb6-9fed-b7d99c9a82ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca4e279-7139-4cf2-8f5f-789230848e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6d7fd7-f5bc-4af6-a494-4f974ded01d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3289c9-929b-40bf-8840-50e76cab69af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e540864-8f34-4aaf-81e7-d08e5d979cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c247339a-4b4c-4570-8685-2bc74ea416c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c39f653-2cef-4799-baf2-a8038b6a5f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701c7696-33ae-4b8c-9230-3ccd866883f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a3b37d-7965-4804-b6df-add3ddedcb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15defaf4-ada6-4ca5-966f-540d020cc656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926c2006-5b65-400b-a502-da338db62556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0d0f4d-f506-492f-a798-20b1a2e9f697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0175cebb-2257-43bb-9f9f-a6967a5fa342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e72d13-1001-4328-aa5c-cbdf8381bda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1842563f-eeed-4fe4-bf43-69d5ea535637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 528307c1-d02b-4730-a2bc-5a13d1178091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25320515-991e-4095-b3fe-badd2761e920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f5e0a81-f82a-4273-b8a3-523c4cc75991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46104e75-f5e0-48e4-b687-2b9e251fbe32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa4119b-fbf6-4654-9bec-bef96e4d0ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626c2a8d-89e3-488d-8bc5-2c9fb996fc5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb5c126-454e-4120-9d6b-f7cfa6ce8d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 500f0a8c-d4f5-433a-8fe9-ddd006b95225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510d5f11-ef1d-4285-b796-aa92ebbfa649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b53fec0-c013-4648-a588-71a548a954db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49602f03-e75a-4d74-b5e3-d84e4646c8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b78a236-a35d-4872-a040-1a49f32adf4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1d6ff8-ad61-4079-8158-dab2e0338199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961a119f-2132-4666-bf2a-ebe0c849c8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b74c0956-9c4e-4b48-937a-ff65cd020858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d30d8f-ddad-498b-8ac3-e0982237ec07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae1143e-ba49-4bea-9e1f-352c4d645e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d012f6d9-5f1d-455b-90a2-41fc68d928fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebc75a4-bc26-435a-8acf-8794cfd9ee90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22081344-6a82-4ef0-8fa8-6204e6b806fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7aa88a6-a3aa-4a35-9b5b-aaad25baa4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4cdcb8-41ac-4bd6-9a4f-0bfca4f2990e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4bfc10-eccc-45c8-b8bc-d55e9bba5e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc04063-cf5b-40af-86c4-575c1a8928d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f21c936-6eaf-49b5-a141-9c41f4e51a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c96c6bf-abbf-445b-973f-3b4a08807e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ffb449d-e282-42db-ae32-35e918ffc318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8e5a5e-4d1b-4636-bbd4-f1b2858e827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a29b11-5cb8-451f-8e24-2b67faab1858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38510970-9de1-4ba6-9ab5-f90af2d72d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f33d63e-f676-4b36-bc90-8cfc7173a8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704dee73-5a4f-4a68-9e66-dde2e184eac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f916697-32d7-49e1-bdd9-9a0ca8dfae04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8470dc59-16cc-49d3-9368-73fa1e36158c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb93b30e-56b1-439a-bb90-96cdd691ab00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc2ac55-09ea-45c5-b9d8-f50c6c343035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410a616b-8607-4149-b906-e0724049391e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0092d056-afa6-40ab-acf9-36f6d2406a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e68e061-1f08-4f40-ad20-d950e9efca9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53956d7b-4710-4099-ba2d-2f8c50de574b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b4b9ec-1f62-4a23-aad0-c2dde54d0f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103e5ecf-2fe1-4213-8f3b-96c2bf8c6800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb71a63-a7e1-44f4-9052-d30a14d51c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2a8661-a6ac-47f0-8233-4647883d6a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e8882e-0175-4aa0-b19a-911947c5e19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55b287a-25b3-45cb-a917-5f20d250ee0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 835a6a63-f4af-481c-af44-bbd2ca7756f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc76405-5064-422a-b53f-1f355a7e488a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6d57ff-6022-4d43-90dc-2d6f43e7c619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39ea0bc-1e4c-40fb-b6a0-99ff158817f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026ead07-4e70-4f02-8d80-5aa4ad761e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e296e6a-3237-4e4d-b923-fc56d705f9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4411c6-9df4-4ce0-bb6c-d37716830caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e65125c5-f587-4273-90c8-fbf054a645f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c3af0fe-7755-4d0e-8f03-8f244ac89bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce8e047-c340-4c19-a29e-5fc4da7e5a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab92f9b-1123-4ca6-94d6-1567b0199aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3743d2ed-f2e1-4d3c-9b31-544db1d3d10d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f89201-e9c3-4763-be0f-fbaba622dd85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7434c9e-c5bf-4b52-99f9-2de71ee5ef5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f90858-eaac-427d-8a89-b39f43267303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5352031-65d7-4db4-a91f-af2751e6edb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14eb665-bb9b-49e2-946c-2d9cff66e7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dab17e3-eb74-4f41-be0a-740721c9c1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0524317-a490-4d42-b6ce-e717c566c400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ee8122-0932-49c4-aa20-47626aebfbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafe8806-7060-4bc6-b79e-14908e3e25f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9825387b-1133-4e58-822c-5e1a1f96e53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e33110-50d3-4252-9a4a-7dafc18c7145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698315f3-5369-4086-a888-50ae90984f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c038a48-356e-4fce-8240-2d6f272e6c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b37d58-d7d0-4777-8e38-62e907a4ab56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce6c620-ef9d-4c6e-b785-3e732810c545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2515f7f5-5903-4bfc-b6c2-1c297e191b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e66b009f-8721-4207-be6c-0101f19af6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f84deed0-31b8-4e19-a120-73540aa9636a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1dba110-b368-414e-b911-4debab109d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979a50fd-2235-4089-892a-0988631d2fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f6cb49-2ebc-4291-8a23-e38e18198be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f3c5cd-03d8-4149-9df9-81ec23be0472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54fc14ae-8521-41d8-988f-0fb69d823ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed3cc8a-744a-491d-a391-589923d7558f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45e6066-3bf2-48fb-91d3-6a8fe4b10d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dc198e-a1d7-4360-b768-9af38457f69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5beb6f-0340-42c0-8b1e-ba97e6afb091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989e02e3-1377-4c14-b998-4e5d8df6f5e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e54716-b973-42cb-adfe-e1247c0d0ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 381539d1-4db3-4523-a8ed-4c75e6d33bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c469f63-ffed-42ee-91a5-a388a0896614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad95371d-a703-4117-9a10-66b223f44928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7534adc-f72a-4e67-a599-f74017ba5019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2deeadd3-8513-42c1-b4b4-348387892e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd53d7ca-f785-45ff-9f79-dffcdb508673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b660b9-585e-4e6d-a5a5-920a911f0fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e60750-31d5-49b7-81bd-ffa42652cf44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1ff00d-4013-4a44-9772-9d8fa8a32467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fee462-a62e-45ef-865f-2d6150f67392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44184f6b-aa44-4477-a8dd-b0216d351eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea20405-179a-4daa-a43b-4a70947be253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51d61d0-fd84-4fee-8a0c-421be232b09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b7fbff-fea3-4416-a9a6-a89a6f435b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3a6230-ba8c-4d10-b2ba-c18093af6174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f85ea9-218b-4cad-a218-84603335a28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f055fc-b6c6-45c1-90b5-bd5ab68db462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8c6774-fb4c-4428-b8e3-ff01d8465b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d9b414-4935-44fb-9234-feb9d497dde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa58a3fe-3381-43b5-8c83-a124421f9230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d292f266-1f17-4dec-9786-ba11a2b07562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab686a5b-0f21-4565-af18-cef50772288f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5f91b2-97dc-4943-9b07-9fde5c37faff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04114bc0-9f42-4d1b-9947-ef0b0d214247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c53a1d2-254f-4709-b53f-2f339d1783cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd4117d-733e-4194-88f6-fc42f1646c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37035677-b020-46ac-bebe-5e7747eb6f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba14ee62-9494-4cc6-8c9a-c6a7e072fda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5637c0-e740-40c3-b380-6f55b9f954de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98a8667-9385-4478-8223-acd8a8f3e505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2287a52b-186e-441b-a6b0-29a0becfa99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95494a7a-7dad-433c-b140-64431544e5b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b93380e-b731-4682-a6c1-49d62cd57e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67dcd3d1-cc3d-461a-96a4-f9e8b667b896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7018b48-4afb-4467-ba3b-034d5d9df6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc4c51d-3ba2-4670-b015-377e71b101ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514fe28b-833e-4186-8a1e-bc22ceb36f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976b02ee-9721-4621-8faf-21a212975d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f40d52-1f24-4094-9ab5-3703d7b4402e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1de4b0-8471-49e6-aac1-0a6951d93f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cb19ba-80c5-41cd-9a82-3fbbae78d3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e4b467c-82c8-491f-b23a-e6dd23bcc93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1834e802-0f46-4266-9f62-349713c36cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9272ad68-47e1-47fa-937a-3c54055027c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38733854-d45e-4724-bf4c-97f66d55be14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc8bb08-94b3-4a41-899e-5c307a47f7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b998f9ab-c0d3-4444-898b-675664cfcfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79afdb39-e510-429c-b474-a8ebcb6942ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dcf702a-421f-4390-8153-998f70b0a42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6183395-8494-4be5-a224-87564f6e9871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95c1d121-4bc9-4100-9f2a-f7bace6f1acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ce5fd7-9d18-4254-b1cb-a09f61a2df1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d0095c-250e-48b7-b64f-7b23c66a2f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011af36b-1bc7-4e5b-971f-78cf67d45d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cbf7a7a-501b-4178-a1d1-2327e2f5f79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6681f3a6-76d8-4c5c-adab-6103fa145cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb61de03-8a1d-41c2-9e4d-831f1b3e2530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e365c5-5201-4ada-9963-a7df4446cc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6afff072-bd1a-438d-9b85-af52d6e3bf14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10661da9-c1ee-4c9e-9255-a2beca883f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 488573a7-cc8d-4aa3-8152-4e73a1e3c824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5f9702-4021-4030-ad06-bd66b6d1d084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed9746d0-d261-4767-9f39-662f31ba7d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c329db-3bf7-4d22-bd95-2575e9023201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dabfe78-81ce-4525-9a41-37236071ba72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a912f3-fd6a-43d3-8b9b-f144c62046cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c79064-984e-40f7-a1e3-f2984928798c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1aadb4-2534-479f-8648-3625ac3c1610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51ffe2e-179f-48e8-a964-21475ab88612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa6ffee-238b-495e-8cea-51988077feab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c177390d-fc81-400c-820f-d18903f8a1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed513540-016c-4d6a-b46f-18cacc2cd7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cff9198-9fc2-4474-8aea-2b2ff4eeda49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd6616f6-764a-4938-a365-cb3b5950d3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcf6ca45-d4f1-40e1-b7c5-0ceec5a52837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321ac7d2-df8a-47a5-aa1a-b031529b8cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f30f3f-c995-4fb7-b3dc-a3e235478647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7151b54-0673-4253-95bd-a0d6fd7d7060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29cfc762-a26f-4013-812d-e6dd7eb2f42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8d5f78-7b83-402b-97b7-9e5f6cba8506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2c6b4f-d3b5-4db0-8c2c-caa43b7f997f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942fa42c-e4d6-4d34-a61a-b8c601a5e2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e42e8b-dd2a-4e08-9874-6795c8b233ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f521e28-97c6-4dc8-b723-34e75e3e7aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ec099cb-2211-4afc-a3b3-52a7a6542fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b631aa-7e20-403b-b3b1-e2ea81cfabb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007a6854-0398-40d4-85a0-f569d5476e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74edb043-9ad8-4d57-bd1c-bbf1dd470b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b9c0ab-6e8f-4d17-a37c-4f8f258de8b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709e0a6d-741a-4912-ac36-1ec4d5bc5e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e610bc-67ce-4c19-a53d-6c75e280ec7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a744e8e0-6d12-401e-b4ef-47e3af3a8c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6fe435-0813-444f-910d-d5aa0640ff04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 972d9612-1473-4ce2-9962-8809b2bda337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc2699c-62fd-4b0d-8c45-4e7aeea6e73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6961cefe-3f94-4091-a60b-73ab19e69829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 190b9393-72ec-42eb-a05e-3cf88ee9619d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e515dfd-3227-47db-bc9a-85f1b88513b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674a3d16-3147-40fb-880d-8e2ad19b49fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d025cb-c1c8-4f7c-b27b-a2d234559630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac0a28e-6c22-47e8-aab5-df97ac64be82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6533133-ea74-408f-abea-846302e9d501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9192f40-9ddd-4c79-b06a-93e30146505e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcdd30a-376e-4e41-bd51-4c37f5ffd6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3af09a-e824-40c0-9ddb-bc815a028cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad3bbcbe-8478-42c2-953a-adedfe0fb4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b6e502-cf84-4c45-8e89-dc93a65b35ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084987c8-7466-4e8f-91b8-439fa6c4d975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bee7b4-5898-4b91-9c12-f8f84d8e983a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc0b588-e354-4b7f-a476-df5c2a322bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 004459b8-fbe1-4802-91f1-98bc13aa993c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message defda5fb-eaa9-426e-b1b5-46399d7571a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4641e50e-47bd-437a-bad4-7f14cd793cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d30162a-6af0-40e6-bce0-020f8336bb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f26a524-8124-4314-9413-38fb18fd737c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d350981f-5be1-428c-8e6a-e6a772e2c88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dcbe392-1539-4d75-8f60-6737d5314786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78789d40-01c1-4b3f-b192-ffaac82b63e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d720de-4a25-438c-a6a7-42cfa8b9482d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50067a61-72f5-4f5e-91d6-8c98b4aa7466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85ef895-8b4e-4833-bd2c-26348739ef21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35161bd5-ff1a-4541-8e20-df8f992c5384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2a3f3f-5dd1-40f6-99f8-f06d8f47161b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12bd365f-7896-42ea-965c-9065eb734262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18768cf7-9228-4c89-ac5b-5aafb4786591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3577c718-20e3-4638-b20a-4f5b1eec94cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2151e0d7-3f52-415f-a3bc-13870aa5590d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6cb5609-b878-40bd-8995-530b26b61817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc99142c-e269-4697-a825-990e7a6d9990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1a1ff9-a464-4f9d-9915-b066d5c27d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651ea1d9-8e8c-40a1-9c2d-08fefe8725ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0986bb64-cfa6-4941-a2c4-fad303a5cf9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 685456cb-8cc3-4169-97b3-e207076c1086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b01a682-18f7-4b83-aa0d-f763169cc09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09390fe7-d776-4cab-99bd-a9ed4aa067c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c995f1-4f3c-4281-a840-7023ec71a601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce11850c-20fd-431d-b569-c6d15bc06ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177b646b-1884-4bea-ba41-3241710aa78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4647276c-c4ec-4cb7-9e69-425a7b937b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb78db0b-a08c-4507-b2d3-b17990fa9fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4263bce-b87f-4e26-8522-0882672a711f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b723f203-a590-4aed-9c76-b003f0dec67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2dc398d-ae76-45ea-8335-1c9350352f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f327cec-02ca-40a9-9474-dfc97cd7e5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041bc72e-f580-4d48-aa6e-c1e1fbef316d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(6192, 24), y=(6192,)
   Test:  X=(1549, 24), y=(1549,)

⚠️  Limiting training data: 6192 → 800 samples
⚠️  Limiting test data: 1549 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0879 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0889, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0821, val=0.0867 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0814, val=0.0857 (↓), lr=0.001000
   • Epoch   5/100: train=0.0802, val=0.0858, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0775, val=0.0863, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 2 Summary - Client client_7
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0110
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0091
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0069

============================================================
🔄 Round 4 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000250
   • Epoch   2/100: train=0.0790, val=0.0866, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0789, val=0.0864, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0788, val=0.0864, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0787, val=0.0864, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0783, val=0.0863, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 4 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0070
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0142
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2488, R²: -0.0044

📊 Round 4 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2489, R²: -0.0051

============================================================
🔄 Round 6 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000063
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0809, val=0.0802, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 6 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0063
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0058
============================================================


============================================================
🔄 Round 8 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0852 (↓), lr=0.000063
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0795, val=0.0858, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 8 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0035
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0227
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2489, R²: -0.0053

============================================================
🔄 Round 10 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0747 (↓), lr=0.000016
   • Epoch   2/100: train=0.0823, val=0.0747, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0822, val=0.0747, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0822, val=0.0747, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0822, val=0.0746, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0822, val=0.0746, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 10 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0050
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0001
============================================================


============================================================
🔄 Round 11 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000016
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0801, val=0.0832, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 11 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0049
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0004
============================================================


============================================================
🔄 Round 12 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0728 (↓), lr=0.000004
   • Epoch   2/100: train=0.0827, val=0.0729, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0827, val=0.0729, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0827, val=0.0729, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0827, val=0.0729, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0827, val=0.0730, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 12 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0030
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0107
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 17 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 17 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0084
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0067
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 18 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 18 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0068
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0086
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 20 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 20 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0080
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0127
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 23 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 23 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0098
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0014
============================================================


============================================================
🔄 Round 24 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 24 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0062
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0151
============================================================


============================================================
🔄 Round 25 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 25 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0074
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0046
============================================================


============================================================
🔄 Round 26 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 26 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0081
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0089
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 27 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 27 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0078
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0090
============================================================


============================================================
🔄 Round 28 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 28 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0081
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0001
============================================================


============================================================
🔄 Round 30 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 30 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0067
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0032
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0081
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0006
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 39 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 39 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0078
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0044
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 39 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 39 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 44 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 44 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0089
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0052
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 45 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 45 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0105
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0015
============================================================


============================================================
🔄 Round 47 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 47 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0068
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0104
============================================================


============================================================
🔄 Round 48 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 48 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0075
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0089
============================================================


============================================================
🔄 Round 49 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 49 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0073
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0111
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 50 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 50 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0090
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0024
============================================================


============================================================
🔄 Round 51 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 51 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0068
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0145
============================================================


============================================================
🔄 Round 52 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 52 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0085
   Val:   Loss=0.0781, RMSE=0.2796, R²=0.0049
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 54 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 54 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0071
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0050
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 60 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 60 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0092
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0043
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 62 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 62 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0069
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0113
============================================================


============================================================
🔄 Round 63 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 63 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0098
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0016
============================================================


============================================================
🔄 Round 65 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 65 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0060
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0131
============================================================


============================================================
🔄 Round 66 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 66 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0085
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0070
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 66 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 68 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 68 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0099
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0109
============================================================


============================================================
🔄 Round 69 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 69 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0085
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0014
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 70 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 70 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0077
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0071
============================================================


============================================================
🔄 Round 71 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 71 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0063
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0060
============================================================


============================================================
🔄 Round 73 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 73 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0078
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0025
============================================================


============================================================
🔄 Round 74 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 74 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0085
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0073
============================================================


============================================================
🔄 Round 75 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 75 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0095
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0183
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 80 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 80 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0079
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0027
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 80 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 80 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 80 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 95 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 95 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0065
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0082
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 99 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 99 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0075
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0188
============================================================


============================================================
🔄 Round 100 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 100 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0085
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0007
============================================================


============================================================
🔄 Round 102 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 102 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0065
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0127
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 104 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 104 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0071
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0103
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 104 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 106 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 106 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0080
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0081
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 108 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 108 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0074
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0108
============================================================


============================================================
🔄 Round 109 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 109 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0091
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0067
============================================================


============================================================
🔄 Round 110 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 110 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0073
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0025
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 111 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 111 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0073
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0100
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 115 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 115 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0101
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0007
============================================================


============================================================
🔄 Round 116 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 116 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0072
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0121
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 116 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 121 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 121 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0076
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0178
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 123 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 123 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0090
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0026
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 124 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 124 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0054
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0193
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 129 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 129 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0057
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0168
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 130 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 130 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0090
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0022
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 130 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 134 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 134 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0090
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0042
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 134 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 138 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 138 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0086
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0054
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 139 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 139 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0102
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0020
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 142 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 142 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0057
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0082
============================================================


============================================================
🔄 Round 144 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 144 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0078
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0099
============================================================


============================================================
🔄 Round 145 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 145 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0076
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0052
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 146 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 146 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0095
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.0023
============================================================


============================================================
🔄 Round 149 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 149 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0079
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0064
============================================================


============================================================
🔄 Round 150 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 150 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0076
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0047
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 152 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 152 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0071
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0057
============================================================


============================================================
🔄 Round 153 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 153 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0064
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0131
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 153 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 153 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 156 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 156 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0084
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0078
============================================================


============================================================
🔄 Round 160 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 160 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0067
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0133
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 160 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 162 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 162 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0096
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0031
============================================================


============================================================
🔄 Round 164 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 164 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0062
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0159
============================================================


============================================================
🔄 Round 165 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 165 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0076
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0025
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 168 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 168 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0070
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0053
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 168 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 170 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 170 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0077
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0104
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 171 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 171 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0095
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0026
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 171 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 173 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 173 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0080
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0095
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0020

============================================================
🔄 Round 176 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 176 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0082
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0019
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 176 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 179 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 179 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0081
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0091
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 180 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 180 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0083
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0264
============================================================


============================================================
🔄 Round 181 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 181 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0071
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0124
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

============================================================
🔄 Round 183 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 183 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0070
   Val:   Loss=0.0961, RMSE=0.3099, R²=0.0112
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0019

📊 Round 183 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 183 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 187 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 187 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0081
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0018
============================================================


============================================================
🔄 Round 188 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 188 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0090
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0025
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 192 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 192 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0097
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0024
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 195 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 195 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0067
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0089
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 198 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 198 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0078
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0047
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 200 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 200 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0090
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0050
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 200 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 200 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 206 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 206 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0080
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0081
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 206 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 206 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 206 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 211 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 211 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0090
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0056
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 212 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 212 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0078
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0100
============================================================


============================================================
🔄 Round 213 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 213 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0052
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0024
============================================================


============================================================
🔄 Round 214 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 214 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0097
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0002
============================================================


============================================================
🔄 Round 215 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 215 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0072
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0128
============================================================


============================================================
🔄 Round 219 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 219 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0078
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0012
============================================================


============================================================
🔄 Round 221 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 221 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0074
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0100
============================================================


============================================================
🔄 Round 222 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 222 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0088
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0065
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 224 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 224 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0073
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0276
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 236 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 236 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0095
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0143
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 237 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 237 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0081
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0021
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 238 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 238 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0074
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0084
============================================================


============================================================
🔄 Round 241 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 241 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0096
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0004
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 241 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 248 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 248 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0095
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0014
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 248 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 250 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0640 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0640, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0640, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0640, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0640, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0640, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0640)

============================================================
📊 Round 250 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0080
   Val:   Loss=0.0640, RMSE=0.2529, R²=0.0101
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 252 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 252 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0091
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0037
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 253 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 253 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0106
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0003
============================================================


============================================================
🔄 Round 254 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 254 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0099
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0056
============================================================


============================================================
🔄 Round 255 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 255 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0073
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0055
============================================================


============================================================
🔄 Round 257 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 257 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0082
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0026
============================================================


============================================================
🔄 Round 258 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 258 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0077
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0015
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 260 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 260 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0070
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0116
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 260 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 262 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 262 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0062
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0132
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 263 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 263 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0081
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0081
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 264 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 264 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0053
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0075
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 266 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 266 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0111
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0057
============================================================


============================================================
🔄 Round 267 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 267 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0096
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0013
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 267 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 270 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 270 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0077
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0056
============================================================


============================================================
🔄 Round 271 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 271 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0083
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0054
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 272 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 272 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0096
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0002
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 275 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 275 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0078
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0103
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 275 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 275 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 275 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 275 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 280 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 280 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0086
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0012
============================================================


============================================================
🔄 Round 281 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 281 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0053
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0193
============================================================


============================================================
🔄 Round 282 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 282 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0077
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0061
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 283 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 283 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0066
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0072
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 285 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 285 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0083
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0074
============================================================


============================================================
🔄 Round 286 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 286 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0093
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0024
============================================================


============================================================
🔄 Round 288 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 288 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0074
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0085
============================================================


============================================================
🔄 Round 290 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 290 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0061
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0037
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 296 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 296 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0094
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0009
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 299 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 299 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0083
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0045
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 300 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 300 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0075
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0120
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 307 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 307 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0083
   Val:   Loss=0.0690, RMSE=0.2628, R²=0.0079
============================================================


============================================================
🔄 Round 308 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 308 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0111
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0059
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 308 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 308 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 308 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 312 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 312 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0099
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0015
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 312 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 315 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 315 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0091
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0020
============================================================


============================================================
🔄 Round 318 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 318 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0081
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0074
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 318 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 321 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 321 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0088
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0028
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 323 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 323 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0084
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0066
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 325 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 325 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0105
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0057
============================================================


============================================================
🔄 Round 326 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 326 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0088
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0071
============================================================


============================================================
🔄 Round 327 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 327 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0060
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0131
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 330 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 330 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0051
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0178
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 331 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 331 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0079
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0023
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 333 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 333 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0077
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0021
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 336 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 336 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0074
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0115
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 336 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 342 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 342 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0086
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0023
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 342 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 342 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 342 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 342 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 342 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 355 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 355 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0095
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0034
============================================================


============================================================
🔄 Round 356 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 356 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0085
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0083
============================================================


============================================================
🔄 Round 357 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 357 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0071
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0121
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 357 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 359 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 359 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0060
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0186
============================================================


============================================================
🔄 Round 360 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 360 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0083
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0071
============================================================


============================================================
🔄 Round 361 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0622 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0622, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0622, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0622, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0622, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0622, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0622)

============================================================
📊 Round 361 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0090
   Val:   Loss=0.0622, RMSE=0.2494, R²=-0.0082
============================================================


============================================================
🔄 Round 364 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 364 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0067
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0028
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 364 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 368 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 368 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0089
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0065
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 370 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 370 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0096
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0136
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 371 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 371 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0090
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0087
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 371 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

📊 Round 371 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 374 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 374 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0087
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0021
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0018

============================================================
🔄 Round 376 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 376 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0076
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0098
============================================================


============================================================
🔄 Round 378 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 378 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0089
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0014
============================================================


============================================================
🔄 Round 379 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 379 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0094
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0024
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 379 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 381 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 381 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0101
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0017
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 383 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 383 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0082
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0055
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 383 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 385 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 385 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0059
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0193
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 385 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 387 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 387 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0093
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0034
============================================================


============================================================
🔄 Round 389 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 389 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0074
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0116
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 389 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 389 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 389 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 396 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 396 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0084
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0010
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 398 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 398 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0104
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0008
============================================================


============================================================
🔄 Round 399 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 399 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0090
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0024
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 400 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 400 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0069
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0109
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 401 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 401 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0088
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0016
============================================================


============================================================
🔄 Round 403 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 403 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0090
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0061
============================================================


============================================================
🔄 Round 404 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 404 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0076
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0037
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 404 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 408 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 408 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0074
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0095
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 408 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 413 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 413 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0083
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0080
============================================================


============================================================
🔄 Round 414 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 414 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0047
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0010
============================================================


============================================================
🔄 Round 416 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 416 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0047
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0092
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 416 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 416 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 419 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 419 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0085
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0050
============================================================


============================================================
🔄 Round 420 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 420 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0098
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0028
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 421 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 421 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0104
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0006
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 425 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 425 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0090
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0041
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 429 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 429 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0093
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0049
============================================================


============================================================
🔄 Round 430 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 430 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0101
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0016
============================================================


============================================================
🔄 Round 431 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 431 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0082
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0052
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 431 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 435 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 435 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0057
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0215
============================================================


============================================================
🔄 Round 436 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 436 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0076
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0112
============================================================


============================================================
🔄 Round 437 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 437 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0105
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0007
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 442 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 442 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0085
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0008
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 444 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 444 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0089
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0039
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 446 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 446 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0102
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0012
============================================================


============================================================
🔄 Round 448 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 448 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0077
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0119
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 450 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 450 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0090
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0008
============================================================


============================================================
🔄 Round 452 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 452 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0076
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0058
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 452 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 452 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 464 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 464 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0089
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0041
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 469 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 469 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0080
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0044
============================================================


============================================================
🔄 Round 470 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 470 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0061
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0120
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 471 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 471 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0087
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0097
============================================================


============================================================
🔄 Round 472 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 472 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0093
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0052
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 472 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 474 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 474 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0071
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0130
============================================================


============================================================
🔄 Round 475 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 475 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0077
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0023
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 475 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 477 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 477 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0089
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0060
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 479 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 479 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0097
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0002
============================================================


============================================================
🔄 Round 480 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 480 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0098
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0026
============================================================


============================================================
🔄 Round 482 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 482 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0075
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0105
============================================================


============================================================
🔄 Round 487 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 487 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0093
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0004
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 487 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 487 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 492 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 492 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0068
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0004
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 494 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 494 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0075
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0116
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 495 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 495 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0059
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0199
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 497 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 497 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0082
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0085
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 498 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 498 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0092
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0015
============================================================


============================================================
🔄 Round 499 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 499 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0081
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0031
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 500 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 500 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0092
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0244
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 500 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 507 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 507 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0059
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0185
============================================================


============================================================
🔄 Round 508 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 508 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0088
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0060
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 510 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 510 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0079
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0104
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 512 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 512 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0093
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0018
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 514 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 514 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0074
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0126
============================================================


============================================================
🔄 Round 517 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 517 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0092
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0112
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 517 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 520 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 520 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0081
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0094
============================================================


============================================================
🔄 Round 522 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 522 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0071
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0145
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 527 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 527 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0096
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0027
============================================================


============================================================
🔄 Round 528 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 528 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0094
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0030
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 533 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 533 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0088
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0054
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 535 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 535 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0073
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0119
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 535 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 539 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 539 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0086
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0036
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 540 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 540 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0069
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0089
============================================================


============================================================
🔄 Round 542 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 542 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0085
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0082
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 544 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 544 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0082
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0094
============================================================


============================================================
🔄 Round 546 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 546 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0065
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0097
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 546 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 549 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 549 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0065
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0113
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 550 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 550 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0088
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0077
============================================================


============================================================
🔄 Round 553 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 553 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0106
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0076
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 555 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 555 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0093
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0054
============================================================


============================================================
🔄 Round 556 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 556 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0092
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0055
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 559 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 559 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0087
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0046
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 559 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 561 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 561 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0069
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0122
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 563 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 563 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0062
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0187
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 564 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 564 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0061
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0120
============================================================


============================================================
🔄 Round 565 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 565 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0094
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0008
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 565 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 567 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 567 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0085
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0100
============================================================


============================================================
🔄 Round 569 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 569 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0082
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0011
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 570 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 570 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0081
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0096
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 573 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 573 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0057
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0535
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 573 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 581 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 581 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0107
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0002
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 582 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 582 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0091
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0025
============================================================


============================================================
🔄 Round 583 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 583 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0064
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0177
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 584 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 584 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0070
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0092
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 584 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 584 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 588 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 588 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0082
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0093
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 590 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 590 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0107
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0044
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 594 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 594 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0081
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0105
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 594 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 596 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 596 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0090
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0070
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 596 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

📊 Round 596 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 602 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 602 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0083
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0097
============================================================


============================================================
🔄 Round 604 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 604 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0088
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0073
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0015

============================================================
🔄 Round 605 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 605 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0076
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0082
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 605 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

============================================================
🔄 Round 612 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 612 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0080
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0061
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 623 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 623 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0094
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0038
============================================================


============================================================
🔄 Round 625 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 625 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0069
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0155
============================================================


============================================================
🔄 Round 626 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 626 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0080
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0109
============================================================


============================================================
🔄 Round 627 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 627 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0076
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0120
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 628 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 628 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0081
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0092
============================================================


============================================================
🔄 Round 629 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 629 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0063
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0161
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 631 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 631 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0080
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0016
============================================================


============================================================
🔄 Round 633 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 633 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0082
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0043
============================================================


============================================================
🔄 Round 634 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 634 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0105
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0017
============================================================


============================================================
🔄 Round 635 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 635 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0066
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0127
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 635 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 635 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

📊 Round 635 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 639 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 639 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0079
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0024
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 642 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 642 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0097
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0011
============================================================


============================================================
🔄 Round 644 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 644 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0086
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0275
============================================================


============================================================
🔄 Round 645 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 645 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0081
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0015
============================================================


============================================================
🔄 Round 646 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 646 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0101
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0028
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 649 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 649 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0079
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0085
============================================================


============================================================
🔄 Round 650 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 650 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0078
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0067
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0017

============================================================
🔄 Round 653 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 653 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0085
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0088
============================================================


============================================================
🔄 Round 654 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 654 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0087
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0117
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 654 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

📊 Round 654 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2485, R²: -0.0016

❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
