[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22346a6c-38d7-4734-91a1-170eb67c95c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10c96b7-5b5a-4cc5-a124-13cb10c23d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00d8b97-9b3e-4557-8274-f0ba740a9cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02974d7a-cca4-4e98-9324-f04c2b3942ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d29ac0-3853-4b98-90de-ba9002409494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c0cc71-30bd-4c10-ae7c-e1e265707787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9934c3e1-43cb-425a-9fe0-0925c295a97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce538dc8-1e0e-413c-a7c0-64052d08dd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f9eebe-7728-40b1-8289-be2572865074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133a7272-66b9-4911-88cf-369afd9dd027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38db5b83-77d1-49c6-ae69-1c15af66102e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b8c84c-c8d0-4fab-9d7e-aeffb8baabf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c69917bc-dbaa-4461-a6a3-151b6718a5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964de912-9f1e-4375-80e0-c3e253e231c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852b9735-ab7a-42ff-86b2-fef56dfd3c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6928bc4-4e92-443c-a682-bb4a8863e182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a999e39-b8a3-4a30-8b8c-f52c1d4ac9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a105a636-f5f4-4018-b646-cb8ad0d4fb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d6564d-a562-40d4-b45b-1c85a313b331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ddcc4e-eed9-401d-a95e-7f6d54b1ccb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718760d5-057b-4684-ba91-2038469a6fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f3785a-7b59-4897-aa6f-d62a78bfe8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f027e4f-3052-468e-a6a4-c9738b50816d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42db9e54-01d7-49e8-9b14-27e2eec0fe30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01032648-726c-4cfe-8188-e9719e2e0b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc15c32-2155-44e2-9031-f7dc599a1923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb59468c-9ffc-4abd-856d-f009c3eaeef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f5474c-0493-4653-88e0-39026ade01bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1372be-4cb1-4108-89ad-e0e795e9899a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b98147af-7892-4892-8662-f17347d5fbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e648fa-9fe3-4487-8287-7027d9424c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3215f6a8-76b2-470e-ad46-274ddd721247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fdd32cf-3e34-4c48-b7d6-72d8ede9019a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac66cdc-7f4d-4601-bc30-8c355f6e7a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b2946b-3e66-44e3-89a1-7d8a304b59fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b9dc303-3d42-45f7-b0be-2f737f804c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1efc0f51-efd2-4a0b-ae6f-b314da5645d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc74cc2f-ba72-4470-b77a-8a7b437f0e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9b0c43-1f68-400a-83a1-9539d6e11c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006620d3-5a23-4897-97cc-c0a6d581a076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1311a0-8baa-4b74-b713-62701215a4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f54b76-adae-40ad-a1c5-47bf9e4615b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe622c0-22f9-4e45-b9cc-8be27eb32c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a3b18a-6b20-49c6-b2da-95b61969d27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f07881-74c5-4542-91e8-972e3611bf4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed07290-293c-4b6d-9852-4a3cd247e6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70285371-5653-4fc0-9c07-d3581a29740b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525967bb-2d73-487e-a8d1-5a4c6cd3dee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b2a2b81-b455-4b2d-b2d7-a860cd0cd506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834ff17a-53a7-4437-a739-e45a83965a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13306f4-227f-4902-ba9e-8c371fda6346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c08cced-a1b8-47c1-bcc9-e351b858cec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94e4af9-4d78-4bed-9822-96a0c991492e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8501f2f-7827-4746-b944-87aa1c0aab93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65498991-bbd1-4bee-925e-55c5256f5445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71464612-3b3b-4196-9a28-14a7e23ef3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c63901c-cf2c-45ec-b06c-15ac73bcba5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bd913f-06b2-4d03-9cd5-ffe574d728f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d313012f-e931-453c-a320-3a274e3e0eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437edd2b-c068-40b6-ba4b-ac34a72ccd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1c16fb-26e4-457c-9656-69872375ff39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fbbd2d-5aa0-429e-87b4-83ce0ec44a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a109c372-eb64-4aa2-88dd-790383126199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036554f9-d543-40a4-9c1f-0d9a0a9f5293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d6c8f4-eca5-43c5-864b-24c60cac4ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71463cc1-27b8-4ac2-bd50-068d4ad2d514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed867e72-3e91-4756-b855-75ff6fd318d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c926df-0f27-4a69-a6d9-1b5e5cd64bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6379d7d9-1583-4027-ad67-c9be20df0a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd09ed87-eb79-430d-9b41-6a8d880f2d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089ba450-e62a-4aa3-9f77-2a23793d35bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056dc5fd-9535-4280-9be9-61a157944ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff45cd7-3ce6-4364-86d8-d3b6ad3d00b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e944a9d8-7090-401e-83b5-6c97d7dc7d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc171054-8141-4d32-99b1-05e1947f82f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b810c1a6-a42e-427a-9fc7-bbaa9e26fee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb11f61-6478-45a3-aabb-d4dd74f7e128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394b4ed5-99d9-44c6-a0de-5f562fd29d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb19a93-a02c-42ee-981f-53a1f9e9d8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849b3f10-6864-4660-ad85-9cfeb067604c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361b61ec-a39d-425a-b2a9-0b488a82ff5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fea1ac5-a118-423f-af8e-a659555a190a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e8f6fce-4087-4816-9b25-0680e18500c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95753c1c-ffae-4104-9c49-cb6ed790f211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb3802b-d4ac-4fb7-a208-2eea2f5e8a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbda227-2d13-4cb5-8949-8d7b899f9832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee51a282-bd05-40ad-8296-1ab01b1b1113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c679a32-4de3-4b44-b378-4414bddc0f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9252fd2f-2e87-4855-8927-bdea531542b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32f9a14-9a5a-4acc-a75b-1a74fa38e577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274a8d65-5afd-43d6-9ac2-084211574ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05967329-b26e-455d-bbc7-58c14f6de477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b35b21e7-1917-4fde-9d87-be950145ce41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae5dde3-3875-47be-b0e0-2ba41329236e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a2ba50-60c6-4b71-a77d-d80d2d2df429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65ccd47-fdef-4c1c-9c7c-fa2432f880d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b060fc-9970-4aaa-a1e8-e5f83d01005b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c16179e6-6302-4a87-ac70-2597ed07e26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 213a8046-aad9-4e62-92fd-0fff0d13e7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46027c83-af52-4b2f-93e1-023277c1d223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e9c62e-7468-4620-8212-8831819171dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14836f1e-8cf3-416e-8d83-fd6ac526b6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3338e2c3-55e6-4fcd-9dee-1ba1c0bc3446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868d2455-7785-42d5-8795-35e15188a896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468c6cd5-7c87-4dd9-a346-d1c76a6d79ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb163bd2-3c59-4219-b4a2-bfb6f9ea82eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6c5191-a212-4d26-8b69-a25017ef8544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9aa3fa8-6da8-4eb0-bf31-6d78f7d24d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4b5fbf-2fe9-4ba4-8e16-151bb7b8ec83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5b2d11-f5fa-49c4-aa71-408967fdbb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50efc9ca-e6bb-4431-a241-40369912806b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14fe54a-1822-474e-b26f-d623814f5e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77ed7258-3b98-4280-9da5-b4344408d679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13ca9d3-e377-43d2-a063-e08e404b4520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf05998-4cd2-462b-8f95-836698c861e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766c8e27-ef46-4eaf-99b8-f478bdde12d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c05878-8685-44ba-8506-ceef09d16ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0ea91b-9e75-4688-bc9f-2ef1db106626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b811594-5931-49fb-acf9-aef6ca3150cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e318153-1d87-41ea-9269-e4c4fd2b9218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20ec6cd-f414-4925-9291-6f230f0ef40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be610aff-6302-4ea1-bb7a-6d94c9db9e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b90890ed-4631-4517-b55b-bbdc04f72c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebebc05a-5a04-4a6a-a91e-d44fe0420881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16abaa6a-d4d5-4196-b653-49a194b3b7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9c1137-2a1d-47d8-9114-c2c0b9a19a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7dd9c63-0d90-42ab-80d1-40f536ce16f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb0a963-ed0d-42d9-b416-599e3bf1d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d6cb7f-7fe5-4d64-a906-7a7b8a1f6172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a9103f-a0c0-45bb-b28a-ea7c088fc912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846bd11e-3b4a-4a42-8d46-8b4a9e1e0a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 865c8472-3bb5-4aa2-be1c-ad7ab8e185bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c67a6229-f22a-4bef-9ea6-1acc5c6b50ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74967567-0db7-4481-8d8b-5c4d457d567e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb737d8-b5e8-4f3e-a4e5-c7b08d72c37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 333334dd-1237-4ddd-9c7c-1af1719312b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f9c73e7-ab4d-418e-8c27-817826e0d6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e1f42ab-fff8-44ed-b0e2-ef6ce800a058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b130931c-5cbc-453f-bc21-3deee9f61557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07919cf2-cd41-4dc3-b7eb-7d3b0b98bc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edccf162-7800-4efb-b959-7fc6b5136514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9afff77-889e-46a8-b288-9fc5066c7ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a58e016-2675-4ab3-9154-f530abc0f764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a316f6-341c-43e2-978b-0728dceaf6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 106c5d9a-a2a7-4446-a690-ab3dcbdd4b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7aa09a3-655a-4acd-aeac-4255c1a6df86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71eaa10b-b1ff-481f-8a4a-9d8c316df107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04b41c9-800b-4458-908c-8dddb69e9c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a67185d-5da9-416d-98ea-ccc483a3fde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d371742f-1d83-4714-a380-d83f22ded2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b604a64f-d13c-4321-af1f-38b4bbef1b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f05f162a-41b4-447b-9fb9-3c56dfe7d778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b682e54-9675-4770-9f3d-701f7f8f1f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e92a8d-cb20-41b6-87fa-4ef476c464b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f33e4c-ea60-4fa4-9caa-410b18db719d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2c4928-5432-42f0-bccf-a67d9142e02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e1c399-ac03-4298-ac53-bbf0d4d50f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb0a75b5-ad61-4592-9800-cfba3207a612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b52603-27eb-4ae2-903b-cedc02ace6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd03d296-387b-4bed-8a96-b7a58188e382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db18beb-3ccb-4d13-89a6-c35b2af02aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8888095-82e2-4b90-b5be-31326513f3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14018c5-069c-4066-9cc8-a7d557fbc835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab3f6b1-9832-4882-a837-6c75b063568e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c069973-389f-4629-83c3-8b67c2e76bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1d31081-1eb4-408b-91af-c46e3c8681b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122fe419-953a-400c-a140-6120f4ab9249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9458ec27-2227-4333-bbd2-d7ce333b46fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04fcceae-9716-4bf1-a4d9-ed775bc83d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff27acf-9d29-4f59-8d8b-471d317506bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 532e163c-0db3-437a-9a49-5e67f183dcfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcce146d-f5d0-47a1-80e2-c8844da99a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2597db25-8085-4423-bbf8-eb61b0675c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ce77b6-927f-4db6-a226-3de730fce90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ed82c0-18bc-4c6b-a55d-160703f23bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114b089a-36dc-45ce-9408-b494c33e1639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b0da25-6e3e-45ad-9d7b-36de93b25956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce5d930-3160-48e6-aebc-6f3b1f24727b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be713767-186e-49d6-b2ed-bfb2c3572478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9bcfc3c-fe55-4de0-b0b7-44775cf9a52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79643ec-b676-4d89-91be-0ae346b51922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19ef9ddf-7fb0-414d-a649-7a7e4339fd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903d761b-2750-452d-9681-c29950fd79c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59169152-fec6-46ac-85f9-bacb78dffbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7be2294-e3cb-4256-95f0-ae9bcd423c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca5a0a2-74f9-44f0-9b48-be4a68a77686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9c6a5d-fd95-4f25-8414-36cc206c7313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcbb5670-dbcf-46c9-a2d7-dad5cab85eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11dce00b-2411-4d23-bd94-5668a55cae8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59fc14d4-dbdb-4aff-89ac-7e77fd91296d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f558b6-1c46-47e2-8ff9-a08f37517bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1efa6c-2bc8-4db0-9b75-e69c847eb015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a83d83-b780-4945-8c8c-611ea8370ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77dfcd34-bc7c-4e89-96e6-298899a84104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752749ee-ad08-4fe0-a02a-49fc744abba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d9bbe3e-fab7-443b-ae50-8f5dd2edc752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ea207e-a987-4a02-bac6-3759662d38d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4361c2e7-7028-49fb-b2c3-a6c5f64fd4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc81e5b-d18d-4a59-bf80-17364d07b206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d8bc8f-01d9-43eb-b1fb-14ed81e9a906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352bbc92-cb69-465c-84a9-bd66d61ddd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6846f2bc-37a3-4554-bc21-dbad4845a142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef30c07a-2df2-4dc7-a180-17736656434a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ecbaf6e-fa28-4e17-a49f-fbf0dd4aab52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4476fd00-5191-4034-8b22-622eb966fe76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a121e01-e7ad-494e-8138-594049700343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3a0500-7d02-4094-b773-cdca847a9ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5913c597-7b13-4d4e-ac9f-8335e41223bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b47199-fbd4-4ac6-913a-ef884a7e5816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13f164e-83a4-4e40-83ec-cc217d6554e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada6e556-2b45-4ad7-83f8-54ffb303438a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d06e63-1adb-4297-933d-b240d49af5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3dce679-b21c-407a-9612-2e9c7bb08d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3501e378-be2a-456c-8128-141bfc6fe410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ce236e-97f9-4d1f-808a-04bb355038e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0565ca24-f02b-47ec-9b68-f636c440ea96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 366e884d-86f7-4016-90be-9947a8fd6c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da183e21-d211-40ac-8376-847521b078f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d369b4-479c-4127-b84f-1b852649d0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4947f289-5234-4558-9e1e-fd27383939fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e100a27-9894-4e7a-9d0b-b235f9330a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5f92e1d-4727-40fc-8415-36fca4feb8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894f24d0-a569-4a1b-bb1f-9dcdd9bd608d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce2382e-c10d-475f-abdc-7979c356339c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 568672c7-f365-43ec-9338-6e20310d2e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5ba43b-3fbd-4331-aad0-a7c9dcf43c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e463f98-1d64-4392-b243-43259f0f6d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1d3549-c85e-4610-ad43-766665e49d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a14437-a725-440f-8481-17e4c2281cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84719ec-647d-48c1-86d7-03596139c26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594f9314-de59-49cd-a31e-2d4533ff038d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 635c7220-f661-47e7-8f7c-a7ec6ab038da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4b9b96-6d27-463b-84a8-af6b70fc7534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36802367-9cb4-4547-b0ee-c4b93d882cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45020aaf-9188-44cd-930d-ae15370b81e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04caddc-7cf0-48e9-a87c-9de7712f6429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9ee3ee-a9b2-4c51-b9c8-d645a803c424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b553874-769f-43bb-b18c-9116d08bef3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b64ee4-db93-4652-9de4-2195ec9fae3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7839b7-c8dc-46ac-8602-7eff96b7c4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63a941d-b157-4a87-b473-db5662aae782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ddc8ad-8d98-4e86-b2a8-83c747baf4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af7af00e-1bbe-481a-a923-53cd1e810399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650a63b9-f7a1-40f9-9a56-a52f0b0bc7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7080fab-70f5-41ba-92ee-e435e119e232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4a8e5e-9202-46f6-9ade-b5b8e726333b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c1974e-f542-408f-8909-4310fdfc75f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eea9345-ad29-4876-a972-61adfb141d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a444f9a-3db1-40b1-bc9e-d22111021899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4f5fbc-ce01-4a1e-ab25-4c87d65aa9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1df4bb-a589-4636-8b5d-d6406cd10356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aea96aa2-cc84-4453-b222-b53db144be39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52277372-01bc-4cd5-9015-e9a8aacb89ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8a6512-a0c0-4ff8-a12f-715edb4938e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee278c09-e2f1-4a1d-a36f-59f2c4a14c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171034b4-c9ea-4ccb-848e-f42bc22423a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2970f2c-9fd9-4fcb-92db-43801366512e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8dfab9d-9d70-4a1b-b4a1-55ae64e63c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda449fd-8c30-4919-b360-57d9a4f74db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d4e077-27c3-4b3e-bf47-7ac78b3835b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c99281-eb3b-4788-801a-de8a63986105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9e0d84-7b7a-496c-ba39-ca480c4d70ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7189aae5-e7aa-4391-a4fa-4e41488c684c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb12cd18-ed7c-4790-a746-bfb3fc0a953c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd76561-ef22-4d00-bd8a-c64e6d7694c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac362a70-e712-4ddb-a469-59653c310fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b32862-01b6-457c-b645-8ea35c63b4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b6436c-3052-4450-a21c-928e06edf7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e029a076-1544-4d72-a228-6e374e450236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e70b79-26e2-453b-a821-9b328076c665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42c07ec-374d-4dde-aed6-23a5ad705f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bd0838-45de-4f2e-b4c0-14f34b9709c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe676c7-eb75-4f7f-894b-387a7e7308ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0dc3c4d-964c-4f4f-bb17-a024e6fd4e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca8e021-f1ae-453a-82bb-da009f834dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8294862f-5afa-4d8b-9232-2406255d9002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae0dbcf-cdab-4ac6-8306-426ea23403db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c53aa2f-e206-454d-8510-3a64cc6d2edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aad3b12-d089-4e5e-8197-f7648519df6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2faa761c-13cc-43a4-89d6-f8095cef7305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd719e2-84ed-4525-9697-f1d978255f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfc5ce9-47c8-45d2-b784-b94c60dafd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c792a09e-acfd-4a48-aaba-d134e5feae41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 241f7175-55c9-4901-941b-f387ae240952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9d852c-e2fd-4264-a14a-1a14764c4587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc71d7e8-5fd5-463c-895c-47c5a573a073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600a4871-b731-45e1-be33-be58306b85ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4560e314-8786-4f2b-9c38-31a4468f25cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c73cac-e82f-4847-a5dd-911769e8660d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f1ca55-faa8-43e1-970f-5659ece5140f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255292b2-8320-4803-9d0b-94de7e95e02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9337a8c0-9cbb-4d3b-b273-e6a4912e5c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d14641-a38f-4e34-95f5-e53a3b6c548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 476c52b3-d381-4f3a-8cdf-1679fdb38259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cba3fa-4567-4d59-9674-954567e61565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a139ec6f-f22d-4215-9463-acbf8f366d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05073e7-2784-4216-876f-e6c10cb21373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8287c8b1-4ff2-4ff0-ad58-d75900460d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120eaba9-9458-416c-b73e-243e940f7576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0b93fc8-ba5a-4e72-95e8-e4d68208881b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42381948-bba7-4b4f-b15e-14f3e1b3422a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4cb27b-95d8-4ac9-8e4b-45bcf31f6724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddb0b63-b282-4325-8139-26ed64615931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e86d103-7db3-4151-b2e2-daa466912dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab8474af-2e33-4c14-9ae7-c0c2c8cb25f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86f2d92-b0d6-4a7d-9064-338b61f336bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2929ab46-15a7-49df-a89d-6d8d5b5d66d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79fc9379-2a17-4f57-833c-6fe100662669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf3ca3d-a83e-469c-9e2a-e3d2f2a9b643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a91735-4b51-44e7-b52a-5b55eeb103ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e1fad00-fe64-47c3-8737-553e5166984e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f98d8f-4e66-4d94-b5e9-896df9b80974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71bb9e9e-4f7c-4a2f-a522-35fad4a43bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3938ea09-e353-4ac0-8dea-8f00aa66f252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7cd19b-3d01-4dc2-8dfe-08841e2d0fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ac29bf-3189-4183-959c-24f80c959cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf14c4e6-ee38-4465-a6ed-ecf53f81a165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e89126d-40db-46fe-8701-c9e602a09459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6275c54-e1d0-410a-9971-c82f137755d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb34075-35b4-4558-a0ab-97059be55f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 362b5c52-33f0-467c-9158-2d498e3bd595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cc5de6d-89e0-467c-be2b-8feb3af3be77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15f21e4-abcd-402c-982c-11b8e41ba127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892334cc-8196-41cd-a6ca-91ed7808ed24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc30d8a-d163-4699-b1ba-97ac92684c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06615115-f318-4f2b-a54e-1e6fc206b1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6ab1b0-1976-4572-8188-c19322a99df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7ea80d-a6e4-4812-9e65-93a4f0984939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5905c90-5c89-408c-b587-7569fcb83483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1de55c1-949e-4ea4-b186-e405bf616317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f2381f-a6d6-486b-8b7c-4048640dd4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa0de1e-d37f-462d-9e78-d47b037ed0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc738239-898a-42ce-b518-df170f6ee884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6556302b-9825-45f7-9cfe-a1bebfc3fd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690d53b8-1e6d-4c90-9569-ad26633f9f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e430b41e-c935-420f-bebb-fad4b5c96856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f1c350-9704-49dd-8e97-abc141fbb07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86897f6d-92a3-4221-b334-e11287f9ef83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f220f5c7-152d-47c9-b8d1-e6f93ef50301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71940213-d6a4-47fa-a14c-8383c89f1cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4fab1f-a99b-4e1e-9dda-fe385cd0bf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86036c90-1c1d-4629-8732-71fee9d9fdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6954fa58-6845-4e41-bd14-3b2a0f51a5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3bcfff-c897-4d40-aafe-e8f22d3429fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459ddc58-309e-4f13-bd82-96c98b8abb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b755e9-d226-426f-8e26-e30ef1222d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 357f5829-9165-4b5b-a50c-81598b783b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e63488a-1814-4b2e-8fd3-0371484b5a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02071298-2769-41fd-b814-188f6d30e4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823fdd07-52bd-48bc-8ef7-c1cc6797f32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388947b6-7e01-4a72-abdd-0ee383aa7035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a3995f-2cb8-4b53-a21c-7da59a3facdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b798661-c98e-499d-9d00-e914eaf9fa99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d3cf64-9a9d-4a2c-a366-3c1ee23d346e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7041321-10e3-4328-9f91-298d9309da30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986d6bed-64c1-44ba-9a30-41ee86ddfd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb7c313-9bf3-4a6f-9dcf-213de30d4150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48758d08-6023-4426-a5ef-b2abbccf7036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08fa5730-c68c-47db-8b31-eb3bc09ad4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f639117-add1-4a80-a5ef-0cb9503f9a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7a2bb4-3186-4100-9327-121be458771c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5839df9-2256-4ffe-af56-9577923d986e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f7523d-49d2-4720-af6e-df7f8512a591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df20d81f-a233-40f4-9d41-ebef89df885a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d55a2e51-f27c-4278-80ea-f1d77d838a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ea5ceb-89ed-478d-a3ef-80f3d7382cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baadebee-856f-4ed4-93c6-b8d5c725f578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b98b065-4b62-4198-9578-77ae000ed6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efaedc03-f020-4a62-bf1b-8a047b10d094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d69dffc5-ee93-465a-8d6f-b75e66113aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34fe867e-0dcd-4a63-95a1-deb50e45ae65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c5b11f-d5c2-4289-b2ea-2e661fb04de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c7f866-eaec-4fd1-8a9e-12da96f9dd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f820ce2-0be0-41ed-80a9-79781ab44fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82fabcb-53a9-44cf-82b4-65b6e2c3e68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af507d3d-8319-413b-b976-c81ad3066fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4a89b1-f8c5-4e4b-ac70-9d31a175a348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136ded85-cc49-477a-9da4-07e780b9b072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85e3df32-0e7c-4223-aa9b-1cbfc28e339a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad45fdc-adc5-419f-b307-c8fc0bc74de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac83334-824d-4c7a-9cc3-f250b49358c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71aa2d68-673a-4678-b9dd-abe25a728355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881e5c68-0f4e-4bee-a760-b1c6617f7e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfdab0da-a58f-4577-beeb-d648bf4a9cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8da869a-6a52-4a02-84d4-fcb588be954a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca1ee46-1218-455e-b448-0850c747dceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8bc29e4-3afa-4130-ae9d-295488fe6ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6512719-9cee-48e7-bca0-df3b695d734e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3ec640-8545-4101-830c-74b12ee15464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb574722-c86f-417c-86b2-0748802bbe57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8068a6f9-fae2-49ef-b7c2-9a11a4456672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eead85e6-14f7-40b2-9b7b-f549ce715286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fa3cc6-ab1d-4c26-9f8c-75fb93c29d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c39a301-e93d-4376-9950-c004b80c570a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c64c9f-6f51-46b7-90ae-344f6e3373da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19cb24c-7456-4608-b2d5-415d7ce50fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14f0019e-4e30-49bd-b544-a0089ede6897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0a7ea7-6226-4282-9e64-a1e00e7c1270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 673dee16-f0b7-4631-be82-1a67ef246221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067a5d23-d32a-434d-95fb-acc76373f8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb066028-bd13-44d6-b190-0eaf49eacb5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9948716f-164a-46b5-8f2b-812f928978eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 471a4b3c-49b4-433e-972a-941de71a0232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1364b0e8-00e6-4598-bdfe-e1832133f7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a8fb8c-c557-4ae6-b3c8-99322ebb5ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f96826c-1cb1-4c89-91f2-5aba4379964e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152734cd-6b34-4c32-907d-87e0c5948a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f20cbb6-c293-4dc1-9742-c303eb6139e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a3554e-b10c-44fd-a948-172d3edd4eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9115ec-235d-41a6-84ea-646101220631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb478595-3f52-43d7-9f36-2d9e340abe92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6074ad14-e752-41dc-a2cc-df67e74ccc93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a01bde-d7f6-468e-94f6-5510a6324b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e774de-c902-49bc-93fa-2cc73879a3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23172bd6-4c2e-49bf-982f-6fc668877340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bbe42f-5e96-4d0e-bed5-1e42c794c48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc032b41-17d9-4931-a5de-13994d1bc41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d228bf2a-053e-42c2-ab74-9c233c3a03f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ae4e9a-9e77-43e4-8e76-64f82e1dd0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3c25f1-9af5-4fd5-8cd9-a4cb16c283c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 719fa45a-de9d-4cfe-a68d-dc33db00b016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f15d9e09-eb74-4a16-b9c5-858b97d64ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc85e4b7-233e-4b8b-b187-bfe27afca776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49763f38-4d11-4f1a-a091-7504204498e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2ec98a-0a1d-4f2a-a018-a51034b73c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf00022-caa3-42ec-8a9d-08dfcb21cd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aeb8ff7-41d1-48dd-8371-f7a549978bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876b80c9-2ccf-47f4-b1fe-248b8850b779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd29cf9-d164-4cab-9766-fbe311efa506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec65d229-e775-4f7e-9a42-6b9eca7ea351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9ff73d-0bd3-4ed4-ade9-c2d0ab42d512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d551d02a-e5af-4ed8-9ea7-197186a34807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e08755-2d01-4cb5-aadf-9c9f190c488b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ec0371-3d74-40fd-8375-7c39906a3f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40933d6a-96c7-4c61-add0-9a11ed058223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4df38a-e3be-4e07-8cc5-f4325d3578a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9653077-1b90-47da-b8d4-c9d4a9cee276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1d5da3-0bab-428d-9f9a-d0ae8df20262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ea8818-0ce3-422d-8984-ecf6e4177c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df2b3d7e-2819-40b2-a765-b25e26489faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51acf680-ca58-48d8-96f2-3627ae1cd1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e028a19b-2727-4afc-bd15-ce037d36473f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ceea70-2f2f-4876-a805-b380d880e6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec23704-28a5-4d53-9099-012fccdbccac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f61b51-5190-40f5-8d24-b44f4da9f5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218800dd-43b5-43ec-b7b7-83282b5c69d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ecc8f1-2991-4c2a-b3b1-abac243afe0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe2d673-8cd1-4250-a94a-7180757e256c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a670c5e-d942-4f47-be87-d78612dd2382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff701b0-e1a5-4a13-85da-aa32f776d5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0654df-cd23-496d-9f44-01d5ddf581bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef8fe6e-ccc2-4ba0-8556-e8a01b8684e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853e1344-e964-4137-bc13-98f69c804ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf71905-5bbf-4275-83ed-683125da762a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9b5b78-828b-4513-9f0e-d346348dd2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d54851ad-9754-4fda-8a0b-a9743ed6ac7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b118910-28cf-4db0-a988-a5e31ccbebdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88db1a87-2bc9-43bc-a144-b929b3396e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e8c2eb-8af1-496e-8de7-b3e66959ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1d43ca-ce5c-4de6-85a6-4c5e44e94885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216df240-7dba-4fde-b6d3-9bc596d6ae19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fbd8af-e127-4e49-ad8f-df3849f21c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ca96ca-166f-4513-af66-27162e01f563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75bffd26-e75b-4db9-a830-80852ffb1830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 142e2607-5fab-404e-9816-a9ec0d06abb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb5cbe0-61fa-4cd5-8d0c-1df251c6fd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15063aa7-4961-4b03-874f-7d95577b30a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 418400a0-7263-4a53-82f7-955bcd5a78d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e45dd8-f836-48aa-ab0a-17e7c03e5585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b517405-bc35-4227-ac40-56111a4605c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a646a0cc-da6f-4643-b7fc-d67fe8e4a046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2731eb8-4bb0-465f-a581-cbf9746dfa72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8d83a5-a26c-407e-ac80-4a0acc0297ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d97943e-501b-41ef-ba2a-f49f909f91bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb7161e-ec3d-4fdf-a4a9-aaf0bad32d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19325694-5134-41a7-985a-0050b4b9c461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de3dc784-21c4-4dc8-9a4e-aa4bef19ca6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8399c2e6-0411-4ff1-85f9-8a9dad2ceb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4e4f88-2d44-4e46-89dc-c44249001d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96becf34-b882-4ba4-88b2-7a87bd6add94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 956f709f-3bc2-454c-b3c1-68ec0d9301bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4751c226-020b-48b9-8f12-2320e67f4570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80ec751-3a4a-4e89-8b55-ddfcac665475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53d1bd5b-bbc7-41cd-bd48-d51bc6e9e7bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5991753-f978-4f60-a4ce-c866014f8bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e0f96e9-34ba-4f28-a9e6-a975e23f8fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce92019-fb02-4f98-964d-4434ea07824c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92735493-aaed-4d34-a10f-b65646e822a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28a69868-760d-4540-b446-529e8f5ab074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e49e208-5ed3-4362-a4b2-1d9b949cd557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b3c05a-2382-43f0-9062-195cf24e10a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3180e69-e131-46f6-aed0-3be1f22dd2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a0edee-646d-4c96-af9d-235778696810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f6647b-0cc5-447f-b321-769d178eaae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76499e8d-d6d5-4856-8648-deef4bfb41c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34acecf-4ad5-4c64-a53f-72acefbe77a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b76e7c-41a2-4e77-bcba-54b681e85982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e514441-5f39-4e40-bb87-9226bbae8003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ead523-8625-42c5-b563-4136199a2053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432ea447-c03e-4e7f-bb16-92d90b14948d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c96d6e-d9a9-4661-8694-4b88c0086207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f672c1de-bc5e-4d88-8378-d20a83ea7f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1148386c-1cf1-4fdc-8fcf-f757a080c0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f3b0a5-11a6-4327-8fa7-5f74f2db1c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf2c528-72b4-449a-bd32-9ef86c8ce970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7fe6243-252c-4c8d-972d-a6981de67e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7b6da6-0508-4b8a-b14b-5fc6f6088be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa239b8-4cfa-4c0d-9238-3c065480b3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c7a066-9cc6-4083-83fd-efaff5e687c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f645d44-c652-42ba-983e-e90910e26286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46197a81-86d5-4e07-a51d-8ebe06f5eb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3806bef2-4f29-4aa0-aa34-9acb06250f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d083f783-e13a-4fa0-97fd-772da92fa945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09f2bae-1f3d-4113-8cc2-dce8666b8234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980e8898-7e6f-466a-b49a-4c8cd83cb99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 398da1c5-3193-4730-9857-b39948379fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27eeeecc-8d66-4d5a-9f68-2d30d3ed304b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ec5aba-a528-45df-8c08-1d79658e853c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53095cac-cec3-4f07-b6fd-1b0fa1704f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee43e20-99a8-433e-a9ab-f52edb136f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4dc4621-16bb-4fa4-8e5c-3ab364bc718f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0751aa85-1287-4248-861e-b39432a7830a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19824d43-b7c6-4de5-9ea3-e04bd3ccc332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0251cbb-3a1c-4c0d-b9f4-e6f3c033516a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f34d02c-a197-4ad3-8964-07080f784c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24fc5f3d-da5c-461d-82da-42dab7d7f6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafa96f6-aa4f-487b-998a-dcff66d8c44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65527109-ed38-4378-b158-d28a72d19ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb2c0f0e-e9e1-4aaa-9024-65bf86d6b5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c682c2-8af0-4c5a-b54f-a17e195adae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cec6e53d-788a-4d09-a749-4b1347259da1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(5265, 24), y=(5265,)
   Test:  X=(1317, 24), y=(1317,)

⚠️  Limiting training data: 5265 → 800 samples
⚠️  Limiting test data: 1317 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2505, R²: 0.0012

📊 Round 0 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2509, R²: 0.0003

============================================================
🔄 Round 6 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0824, val=0.0843 (↓), lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0846, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0826, val=0.0853, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0856, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0888, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 6 Summary - Client client_8
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0237
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0069
============================================================


============================================================
🔄 Round 7 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0805 (↓), lr=0.000250
   • Epoch   2/100: train=0.0835, val=0.0808, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0810, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0832, val=0.0812, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0831, val=0.0814, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0827, val=0.0818, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 7 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0018
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0061
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2510, R²: -0.0001

📊 Round 7 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2509, R²: 0.0003

📊 Round 7 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2509, R²: 0.0003

============================================================
🔄 Round 13 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0914 (↓), lr=0.000063
   • Epoch   2/100: train=0.0810, val=0.0914, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0809, val=0.0914, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0809, val=0.0913, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0809, val=0.0913, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0808, val=0.0913, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 13 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0007
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0054
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2512, R²: -0.0007

============================================================
🔄 Round 17 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0798 (↓), lr=0.000016
   • Epoch   2/100: train=0.0838, val=0.0798, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0838, val=0.0798, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0838, val=0.0798, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0837, val=0.0798, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 17 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0003
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0033
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 17 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 27 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0976 (↓), lr=0.000016
   • Epoch   2/100: train=0.0793, val=0.0976, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0793, val=0.0976, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0793, val=0.0976, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0793, val=0.0976, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0793, val=0.0976, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 27 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0006
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0123
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 28 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0764 (↓), lr=0.000004
   • Epoch   2/100: train=0.0846, val=0.0764, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0846, val=0.0763, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0846, val=0.0763, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0845, val=0.0763, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0845, val=0.0763, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 28 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0001
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0056
============================================================


============================================================
🔄 Round 29 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0836 (↓), lr=0.000004
   • Epoch   2/100: train=0.0829, val=0.0836, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0829, val=0.0836, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 29 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0104
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 31 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 31 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0155
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 31 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 33 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 33 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0016
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0058
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 35 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 35 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0107
============================================================


============================================================
🔄 Round 38 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 38 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0012
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0000
============================================================


============================================================
🔄 Round 39 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 39 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0001
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0051
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 45 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 45 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0019
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0151
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 47 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 47 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0009
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0462
============================================================


============================================================
🔄 Round 48 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 48 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0013
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0006
============================================================


============================================================
🔄 Round 49 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 49 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0038
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 49 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 51 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 51 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0025
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0011
============================================================


============================================================
🔄 Round 52 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 52 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0031
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0081
============================================================


============================================================
🔄 Round 53 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 53 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0029
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0000
============================================================


============================================================
🔄 Round 58 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 58 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0034
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0188
============================================================


============================================================
🔄 Round 59 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 59 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0006
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0084
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 63 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 63 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0025
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0118
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 66 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 66 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0013
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0124
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 67 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 67 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0004
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0063
============================================================


============================================================
🔄 Round 68 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 68 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0012
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0095
============================================================


============================================================
🔄 Round 69 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 69 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0039
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0093
============================================================


============================================================
🔄 Round 70 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 70 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0013
   Val:   Loss=0.0674, RMSE=0.2597, R²=0.0015
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 72 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 72 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0024
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0033
============================================================


============================================================
🔄 Round 73 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 73 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0017
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0039
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 77 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 77 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0001
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0052
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 78 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 78 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0012
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0021
============================================================


============================================================
🔄 Round 79 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 79 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0021
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0034
============================================================


============================================================
🔄 Round 80 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 80 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0050
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 81 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 81 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0002
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0103
============================================================


============================================================
🔄 Round 82 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 82 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0057
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 86 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 86 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0036
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0039
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 87 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 87 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0017
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0030
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 88 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 88 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0015
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0098
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 88 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 94 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 94 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0012
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0020
============================================================


============================================================
🔄 Round 95 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 95 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0012
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0038
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 98 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 98 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0004
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0057
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 98 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 101 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 101 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0011
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0045
============================================================


============================================================
🔄 Round 104 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 104 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0008
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0099
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 105 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 105 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0009
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0015
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

============================================================
🔄 Round 106 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 106 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0013
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0024
============================================================


============================================================
🔄 Round 108 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 108 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0010
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0136
============================================================


============================================================
🔄 Round 109 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 109 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0049
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0006

📊 Round 109 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 109 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 114 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 114 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0009
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0116
============================================================


============================================================
🔄 Round 117 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 117 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0415
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 119 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 119 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0155
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 123 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 123 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0023
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0141
============================================================


============================================================
🔄 Round 124 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 124 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0010
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0086
============================================================


============================================================
🔄 Round 125 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 125 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0013
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0155
============================================================


============================================================
🔄 Round 126 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 126 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0056
============================================================


============================================================
🔄 Round 127 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 127 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0043
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0294
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 129 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 129 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0005
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0068
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 135 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 135 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0001
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0039
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 135 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 135 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 139 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 139 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0009
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0014
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 140 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 140 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0012
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0102
============================================================


============================================================
🔄 Round 141 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 141 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0030
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0057
============================================================


============================================================
🔄 Round 145 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 145 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0006
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 145 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 145 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 151 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 151 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0005
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0027
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 153 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 153 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0010
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0008
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 155 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 155 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0012
============================================================


============================================================
🔄 Round 156 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 156 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0032
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0061
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 156 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0011
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0101
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 158 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 160 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 160 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0012
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0037
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 160 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 165 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 165 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0004
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0091
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 165 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 171 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 171 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0013
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0165
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 171 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 177 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 177 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0026
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0032
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 178 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 178 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0004
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0065
============================================================


============================================================
🔄 Round 179 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 179 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0049
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 179 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 179 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 179 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 187 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 187 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0004
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0028
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 187 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 187 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 194 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 194 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0001
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0054
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 194 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 194 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 197 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 197 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0005
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0031
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 198 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 198 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0033
============================================================


============================================================
🔄 Round 199 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 199 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0007
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0323
============================================================


============================================================
🔄 Round 200 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 200 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0027
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 201 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 201 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0009
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0026
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 202 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 202 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0025
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0211
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 202 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 207 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 207 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0045
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0126
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 211 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 211 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0024
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0020
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 214 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 214 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0018
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0018
============================================================


============================================================
🔄 Round 215 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 215 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0008
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0061
============================================================


============================================================
🔄 Round 216 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 216 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0007
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0099
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 219 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 219 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=-0.0019
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0029
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 220 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 220 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0010
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0074
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 221 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 221 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0012
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0086
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 224 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 224 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0015
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0020
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 227 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 227 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0036
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 227 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 229 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 229 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0010
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0204
============================================================


============================================================
🔄 Round 230 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 230 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0011
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0021
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 231 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 231 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0020
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0060
============================================================


============================================================
🔄 Round 232 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 232 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0016
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0003
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 234 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 234 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0011
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0014
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 234 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 239 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 239 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0009
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0066
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 239 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 243 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 243 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0031
============================================================


============================================================
🔄 Round 244 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 244 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0019
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0008
============================================================


============================================================
🔄 Round 245 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 245 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0001
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0275
============================================================


============================================================
🔄 Round 251 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 251 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0009
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0016
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 251 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 251 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 255 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 255 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0019
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0014
============================================================


============================================================
🔄 Round 256 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 256 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0031
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0005
============================================================


============================================================
🔄 Round 257 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 257 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0007
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0082
============================================================


============================================================
🔄 Round 258 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 258 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0055
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 258 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 262 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 262 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0011
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0052
============================================================


============================================================
🔄 Round 265 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 265 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0001
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0072
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 268 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 268 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0006
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 268 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 271 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 271 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0010
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0018
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 271 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 274 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 274 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0020
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0006
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 276 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 276 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0004
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0072
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 276 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 280 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 280 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0018
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0009
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 281 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 281 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0007
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0079
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 281 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 285 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 285 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0032
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0185
============================================================


============================================================
🔄 Round 286 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 286 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0019
============================================================


============================================================
🔄 Round 289 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 289 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0004
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0035
============================================================


============================================================
🔄 Round 291 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 291 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0000
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0081
============================================================


============================================================
🔄 Round 292 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 292 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0015
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0023
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 293 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 293 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0018
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0026
============================================================


============================================================
🔄 Round 295 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 295 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0013
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0017
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 298 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 298 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0197
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 298 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 301 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 301 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0001
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0078
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 301 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 304 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 304 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0027
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0069
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 305 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 305 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0014
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0053
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 305 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 305 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 309 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 309 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0015
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0057
============================================================


============================================================
🔄 Round 310 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 310 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0006
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 311 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 311 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0008
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 313 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 313 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0015
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0129
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 314 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 314 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0013
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0231
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 314 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 314 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 314 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 314 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 319 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 319 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0014
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0062
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 320 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 320 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0001
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0062
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 322 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 322 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0006
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0062
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 323 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 323 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0018
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0027
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 329 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 329 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0009
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0011
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 332 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 332 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0015
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0275
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 336 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 336 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0017
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0006
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 336 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 339 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 339 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0010
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0472
============================================================


============================================================
🔄 Round 341 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 341 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0006
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0094
============================================================


============================================================
🔄 Round 342 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 342 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0005
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0170
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 343 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 343 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0000
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0077
============================================================


============================================================
🔄 Round 344 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 344 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0009
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0184
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 347 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 347 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0007
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0065
============================================================


============================================================
🔄 Round 349 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 349 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0012
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0003
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 349 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 352 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 352 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0036
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0057
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 354 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 354 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0026
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0031
============================================================


============================================================
🔄 Round 357 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 357 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0020
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0035
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 358 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 358 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0011
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0001
============================================================


============================================================
🔄 Round 359 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 359 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0006
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0073
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 367 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 367 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0042
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0010
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 369 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 369 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=-0.0011
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0004
============================================================


============================================================
🔄 Round 372 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 372 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0020
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0022
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 375 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 375 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0030
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0059
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 375 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 375 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 381 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 381 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0013
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0034
============================================================


============================================================
🔄 Round 385 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 385 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0006
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0101
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 386 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 386 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0053
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0225
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 387 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 387 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0007
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0084
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 389 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 389 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0039
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0050
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 391 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 391 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0038
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0065
============================================================


============================================================
🔄 Round 393 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 393 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0013
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0080
============================================================


============================================================
🔄 Round 394 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 394 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0009
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0047
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 394 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 394 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 397 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 397 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0010
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0050
============================================================


============================================================
🔄 Round 398 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 398 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0004
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0032
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 401 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 401 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0009
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0113
============================================================


============================================================
🔄 Round 402 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 402 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0013
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0133
============================================================


============================================================
🔄 Round 403 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 403 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0018
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0023
============================================================


============================================================
🔄 Round 404 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 404 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0018
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0030
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 406 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 406 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0018
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0150
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 407 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 407 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0010
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0299
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 408 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 408 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0025
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0037
============================================================


============================================================
🔄 Round 410 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 410 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0003
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.0094
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 410 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 410 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 410 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 410 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

📊 Round 410 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 423 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 423 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0003
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0183
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 424 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 424 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0018
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0032
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 426 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 426 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0137
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 428 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 428 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0027
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0032
============================================================


============================================================
🔄 Round 431 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 431 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0010
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0191
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0005

============================================================
🔄 Round 434 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 434 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0011
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0045
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 438 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 438 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0016
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 440 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 440 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0008
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0012
============================================================


============================================================
🔄 Round 441 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 441 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0001
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0077
============================================================


============================================================
🔄 Round 442 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 442 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0003
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0456
============================================================


============================================================
🔄 Round 443 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 443 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0023
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0001
============================================================


============================================================
🔄 Round 446 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 446 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0005
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0116
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 447 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 447 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0014
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0011
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 451 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 451 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0010
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0034
============================================================


============================================================
🔄 Round 452 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 452 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0005
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0029
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 454 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 454 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0028
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0231
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 455 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 455 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0023
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0046
============================================================


============================================================
🔄 Round 457 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 457 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0007
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0090
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 459 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 459 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0031
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0016
============================================================


============================================================
🔄 Round 461 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 461 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0001
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0043
============================================================


============================================================
🔄 Round 463 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 463 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0003
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0147
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 465 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 465 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0018
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0018
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 465 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 470 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 470 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0026
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0058
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 470 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 470 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 482 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 482 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0003
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0060
============================================================


============================================================
🔄 Round 483 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 483 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0010
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0141
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 483 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 486 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 486 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0013
   Val:   Loss=0.0813, RMSE=0.2850, R²=0.0000
============================================================


============================================================
🔄 Round 487 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 487 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0043
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0090
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 487 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 491 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 491 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0013
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0011
============================================================


============================================================
🔄 Round 492 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 492 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0032
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0070
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 493 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 493 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0007
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0133
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 495 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 495 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0018
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0027
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 495 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 500 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 500 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0004
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0063
============================================================


============================================================
🔄 Round 501 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 501 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0009
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0009
============================================================


============================================================
🔄 Round 503 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 503 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0009
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0124
============================================================


============================================================
🔄 Round 504 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 504 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0005
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0091
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 506 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 506 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0013
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0007
============================================================


============================================================
🔄 Round 507 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 507 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0025
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0052
============================================================


============================================================
🔄 Round 510 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 510 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0017
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0007
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 513 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 513 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0032
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0000
============================================================


============================================================
🔄 Round 514 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 514 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0003
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0098
============================================================


============================================================
🔄 Round 516 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 516 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0012
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0005
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 516 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 516 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 521 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 521 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0014
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0014
============================================================


============================================================
🔄 Round 522 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 522 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0031
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 523 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 523 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0017
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0007
============================================================


============================================================
🔄 Round 524 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 524 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0014
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 524 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 524 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 524 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 524 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 529 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 529 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0009
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0073
============================================================


============================================================
🔄 Round 530 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 530 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0037
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 532 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 532 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0023
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 533 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 533 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0045
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 533 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 533 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 536 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 536 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0016
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0278
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 541 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 541 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0010
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0016
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 542 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 542 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0002
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0049
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 542 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 544 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 544 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0003
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0046
============================================================


============================================================
🔄 Round 547 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 547 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0002
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0141
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 548 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 548 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0014
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0102
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 550 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 550 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0001
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0125
============================================================


============================================================
🔄 Round 551 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 551 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0010
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0020
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 552 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 552 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0001
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0093
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 554 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 554 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0002
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0034
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 556 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 556 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0004
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0026
============================================================


============================================================
🔄 Round 557 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 557 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0008
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0023
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 559 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 559 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0086
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

📊 Round 559 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 561 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 561 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0007
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 561 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 561 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 561 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 568 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 568 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0026
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0055
============================================================


============================================================
🔄 Round 570 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 570 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0012
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0129
============================================================


============================================================
🔄 Round 572 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 572 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0001
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0047
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 572 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 572 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 575 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 575 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0019
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0137
============================================================


============================================================
🔄 Round 576 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 576 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0019
============================================================


============================================================
🔄 Round 577 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 577 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0019
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0060
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 577 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 582 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 582 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0010
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0010
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 583 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 583 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0046
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0061
============================================================


============================================================
🔄 Round 584 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 584 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0018
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0050
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 586 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 586 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0041
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 587 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 587 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0004
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0355
============================================================


============================================================
🔄 Round 591 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 591 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0006
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0047
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 593 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 593 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0005
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0104
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

📊 Round 593 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 601 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 601 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0004
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0064
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0004

============================================================
🔄 Round 602 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 602 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0003
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0060
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 602 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 602 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 602 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 609 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 609 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0022
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0074
============================================================


============================================================
🔄 Round 610 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 610 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0001
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0034
============================================================


============================================================
🔄 Round 611 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 611 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0021
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0134
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 614 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 614 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0023
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0131
============================================================


============================================================
🔄 Round 615 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 615 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0023
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0051
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 616 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 616 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0008
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0076
============================================================


============================================================
🔄 Round 617 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 617 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0012
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0091
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 620 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 620 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0006
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0011
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 621 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 621 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0008
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0005
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 625 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 625 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0006
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0037
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 627 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 627 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0011
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0002
============================================================


============================================================
🔄 Round 628 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 628 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0031
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0059
============================================================


============================================================
🔄 Round 630 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 630 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0003
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0059
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 632 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 632 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0006
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0078
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 634 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 634 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0022
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0113
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 634 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 639 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 639 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0002
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0041
============================================================


============================================================
🔄 Round 642 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 642 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0012
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0001
============================================================


============================================================
🔄 Round 644 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 644 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0020
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0035
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 644 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 644 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 644 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 648 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 648 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0023
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0036
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 648 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 651 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 651 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0011
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0151
============================================================


============================================================
🔄 Round 652 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 652 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0010
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0000
============================================================


============================================================
🔄 Round 653 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 653 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0027
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0059
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 653 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 653 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 657 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 657 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0022
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0034
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

============================================================
🔄 Round 660 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 660 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0008
============================================================


============================================================
🔄 Round 661 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 661 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0019
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0002
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

📊 Round 661 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2511, R²: -0.0003

❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
