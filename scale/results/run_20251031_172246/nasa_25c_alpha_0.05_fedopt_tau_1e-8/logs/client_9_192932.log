[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1efdcb41-1f25-4968-b622-bcdfe9a12adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6914110-16a2-4b17-8b56-1c161da9106d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc6d927c-40f4-4044-9e9e-18c0deec597b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d6d92c-3317-40be-bef9-1b7472943d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00284710-0646-4440-80b4-980bd2ded1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 540b1f55-e19c-42fe-99d8-ea73a8d6d44f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f950f8d8-fa73-400d-9327-307a8942df46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942eec91-a955-4f73-9f94-626233f4d3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda32d38-d88f-4d30-bfe0-bd4ef697f695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c0cd28b-84d3-4428-a390-9cf0262c1dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130d55fb-c196-43ec-8579-db29348cd62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3549a9b-9ce7-4cf4-a057-85ea357864f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd51a90f-7d93-4d45-989c-b40d4360a035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ec709d-9fe4-47ad-ae90-5526d51d3d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fb5cf7-6899-4de5-a2e7-3e8802c4128c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf34edc7-f96c-40c4-aea9-37531b4b7fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72e9f2e-d6bf-4970-8e4a-325f49cb98e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add71306-cee2-4482-aada-39ddc1054cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bdaed47-6a47-4e04-b859-56841750b68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f6fc2db-123a-4e7a-b50a-cef35d7187dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215585fd-5572-4883-a95b-49a9cc42a54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08bfafa-25c5-4e05-a37a-bf73b84b27b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6fec94-f83b-45ef-bd0f-243c3612a895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b754b774-f5d4-4b35-9621-d8ee6a0deb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf58aee-4bcf-4682-9c06-8829990a9e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89c8169-300d-4717-a1d6-ba1286adacd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 930f44e4-ff8d-4934-80d5-b063ef1e8c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ce4669-65fb-45c0-b4dc-ea4418e2c47a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a52411b-d47f-42fd-b3d2-2356826a9f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fad86fb-890e-458e-a21c-970df9f0ba1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93001b3d-c038-4a13-8354-12c9e98a26d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aea5c75-d173-4643-b5d9-0e4a7c65aa42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7044c426-9c24-442f-baec-eb9b3acf3290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e07ad6-9d97-455a-9840-b52ca8bb856d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f12d89b-0a9b-4dcb-81aa-6f82e5468582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6b14e1-a73b-4c2f-ad50-cd5b598f783d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ce1822-2ade-4c3c-a06e-0ede6ce4ef04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e74e54-05a4-42b6-8002-7bffe4d99cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40be4aca-fab8-4ed6-91ac-64170ab299f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f54e7b-3020-4256-bf2e-373f868c0019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd193ea-0957-49d3-8349-4b54af858a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80e27bf-fa7f-48cc-aded-d9529d548b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e617e9-3e78-40a5-a441-05280ba98e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee077b5-9579-42b3-930b-1d793ef6023c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b646d8cd-64ba-44c7-b0d2-1c8939fce2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0914cc74-4ae1-4668-9b40-0f5033de65e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eefe4991-5ef0-475a-86c8-fcf6f93bf4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27020d27-f6db-4118-b2ac-24178a1f8767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc796bb6-51f7-4a02-bf05-7af73508b718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb4ba03-8642-4de0-9828-09977eb20d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a97019-234b-4733-8863-4020aaa1c95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c62f570-5924-4f0b-a083-167cdf6eead1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5b089a-2112-4bd5-bfca-9de889f8eacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b272f1-2bdd-40c1-a0e4-eaa912b8fc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5623178f-64e7-4dc0-aa7e-724446e4662d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f30854-daef-4125-a8fb-0ca34942d585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2880a4ec-dcf2-4d4d-bfa2-774e324e3753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5c11b7-d7cf-4643-bccc-3d0bb5ea8ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc500186-8d0f-4adc-a187-a9c1a9f87ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483765cd-ff86-4d85-bf30-b75ea8980d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8e71be-560e-49ba-832f-dffba1abdcf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aae0cdf-f11f-44b0-8016-fafada6c8f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6b007f-64a7-4be2-8b9f-57e4d4348dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e35fd32-7cc4-4af2-8704-7649a6272b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0a2a51-afc8-475f-b1d3-5504515f7539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c17ec5-aa54-45e1-9fc5-81570935f5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62eddd10-ac7b-4fdb-b307-06c51c6a7c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3c77f8-7cd4-4f3b-9590-d6551814ba58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c52553ac-7d3b-4d20-a38c-a4f519d0b925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4c0028-c955-4281-afa7-8b88249d41f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63969d9-194f-48c7-8cf1-d75d029cb7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c313b2-6fbd-4073-bab6-628615d09c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e644af1e-d666-4cfb-9fe3-5bd831e29895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49e6d55-14f3-4afe-9d56-fb6f2f99b7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d17c02b-1a5a-496a-8760-081af8673aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a91823bc-b290-4caf-8fc8-cd4c8db32d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d067b7c-4c70-4a73-8f90-6a35b294d0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c687343c-4219-4f64-8fa3-6e912bc5c7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4ae45fd-966b-4848-8667-55479d4179a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50dd515f-c490-4945-8eac-c73b0832bf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23c5d9d-12a7-489b-be66-9a7a0d111c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3fecf0-73c4-4c31-83b2-cfd2675ee7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17994f30-d425-48d7-a96c-699529876a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043d4875-9cbf-4607-ad8d-1a0b9b07dc14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f235290-2c22-4a10-8ed8-e4ac84d2ba49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec07f0c-a145-4944-9363-77fde3131e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8aaba1-68a3-4596-9e2d-48f7681f2dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d7ba49-48b5-4449-93c9-f03b67915dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b54c3c2-9f5c-44b2-963f-8f192a3128c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151916ca-56f8-4791-92ed-977cf77c11f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29001fd8-beaf-44cc-8366-60fcc3321acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da5f560-92d0-4cb2-9240-d30bae7b8a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9091a2cd-a70d-4aef-8892-d834ae2ebf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b8cbca7-4446-48f0-9d57-d8c0dfa278c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222f9b3e-c4ce-450a-8a51-dfe279050033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def70845-a4e2-4e2b-b498-5069973f4d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e707ca09-7031-4f45-8620-576c3179546e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fc2fec-8ee0-4890-b674-4289d2cc2cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc64454-e5b8-4804-8d8a-660c35557aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c1776a3-b18b-4626-b755-54baf5ffcc1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 895e5696-c7c9-4c9e-b185-c34858860f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3589ad28-c709-4a19-9624-b1243216d210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97a564b-457b-4913-a4c9-d0b2cdc105ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fca6e59-fe44-4e13-93e9-5f81769a07c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b682e5df-9a8f-47e8-8cc3-d49da5b7b7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb2aa05-3d1f-403e-986e-95429416d5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3695ddee-8a28-42b6-a6f7-dc74fef26be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05798924-4465-45ef-81a9-bf550fe4251c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ac3dff-b8d8-48c3-a1c4-0a9f5e12ffaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7db81d4-2f3b-4872-a2ec-7c22c2cec8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a460936-1ae4-4168-a449-41540a92d102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101f3389-fcfe-464b-8636-3285766b3b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2ed731-6729-4b00-8bc8-cc0fc9fffe9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cdaeb16-9aa7-4cee-bc3a-39c6a9dfd640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b4bdb8e-dfdd-410d-ad5c-2e9af4f6beb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a587b8-9c73-448f-9644-3267db686add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9547c49b-8e7f-44f8-8bf6-51d8efe04e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8d15ce-4f41-41eb-bbaa-47450349d123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ecc06e-ab5c-431e-8325-d937c0f33caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea2d6383-e6d9-43ab-845b-609327fc53de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7fa2917-4399-4dd2-b24f-4f5917772ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087ac623-ccaa-4041-9680-7c732a336a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9132071f-2ade-43d6-9103-cd8ea45bfd7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7780a21-edb2-4da9-afaa-f395fdea2d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20320f4c-7382-4dc8-8ba9-04eeb2dc53c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1079d7-235c-42c2-82f2-ed83462557a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8058b35-25cd-4f33-926f-7856f93ca800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf02310-afaa-4e7b-9a5b-9819f876c3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 802adf33-0b6b-4991-bec4-93b79a7c713e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d2856a-ea04-4134-812d-947efa609c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ecef576-015c-40ba-9eb9-c2affdd58e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca1d822-0deb-4ef3-8808-82f344586647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d2ad380-2b48-465d-8fd3-634e63a5dd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ba73ed-77c1-4df9-a54a-23588f708e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead3b860-c2bd-4b39-95e6-5a913d1db29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f12580e-20aa-433f-9671-4f1dacf63862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a2d873-d865-42ab-b08b-814e675c5c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd359665-7be2-449e-bc05-fb7ac8540590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffb8642f-757f-4b2c-aeb7-b2e006781299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed2ca14-f6f9-43ee-a6c1-8f8ed2d3b544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd8b2c1-dae3-4c17-818c-2b11a77972af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae26e2ae-b511-49a8-a898-f3aa88a72773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cbe4603-86f1-4eb6-8fee-ccddaac9ff63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c27dbcc8-4e10-4ada-b263-ec8dc2c40680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562cd67b-04fc-42be-9eb1-9a0b909a8697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25da3bcf-0b4a-4a20-b5da-0e7f631c5c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adff120-0991-4d0c-9316-dad3fc251adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31cefb75-0593-455a-995f-8c9801e3d551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c34f25-2dc4-4108-8c0e-66c8f9511041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2158377f-553f-40f0-a530-72466ca75919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2b261d-edc6-46af-ba92-5f6d3dcb1bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77169a5-eba2-47e8-a996-3c7aaebfb0ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff191e7-8a39-46e1-ab12-b84cd45388a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e334fa-185e-464d-a3a2-c4f7142f2ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2221e2a6-0fba-4e1c-a4df-d1ec2f5bfe30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a1a32e-525b-4893-8729-7bbfd2c500c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2efd385-8254-4fee-adbb-f9cc321a4478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9182e2-51f7-4051-b1bc-57da4b9aedcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5451bcaf-5c85-4395-8255-baaa548c39e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af33aff9-6d67-41be-85a9-8ba345963b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a138e7-a8d9-4300-9f97-f3d43f1ee826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 916ebdff-ebf4-4482-a9d1-5dc08718167d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ca5b0a-118f-488f-ab71-3b0eb8b4031a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c82583f-3bca-4257-b03e-37c3d1fc1adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7acbf54-2454-459f-ba39-41b9fcb5fe99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d90efedd-9a17-4d63-944e-4cc8abd6e137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7c2f1e-5c4c-4615-bb37-8475073ace16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c67fc9d-0c9c-4fa3-9348-ac8bfa0b0dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d99d3f-623e-4409-92ec-a367815ae7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb35fd3b-39c0-4f7c-bf4b-a39687c31e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f5a152-cd88-4541-b92d-7c8de02e1376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a265fe-8ccb-4c8f-891a-f76e829e3233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6057f03f-a304-4a89-8e85-51fa5163ebd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023206e5-e49a-413f-8623-d51134d0dd67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23647b7-eff6-42fb-8f00-1c2700acf09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859b3648-59a1-4003-b657-814f4c192e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea6ca9e-ffce-4bdb-8b1e-2c0b40661d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79750568-68d9-4f6d-bc6d-bfd037019379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3e9e23-3339-414b-93f0-61e233f80e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5e349d-8694-44a1-842d-b0ba34665bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d283271-1d50-4ec6-836b-38b2ca61188e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52875ae6-e06d-489f-85db-980a5672dcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ae9dd8-ffb5-47a8-b319-685bba2017e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a305ac99-f076-4e05-8637-69dcb9a59081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a0616e2-f3ef-4c81-9251-14eb3ac0d8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc34a1b-0c45-4b7c-97c7-b67f234452e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca70987b-f146-4c08-a312-27657ed48161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11f248b-1a07-4715-856b-9bf358bfe6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5313c2ea-92ee-4e10-9ed6-4011eeeae260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f15d2ed-73f7-491c-bb2f-6e9dbfc43739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a61acb9-cd21-4804-ae5e-04dc911cb203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 149499a4-5bd1-44f4-8c43-48fb20f81594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05cc7b67-c4ae-4c71-ae76-e50e3d1e5794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4985347-86cd-4d6f-b34a-528decec4f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba9a52a-f2c2-4e5c-8e5c-43f39015dc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306ffcef-2f45-4823-b688-e271cba9c5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1cfec13-b100-462e-82fd-586f8a705d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceac8322-2b4e-40cb-adeb-fb960a6c81e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ec42a3-2e4f-43bb-80b3-b80a67196d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8b4cff-6633-41b3-a4ce-f8e78f49e28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525268a7-58ee-4e99-99e6-81877be77408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e74e75-d4ad-46e1-89f8-5505e52f0717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3a3c784-0eec-4773-b725-4a8a0d078461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b05b25-b638-42f6-9dba-c44350d31539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59093c1b-6f4c-4819-a30f-9a062e09a6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719a76d5-6f5e-4998-a4f5-ce49e2bd69f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505a3f29-b6b1-411b-9e1f-3189421e704a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdecd79-2f7a-4541-8c6c-de4b0c735849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052cf1b8-180f-4226-bdbc-f2974c5a8b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e42c11-481f-4588-92fd-6005a9c913c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e4da48-33a0-47f5-b669-ebd99d89a186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21ea0abe-f178-4ea0-a416-3a3076036c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d63bfb-c144-49c4-b476-8f4a33de635f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3e2fea-3bd3-4fc6-b26b-9c60bf720331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b396f38-0432-4eae-b49f-f6ae14fd5ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b41e738-40ba-421f-911c-4b7e4b566e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8934dbba-3e5d-4f79-a907-bb63bbcbfd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f73ee4-6c20-4fee-a9be-9941ff6dc2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52628b47-1016-44d3-9d87-403ee05075c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494099a5-e500-4923-8375-67cea4022e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9fcaeb-cacf-4912-9ecf-30747569451d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0158fceb-32d5-4485-a1c0-23aff8690acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd16950-82d9-4d5b-a185-c5e88662756e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba995ff-c82d-4005-b61c-ad9d901030a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214ae03a-d38a-4d90-b04f-b666da491a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ccbf87-69dd-4df3-8b3e-44024ad50f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5f12ae0-022a-47ea-bff3-fc70fe8cddd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b861c2d2-79f1-477a-ac57-baa4b95b0ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761fc958-344b-4fec-a860-349f1e27ddbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15af4928-0fe3-486d-914f-6f2b8ff82adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3a42b0-4d10-4079-803d-037beafab4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d24b76-3430-4452-8d3f-8b6097f534d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de7b8203-8400-4b6e-883e-0691e5c945bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d818ab28-f9c4-4548-ba7d-87c35765debc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859b3dd6-761c-438a-af5a-2227bfd4684b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da24b961-833d-4720-be98-12dc954a7cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de77a70-d63d-4b65-a539-218b42242da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a4b25f-5f89-4e6c-8a9c-8f6c8278f461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f28ccfa-cce4-49de-98bb-e337f5ede925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ca8b2d-2e10-458c-899a-d0d94b374f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a10687-68e6-461b-9b58-d4d4503a1952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ac61cb-2c2d-4798-bbd3-156c1bdbc182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71e424c-fb7c-48fa-9c9c-1fbd4cd71005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f10a222-7fa8-4977-8252-f82ca501aace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7786714-c2fd-46c1-a725-c3fe3ea4474e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0f070a-148c-4b5c-9896-c4f98c77b322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5a5d71-640f-4c9b-8c70-10b07b94cd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa8c6fa-c004-4056-b8a6-a035177dcd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4c2731-e273-4640-ac02-0f69ee6e5792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cf20a9-53c7-4f09-ad95-966c150fdf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbfa268-d07b-43c4-bf0c-dd826b3d565c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f295ca-e052-46ec-8955-9a19a2790c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7fa98c-b2cc-40b9-8a9d-9206a19975d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae6b3e2-adf9-4bc7-ad99-20b7f6993b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f671f906-e197-40eb-8dcc-f6df8da88e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be8094d-f218-44ad-821a-77d89668a2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba504156-608d-4bef-9d31-ab662f76a730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1a5598-f1bb-4d77-a854-02a8470ac9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f6dbfa8-a9e9-46a7-9cb5-724bab4f1b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d43117f9-0ea7-43ce-ab40-e4765f7405f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ccdde2-72f8-4c08-8f4e-01749bb20181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe7570c-eec5-4b9d-88d3-6d3e3fe3c115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66ae1b2-84fd-40f7-941f-2069e52ed61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f31b8e-74ff-4f1f-9040-19a7081bffda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183fa804-38fc-48ce-b0c4-a0d5fff1a548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f90e02b-1356-4b2a-bf23-a421baa04228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e828984-a922-40b2-ae77-cdcf6238970a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4db88a3-9e56-45ab-b2d2-3cf39432b72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63892197-90e6-4743-80eb-2cba973b5116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c81465-62f0-4a1c-a379-f5e077211067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d51b5635-195a-40fe-9826-596008a2915b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1824ef70-0c89-4fe9-8119-8aceecb27d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8218045-f20f-4322-b455-b4adad2bd3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c566b3-13be-423c-b079-3f0a07b7d2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a07f51-dcd9-4306-a939-01ed37190835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5db19b-e245-4e05-b3c8-6fcb61910525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a7f1156-3a78-4145-a998-e21d64701eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05193d4d-8557-4865-aa10-8ed513a4de4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a8f2ba8-f10c-4087-83c0-4cf27c1ca2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1678dab-e3ab-402c-a880-32da7dda3cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77c7bdc-9f61-4449-96a4-83dd0ae2c7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0429686b-43fb-4517-bcec-39103c438213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de62ba08-251d-41f8-9114-1e609fe651f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f96c63ab-f0d4-41f0-ab17-63bc5d1ccb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ca64e4-41e4-4963-a937-0453606f7d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd5f6d9-63f8-4b43-b986-fd6af61f2727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53290821-d1bf-4a9c-9501-76e8842faff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 187ac23d-465b-4c89-ae9a-c4c9e334aafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ea0f07-b5ed-4751-a267-8dba86cb7c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35eae998-91d6-4752-8cc3-d36116fb3af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1243db40-b240-4932-968a-21053660ca3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69e89fa-09a1-4707-bec5-6257bce30ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820638b1-37c9-41fc-ab05-d583d6f00796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54a8cd5-01dd-4597-b3dc-56cf42ccee39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f952eea-e35d-427b-a3b9-07274794857d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5f546a-9bfa-4d68-8999-b4b2eeb8fd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff57506b-4ded-4da9-8dd7-0aad1b3702eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd26b5e-af7c-4de0-b5e9-28797c3a07be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce53376-48c8-48ac-a530-af3ea06fc244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be535a8-3b4a-4308-96c0-6911bf441ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17d3b0f-6441-4090-bd21-f908f59569f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6911b458-3650-4986-aa3e-18737f8f69a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d012647-57b9-4aa3-93be-ffa3e8c4713a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f965ed-529d-499f-999f-f1466e578541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c81341-88c1-482c-9814-904cdc3ecec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89fa1f7-d0ea-464b-bcdd-93b227a64df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdef1629-51f8-4d8a-8b41-44526ac65bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c89554-5c94-4c4f-a857-e0fe3b636003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b3c48e-c607-4417-ad5d-78be049c83f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7fdb1c9-0f0e-41c9-a30e-0e2b1d2a9c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff55c38-145c-4eea-92d5-e563e0822616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8d3863-9601-49b1-8c16-df6c1ed2a994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34fe6090-0a64-4c9b-828f-d300fd88b73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6951a804-ea7d-40c9-a593-6848924fe89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 032802c5-346f-455c-aa57-3e9bcaea9221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0f3175-6afc-4098-b0ed-63a2a83ba8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc11376-9ee6-460e-ac69-7ccc53d22fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47ab5de-8852-4527-8560-07840f96f7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e0cfc6c-86e3-4cfe-9a20-f5a6bb7fa688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e5ee51-7bfa-43a3-a0a0-057bc7c9de1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14529e36-13aa-414f-8638-3303998801fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e10c992-6a54-47f6-a563-4800c7063394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f0cbc2-2327-4033-a751-67d4491d49ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c3a772-3e8b-442b-bbc1-70c2c915ca27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d5bec2-7020-41e0-b7ba-86989696b754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d2a074-61a7-43dd-975b-940ba6b00d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29797cda-985f-45a6-a58a-cc9957df44c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82cf1893-b280-4fe5-abc9-447c7bf585ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cadd81-e893-4985-bdfb-c0c48171d311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a275bdb6-7f55-4317-b917-1642dc4314e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be1a9c5e-968e-481a-81bf-8201c3d41f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca1c5d61-e2de-4562-ae86-db32a57126e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ab7811-e131-44b9-8c84-ee3ade6d7c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d0aeafa-f2c3-48df-a598-6b12a018a5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b9fc808-e7f1-4c69-931b-4d4f5e3239c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd26d35-38f1-474c-81fb-5215bb2fd310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a85e87aa-e0f3-4622-b2ec-12718f23ec4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc22c5ca-1a1a-45ba-8c7e-adea5e41b48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21243a58-9f7d-4bef-a1c0-a47878c9d636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f381e9-07f9-40a4-a568-5dd0fd71f7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52371f6a-42ba-436c-8c5b-bf78671fe92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9961b6c-3ed2-4ae5-8985-afdf348a49ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb592923-d298-4cb7-8fa2-6d9b1bc038c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e7fd405-3b60-46a3-adfa-fc81a1466eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80438bc2-3105-496d-b348-65e39c264919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc7094d-6342-4f5d-bff2-d64f558009de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a60760-b024-417d-92cc-5e3a9af31830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56e6be6-6d2b-4abd-b723-4f63602730cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf86934-afa1-4af0-bdf6-6bdeecb6693b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83c3191-3c6c-4ce2-8b47-a7fa2a958682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f81e25-8b9e-46e0-919d-8405ab7146cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36ee889-c102-49b3-8ab0-dfe953235127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddac29a2-a313-4777-b973-649a3e5febe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c25cc367-66fe-41a0-8df4-15192a426409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d7a586-ead2-4973-ae73-96175190e78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a7948a-f85a-48a3-9b40-5bdf6c7b7538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb212b7-f84e-4222-bcff-9f5293e24d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94431a8b-4661-44e1-b33c-9272d6218556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60e004b-178a-4d38-963b-03904c0c3f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25c5fc0-7ac7-4df3-bb30-bcebd2e12cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 407d5223-4b17-4207-80a9-393764e7da41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 220c70a2-e04a-47aa-9d84-0c05a85178b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b63189-a414-494a-b8aa-76f015f3267b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e77f1950-5674-43d5-bcf1-64077cbdf2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585bc762-5a15-48b7-85e9-41f5eaa2a70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53d698b-269f-4d05-87f9-55f0484407c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5721ef27-e603-46ce-ae7e-5d51353e25d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b456f27c-e075-4616-9bfe-fe4dc631c4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0405a31-e35b-46a6-ba53-6e10fa68492c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82dd0f11-31f2-4246-9cb5-d89d5fdf86d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d036b9-5473-4f93-a7c8-6f1a32ed3b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 624a1e0f-aebc-4670-87e0-d89e2ba9eaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3624916f-5d98-4b2a-b20a-d6b14810f2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24393296-61a2-4c54-ba61-0a20d3a2c012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380d7166-6c86-45e5-991d-685b3e816a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a224f7-1505-4095-a833-1210a98a4615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a5156a7-65e5-4753-a14e-57df2d4205fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c2c9ee-d62b-4b44-85b5-cc3ee59a5e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975e08ee-5e0a-4cf0-9dac-7cf8efebf0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5b12d2-d8b2-4885-8333-29a6756ea0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88827baf-5a1b-414a-ac6a-59b1b35fa04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef03a265-438b-47fe-8814-7d2fd5d4759c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c655a89-4e3c-4f84-9c40-afeeebb24931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68925180-c00a-41b8-89b6-c1773a0d31ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485ea79b-3627-44a4-b667-78844c82d67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e2de9b-3cd7-4b88-a3a0-0f0f022fc46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239288f7-d35e-4825-9b76-3f9374161d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 271ed073-a683-46f2-928c-3242b88c0963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f3be52-e640-4969-b6d5-b282b4d7506b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be23ee0-2253-40d7-b976-f5a83d1d8a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6219cea1-53e0-4fc5-89ee-8a9664233c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0d6a13-cda9-4ebc-addb-c806889c8adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f640fcd-d551-4ea0-b08a-8be88d9f7507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af044a8b-d43a-48d3-8d7d-c1ecf98a7fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63919a97-1ff7-4ee8-83c8-96afce29034e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5eb2fee-4276-4181-af19-607352d8d7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b121d039-ef65-4092-8e2b-65c1da18ecab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 750f26c8-0e3d-4056-bf1b-448d1b4e0c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 631d0cc7-7bcc-4158-85bd-1d1a5cb95358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3920c7-c33e-4d38-9634-781232961328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51438e88-98c1-4a99-86b5-c9e1773bdddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a70559-1017-44a8-804a-4d15210ca785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c0a301-4f34-4e1d-8e7d-7a7fc8911ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835a5c0a-9383-4c15-ae01-6d9cb64e77a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5221c4d9-065f-41df-9bb8-c30b88e447dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2c8ad6-4038-4383-bdaa-7311116a1027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23709a74-8fcc-4c19-8a27-3f1272dec850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2641b675-cb0f-4fc0-a3eb-365e929f6e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e4d5732-7c79-4e22-bbd7-c0863aec6c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b87fc7-76c3-4c69-aa18-d7d629a6fe78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e6e1a8-256f-4a7e-9bb3-0e6c58afe768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc35feed-b504-4ebd-8677-2dd83b427346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a6c2939-504f-40be-9844-56b41c5e3094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6873ae-ec46-4749-b8e4-defa0c21c1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863e49f0-6c05-42f4-99ed-49ad47fe6bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6677f35f-f5b3-407b-b456-450620cfa6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f15b4b-12fa-497a-8da5-c237ad51e9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e545f585-4d5a-4c0f-acb2-320ec6a71a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571f61e7-27e2-471e-9ede-de3cb96b908f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a50b28-a674-41e2-a7ea-b860fd8a6553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f67c21-1ad9-4705-b44f-414211a334f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71de6c2-4ea2-4e06-bb04-dd674d9b1ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7f3b1a-b1ea-434b-9373-641564cc1ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27d95db-337a-4180-bf77-00ed623d60dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d25f098d-4e05-4b89-9a41-04e10ce4b130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30aaa46c-a1d7-4cc0-a468-e953b6cdfe09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4164eae-9d3f-4dd0-9afb-9d858726e304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e44b6b78-f532-45fa-be6f-7cb3b8aaab80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0d5d6b-e6b0-4cee-b563-dab3e00a4fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645bac14-f0f5-497b-b1e5-8c3e93b69e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cfd5c5-13c4-44b9-ae61-dc9b2e032206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701e523a-c8df-4515-a26f-6374642132e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f28e39-bd4a-452c-a2bc-10261fbe0391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0412644-fec0-4677-85f5-771e594c0878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cedecb89-b229-4baf-bd75-cfe068aaccf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c68a671-5fec-4f2c-8ede-d05e207a8fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413de416-83e6-4823-890c-3e5be91e3fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a671499-4aac-4b5c-bbdf-4dd8c328ea67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f475520-0aea-45af-980c-f787bf7fbc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6427ddb1-c0db-4aa2-a04a-0d770b2b6d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693dc063-7b82-4e26-80f8-23fc82e0ac45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ba8909-3953-4a60-8c9c-cd8612024ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf4803c0-db8e-4ec9-b91b-fa9a43a82fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f686a736-4be4-40c9-ac06-754ba25f0c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d99fc15-1f9d-4584-b0d3-95b8a13caee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a64369d8-fa2e-4b3f-983d-4755d4120fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96552c31-304d-489a-8dbb-3bd9e4fad439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78308cd-1124-4559-8b8c-c790a3da7f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bd6990-d5bd-4fdd-92ae-1366d6ecee3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d3802a-767f-4be2-844c-aa04a294bd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5811e1-7fa7-4877-85e5-6aee57252f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0802af66-b7ec-41b3-9b54-bf9104a9633e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e11e2f-3b7a-4c53-ba22-df86c113ccc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b290a63-71db-4d8c-b83a-41bb44ea9112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02aa0e33-6cc5-464f-99a7-97c72299a9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6005bf7d-e315-4430-87af-1cf326269898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 674844a6-ab89-4b74-abbc-ce553d13b20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf453de1-4ef0-453c-aa65-ea6d37158c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94c20d20-900a-44cf-8597-5dd171c44551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6585de11-bce9-4c1a-891d-977c62721871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83fd1947-4d22-4cb7-a34c-94e5bdd9cec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58573c6-9539-4e0a-9f5a-539a6095d23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16e87e67-46e3-4687-947f-c81c94bf85cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a38df5e-f080-4439-8d1c-5d2bba43efea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97231c10-1b05-4510-aa1d-75afe60d3836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c34850e-3b97-41a4-a5d9-7641f63525e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741bff40-1772-43e6-8491-0a0e41f26b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a27fe74-ce7f-4695-82fa-cf9a40c678ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56efb541-46ce-41b5-921d-7ae34f080c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925ecebf-9811-425f-bcf0-11b53bfa1316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1dcf50a-609e-4b7f-8ce4-32cb680041e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351767ee-4315-4d3e-9841-cf501ac3a3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ea909c-e33c-4dbb-b916-5dcd5e0daf53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c122d7-56cb-43ca-aad4-31a73b03ad72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e2012d9-54ab-47c5-b9c1-22e7a4a471bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4562a8-e9a0-4bce-b80c-39cb88dab2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d66061-07cf-43b3-9a36-a18f40fccd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d012218e-e6f3-4a05-bb62-579c3574da3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c2c87f-52de-4f00-8413-2e35e70b4950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39769826-22a1-4cf8-9902-7a03aa6d569e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb0e7f1d-29fd-4320-9cd2-50a60f0d891e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5421d946-26b4-4882-9d04-2fca2161155b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 952f2a42-24e1-400d-afc9-1f08583565d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9001b949-efce-4d31-88d5-1da085eb5a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85c8df0-afe8-4386-95ed-2a69fcbfe47a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0abb2c4f-9f81-4ecd-a3b4-563b2ea35718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77340db5-d53a-49ca-a1ed-33c7c0411495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d7a68c-1f47-49fd-967d-5ad09cda7a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47b1ff5-adc6-4206-bb95-fb24b200c970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6da9b7-57f8-48c1-a71e-3226f8313893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645ece5c-66bf-497c-b5cb-0b94e2cf45c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324f2067-7fc2-411f-8741-af76f703d363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49fc8a9b-12e4-4654-9bc2-df25e4255e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c634df-2b41-4082-9523-cd0a24978a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb76a8e6-ba9f-4b5b-9940-e297bfab677a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c28c03-0555-4266-b525-8d55d6197089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a86173-0b63-40ca-b6c4-664af8ccada7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19990e87-7131-4466-80fe-b8c2eeb1f568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dfc5a23-7be6-4ac7-a273-f154bd65f92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d367c41-4966-4c91-9789-3ea6d04fbbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c74998ad-38f2-438c-8b25-5dfbe33282a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1fec313-f073-437b-aa39-7c5469bb24cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4dd7923-3349-439f-bbe1-877ef581c6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ef728f-07ba-477f-8710-8c6fb7368041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867a30f1-8076-4aa4-a83e-c32833a9ae15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e36e0fe-9d5c-454f-bb65-74b5ad5f9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message decfd3f2-50eb-4ee8-9d79-0d67e2ddeb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1dd03f-e847-483b-baf3-3808f9efa5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa55909-2b4b-494c-8544-8de9a6483d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a2f36ac-3639-4fdb-b7a9-799251b36f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7892878-11af-41d6-8fad-556b08a98b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcddd80e-c73f-4bb9-969f-5fd2951efe7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7d64bc-a42a-4a0c-8434-e8595618b686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b140c9-c44c-42ac-b555-e5157248263b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d3ea0aa-fa2e-46b9-931b-c353771bc6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0891a15-eb9d-4d89-a721-54ecf2341f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3545c7-ed28-43e2-aeae-1a5b24cbcb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb14808b-d907-414b-8566-033be7ccb27c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28218898-523f-4068-893f-9a412b78b517
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(5643, 24), y=(5643,)
   Test:  X=(1411, 24), y=(1411,)

⚠️  Limiting training data: 5643 → 800 samples
⚠️  Limiting test data: 1411 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3105, val=0.1059 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0963, val=0.0761 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0849, val=0.0744 (↓), lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0743, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0739, patience=2/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0741, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 1 Summary - Client client_9
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0028
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0160
============================================================


============================================================
🔄 Round 2 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000250
   • Epoch   2/100: train=0.0805, val=0.0820, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0803, val=0.0819, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0803, val=0.0820, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0799, val=0.0818, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 2 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0021
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0076
============================================================


============================================================
🔄 Round 3 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000063
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0807, val=0.0806, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0807, val=0.0806, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 3 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0032
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0100
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2472, R²: 0.0043

📊 Round 3 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2471, R²: 0.0054

============================================================
🔄 Round 9 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000016
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0809, val=0.0802, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0809, val=0.0802, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0809, val=0.0802, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 9 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0040
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0095
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2469, R²: 0.0051

============================================================
🔄 Round 10 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0813, val=0.0782 (↓), lr=0.000004
   • Epoch   2/100: train=0.0812, val=0.0782, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0812, val=0.0782, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0812, val=0.0782, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0811, val=0.0783, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 10 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0001
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0005
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2469, R²: 0.0049

============================================================
🔄 Round 12 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0797, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 12 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0020
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0228
============================================================


============================================================
🔄 Round 15 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 15 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0024
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0118
============================================================


============================================================
🔄 Round 16 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 16 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0010
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0026
============================================================


============================================================
🔄 Round 18 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 18 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0005
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0026
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 21 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 21 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0042
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0094
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 22 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 22 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0004
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0032
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0008
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0045
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 25 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 25 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 30 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 30 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0014
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0000
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 32 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 32 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0031
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0045
============================================================


============================================================
🔄 Round 33 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 33 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0031
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0066
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 36 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 36 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0037
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0111
============================================================


============================================================
🔄 Round 37 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 37 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0037
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0093
============================================================


============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0014
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0023
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 39 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 39 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0010
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0023
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 39 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 39 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 43 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 43 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0025
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0061
============================================================


============================================================
🔄 Round 44 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 44 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0037
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0163
============================================================


============================================================
🔄 Round 47 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 47 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0024
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0101
============================================================


============================================================
🔄 Round 48 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 48 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0026
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0103
============================================================


============================================================
🔄 Round 49 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 49 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0010
============================================================


============================================================
🔄 Round 53 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 53 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0029
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0109
============================================================


============================================================
🔄 Round 54 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 54 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0001
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0068
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 55 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 55 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0004
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0049
============================================================


============================================================
🔄 Round 56 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 56 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0019
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0012
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 56 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 59 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 59 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0003
   Val:   Loss=0.0665, RMSE=0.2580, R²=0.0070
============================================================


============================================================
🔄 Round 60 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 60 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0025
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0118
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 60 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 63 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 63 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0003
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0035
============================================================


============================================================
🔄 Round 65 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 65 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0006
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0056
============================================================


============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0007
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0023
============================================================


============================================================
🔄 Round 67 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 67 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0014
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0114
============================================================


============================================================
🔄 Round 68 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 68 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0015
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0041
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 68 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 70 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 70 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0016
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0002
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 71 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 71 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0043
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 75 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 75 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0033
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0285
============================================================


============================================================
🔄 Round 76 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 76 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0011
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0129
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 81 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 81 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0031
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0055
============================================================


============================================================
🔄 Round 82 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 82 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0027
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0056
============================================================


============================================================
🔄 Round 83 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 83 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0031
   Val:   Loss=0.0693, RMSE=0.2632, R²=-0.0099
============================================================


============================================================
🔄 Round 85 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 85 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0022
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0107
============================================================


============================================================
🔄 Round 87 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 87 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0009
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0005
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 88 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 88 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0026
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0039
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 92 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 92 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0037
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0187
============================================================


============================================================
🔄 Round 95 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 95 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0050
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0302
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 95 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 95 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 101 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 101 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0001
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0064
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 101 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 103 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 103 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0010
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0010
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 104 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 104 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0004
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0004
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 104 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 107 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 107 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0000
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0088
============================================================


============================================================
🔄 Round 108 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 108 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0022
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0057
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 110 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 110 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0019
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0006
============================================================


============================================================
🔄 Round 111 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 111 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0000
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0067
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 112 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 112 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0007
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0011
============================================================


============================================================
🔄 Round 115 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 115 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0027
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0038
============================================================


============================================================
🔄 Round 116 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 116 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0012
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0003
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 119 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 119 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0000
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0065
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 120 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 120 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0031
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0042
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 124 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 124 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0002
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0056
============================================================


============================================================
🔄 Round 125 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 125 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0016
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 125 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0011
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0020
============================================================


============================================================
🔄 Round 140 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 140 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0003
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0056
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 143 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 143 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0007
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0092
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 144 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 144 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0013
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0029
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 146 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 146 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0035
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0063
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 146 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 157 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 157 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0024
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0010
============================================================


============================================================
🔄 Round 158 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 158 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0020
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0003
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 158 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 160 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 160 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0034
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0113
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 160 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 166 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 166 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0011
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0004
============================================================


============================================================
🔄 Round 169 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 169 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0016
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0005
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 173 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 173 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0000
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0063
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 182 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 182 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0010
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0055
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

📊 Round 182 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0065

============================================================
🔄 Round 184 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 184 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0005
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0062
============================================================


============================================================
🔄 Round 185 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 185 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0016
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0015
============================================================


============================================================
🔄 Round 186 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 186 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0034
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0283
============================================================


============================================================
🔄 Round 187 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 187 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0010
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0024
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 193 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 193 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0012
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0031
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 193 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 195 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 195 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0001
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0036
============================================================


============================================================
🔄 Round 196 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 196 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0020
============================================================


============================================================
🔄 Round 197 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 197 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0019
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0001
============================================================


============================================================
🔄 Round 198 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 198 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0018
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0003
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 198 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 201 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 201 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0017
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0071
============================================================


============================================================
🔄 Round 202 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 202 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0021
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0051
============================================================


============================================================
🔄 Round 203 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 203 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0003
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0079
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 207 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 207 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0042
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0104
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 209 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 209 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0035
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0069
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 212 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 212 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0006
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0054
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 213 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 213 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0009
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0021
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 213 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 217 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 217 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0047
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0122
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 220 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 220 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0011
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0028
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 221 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 221 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0023
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0007
============================================================


============================================================
🔄 Round 224 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 224 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0014
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0127
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 227 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 227 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0050
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0203
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 228 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 228 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0037
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0106
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 228 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 230 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 230 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0035
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0095
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 233 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 233 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0044
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0104
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 233 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 233 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 239 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 239 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0037
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0063
============================================================


============================================================
🔄 Round 242 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 242 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0027
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0035
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 242 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 246 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 246 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0010
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0132
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 255 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 255 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0031
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0083
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 255 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 257 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 257 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0018
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0143
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 258 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 258 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0004
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0076
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 258 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 258 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 267 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 267 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0024
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0026
============================================================


============================================================
🔄 Round 268 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 268 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0000
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0041
============================================================


============================================================
🔄 Round 273 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 273 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0022
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0005
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 273 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 275 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 275 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0004
   Val:   Loss=0.0724, RMSE=0.2692, R²=0.0073
============================================================


============================================================
🔄 Round 278 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 278 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0011
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0027
============================================================


============================================================
🔄 Round 279 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 279 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0014
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0006
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 281 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 281 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0055
============================================================


============================================================
🔄 Round 282 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 282 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0017
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0001
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 282 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 282 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 282 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 290 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 290 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0029
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0030
============================================================


============================================================
🔄 Round 292 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 292 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0017
============================================================


============================================================
🔄 Round 293 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 293 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0008
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0038
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 294 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 294 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0028
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0028
============================================================


============================================================
🔄 Round 296 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 296 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0032
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0025
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 296 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 296 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 296 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 306 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 306 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0012
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0103
============================================================


============================================================
🔄 Round 307 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 307 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0014
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0017
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 309 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 309 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0034
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0054
============================================================


============================================================
🔄 Round 311 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 311 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0013
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0004
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 316 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 316 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0014
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0026
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 317 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 317 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0002
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0072
============================================================


============================================================
🔄 Round 319 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 319 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0034
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0089
============================================================


============================================================
🔄 Round 321 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 321 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0043
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0279
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 321 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 325 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 325 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0017
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0031
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 326 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 326 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0014
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0027
============================================================


============================================================
🔄 Round 327 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 327 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0023
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0392
============================================================


============================================================
🔄 Round 329 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 329 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0030
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0097
============================================================


============================================================
🔄 Round 330 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 330 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0029
   Val:   Loss=0.0691, RMSE=0.2629, R²=-0.0084
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 331 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 331 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0026
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0115
============================================================


============================================================
🔄 Round 332 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 332 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0004
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0029
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 332 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 334 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 334 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0012
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0030
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 337 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 337 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0009
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0042
============================================================


============================================================
🔄 Round 339 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 339 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0011
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0041
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 339 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 346 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 346 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0029
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0021
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 348 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 348 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0011
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0101
============================================================


============================================================
🔄 Round 349 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 349 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0008
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0047
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 351 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 351 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0018
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0001
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 354 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 354 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0036
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0095
============================================================


============================================================
🔄 Round 355 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 355 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0019
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0009
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 356 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 356 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0046
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0460
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 356 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 358 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 358 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0018
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0005
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 358 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 361 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 361 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0028
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0069
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 363 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 363 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0008
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0042
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 364 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 364 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0025
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0018
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 367 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 367 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0031
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0176
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 367 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 367 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 370 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 370 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0082
============================================================


============================================================
🔄 Round 371 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 371 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0027
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0018
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 371 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 376 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 376 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0019
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0056
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 376 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 379 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 379 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0016
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0012
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 386 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 386 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0017
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0015
============================================================


============================================================
🔄 Round 387 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 387 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0021
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0007
============================================================


============================================================
🔄 Round 388 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 388 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0007
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0045
============================================================


============================================================
🔄 Round 390 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 390 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0023
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0047
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 390 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 394 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 394 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0031
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0047
============================================================


============================================================
🔄 Round 401 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 401 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0016
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0039
============================================================


============================================================
🔄 Round 402 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 402 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0083
============================================================


============================================================
🔄 Round 404 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 404 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0018
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0145
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 405 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 405 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0021
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0038
============================================================


============================================================
🔄 Round 406 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 406 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0050
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 406 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 406 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 412 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 412 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0021
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0000
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 412 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 417 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 417 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0029
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0131
============================================================


============================================================
🔄 Round 419 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 419 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0031
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0211
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 422 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 422 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0003
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0119
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 424 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 424 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0035
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0075
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 424 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 424 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 424 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 424 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 424 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 433 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 433 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0014
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0034
============================================================


============================================================
🔄 Round 434 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 434 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0019
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0152
============================================================


============================================================
🔄 Round 435 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 435 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0023
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0008
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 436 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 436 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0007
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0023
============================================================


============================================================
🔄 Round 437 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 437 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0034
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0060
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 437 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 439 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 439 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0012
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0029
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 440 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 440 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0024
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0051
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 440 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 445 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 445 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0014
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0017
============================================================


============================================================
🔄 Round 446 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 446 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0035
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0109
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 447 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 447 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0021
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0065
============================================================


============================================================
🔄 Round 448 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 448 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0043
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0107
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 450 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 450 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0040
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0072
============================================================


============================================================
🔄 Round 453 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 453 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0036
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0159
============================================================


============================================================
🔄 Round 454 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 454 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0013
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0029
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 455 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 455 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0017
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0016
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 455 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 455 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 465 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 465 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0019
   Val:   Loss=0.0706, RMSE=0.2656, R²=0.0137
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 465 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 467 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 467 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0004
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0116
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 468 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 468 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0019
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0010
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 468 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 472 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 472 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0005
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0061
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 473 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 473 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0029
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0037
============================================================


============================================================
🔄 Round 477 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 477 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0015
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0027
============================================================


============================================================
🔄 Round 480 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 480 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0064
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0337
============================================================


============================================================
🔄 Round 481 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 481 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0028
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0027
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 482 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 482 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0053
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0189
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 483 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 483 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0011
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0104
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 486 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 486 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0009
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0059
============================================================


============================================================
🔄 Round 488 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 488 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0013
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0027
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 489 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 489 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0015
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0019
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 490 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 490 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0006
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0027
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 490 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 493 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 493 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0024
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0050
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 495 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 495 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0021
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0016
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 495 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 495 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 503 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 503 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0073
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 504 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 504 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0015
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0006
============================================================


============================================================
🔄 Round 505 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 505 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0029
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0031
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 505 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 507 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 507 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0035
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0055
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 511 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 511 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0019
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0019
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 512 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 512 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0051
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0242
============================================================


============================================================
🔄 Round 513 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 513 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0012
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0002
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 515 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 515 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0023
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0002
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 517 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 517 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0014
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0022
============================================================


============================================================
🔄 Round 519 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 519 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0022
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0001
============================================================


============================================================
🔄 Round 520 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 520 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0022
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0061
============================================================


============================================================
🔄 Round 524 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 524 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0007
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0052
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 525 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 525 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0012
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0027
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 527 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 527 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0022
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0043
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 528 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 528 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0015
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0131
============================================================


============================================================
🔄 Round 530 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 530 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0032
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0070
============================================================


============================================================
🔄 Round 531 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 531 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0020
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0062
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 532 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 532 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0046
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0391
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 533 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 533 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0117
============================================================


============================================================
🔄 Round 534 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 534 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0042
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0227
============================================================


============================================================
🔄 Round 535 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 535 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0011
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0018
============================================================


============================================================
🔄 Round 538 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 538 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0023
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0022
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 539 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 539 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0030
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0209
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 539 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 539 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 539 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 548 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 548 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0038
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0066
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 551 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 551 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0022
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0006
============================================================


============================================================
🔄 Round 552 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 552 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0037
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0055
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 552 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 552 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 560 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 560 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0016
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0030
============================================================


============================================================
🔄 Round 561 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 561 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0018
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0015
============================================================


============================================================
🔄 Round 562 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 562 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0026
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0019
============================================================


============================================================
🔄 Round 563 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 563 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0025
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0023
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 563 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 565 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 565 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0036
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0050
============================================================


============================================================
🔄 Round 567 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 567 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0032
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0154
============================================================


============================================================
🔄 Round 569 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 569 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0029
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0090
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 569 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 571 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 571 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0030
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0171
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 572 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 572 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0016
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0131
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 573 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 573 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0008
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0033
============================================================


============================================================
🔄 Round 575 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 575 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0016
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0023
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 576 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 576 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0013
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0008
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 576 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 578 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 578 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0079
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 578 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 582 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 582 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0018
   Val:   Loss=0.0821, RMSE=0.2864, R²=0.0019
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 582 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 585 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 585 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0067
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 587 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 587 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0015
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0032
============================================================


============================================================
🔄 Round 588 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 588 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0029
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0125
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 589 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 589 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0046
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0101
============================================================


============================================================
🔄 Round 593 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 593 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0081
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0515
============================================================


============================================================
🔄 Round 594 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 594 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0002
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0058
============================================================


============================================================
🔄 Round 596 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 596 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0004
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0101
============================================================


============================================================
🔄 Round 597 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 597 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0037
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0095
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 600 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 600 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0013
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0012
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

📊 Round 600 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0067

============================================================
🔄 Round 603 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 603 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0040
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0066
============================================================


============================================================
🔄 Round 605 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 605 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0015
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0025
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 609 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 609 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0013
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0043
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 609 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 612 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 612 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0033
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0317
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 615 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 615 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0017
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0032
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 615 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 618 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 618 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0008
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0039
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 620 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 620 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0007
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0034
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 621 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 621 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0014
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0113
============================================================


============================================================
🔄 Round 622 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 622 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0090
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 624 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 624 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0017
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0033
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 628 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 628 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0031
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0367
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 629 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 629 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0036
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0172
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 631 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 631 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0008
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0073
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 631 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 633 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 633 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0023
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0013
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 634 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 634 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0025
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0005
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 641 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 641 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0001
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0086
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 642 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 642 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0010
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0030
============================================================


============================================================
🔄 Round 643 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 643 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0060
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0248
============================================================


============================================================
🔄 Round 645 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 645 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0093
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

📊 Round 645 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 649 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 649 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0023
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0060
============================================================


============================================================
🔄 Round 650 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 650 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0046
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0174
============================================================


============================================================
🔄 Round 651 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 651 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0013
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0012
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

============================================================
🔄 Round 652 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 652 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0012
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0022
============================================================


============================================================
🔄 Round 654 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 654 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0037
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0048
============================================================


============================================================
🔄 Round 656 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 656 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0041
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0077
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2468, R²: 0.0066

❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
