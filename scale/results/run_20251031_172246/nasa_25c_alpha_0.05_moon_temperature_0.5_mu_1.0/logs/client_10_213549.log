[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3741d415-e928-497d-a416-1a2a15a1cde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66931e65-b556-49a1-a342-2124ba82bd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a58527-b5dc-4e0a-8dc7-ff06cf5db004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3ab77c-a027-4d2b-ad9a-ec9ee1133f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2849c8-d4a9-434f-9c0f-dfaba0af4fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f14f5c5-f97e-497b-a3d7-ecde8e18d9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46359e69-606d-4a71-b4ba-bb5425e0b225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d27bd3b-e1f7-4f24-9ed6-875d1b97b803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477e43cd-6339-4ae6-8e2c-871b5c1b713b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4cc936-4a62-4811-b83b-420f9188c361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e5b36a-41a7-4129-b80b-c451f8e4adbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a5c827-2845-446b-86f4-ec49554ee4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efbfb00-3048-46e4-b828-4ff45f7f1eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b48bd7-7296-4875-98e3-bb1c86113e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9af7fd-a5ad-40f1-83aa-3f52c68f2331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44d175b-b45e-434f-9f25-9cc5019a9957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5926329e-f9e1-41ca-8047-3118a5c85345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9449cc28-7fed-4460-bc8b-326c5f5f50c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b18fa82-9381-4ca8-96c7-780ef45a472a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f63dc6c-8cf8-4c12-9e90-24c3b88922ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08be806-d34b-4b23-9f09-15524a495195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3027ae03-2614-4f63-8dfb-7acac82ea2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aac364e-23e7-46b9-ab8d-fdd0226fbbbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74661d9c-b19f-4012-b03d-1561b953758c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c4e088-308a-42b4-bad2-7413f405b557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21607d88-b28e-43a6-9fc8-f3c27dc977d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1375a3e5-5769-4785-9ea4-88da222ce717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 013d21f1-5956-4b44-8ba4-76137deaef24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcc9976-82eb-46cf-a020-c1f4e5ec6a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061501ad-9806-4e2f-a3f6-58549215a967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 925480e7-7077-4574-9a65-c5fc62021210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fceaafa3-9185-4eb0-8e27-65f271a1c0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e265225-cf78-4ec7-be00-f3dd590484e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0d29c9-3e3a-45e7-be08-12dacdd89308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e318a9-d0b8-43d7-bcd0-fed9931473d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30bb19b4-546e-4efa-91e2-15180563cf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca85ab69-a342-427f-a70b-cee08cd5b07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17f036b-706a-4232-9b5e-2fe09cf73841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b0a33e-7b2d-46b5-84ce-2ed8cf99ef98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd0b750-1a10-4644-b9cd-01a4495c7514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb70ffe2-5b9d-4a7f-9484-38bc2b64202f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a41614-37c6-46d6-b032-cc61fda4b132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbfaebc-d0ed-4e6e-aea2-a1557121d1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be4018a-0815-4500-9150-fbb552c0fa82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa08754-e93c-4fd1-8e98-3704a3fcfeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d88e6cd1-c401-462b-a5a4-766c60248198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae73cb5a-aea4-43b0-a5a5-4eacda88e689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d980012e-1981-4fb7-b099-00ee2253d627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a85684-2182-4b90-b452-9cf4ef93c21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d0236b-41dc-4628-a85c-056e3f326831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a82433-b201-4eae-babe-e87cf0ebb4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ebeefa-332a-4f4b-ae65-e3fe75fd4dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3016427e-1509-41e2-a165-c786a75d9c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2824b80c-2028-47da-bbf2-63ce7e473d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3765b0-fb05-46c1-a573-2d2c1201bbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3528296-5fd6-42e9-bdee-e8dd1432564b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46fae70c-96df-4c96-9084-8080a3268f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4811e896-9422-4ed0-a246-76b6d01232fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05cf66e-ba19-48b1-99ca-7d77ad7b0a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f8ab80-4625-4cfe-8e33-db0e38731f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e39e97-3825-4263-9928-795c5513e267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80653e11-0a48-420b-80eb-ed28d740c9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb54de0-9872-48e5-9c72-d81dab8c7ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2e981c-2621-4a1d-8a3c-b203b95af4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3647bbe4-2898-416c-9ffb-04e7a163c672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63501bc1-243a-4daf-ac37-0e05aa072f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9476553e-28a1-45d5-be49-7322b3bb26ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d735290-a406-401e-ba66-50c6fbc291b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4bdeab-d942-43f9-b9b4-3bc0d0b278f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6021c701-01d7-4874-a8e9-8fa1c5abb62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eaca0bc-2b28-4505-8413-fd18202310d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de3bcde-6bcc-4281-8bc2-5f19a7920991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5feaf762-d973-4e45-b95d-5c5ec44d3881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0cc7e7d-3a9f-4ade-b75b-0b6c81c5d89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4109979a-13bd-448e-a3e3-dbe3d6e802a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc8a6c7-0b02-412a-86e8-0c0aa425446b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be34c2c-6072-4156-a03d-2497ab3cfa1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f2f5a5-e949-4605-8986-560cf8c6b9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 536c2b76-7272-4683-9f42-b397f8a3df5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c96f8dc8-e184-4e1e-a958-3600168abbb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8709aad-332c-43ab-a015-6a7817a32f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e5f988-0d80-4f37-bcfc-01527356fffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18473273-8b32-4c0b-8839-69f1d78589f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edfb4180-7613-40ed-b214-29f537ef375f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96066a52-e4c6-4da4-b95e-106ebf8b7acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202c25bf-8605-442b-b242-c1f3edfc7795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3500f9c1-cf30-431e-b4ea-b2a9cafe0e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1760ca1d-2254-4f44-8946-984b0c10a5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c3090f4-7173-4766-93ca-98d212fb9e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29289f2a-f8df-44b7-ac03-e0a5e7763d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8007835-f1e9-4f13-85f2-f09ce75ce870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2efa5a-5fcd-4c9d-a719-f7485fc3d0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8f80a9-7367-4c10-b9cc-b961610dd3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850b1558-f8dc-4f2e-9c1f-c0e743314e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6c8dd6-487b-4d96-8255-98cbd44d8d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff447a1a-290f-41e6-97b3-868412b66271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3590f4-c5f0-45c5-a6f3-4908eb365b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e345267-059c-4727-a5ee-4fd27db62c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f09774ad-6270-4d72-b7b1-6f30c6c85f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6aa0a94-c6fe-48eb-93b6-cb94441a9e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110e6436-d98a-43fc-9ce1-01f7ca650483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fcfede0-1f6b-47d1-955e-94eee7731c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b0a92dd-2ef4-4e2b-8533-090148959779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a7a465a-480f-4b92-bf8e-323461565a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf73ed2-8b4e-496f-ab24-347ae4fa0673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 817d1492-2ec2-40d7-8c74-3ca3790b8861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adae32f0-e1e9-4699-a16f-965eeb064275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6921d5-106c-4e27-8fe7-9608f98e1d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c77344d2-72c5-4267-8c6a-3e51dac74ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52658d33-b8df-4501-9e9d-6d4ccd213ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f032b41-dc32-446c-b87c-25b718203d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df8c115-6c80-489f-916c-92fc3fa171f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f11c439-185e-4093-8fb0-1d324c5f9d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7678c16-9122-4e3e-b31c-6c7147433988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac35d61-83d6-4aa1-9e63-f8aee818af4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6feacf-46c9-4630-bc1b-de7c7f81babb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922eaaa2-9493-4355-b81e-1dff8d47fb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ce12bf-200a-48b3-a1a0-ff04be89021f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c07f4c7-f985-459a-95f1-e52e95eb5fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dbbfec0-dc57-4f84-a14c-59cf6d9d2562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a070e7-491f-470c-a2f6-4784a03c05bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b806138f-94a2-4065-86cf-dc988f4eaee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c429a7-0592-42c5-9ff1-3bf7d40ed78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffbb5037-e201-4f81-8780-ea9046246825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32f33c7-18b4-416f-af9d-17d5fa94ab2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4530da85-449a-4c4c-be79-338f4b378066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4541068e-2e75-4a13-8a66-6499b45b7219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dccd651-5057-456a-b437-872727687845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4c3cad-b80c-429c-8d12-fbb62fb80221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb08583-4c5b-4278-b54f-d630efff70f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2421587b-7382-44e3-a164-fcbd68dafad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5e2a93-d43a-480b-a623-e74f9fabb8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700edc50-c528-4e72-8e6c-785f06fe5933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228dfe0c-3852-459a-a3d4-9745a8acfaaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b461c112-6795-4e87-b0d3-9c9f51bb5daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912f701d-9829-42ac-a1c2-5b7086d5c87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19071996-8d57-41b6-b4b1-54ba2367527c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee3b3229-67e3-4e95-aedf-a69af0efb69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d85ed7-0bb5-4201-a163-44dd5aa4a448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adc69ae4-3893-407c-988c-f668ccb30a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a20d10-f237-4218-966b-e78c3f5dfc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc4ad74-3f7d-4cf1-8e40-b0974a5d0c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a5d117-862b-4ae2-a520-3d6abc605adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8517342-97c3-4957-8fbf-aa743b202160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13cd4bae-9e45-42c2-b69c-92d544ec39c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a97fb02-d943-47bb-858f-d404b0eaed4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99db5243-eac5-4c20-b7ea-d20ea73278d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abeb2954-56c1-4996-88f9-1d2f391fd730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4d2d7b-e8bd-4e85-be3e-403dee2ef16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26bf3b03-db06-4ca9-b526-c0f1933a9010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9af8ea6-ade5-4a7d-ba83-28c6fbb1e353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a50aa070-8339-49b4-ab93-a53d2db6ab96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af6e562-254c-4348-887e-b0fe4c4dba5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f4fc6a-8998-409d-850b-ad696094a84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c654ae70-ee0c-4f36-80f1-3cb449f874e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c717fa5a-59cc-4ba3-803d-8abd1837a53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b71c4dac-b30f-4d9a-be34-134d3dfd7351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb829ac-c6ad-4817-bd6a-547b781f0f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8310be-4ab0-416c-ad9d-b9b3208a3222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49899e54-cb98-48da-958e-933008c92917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179342d9-4793-4e01-9ad9-8edf414911ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353dd281-b8d1-4ba4-a909-4f3283bfe84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eae6227-a8c2-4ad6-9f4b-df71b1898633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00092b47-6634-4359-a98f-7ded9533d1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063637b4-a177-4eac-87c5-8b31b2f0b24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be911bb-615b-4bef-aec7-6a7c8149cd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9246042e-9508-4946-a20d-c2800a1de2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc115be-1465-4f68-9552-59beb3051e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14faa462-c8fc-4e12-827f-8a66460123f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b8ff66-eb91-4688-9ffd-b2b37e4cee7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdbd0ff9-6141-4c82-aead-3086f9c3c157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba89eb9f-9eaf-473a-9baf-7ee369ee965d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfae0e53-8d7d-4536-964d-a1bbbc1ddca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19d3b9c-84d0-4d6b-a0e2-4d9ca72fada0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c499cde0-ff40-4ceb-8529-e492751958bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cbf6257-6365-4b8d-9c10-0e9a14dc4503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfe11da-e9d9-4b64-aade-7538902c5bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ba922e-c8b8-49ce-b5a9-68631fff31d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35092305-aace-45f8-850b-847ba9c1c187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2009fc-81f4-4a7b-9ee9-97dc329e24ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ea7492-b268-469e-8f73-ed4e43fddc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3477df-b4dd-4735-b546-c1b660f5064c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f86afe-d901-4f38-997d-957de334ee0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890f8792-8f75-41b0-9aa2-226b538ba9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4233ac4-2b7b-4df6-bf56-6cbde329a18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a344d48-24ad-4b69-aa1a-ab621d275847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63447d53-0ea2-4d57-92c2-7888dcacceef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5dd283-30ff-4ce2-a400-1e0b00d569ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5725f44-c4e7-4503-bb1a-9404fd39671b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376efcc3-0327-434f-a5bb-d5418a719721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0ee3c9-c5d1-4dc2-bba7-7d16b80da877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5d103a-0a7e-4515-9899-a0c8991343db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccf9b20-e0af-44d4-bce8-5328b483c35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89364c44-4005-48fe-aefe-12c9bfbc05c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd1d309d-dc9d-4174-85ab-0ad479251b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad4d725-da9e-4270-8997-e4b9af9f34cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379f31c0-d2a4-45b3-b95e-01de458c7f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1633d914-ddc6-4578-b91e-d9c29dd4a354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b71a762-0391-4a90-a206-fdceb5e71e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a24d4dd3-dd3f-4820-8bd3-96fe95a2b80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23cbf99-109c-47a9-a0a0-06647f5a45b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41051399-3ebc-48ca-b499-56bd914096ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aecd4e69-f0f5-4be9-920c-286e21b06843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec03b770-fcab-45d5-bbe1-9c522402ad33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 017b1d82-8eb4-461a-91e2-1b642108c8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad5ea741-88aa-4d32-93b2-3f568cee562f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb0fc87-9a76-4372-af3c-2fdebf88308d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d7f4e92-5426-4fba-98b8-dd3c2d5a35a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af165d02-105b-4f3a-b5ae-9bae3e6a5d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee24e76-de8a-4af5-aa8a-e7372eba062f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4caaeeac-1dcf-4fe7-b6c2-67c3333536c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54cd6775-c2d8-48b3-bbdc-3dd67c2cbc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd42ec9-488b-49e8-8dbe-53cd55f51cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5615b5-40fa-4f69-9550-e8db58fc85d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f178f969-92bc-41d3-af99-0cb8484715a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63dde8ac-d5e1-4fde-b349-9325d79568a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938d6345-65c2-4174-986d-4d2554951465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66488a7-0eb2-454e-9e3f-3a879bd9a353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ada430-2e91-4f1e-ab0a-599de2556873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6639dc91-27c4-4cab-ab87-fb25fa445637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fabd9f-ae42-44cf-b92c-2e260eec63dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e253c65-47be-4ea4-ab9f-9c01cdee8781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad7c3e9-8bac-42ba-83d5-dcb5065d589b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b77a026-5e28-46db-99ce-ac229c5f2cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abbb0c74-6012-444e-8f7a-daeed8585b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60dca59b-54ac-415a-9bc6-437c69201a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a62b3cb-0e6a-4cf0-9a8d-81a0d6f32d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f27fb7-55cc-43e5-812d-0aa16c88ead3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1c4d5a-caf4-42a8-b233-d422d22a9048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5805d1ef-e397-48da-abf4-38329577a581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1c0098-19d4-423d-bd5e-a8902bc4b046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d55c7c-303d-4008-b67d-ad505941f4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9837d8-3acf-468b-bdc3-f29b85ae21c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac5303b-ff56-484f-809f-0a6031f4acea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0b0971-f16a-48fc-acf3-d27c25ed1ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff069e6b-45c6-49c3-bda4-48e6db98182e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164f67ef-57b3-4f20-befc-86c1a19ad0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78c4882-736d-4a1d-bfc4-52523fb20858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfb3f97d-b3ca-4a53-aadc-397b0e917cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986dd04b-1704-4e9f-8932-68f5382e3b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c86254-51b6-49b0-8e16-d8be5ecbb690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d1679c8-41e8-4a3e-9ee6-bc71bd917286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee4d28e-1ea5-4e80-9ac1-0acf0315dab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b21bb17-3878-47e3-8a11-aacc566125b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f40cdf-0f7c-49d5-a040-d36a5dada9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331b05c3-ad5f-433e-b971-a511a140cd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bbcb2c-9ebd-4e1a-b0cb-e22180244c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6992abe-340e-4fd3-a915-8fea7777da62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b69a0d60-e3b7-40c3-9f02-7b3eae84f0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210abc4a-2dff-478b-8716-ff141bb8442b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8040324e-90ec-488f-a343-2b80f673c4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f74545ee-70e0-4efb-a715-981c8c205aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0986943-53fd-4f31-81e9-ebe66d118bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4392910-397e-40a4-9085-845b862b54b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97aeef2-294f-4c63-8d52-ce0965c31f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6b4e98-b368-4d73-8e83-caa6233a693e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5caf6657-5e14-4ae1-a818-7d0352a72c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a680c3be-633a-4fda-b2bf-7047ab14ef41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8062c950-7ab3-4f2a-9ad3-48c4a2c282a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0b1dc0-77c1-4b4b-ae41-015060b074f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2fc0c9b-29aa-4970-9fc0-74e9323e9f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51dcbbdd-9d29-4557-96a8-48442e99d683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449cd9f0-b5db-4d9b-9936-aa3db352e6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca1f2fc-854c-48c0-a9e2-2e7ae9a3746d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b03cf4a-90d2-474c-bf09-82368b46b62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0a553e-16c5-4f6c-8f36-952bc0d0f8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afe5bd4e-fb01-4757-b3a4-c5f1e0ba10be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0f3a94e-e19c-490e-a3ae-8516f8f9584c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c79d220d-405d-444c-ae55-691654b31a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7960a4-15df-431d-9784-c8ea93c75231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38532a21-5f72-45df-b133-c135872ceff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f536a1a-4b8b-49d2-9328-32680b67db23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df3ee3c-586e-4e33-9e17-e052ff96b7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22bcb2e4-54dc-4e19-beb4-d28b4400fab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4398f52b-c227-4776-9652-37a7501bb6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db12ebd-3741-49b9-b7b2-22caf2b30006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5757901-3608-4e93-8bd3-d50297cfc28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105c200e-17e2-485f-be69-4d9a1b401544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f3d46f-89e2-4996-9bae-7911600dd21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f703f2-6eb2-40b9-87de-0ca3db64f16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d78eba-5d2e-4e26-a165-0892bd63b6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d310121a-4846-462b-8999-7da98eb72386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffbb3dc-5930-41a3-ab35-6770380ed519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1bdbd0-51e8-4dd6-b10d-dcca813291cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2452af1a-0827-4c5c-951c-dd2628f2f8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d66d42-e178-4d1f-928c-756e3cf3291c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e97a9eb2-4035-4de2-bc88-e2ce35b22509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e7cc41c-da8c-418c-ac8c-59addf118255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e62efc-6869-4375-bed3-a230ef22afa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0813a1a-2808-4fe0-baf2-286ce9639843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d70679e8-9c87-4d97-8e9c-7d4857c3cbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d597e2-5bb4-4b5f-8423-e07e93464a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc749ed-adc2-4a25-94c8-646c9c029401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b98cb2-6407-42be-b955-30d8ff401be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c5ccd5-7553-47d8-bffb-98c25c095f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46e0a946-68e5-479d-afb3-8f681d57cce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c792726-8011-4dea-8009-099d805fc303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f0a08b-9309-437a-af2f-3603073dbe21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610c3a8c-e34f-4700-b687-3125546648c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e12ce1-21cf-41a0-ba5b-b3d0e08b3d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8188656d-ae22-487b-9e23-27c535ffaa7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7741b105-ecfc-4fd7-9e0e-df751df9f0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9962678-6f64-4e76-a054-4430b4af7625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cfa095d-c1f6-45a8-83f2-674cff697c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f9f72d-7717-4fa8-8a71-b96d3e7ed2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc0d5528-c3a5-4357-8989-b0598f8e3c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46160a81-c26f-467c-a559-04768ede0d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4d6715-caad-4163-97a5-2d85cd00cfb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2546533e-84af-4b93-8cec-9205431dcb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e5d8b6-3dfd-4dea-b741-0864d540cd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42f895c-deaf-4dff-a046-e848c46042bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f16905ee-98a6-4956-940f-1d53782b7077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f39a35-9be5-4b42-af75-24678d4854de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095d3d99-7304-4caa-91f6-c6785b6dcf86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0403ba9-0724-4f6d-8c45-c6668214a1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f90e90-1017-481c-9ad1-ca709edbaf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af4ba92-dc71-4b69-a4e7-02d53ad6501f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6904572f-46be-41b8-82ed-ce25fa3db17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1455b10-01fd-4a9d-9535-ca50433e054a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63d854c-6b1e-4315-a385-1165349fcaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69665166-9106-4a73-a8fd-170f20a1fc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09603386-76ff-4157-b4b9-7b1b05d7ff23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56ed09f2-254e-403c-970b-ee2f87f8d67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070a673b-116e-49e0-bffb-d2af84c1f595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82259d0a-9035-4fde-b319-5c2876024e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78db16f5-e5a4-4667-b5e9-f7ebba9c53fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0622ba-253a-4e2b-b4ca-5f3540f6644f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cada727f-40e8-47df-bae0-2aad17d46cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c3849f-d977-4dac-b78b-6d12d3dc5271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda13619-13f8-4b7d-a0ef-8ee858038081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a85433d-92ed-43b4-ba8a-bf4080fde049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ce69d2-0be4-45e0-afc2-f2ef75829d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d644e6b1-3d3e-4f1c-af82-c1b2696380b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bef3670-f6ca-407a-980f-64c5a6f82cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa4bda3-ad8f-4872-8440-dad55a7e67c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71344ef-5c6b-4210-b7c5-2b9fc7901ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5639ae9e-fece-43e5-bc71-a78dbfa69d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3aa50bd-df2f-49a2-84aa-f95928a7c6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03497744-348e-4986-b6c3-507f4f7b5d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c101d43-d2f7-4c0e-927c-4cd137cf7257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95126ba5-a15e-4274-a56b-3f6881b97407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f982dd-80f1-4665-86e1-9000a4a16341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f77847-716b-4bc3-b1d4-762507fdcf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78fa8b28-72c3-41e5-a204-6e83a535b600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94025b8c-0ac9-4f28-989b-7db38a4a1d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08711faa-9800-454b-a661-5f5d67193d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f5a29b-b884-432d-be43-2f184169263c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a37148a8-5ff6-4a06-9893-17ea61067b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131451a2-98d4-4b47-9e2e-fca67aeb38b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73c7a029-c651-4b18-8512-f7eaba8c1e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379239eb-ace0-4ee9-817e-72f9d8ff60ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d556b74-5035-4fb3-a44e-e5138cb52423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c6c9fb-6d3c-45e5-a9c6-f53048be5df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a5fac6-b80d-4c23-b3fe-1d7f4f836481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5d5aa1-fc05-477c-8bb7-79c1be297464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd47a65-14e8-4859-acb6-46ee17d8cbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87c8184-09a7-4e52-94da-ac550a32fa50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede07c27-15c3-44f7-a02f-1f3f905cf86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3278930f-9250-4246-966f-0a1cd93954a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8c7725-03df-4e92-a9e0-2d168cc3e95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc9cee2-83d7-40f6-baad-29e0166f070c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c9be95-88e9-4296-891f-fabdab6e72f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbee2669-df47-4e2b-9ad1-355be0e3241e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5253c946-7121-4036-9a3a-2d7a30b8fc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6448476e-98dc-4b95-b055-26c140013953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1dec1e4-8418-4b2f-b19c-1430373e2347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d233ae93-9833-4739-b52f-27323493e642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01863c64-0fd6-41ef-b68d-60efa3949103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01fadcf8-6bd0-40dd-96b0-a0a0c40912ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1913c6f-8691-45f0-9aa2-540c99aac474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318ba5cc-04dc-41f6-9097-8f75765ccfd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d31668-c910-4ae8-b08b-8b2094335a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 593d2ae0-e73b-419b-8536-a6f01e76312b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ab0049-1c2f-41e3-a09d-1566b79d13ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdaf00b0-e6f0-4d63-bf2f-2f803f4c6b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90673e3d-db88-451e-9a18-12c422f75d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d94a95-857d-4f50-af3c-f8689bdbabea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e222b84-9b3b-4b47-afc9-016350820de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8669f3d-2591-4650-b7bd-c86e535c024f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38053d3-e335-4968-81b7-fe91c16c3941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf544ed-600f-455b-b529-c76cae6b1ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82496294-7843-4734-85f7-830968bdc9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bccb6a1f-9a89-4813-9c77-a1bdb02ffd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9400f3ff-a536-45a1-8038-6452582966bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d632f0-616c-48dc-81f9-b0b22e2df80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ab640c-9997-4be1-a98c-e4bfb0bf2cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33951f0f-9719-4783-acf0-4af47002e1f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31fc4201-886c-472b-b6e1-75936d0ed3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698190d4-8a96-422d-a420-e3495bf305f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 077f8b31-84a5-488d-88ca-6443337e3060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b81dab1-a934-4b95-bb20-62599e2c807a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ba5031-2cc9-4b04-b2a4-d02723734f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4fb92a-d112-460c-8360-97ab5de9e1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee34cd3-c549-44c2-b29f-bddc2a346435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff06aab8-ec31-45dd-a86d-85b5228ff3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188dacdb-d03a-438e-b1a1-5d50a3cbb3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5b705b-b4bf-44c6-9c67-34af30bd51d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76af149a-fff5-41e8-b536-91ca1bbcbbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4ad900-784b-4bb5-bf0b-0402b871270c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6233e38f-7832-4436-a9e8-3b5f76280ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19da3272-cd80-4928-a3de-a99929ae13a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9a46d00-cdab-4962-aa43-80ac352b70a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ecbf9b-3dc8-4ab7-8e22-ee3d2e10446f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df757df9-0712-4620-96e8-4b627bd28d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c167a63b-5eed-418a-b0ef-1047ec393a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e231f5-4f31-4af2-8ea6-9e9d8b83ddf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d96663-ee31-4e08-8cdb-540a66455b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbd4d28-4fe0-4ee3-8ddf-0b2bf3455fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9327f960-6445-410f-8d11-29567703c49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244b49f3-3f8d-4b81-beb3-cecf4cd44922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f80b320-565b-4737-b904-530637a6b93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b4164d-143f-4be0-8d7c-e7b36d05cf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a363fb4-dec2-44c3-a496-cee09ea8608b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 266e0979-28bd-44c5-85e2-659e90461a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e5500a-df4b-4896-be0e-7d8333dff482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78d36a2-a016-4f14-844f-44fd7221d749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f83a72-1a52-4458-b7f6-41d217a41672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caea97cb-bbab-441c-b7ae-6378ce988fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45b6c48-3cb5-49e7-b937-bf67cc63bd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28ede71-d3a8-43a5-a313-c6ef095e12ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeabe2a2-9186-4a4f-bf53-861b80c32adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c93ed7b-096a-4e60-9748-0b3a881762d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7388c19f-2bc7-480b-8d1d-31288bb156db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4490022-48c2-43c8-9c6e-798ac276ad14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf781ed-1dbd-4666-be0c-026af7f83059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a15b65b-6e83-4a78-bb81-0f921d1c9e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23bd8e39-83cb-4368-8d1f-1b20107df2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376076ca-a2b7-4a67-ae94-1e21b6ea5719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23e09fa3-6e48-4704-8473-ab8805bf9c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae4d3bce-913d-46bd-95a3-12973e10c391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e70b30-8ff4-4e0d-8847-20007b2e8cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa8b762-dc8b-4ed9-ac80-5bc34f037bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f14242-39ce-4d4e-90f1-a9995dfdca3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ad15bf-a502-47f7-8a04-fb6f98e2e81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e33fea8-c151-4ca0-8bb3-e14d09c2ef0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 159b2ab9-924b-45c1-bd1c-6aa3fc43c5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0336cb4f-b715-492c-8622-7d7c16cb3c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b5a6a14-57fc-4044-8cd3-b880ead3365e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c41e64-6507-427a-901f-60e0668f76fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ae37b2-5c9c-414e-aaea-d2239ee88447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c01ddd0-0da7-4c50-8a0a-fd4a1fa839a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af06f583-e8b1-40e4-ae3d-de1028bdd682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07793f3a-4b46-4677-a94b-d1daf9a61a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda06a66-66ef-4010-b54c-44dc1aab2da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e629dda-c406-43f0-8b63-30df96e72d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea7fefd-380e-4b19-8774-84ef9c8d671b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89423ebf-e65e-4916-bbc6-319343a8adf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1948cf-25a1-41ad-9516-11aba7a6a3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc743c1e-d529-4a61-8378-5220af587c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d785a8a-1aec-4795-a0b1-aa54baf3b57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595c2b3a-5757-4222-b8b5-54af7011fe63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39227c79-5587-4ba4-a49c-4f35843f0988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b9e7820-868e-4e66-93a0-c12ff70cd10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51f3ba7-f3a4-4808-969c-56b2d6c9b4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c90325-4ca2-40c6-9661-69daac50d990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4259f34-f462-4a1e-af4f-fa64c5abdf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68105c39-4898-44cb-b195-e8cb7cfeaaa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae43e371-7a6d-40ac-8954-f5147ae97141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5b2447-925f-479e-abd4-127b6560748c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601351d3-fb5b-42eb-afc5-f4e883496187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fadcbfa1-395b-4b0e-a65a-0fcdd5b3c31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6ff657-4dd9-4956-8d7f-f61800d9efc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f150855f-bc23-48a6-a052-71021988acec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b12828-1e5c-4436-a374-97b5a3232563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10fe29c5-88fa-4da4-bc9c-963a03b19c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51eaf2e8-ef14-49b0-afaa-f0a5507f5a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1916d711-bdac-4249-939c-0a92502c5f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25919a06-bff3-4a75-8f81-ce7cb54a6439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c915cce-d44f-4cac-a7ea-7d76af9cc171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab89fe6-15ca-4343-a80d-7dbb178b1d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77409fef-4f9b-492f-a806-ef0ac500967e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a310cf72-363b-4a7b-a3a6-ff637f40380a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602ce7f5-7b02-4ce3-b11d-2acca126baa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f168c6-cda2-47b0-8a04-e33fd49d7bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f113c55-aaba-4a85-af52-5c09e7aea24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 001e3c24-2b81-4ff6-931a-81ee33a8217a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81ceea4-e8e3-469a-808c-6a11a371c387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18422e79-5cca-444c-8e7f-3a0d29ccc2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dbaa619-a6a5-4cdb-a674-72d2236d47da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f62af30-ac8d-4677-9981-f000825ead7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 044fda8f-9af0-4543-bd82-e8ddec676132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a8cee0-4343-4778-ab39-9487e952cbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5410ee-2346-4ae6-8978-c4500d4e4819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9198e610-da3e-4eb8-bd7c-fe84aa661f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3ce3d8-d7d6-4d87-8abc-d744f3c6d8f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39312309-b76d-4263-bd45-a7078aeba38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480c63f3-0054-40c9-aaad-44d087bccff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86505d10-56df-4d48-bc44-f1e71d470974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f263a10-485e-4526-a837-c2793df5bf08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8052018-264a-4f83-ae2d-a65e3e852c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e68717c8-a4d5-44f0-b6ee-8465f54df483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96cdae2d-bef6-4ebb-8e77-2eda90f67d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c629e64-091a-463a-a14d-c1d0c32f5dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e835ce-0405-49ea-bdef-0bb8af34ca41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03dfee95-720e-45ee-871f-0cdd1dee7732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a426e1d8-c89d-4846-b6a8-c06958ea52d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2afc2ca8-1096-487a-ae1e-1b13aa2fadcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369497e2-19d2-4033-9fcd-0052ec325920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8cddc34-696b-474a-98d3-a9320ab57c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf68061-1a23-435d-b605-203ed1e5baef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7150726b-17ee-4772-9f70-6e8997f84123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df666001-d7c1-45ce-b4b7-960541871d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c51ea985-3010-41b7-995f-e48027174387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94b55bd-43a9-410a-8cc6-c927fd038f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4116ea56-ad99-4ef4-b34a-7c8ee25050b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2114f6cb-50b9-4d4e-b321-81d69a10cde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ccb8f1a-3080-4e8e-9c85-b6b54d933d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a23517f-8ad2-40ad-add8-0cfd060ce453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40727845-7d12-4e84-9ffa-144f0ed7a082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3fd653-1eeb-412e-b894-c0c1b62ea0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37479766-b01d-45fb-b359-f327af9a46a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d63019-c8c5-46c7-9a7c-6182e363465d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6db158d7-0303-46a0-a7ca-c2cd7e785da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc8c4a1-3964-4db4-9f82-b5796e70b74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43eec8f-9a97-4423-b9eb-a38be554697b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa6e29e2-9bfc-4ab4-948f-1f0a41479f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34c8321-fd68-4d7f-9266-b3067e9ec6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb3b43b-89df-4467-8823-f5293dcc53a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3370b530-895b-4afd-a7a4-d2f4e430ea5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7815cdcd-79c7-4fa4-94b3-f85e3c96eaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ed7f52-3953-463f-94e3-7ad2d030d8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dcafabc-6eec-4211-b906-9f9028f06b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87660581-56b5-4b42-871c-d4fed6d6dad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9906094a-00da-4a5b-b1c0-00dd565c2014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11bbdb7d-0b5f-48d4-9589-ee93af79107b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4e3b29-3f77-4003-b6e7-6697cccb2c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b2e09c-c299-4394-a66e-1dbbcf15cd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb19e7b-614d-406e-a8a0-add4f28490ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d6b8e0-5248-4ea6-9668-21ac3159e2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00219630-e858-4ca8-9d10-da13ab07cfb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c5efda-93b8-4758-b9ba-27d38f64c069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ddf691-0088-4246-8ab0-598f4ce6da70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb21358-9267-4219-a2c6-ed5d56a6e827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989a745f-066a-47f6-9b56-dc57696d93f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89aa4f9d-3dfd-4ece-8f66-794116b44e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3aa813-7650-471d-8f4d-a19044e3bf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd00e2d3-dccd-4ec6-b38e-1172f698f1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e69df51-7865-454d-8a5e-c2223dc262cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ef8904-86af-4515-a30a-d05ea4d1d4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3373155f-8e09-45d6-a839-c087f508ddf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e262c7-c94d-413b-8a76-cb06b4050a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 897758ce-0c71-4f85-98b1-f49c76e6c8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b61156b-e07e-4409-8796-2f7b54701f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24169aef-3edc-4a63-bc61-bbc343855053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d884425b-5d47-464a-a421-afc48000b5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6757c0ce-62ff-4698-98b4-fb1da1c76b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1beb729e-c5ef-43d7-8230-7dd70579f352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa355593-607a-4401-9047-528611925864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd3a3332-d7ba-452d-8786-8628622e3c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c867ea1-cb68-4d7a-a406-6d1e3d792946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c424bb-b1d0-41fe-ac52-7ca7d7617fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcf7709-fb18-41ff-96ca-0976a7a98cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddeb8a39-86f9-48c8-a3cc-3224a9a67425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93475cdc-b3c7-4ac4-bdd5-e2557f7b51c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c0062c-3da9-483d-a6cf-ed62c88f7aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00182fa2-72fc-4619-a0d5-7aba5ea64c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd8ce4e-c867-4d88-87e9-08435447c56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c78e13-aa0b-44fa-b933-d4f5523031c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2985b6-66a3-41fe-a335-ced095478fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11843fd-9299-4788-bcb1-e75f50b6c65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35266be3-e26d-4b80-84c1-f72411d90bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5b72b8-dccd-44b9-a944-f199eb19036e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f2b096-93d0-4a40-a798-30e0456547e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304ddc8b-c964-42b1-af7f-d3fb75570640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ea08c8-3ac7-4436-a32a-360163072579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f224f2-0835-40bd-ac28-23007a830f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eaea2bb-d847-43c1-b727-eefad1c6b222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ffad6a-e457-4301-a138-fba08f522749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f7816e-e84f-4e9f-8fd6-ce21ea574729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b6268d-f532-4ca2-ac09-b94f885f8218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e17447-3862-4f89-95ac-4ac3d399dd0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e166459-6049-4d78-be36-acc1262f200e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4dac5f-42ee-4a49-af77-9e754040face
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9640f00-6085-4f81-933f-4c22299f03cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35717a20-915b-41e2-9ba6-cfd8faed975b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e69f02-f0dd-4277-b5cf-9d936ddf0061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de040520-a05b-40bd-a8c0-c577dc4f981d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f031e54d-12ab-4db8-9b0c-0e630305a4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f79a615-abe8-42d8-9d87-6f0ba52acf75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ffe607-56cf-457e-8aa7-212869defab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3fd516-2353-42c2-bd69-24c4c0a53bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8edf4623-3413-453f-8b5d-5ead0b88ad11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91754259-9d90-4f11-bc8b-6cca6d485df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18fa398-85c9-4f4c-829b-3f9fc8bb1082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b397fb-5408-48b7-8752-d45721250488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7527267d-6bd0-4835-8c6c-4ab78d99d688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3db35f4-b1d5-49d3-866f-602bd5aad578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b1d1f0-be93-46df-8275-3631dcf93343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047227de-1fbc-49ac-b40c-25a202bcbcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa7cdafa-ebf7-4bae-a6ac-fa2e026c0da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e717c530-bcca-4df1-a2b2-e0f5fe174046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320419de-1f88-4a7d-a57b-8677abc19266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f94cb96-63aa-4af5-8b5d-b04764fe13dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6a1074-e7cf-4265-882e-d14aba70c96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa103e2-9dfe-432d-860d-b5e48c28ef12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae42b654-e068-4d85-ab1b-3f90252bffe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a0e434-bf9c-47e2-a238-709703aea692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a731db5c-167d-4d5a-a969-51c2338da199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6099920-e852-421d-9d96-8c30422c38e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc41e338-d498-40eb-8fa2-64e349ffc739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0aa299-303d-442b-87f3-2dfe54a8d901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9abdb63-319d-44de-95b4-2b67e3891b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e74ee3e0-d582-40c4-9e0e-5424fc3279dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5ae417-7358-4cdb-9c24-a930b4b58e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee9f38f-f3be-4004-b6fe-363a70456e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c42071-b2b7-4a0e-89b1-d559f62f2056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40454183-3ace-4fae-aec1-7407832bb55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb66fc3c-dd62-4f5b-8d85-4a48f73bf1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e9b780-6d06-4c6b-9e57-baa3d39cfdb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13b6a5c-1792-4dbb-a929-00bb8bb1a5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ba1c7b-eb1c-457e-b76a-07374c53a0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d400d18e-f884-4593-95ba-85d4e245996e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e86c59-c440-443b-9e2f-ec49ad87151c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c05313-5656-4f3d-8e05-5f494d81bac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a77e8d-c58d-4808-ae5c-4d574a4eb4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c96b9202-2a3d-49e8-a195-4325b7cca016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7257745b-ae20-4b8d-bca4-b2a191071e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45fbeec3-8e08-42ea-8f02-3e42ed287071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73c62a21-7341-471a-ae12-22ce38287bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ea0efa-705e-425c-9cde-90a1ebab1ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397aa587-e582-4f49-a725-8b2429feb381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06506cd-bb02-4724-ab80-43a822025a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f2f5b74-6870-449a-a134-ef73f5e13fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a699b9-2dd9-4998-850a-de966d3fc512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b945183-b755-45c1-a559-d7ac4f62b2fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd22718-da7f-406a-bc0e-1f63ee19ece6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec86bdc8-c321-472c-b3c6-e6cf6c788b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be273628-5007-448a-a14a-376e0d581026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9cc42bc-1397-497a-a562-7404c2091def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9603b1d1-764e-4948-abce-7b91bd8dae83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e93b6d5-ab0c-433d-8314-adfe2fe8c026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da77ee82-b803-4f78-b645-947a17c35730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2e1abb-d812-4b04-af83-64828a5f64d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610c8b41-2c22-435f-8973-7ea7ef9a0504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b10abd-56a9-4124-91ef-32244733eac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 929f740b-31d9-4577-86cf-0dbf1c0e38d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458c3255-8e4a-4c88-986b-4201ebfb6fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1908b7-a322-49dd-9f71-cabb8cbf5ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7061dd9-1096-49e0-979a-68d242b9483e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c70c0a-f1c2-4933-8cbb-0d710d54c901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fbef45c-2b6c-485b-86d9-0a7ad42122a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57cc558-266e-467f-9fe1-97d102ebc511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e8cd5fe-69f8-432e-8752-f4a1e3ef869c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d663464-147b-43df-9064-353443030010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c406cd59-f28e-4502-b3f8-ad41c34da46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171dca1c-678c-438b-8a41-df2550243980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052445cd-d1cc-40f7-a37c-57615153a2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bfda29-74c1-4cca-96fe-caefcc156e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e5d0c99-a628-47e2-b6a2-d93895fb48cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1535401b-7352-417a-8814-972480ac9789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04dfb7b9-29fe-4298-a8d2-d99ecdee315b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836ce58e-5297-4eed-8ddb-67892e265158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ab00c1-1de1-4615-bf5f-b96dbd564c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1816a170-bc1d-41a0-bbf3-7eb057b78975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 217c5c56-a910-4207-8540-84910708c7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf0f31c-b940-4a71-adf5-bfa900b65962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddb6e8f1-d60d-49a2-8878-e8ad7fbc8d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4fc49f-58ef-42bc-8d1a-36cc614af26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52cd9ba2-6fa5-4865-aea4-49291a31fb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10322c6-678d-4dcc-924c-86812ab0a990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad9d67a-cd3e-4546-9d0a-3829b39813ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72572fa-78f2-4abc-953a-7874840e80cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44fdedc-0d30-4f0c-800c-8c7cb805890f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0566fae2-f0e9-4c60-8e8e-74b5eca4015e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7cd1707-46b7-46b0-9a64-49d74af010da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c4509f-d409-4432-9d49-5a5469f9be53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301fb6dc-4eef-439b-b3b3-592ca2413d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec433168-a7e9-421a-9606-be728e6d5c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa920133-0d3f-41e3-a9ae-a17f88445151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab14316-e9ea-4be8-b3eb-fa634818f57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2352782-aac1-4c3d-943e-c5c8164aa2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ab2a79-2f9e-45fd-9203-90ca2ad27474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd77a7f-9424-42c0-8bc8-02c7f40765ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d06e81e-229c-4288-bc8a-8d951248b21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0be1d02-afa8-4d6a-aa77-cf4a709ced53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d53bfb1-e5c2-4444-a7c1-b998c42a48cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86c8d00-5534-4661-8a74-75657ad1534d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795f9e84-d18f-4932-8c07-e6a5e637e43a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bc2313-4c13-4578-94bb-ae2d48a7d2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3a8eec-ccbc-4ce0-8526-5e4fdcf6db1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26212dd-4fe7-4218-a37b-2c734bdf4c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f844264-9cf4-41f7-ae00-9f2640563477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9064ebd-0440-4410-804f-8a4de6fcf7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bda6983-af3b-438f-9ef4-230d4730b9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9cdb14-288f-4fe6-be64-bfc0444e82be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81855672-85e8-4a1f-a0f5-d456ccc0c698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b03329f-1ac6-46d9-b9d5-b05ace5526a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cf2743-ede4-4391-8def-7e89d5400233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc47ede-ba8f-4b49-9a69-5bdb57b0375c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115e4a62-6009-4297-9171-dadd8fec9e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc19d1a-d3ad-4791-9748-3d1905d0e10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd36a564-20ff-4632-8bfb-7418652f276b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f42b276-9ce7-4ce5-a7e7-78d72ea6b6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cc9ffd7-653f-400e-9e6e-fb5f82dfa3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3e343e-faea-4a1e-8a26-3703becd5197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d7818f0-7ff6-49e6-a4f8-4c3ad7d7dcb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc8175d-8f9a-4f2e-a70f-6148d7681bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b13a0e3-ac29-4f26-aed9-f7231f20c298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a397bade-15a0-400d-af17-d0d9679337fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7898db8-bf18-4cbc-94b0-1f3f57b876d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b91973ad-f6c1-4afb-915f-1d36ace7653f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8d0e26-3b7c-4035-9d54-5f86825e3ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99492949-054d-487c-9870-a7f868e51fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921085c5-7bd4-4c65-9675-e101eb51460f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 494c6600-ced6-418f-925d-662238151f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b703867c-606f-4e84-91a9-0c138044f72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e7b3e8-2cb5-4c02-8442-a9fb4f728648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f5af7c-3cdd-4d75-a8cd-92548d6920e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2537687-6f03-44c0-9b6c-4c8ee66e2994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789256d4-9944-4b6b-8876-c2324e44b5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a64d07-df0f-42b8-af85-c9a6fdad58da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9705dd8d-a99d-41f7-b36d-36b9f9c8881d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4b684a-7df1-4f16-9583-53e3922b076e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa5ee83-6d24-43f1-94ad-f601592ca5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41f266d-2644-44a6-9069-3d35438c2a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341b369d-3fa7-49fc-b102-1f1f899ed6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f46f8f-3735-415b-9e45-865dd371fd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e6e700-d3aa-4216-8c85-2134fe6a0eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b1e54da-2152-4de9-9cda-5c1c55be501d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66308987-83f3-4e8a-8397-edeb097e15f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7030057f-a84b-4c85-9269-d361d402d1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0645035f-ad25-485e-aa00-8783e903bbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11feea3a-f03e-4ab0-9d07-82b8c9e31d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2e5ce0-8ba1-4414-8165-a741a8c6dba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34c3c98-1fe9-4b2f-9c94-bbded04e7244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d098775c-71cc-465a-a16e-660ae5ec7d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898c64fe-14c3-4e89-8d28-e6513499fc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb2b7e79-58fc-437b-84a5-d2972a55be2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb8cd595-27fc-4930-8427-9b762cd977d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabc59a0-b163-41aa-9c8d-26dc29b43b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e41064e3-e201-44ce-8d4d-6fd9af92172e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ebd7aa-5386-43b0-9d13-9a5f44aff2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b596ea0-c162-4a86-abf9-6c22e1e295d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ef6a12-558e-472f-96ee-14137f1eba8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9396dd5-fb6d-41f4-8cc6-108c32ad0a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bfaadb-2a39-4b5b-b19c-c677cd267c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a58791-a7e8-4a0f-af92-b47377a0afd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0acb3bc1-ea9d-4ca0-b859-43b516e54a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af9d4a54-20d5-4d23-9483-d4640cbc2484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f77b0e-de06-4e25-bf1c-f203fcd5a1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2950a22-2070-41a1-ba45-d69b7603685a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4d7c0c-6205-4f14-93f2-6cebb1f46490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b83aa1f-28da-4de5-8905-ce50326d566f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 635713e1-b358-40e3-8e35-f788d510a5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e56b773-82c3-4880-82fb-1b0cea5739a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e79c22-327d-4a06-8383-d5d7b52ba5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b61e2f6-6d87-46f0-bfd3-0326bcc99809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0684c365-2d02-467a-b09a-647c25b3bcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea0a3ad-b221-4b5d-a8f2-aff181df6fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9c0927-dc72-4a57-ab9a-7818b54e17fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83598987-acf8-4f87-b896-c394fa45f331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f39a06c-7052-40e6-bb22-f3804a0f361d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b64ccf-c20e-4af9-bb88-5148d2265a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b4ea93-e08f-47d2-b534-f5e88b2a9e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1497b1f9-48d5-4991-ab76-b55414781483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86626e9a-59c8-48cf-b63a-643b19e91baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc10bb0-6936-4dd4-b1b1-ae1bd11ab71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50833188-edc8-4ec5-8646-706153ef4aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f756065-8776-472c-bb0e-5ceca63daaaf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(4872, 24), y=(4872,)
   Test:  X=(1218, 24), y=(1218,)

⚠️  Limiting training data: 4872 → 800 samples
⚠️  Limiting test data: 1218 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2483, R²: 0.0029

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2500, R²: -0.0040

============================================================
🔄 Round 5 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0822 (↓), lr=0.001000
   • Epoch   2/100: train=0.0819, val=0.0823, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0818, val=0.0827, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0814, val=0.0827, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 5 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0014
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0110
============================================================


============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0747 (↓), lr=0.000250
   • Epoch   2/100: train=0.0828, val=0.0750, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0826, val=0.0752, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0825, val=0.0753, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0820, val=0.0758, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0027
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0090
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 8 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0865 (↓), lr=0.000063
   • Epoch   2/100: train=0.0793, val=0.0869, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0792, val=0.0870, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0792, val=0.0871, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0791, val=0.0872, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0789, val=0.0874, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 8 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0019
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0033
============================================================


============================================================
🔄 Round 9 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000016
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 9 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0004
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0043
============================================================


============================================================
🔄 Round 10 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000004
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 10 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0004
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0096
============================================================


============================================================
🔄 Round 11 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 11 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0013
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0036
============================================================


============================================================
🔄 Round 13 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 13 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0015
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0375
============================================================


============================================================
🔄 Round 14 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 14 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0003
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0064
============================================================


============================================================
🔄 Round 15 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 15 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0011
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0087
============================================================


============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0007
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0045
============================================================


============================================================
🔄 Round 17 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 17 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0003
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0019
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2484, R²: 0.0045

📊 Round 17 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2484, R²: 0.0044

📊 Round 17 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2485, R²: 0.0044

============================================================
🔄 Round 22 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 22 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0015
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0026
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2485, R²: 0.0044

📊 Round 22 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2485, R²: 0.0043

============================================================
🔄 Round 27 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 27 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0025
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0208
============================================================


============================================================
🔄 Round 28 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 28 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0003
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0083
============================================================


============================================================
🔄 Round 29 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 29 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0007
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0081
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2485, R²: 0.0042

📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2485, R²: 0.0042

============================================================
🔄 Round 32 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 32 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0007
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0000
============================================================


============================================================
🔄 Round 34 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0645, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 34 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0008
   Val:   Loss=0.0645, RMSE=0.2540, R²=0.0034
============================================================


============================================================
🔄 Round 36 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 36 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0029
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0084
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2485, R²: 0.0040

============================================================
🔄 Round 44 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 44 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0023
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0394
============================================================


============================================================
🔄 Round 45 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 45 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0012
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0039
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2485, R²: 0.0039

============================================================
🔄 Round 46 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 46 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0029
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0024
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2485, R²: 0.0039

============================================================
🔄 Round 48 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 48 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0004
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0063
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0038

============================================================
🔄 Round 50 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 50 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0026
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0068
============================================================


============================================================
🔄 Round 51 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 51 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0020
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0066
============================================================


============================================================
🔄 Round 53 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 53 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0003
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0001
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0036

📊 Round 53 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0037

============================================================
🔄 Round 57 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 57 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=-0.0014
   Val:   Loss=0.0975, RMSE=0.3122, R²=0.0020
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0037

📊 Round 57 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0037

📊 Round 57 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0037

============================================================
🔄 Round 60 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 60 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0033
============================================================


============================================================
🔄 Round 62 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 62 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0017
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0042
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0036

============================================================
🔄 Round 63 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 63 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0031
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0090
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0035

📊 Round 63 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0035

============================================================
🔄 Round 67 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 67 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.0033
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0035

============================================================
🔄 Round 71 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 71 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0006
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0040
============================================================


============================================================
🔄 Round 72 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 72 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0008
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0044
============================================================


============================================================
🔄 Round 73 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 73 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0012
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0073
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0033

📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0034

📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0034

============================================================
🔄 Round 80 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 80 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0018
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0150
============================================================


============================================================
🔄 Round 81 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 81 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0012
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0009
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0034

============================================================
🔄 Round 82 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 82 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0094
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0034

============================================================
🔄 Round 85 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 85 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0003
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0104
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0034

📊 Round 85 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0034

============================================================
🔄 Round 87 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 87 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0018
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0015
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0033

📊 Round 87 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2486, R²: 0.0033

============================================================
🔄 Round 91 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 91 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0012
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0025
============================================================


============================================================
🔄 Round 93 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 93 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0000
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0150
============================================================


============================================================
🔄 Round 95 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 95 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0030
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0068
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2487, R²: 0.0033

📊 Round 95 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2487, R²: 0.0033

📊 Round 95 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2487, R²: 0.0033

============================================================
🔄 Round 99 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 99 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0007
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0018
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0032

============================================================
🔄 Round 101 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 101 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0008
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0046
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0032

============================================================
🔄 Round 103 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 103 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0043
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0251
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 106 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 106 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0014
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0053
============================================================


============================================================
🔄 Round 108 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 108 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0043
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0187
============================================================


============================================================
🔄 Round 112 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 112 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0022
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0244
============================================================


============================================================
🔄 Round 113 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 113 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0006
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0077
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 115 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 115 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0011
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0062
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 117 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 117 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0025
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0072
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 120 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 120 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0004
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0056
============================================================


============================================================
🔄 Round 121 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 121 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0017
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0001
============================================================


============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0026
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0091
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 125 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 125 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0000
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0124
============================================================


============================================================
🔄 Round 127 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 127 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0010
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0010
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 128 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 128 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0027
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0071
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 128 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 130 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 130 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0032
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0033
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 132 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 132 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0015
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0286
============================================================


============================================================
🔄 Round 133 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 133 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0018
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0055
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 133 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 135 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 135 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0020
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0006
============================================================


============================================================
🔄 Round 136 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 136 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0029
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0023
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 136 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 139 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 139 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0002
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0003
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 139 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 141 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 141 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0003
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0016
============================================================


============================================================
🔄 Round 142 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 142 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0026
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0076
============================================================


============================================================
🔄 Round 144 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 144 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0009
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0010
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 146 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 146 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0010
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0008
============================================================


============================================================
🔄 Round 147 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 147 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0014
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0068
============================================================


============================================================
🔄 Round 148 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 148 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0011
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0175
============================================================


============================================================
🔄 Round 149 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 149 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0000
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0027
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 151 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 151 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0004
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0018
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 153 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 153 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0006
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0060
============================================================


============================================================
🔄 Round 154 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 154 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0008
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0113
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 154 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 157 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 157 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0009
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0008
============================================================


============================================================
🔄 Round 158 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 158 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0011
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0232
============================================================


============================================================
🔄 Round 159 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 159 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0042
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0350
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 161 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 161 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0020
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0015
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 161 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

📊 Round 161 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 165 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 165 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0018
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0057
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 168 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 168 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0005
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0010
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 170 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 170 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0023
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0101
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 171 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 171 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0008
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0001
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 174 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 174 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0004
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0365
============================================================


============================================================
🔄 Round 176 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 176 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0008
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0247
============================================================


============================================================
🔄 Round 177 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 177 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0018
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0021
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 178 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 178 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0012
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0058
============================================================


============================================================
🔄 Round 180 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 180 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0035
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0392
============================================================


============================================================
🔄 Round 181 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 181 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0004
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0002
============================================================


============================================================
🔄 Round 183 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 183 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0006
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0177
============================================================


============================================================
🔄 Round 184 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 184 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0229
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

📊 Round 184 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

============================================================
🔄 Round 190 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 190 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0002
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0091
============================================================


============================================================
🔄 Round 193 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 193 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0018
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0266
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

📊 Round 193 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 196 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 196 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0016
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0042
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 198 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 198 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0016
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0017
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0027

============================================================
🔄 Round 200 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 200 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0008
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0091
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 203 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 203 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0011
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0299
============================================================


============================================================
🔄 Round 204 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 204 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0030
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0184
============================================================


============================================================
🔄 Round 205 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 205 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0003
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0018
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 209 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 209 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0017
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0172
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 210 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 210 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0012
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0121
============================================================


============================================================
🔄 Round 217 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 217 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0003
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0001
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

📊 Round 217 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

📊 Round 217 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

============================================================
🔄 Round 220 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 220 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0023
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0098
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

============================================================
🔄 Round 222 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 222 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0006
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0044
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

============================================================
🔄 Round 223 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 223 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0009
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0092
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

============================================================
🔄 Round 226 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 226 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0019
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0059
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

📊 Round 226 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

📊 Round 226 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

📊 Round 226 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 238 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 238 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0041
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0091
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

============================================================
🔄 Round 242 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 242 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0042
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

============================================================
🔄 Round 243 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 243 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0030
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0116
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 245 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 245 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0022
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0059
============================================================


============================================================
🔄 Round 246 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 246 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0016
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0058
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0028

============================================================
🔄 Round 248 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 248 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0006
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0048
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 250 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 250 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0006
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0008
============================================================


============================================================
🔄 Round 251 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 251 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0003
   Val:   Loss=0.0688, RMSE=0.2624, R²=-0.0013
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 252 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 252 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0057
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0191
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 254 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 254 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0022
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0047
============================================================


============================================================
🔄 Round 257 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 257 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0039
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0007
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 257 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 264 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 264 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0036
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0081
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

============================================================
🔄 Round 265 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 265 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0059
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0145
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 265 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

============================================================
🔄 Round 268 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 268 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0003
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0083
============================================================


============================================================
🔄 Round 269 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 269 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0037
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0186
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0029

============================================================
🔄 Round 277 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 277 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0038
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0074
============================================================


============================================================
🔄 Round 279 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 279 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0028
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0080
============================================================


============================================================
🔄 Round 280 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 280 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0008
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0061
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 280 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 287 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 287 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0028
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 290 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 290 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0002
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0387
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 292 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 292 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0011
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0114
============================================================


============================================================
🔄 Round 294 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 294 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0026
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0137
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 297 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 297 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0008
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0109
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 302 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 302 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0018
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0142
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 306 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 306 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0014
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0019
============================================================


============================================================
🔄 Round 307 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 307 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0017
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0469
============================================================


============================================================
🔄 Round 309 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 309 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0011
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0201
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 309 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 309 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 312 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 312 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0002
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0007
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 313 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 313 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0003
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0047
============================================================


============================================================
🔄 Round 316 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 316 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0011
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0094
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 316 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 319 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 319 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0004
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0060
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 320 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 320 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0007
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0019
============================================================


============================================================
🔄 Round 324 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 324 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0020
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0128
============================================================


============================================================
🔄 Round 325 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 325 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0009
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0009
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0027

============================================================
🔄 Round 332 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 332 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0029
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0123
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0027

📊 Round 332 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0027

📊 Round 332 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 338 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 338 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0010
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0052
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 341 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 341 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0011
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 342 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 342 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0032
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0141
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 343 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 343 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0013
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0064
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 346 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 346 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0003
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0001
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 347 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 347 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0002
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0074
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 347 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 347 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 350 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 350 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0051
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0421
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 350 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 350 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 353 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 353 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0027
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0114
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 353 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 355 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 355 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0028
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0064
============================================================


============================================================
🔄 Round 356 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 356 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0004
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0026
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 358 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 358 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0008
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0040
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 359 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 359 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0015
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0044
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 360 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 360 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0012
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0101
============================================================


============================================================
🔄 Round 361 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 361 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0012
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0336
============================================================


============================================================
🔄 Round 362 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 362 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0034
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0051
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 362 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 362 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 362 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 371 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 371 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0017
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0080
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 372 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 372 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0018
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0083
============================================================


============================================================
🔄 Round 373 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 373 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0012
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0045
============================================================


============================================================
🔄 Round 374 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 374 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0014
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0106
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 374 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 379 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 379 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0037
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0024
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 379 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 389 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 389 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0017
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0006
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 389 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 391 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 391 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0102
============================================================


============================================================
🔄 Round 392 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 392 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0003
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0034
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

📊 Round 392 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 392 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 399 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 399 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0016
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0025
============================================================


============================================================
🔄 Round 400 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 400 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0007
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0018
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 401 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 401 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0002
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0022
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

📊 Round 401 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 404 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 404 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0026
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0071
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 405 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 405 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0009
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0079
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 406 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 406 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0025
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 407 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 407 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0035
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0113
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

📊 Round 407 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

📊 Round 407 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

============================================================
🔄 Round 415 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 415 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0005
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0067
============================================================


============================================================
🔄 Round 416 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 416 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0004
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0050
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0030

📊 Round 416 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 420 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 420 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0005
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0026
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 420 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 422 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 422 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0170
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 423 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 423 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0005
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0032
============================================================


============================================================
🔄 Round 426 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 426 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0013
   Val:   Loss=0.0650, RMSE=0.2549, R²=-0.0201
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 426 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 430 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 430 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0026
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0096
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 432 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 432 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0018
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0067
============================================================


============================================================
🔄 Round 433 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 433 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0019
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0100
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 434 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 434 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0003
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0051
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 434 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 434 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 437 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 437 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0019
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0164
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 437 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 437 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 445 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 445 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0035
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0023
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 448 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 448 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0027
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0178
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 448 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 448 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 452 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 452 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0007
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0024
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 452 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 455 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 455 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0002
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0020
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 457 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 457 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=-0.0029
   Val:   Loss=0.0980, RMSE=0.3130, R²=0.0082
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 458 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 458 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0015
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0044
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 462 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 462 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0007
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0040
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 462 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 464 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 464 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0028
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0100
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 465 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 465 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0027
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 472 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 472 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0009
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0182
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 477 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 477 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0023
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0075
============================================================


============================================================
🔄 Round 478 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 478 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0019
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0031
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 478 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 480 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 480 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=-0.0015
   Val:   Loss=0.1002, RMSE=0.3165, R²=0.0030
============================================================


============================================================
🔄 Round 481 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 481 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0011
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0007
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 482 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 482 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0029
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0062
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 484 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 484 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0023
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0081
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 484 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 486 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 486 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0016
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0059
============================================================


============================================================
🔄 Round 487 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 487 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0005
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0023
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 487 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 487 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 492 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 492 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0027
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0069
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 494 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 494 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0014
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0069
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 496 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 496 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0015
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0059
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 497 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 497 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0022
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0002
============================================================


============================================================
🔄 Round 499 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 499 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0031
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0146
============================================================


============================================================
🔄 Round 502 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 502 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0002
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0061
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 507 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 507 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0017
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0079
============================================================


============================================================
🔄 Round 508 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 508 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0017
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0091
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 510 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 510 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0002
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0068
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 512 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 512 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0008
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0120
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 512 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 516 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 516 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0001
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0005
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 517 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 517 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0011
   Val:   Loss=0.0662, RMSE=0.2573, R²=-0.0086
============================================================


============================================================
🔄 Round 520 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 520 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0029
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0023
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 522 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 522 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0010
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0056
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 528 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 528 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0011
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0054
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2487, R²: 0.0031

============================================================
🔄 Round 530 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 530 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0114
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 535 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 535 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0009
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0038
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 536 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 536 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0001
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0028
============================================================


============================================================
🔄 Round 537 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 537 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0029
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0100
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 543 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 543 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0002
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0027
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 544 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 544 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0033
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0115
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 544 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 546 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 546 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0011
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0041
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 547 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 547 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0017
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0059
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 549 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 549 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0025
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0127
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 549 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 552 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 552 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0021
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0027
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 552 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 554 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 554 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0005
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0038
============================================================


============================================================
🔄 Round 555 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 555 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0004
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0041
============================================================


============================================================
🔄 Round 556 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 556 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0021
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0147
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 559 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 559 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0021
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0075
============================================================


============================================================
🔄 Round 560 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 560 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0019
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0017
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 561 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 561 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0020
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0074
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 563 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 563 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0075
============================================================


============================================================
🔄 Round 564 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 564 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0002
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0035
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 564 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 566 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 566 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0009
   Val:   Loss=0.0690, RMSE=0.2628, R²=-0.0332
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 566 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 568 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 568 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0017
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0133
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 569 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 569 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0014
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0006
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 570 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 570 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0013
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0047
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 570 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 570 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 576 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 576 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0025
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0014
============================================================


============================================================
🔄 Round 577 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 577 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0039
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0026
============================================================


============================================================
🔄 Round 579 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 579 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0028
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0063
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 579 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 583 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 583 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0034
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0029
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 583 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 586 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 586 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0009
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0032
============================================================


============================================================
🔄 Round 588 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 588 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0048
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0000
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 591 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 591 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0017
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0090
============================================================


============================================================
🔄 Round 593 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 593 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0001
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0059
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0028

============================================================
🔄 Round 596 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 596 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0041
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0067
============================================================


============================================================
🔄 Round 597 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 597 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0040
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0029
============================================================


============================================================
🔄 Round 599 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 599 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0009
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0033
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 600 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 600 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0016
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0022
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

📊 Round 600 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 602 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 602 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0011
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0046
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0029

============================================================
🔄 Round 603 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 603 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0001
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0023
============================================================


============================================================
🔄 Round 604 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 604 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0002
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0003
============================================================


============================================================
🔄 Round 605 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 605 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0027
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0084
============================================================


============================================================
🔄 Round 607 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 607 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0000
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0001
============================================================


============================================================
🔄 Round 610 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 610 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0020
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0102
============================================================


============================================================
🔄 Round 611 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 611 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0021
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0077
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 611 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 611 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 616 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 616 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0010
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0054
============================================================


============================================================
🔄 Round 618 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 618 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0029
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0006
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 619 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 619 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0002
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0100
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 619 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 621 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 621 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0011
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0097
============================================================


============================================================
🔄 Round 622 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 622 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0022
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0095
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 627 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 627 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0004
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0012
============================================================


============================================================
🔄 Round 628 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 628 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0007
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0027
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 631 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 631 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0021
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0231
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 633 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 633 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0010
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 635 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 635 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0017
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0012
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 637 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 637 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0028
   Val:   Loss=0.0871, RMSE=0.2950, R²=0.0082
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 638 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 638 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0034
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0006
============================================================


============================================================
🔄 Round 639 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 639 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0002
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0071
============================================================


============================================================
🔄 Round 640 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 640 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0003
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0020
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 641 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 641 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=-0.0025
   Val:   Loss=0.0854, RMSE=0.2921, R²=-0.0047
============================================================


============================================================
🔄 Round 642 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 642 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0025
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0085
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 642 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 645 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 645 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0005
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0031
============================================================


============================================================
🔄 Round 647 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 647 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0029
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0123
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 648 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 648 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0017
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0069
============================================================


============================================================
🔄 Round 649 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 649 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0024
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0093
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 650 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 650 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0134
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 652 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 652 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0008
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 653 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 653 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0020
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0078
============================================================


============================================================
🔄 Round 655 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 655 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0005
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0024
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 659 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 659 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0003
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0069
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 661 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 661 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0014
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0054
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 662 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 662 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0003
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0007
============================================================


============================================================
🔄 Round 663 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 663 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0007
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0005
============================================================


============================================================
🔄 Round 664 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 664 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0035
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0232
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 664 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 668 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 668 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0012
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0007
============================================================


============================================================
🔄 Round 672 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 672 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0017
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0009
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 672 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 675 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 675 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0016
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0150
============================================================


============================================================
🔄 Round 676 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 676 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0001
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0107
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 678 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 678 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0021
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0078
============================================================


============================================================
🔄 Round 680 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 680 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0018
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0118
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 681 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 681 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0014
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0013
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 681 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 681 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 688 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 688 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0001
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 691 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 691 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0013
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0200
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 691 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 691 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 691 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 691 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 691 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 698 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 698 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0004
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0145
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 703 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 703 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0011
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0083
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 706 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 706 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0034
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0235
============================================================


============================================================
🔄 Round 707 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 707 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0003
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 707 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 717 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 717 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0011
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0056
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 717 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 717 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 722 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 722 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0023
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0145
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 724 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 724 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0007
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0017
============================================================


============================================================
🔄 Round 725 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 725 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0028
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0125
============================================================


============================================================
🔄 Round 726 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 726 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0007
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0042
============================================================


============================================================
🔄 Round 728 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 728 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0025
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0095
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 729 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 729 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0003
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0013
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 731 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 731 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0010
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0070
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 735 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 735 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0027
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0121
============================================================


============================================================
🔄 Round 736 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 736 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0011
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0086
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 736 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 738 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 738 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0016
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0059
============================================================


============================================================
🔄 Round 741 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 741 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0011
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0060
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 741 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 750 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 750 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0036
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0164
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 751 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 751 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0023
   Val:   Loss=0.0813, RMSE=0.2850, R²=-0.0099
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 753 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 753 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0002
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0030
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 753 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

📊 Round 753 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 753 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 764 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 764 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0015
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0056
============================================================


============================================================
🔄 Round 765 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 765 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0030
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0125
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

📊 Round 765 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 768 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 768 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0015
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0058
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 771 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 771 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0002
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0005
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 772 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 772 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0000
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0004
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 772 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 775 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 775 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0010
   Val:   Loss=0.0706, RMSE=0.2658, R²=-0.0025
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 775 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 775 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 779 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 779 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0013
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0035
============================================================


============================================================
🔄 Round 780 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 780 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0024
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0054
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 780 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 783 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 783 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0019
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0169
============================================================


============================================================
🔄 Round 785 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 785 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0034
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0125
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 786 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 786 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0003
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0045
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 786 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 790 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 790 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0002
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0042
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 790 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 794 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 794 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0005
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0017
============================================================


============================================================
🔄 Round 797 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 797 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0005
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0116
============================================================


============================================================
🔄 Round 799 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 799 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0020
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0139
============================================================


============================================================
🔄 Round 801 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 801 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0000
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0207
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 803 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 803 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0022
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0081
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 804 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 804 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0047
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 804 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 806 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 806 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0016
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0024
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 806 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 808 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 808 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0017
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0071
============================================================


📊 Round 808 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 808 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 812 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 812 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0013
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0086
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 813 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 813 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0025
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0000
============================================================


📊 Round 813 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 815 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 815 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0012
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0045
============================================================


📊 Round 815 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 816 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 816 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0031
============================================================


📊 Round 816 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 816 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 819 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 819 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0009
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0040
============================================================


============================================================
🔄 Round 820 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 820 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0011
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0022
============================================================


📊 Round 820 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 820 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 820 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 823 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 823 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0010
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0166
============================================================


============================================================
🔄 Round 824 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 824 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0017
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0091
============================================================


📊 Round 824 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 826 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 826 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0003
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0110
============================================================


📊 Round 826 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 826 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 830 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 830 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0009
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0042
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 833 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 833 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0026
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0238
============================================================


📊 Round 833 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 833 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 837 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 837 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0022
   Val:   Loss=0.0958, RMSE=0.3096, R²=-0.0013
============================================================


============================================================
🔄 Round 838 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 838 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0033
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0071
============================================================


📊 Round 838 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 840 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 840 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0005
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0121
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 842 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 842 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0004
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0141
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 845 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 845 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0018
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0067
============================================================


📊 Round 845 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 847 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 847 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0030
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0127
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 853 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 853 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0023
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0195
============================================================


📊 Round 853 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 855 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 855 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0034
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0061
============================================================


📊 Round 855 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 858 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 858 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0008
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0051
============================================================


📊 Round 858 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 860 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 860 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0007
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0232
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 861 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 861 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0014
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0082
============================================================


📊 Round 861 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 866 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 866 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0023
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0006
============================================================


📊 Round 866 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

📊 Round 866 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 868 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 868 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0018
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0020
============================================================


============================================================
🔄 Round 869 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 869 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0018
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0102
============================================================


📊 Round 869 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 869 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 871 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 871 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0689, RMSE=0.2625, R²=-0.0140
============================================================


📊 Round 871 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 871 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 876 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0621 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0621, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0621, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0621, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0621, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0621, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0621)

============================================================
📊 Round 876 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0016
   Val:   Loss=0.0621, RMSE=0.2492, R²=0.0082
============================================================


📊 Round 876 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 878 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 878 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0018
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0089
============================================================


============================================================
🔄 Round 879 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 879 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0008
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0035
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 883 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 883 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0017
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0073
============================================================


============================================================
🔄 Round 885 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 885 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0015
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0058
============================================================


============================================================
🔄 Round 888 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 888 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0004
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0048
============================================================


📊 Round 888 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 888 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 892 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 892 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0003
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0041
============================================================


📊 Round 892 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 894 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 894 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0014
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0060
============================================================


============================================================
🔄 Round 897 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 897 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0007
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0036
============================================================


============================================================
🔄 Round 898 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 898 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0010
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0045
============================================================


============================================================
🔄 Round 899 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 899 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0041
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0166
============================================================


📊 Round 899 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

📊 Round 899 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0030

============================================================
🔄 Round 905 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 905 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0018
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0063
============================================================


============================================================
🔄 Round 908 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 908 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0074
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0763
============================================================


============================================================
🔄 Round 909 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 909 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0042
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0129
============================================================


📊 Round 909 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 909 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 909 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 909 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 909 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 909 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 917 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 917 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0041
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0154
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 920 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 920 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0018
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0085
============================================================


============================================================
🔄 Round 922 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 922 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0023
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0109
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

📊 Round 922 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 927 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 927 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0025
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0188
============================================================


📊 Round 927 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

============================================================
🔄 Round 931 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 931 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0028
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0167
============================================================


📊 Round 931 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

📊 Round 931 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 934 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 934 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0001
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0013
============================================================


📊 Round 934 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

============================================================
🔄 Round 938 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 938 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0003
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0163
============================================================


============================================================
🔄 Round 940 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 940 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0009
============================================================


📊 Round 940 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 940 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0032

📊 Round 940 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

📊 Round 940 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2488, R²: 0.0031

❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
