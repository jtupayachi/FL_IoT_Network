[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 202f1a84-7cd5-4f1d-971d-a91b5ab0ebb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ef69ab2-d997-467c-9066-b8d7de3e55af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e268b73e-695b-4e61-9c10-1461d613ac27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054ce978-fdb1-4324-8cd6-9714481b613d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40594da1-65f2-4fe7-82e0-28da6886d16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31afcf1f-e7ac-4ab3-8ee7-d4d0415027cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ac01c2-ffb0-4ebb-b410-f009a6932ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b3a7af2-1485-423e-940a-c22392558190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432d3dd1-891e-4776-b783-ec343ea6a7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c4a906-eb16-4b22-b9e2-a88ce31b3436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b146f866-1022-4118-b6f7-fc1a884cb5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9750d9b-f6ae-4c5e-b968-41b47b4bba9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a330f5-caf6-444f-b02a-bb56f78642d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cbc49cb-5615-40ac-8365-bf2be9e06196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c484f2b-1d0c-4ed2-adc9-eec7c8850c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6ced8d-4085-4cd3-87e2-a51aaed839ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857a70fd-7fe6-4660-b303-6aa8e50de709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2972eae8-d7a6-4491-8028-ee492349ef30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0ec9ce-f158-491f-96ab-a2fbe5c08167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc05b014-22df-4e89-a1d8-68d179a55800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088784be-b819-4973-b05b-f8e45f21a78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f437bd72-1056-429c-b01e-ccdcf945baba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d87a8e-c927-4dec-b890-21b3062ee22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beae69f4-d200-4f32-a959-33774adc4a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663765dd-004a-4464-a1b8-c7810d737b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af64949d-e7f2-4f80-b5a1-0be529c023c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc48dea1-21fe-43ff-b55a-5028c8fe6b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba16cb4-d3c9-46bd-9cc5-be3755e04c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321bad6b-27e8-4488-bb0a-8dbca56af451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac18edac-fd06-4cb0-96b5-7510a40878e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef24eed-2230-4b02-8760-8d38f429075b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580c268a-ddc6-4573-abef-85e18ac2db71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e40a8765-908b-4905-be30-b64a0ed768ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b49036d8-7c27-4c5a-88da-290dacf561ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b5381c-942a-45ce-995d-2962267837f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35f5ac2-3dac-4750-84b7-fc772712686e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299eaf88-3e6f-4087-8deb-bfb88490cb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931bd51f-de09-4afb-8515-5baf6be23db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d20ec7c-2874-4b2d-b894-d98d638530bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94c1a9f3-defa-4370-8b31-a300283b48dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6843f154-443b-4c6e-bbe4-b0c5ecda7d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a653fad6-abc9-45ca-aabe-7c5677ba570a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e015f36-4b47-4f86-8573-95fb93c76f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc43dc70-3d84-4c17-8bd9-66f69a41cc77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db442b55-b569-4ce0-b2a0-23dad379afe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d83ad7-5e7a-4d73-9208-d475cec27be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d487c462-1bc6-4467-92cb-83021340bbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73c47f9-c828-4b1f-ab1a-cfd94b1cf62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1488cebf-deea-4dce-bd24-cdaa2773e2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05cff7cb-360f-4073-a669-71ef63091d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8efccae2-8f6b-4c0c-a23b-2d21ae6c4681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 860df9be-b4f4-46c9-a9a8-ca66016260f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6e7a013-4b7b-46e4-b132-d6ecaab02ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9d33fa-4627-4537-84d1-bc9990a00eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a857774-f8b2-445d-a1e7-28dd967ab421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cd4d01-1a83-45e4-bafc-5e74d5ba5d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c23f82-880c-486d-b5f1-2c61233f755e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317143b2-99df-43eb-976a-ef9d9bd835f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc096849-2058-42f7-b60e-1771bde24e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82799631-2d66-4d42-bddb-b16606e9a8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a2ad0b-e92c-49cf-9ef3-a26b21721981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a207e0-bc69-4a22-8aae-e46046cade9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd33ee60-97ba-4bb8-8278-5abaa10af1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19cf6dde-ff98-4227-8659-0706e54a5f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9681ab2d-c42e-4556-9493-78ae257ac840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc31472-b4e3-4da5-98e5-217a3852acdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a539b9a7-0ba1-46bd-ad76-d2139e2a0b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ac85e6-9a4d-43f3-85ed-6899e79a2136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1afc90-cc3f-4fc8-87ad-fdcb20a26a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b787559f-7ac7-418f-9cc8-1062e21517dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad21c169-0ce0-4294-a113-69cea5359f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684e0440-c074-4828-a7bf-c3ed18ad06e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04b4e90c-b62f-4baa-a101-72d1a1b333b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4e01f8-310c-44c2-894f-871c988ac2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b88f91-4e21-4d31-ad34-315c0e629f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba92efd1-ef00-45fa-b478-f425fd233a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d1899b-aa4c-4b03-a2f4-ea895e2b480a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a8b565-a7c0-430f-9ba9-a64efea403c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4cbc63-732e-409f-b127-df69b70ce9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fac6642-0898-4ceb-ac9c-2cfdfe77ba77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e50707f-a904-40ad-89eb-1fd7be416bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111dbe9e-497d-49c7-a2a0-cb20401afe20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfd9f1c-b7d2-47cc-bd5b-c3fc99d61611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06bd1cc-7025-4e7a-8ab0-cd3a5b48006d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25924a75-d553-4ce4-83b4-7e471208a708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55498343-c0b2-45cd-adbb-16d5110c085d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39bfdfee-227b-4cab-9e7a-a29c756f4881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c52906e4-5768-4806-9f35-f6dc071624d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15600e2-f6d6-4d1c-a9b1-b20f253b0996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01598f67-12fd-4c79-8f7d-47a4eaf1720e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7aa0ce8-f603-4bdf-8bf8-df9ea553aa23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 270e0635-6438-484f-9ed4-7027a520a479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485ccc12-5698-44d1-8f6e-e6d6c38bb6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d13dcb-cf7a-4461-968c-607d564ea371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a328061e-d4f4-49c6-9015-06952d4da450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f634c5-4db8-4d4f-99e5-52d8069a214b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 332a69e4-15db-4d66-895d-342d796f91ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a419881e-d124-4865-917c-62c7775955e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90bef273-92c5-49e1-98b7-77d6baf33586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51fa5444-423a-4f0b-b405-f2ed3a4ebb8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb22845-be4d-4c93-a2de-26e1e6b86b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9358da8-1746-4cbc-a359-c983c00c60ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a6b46eb-1537-47bf-b653-5bee4e408874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62696d6c-b2f3-4eba-a7e8-f4e29e5bd8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8743059a-68aa-4eb7-ae2d-faa1af73d0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0772dde-2f01-4073-8e5d-248098cdfe59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 477ab43b-f9ab-431b-b363-2b6e04ab2eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0dfdcde-bf79-49c3-9810-0b564df9f4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29823a12-dc5c-41ab-8361-3166f4d2dc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc07175-7b41-42f7-9bc4-95c7657eb51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30eeefc5-2162-476b-a95f-60743c30fd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42bed2cc-8bb0-4ea2-a69a-e969dedc0078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483f71c1-684b-467d-a0fc-20007aa863ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97285fd7-f317-451e-b553-087905782a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ebb576-53cb-460d-9e5f-931eaad205e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc1bf93c-e4c9-4ce2-9c95-c7bc56b14c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e824705-2242-43a8-9e9d-e12cdf5db222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a69b9a66-4334-4ba5-8f02-1ca575d8400a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4389fdf-b884-4274-9496-1bcb50dae83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44bbf3d-559e-407f-8cde-437a3337b827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2ba625c-4d41-4c7b-89a3-9f9a8a5bf643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085f031a-64da-48bb-968f-7e4c6307b518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5799ef7b-dbb1-4cc9-adf7-be66c5eb0a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 526f2867-3269-4c67-a028-6d5b7be7c468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9643cc3e-7aef-44b0-9ee5-fce9f102bbe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d78324-3c0d-4b71-aa94-2991bdc441c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8cb9b2-b951-43c6-bc59-3a1ffb36c7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30b9c3a-e1c5-41da-bd55-ef5fba85abdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d29714-0e58-48aa-9d40-7fc0ae9c209c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c683cfdd-b8b8-483a-8b9d-7d7b39bb1ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bc0376-0f7f-4bc5-a62a-9d2a34315e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417384de-a748-41b8-8e9b-f52dd3db75f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e5e350-fba5-487c-851d-397a94896058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b1455b6-4573-48ea-9849-48a018d7edb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab281bb-9f2d-4f91-9c40-04886fa6cab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034b5ce1-9178-4318-acda-812f2cffd647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d368e4-b4ef-410d-8008-e24733a069cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89caa1cb-b3f9-4115-b98d-6ead2733fe91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b5606d-8ed3-4b86-936a-89d0db7f4974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b053028c-38f6-4a02-9cbb-74438e999457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e4d1d7-e784-4e79-9fa9-87b3183501ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d84494-3668-41c4-b05b-b933964aeee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3502a7-6b92-4955-b7ff-f15442cce939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8577af4f-d8e4-44ed-b0f3-1fb684fd7d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac623d6-e7ea-4da9-bbf8-f0137628632f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc259aef-5564-4745-b05e-5f484facff1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f47519fc-e759-4198-a333-5eb1688f29e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0985a59e-27f8-48c7-889d-a4f85d1dfd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6088499-5b17-4e04-9a24-7221842c6bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a14bd1a-22e2-4fdd-b0ee-f39b9c51a950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ca39b3-73a6-4233-879f-2118f41b2cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084401ac-dbb1-4641-a240-1bbe896805e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287b88f5-9fa1-4f69-a879-ba56d7e010a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21bd7869-19e5-448f-b0c5-46951a74047c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d59a7e-1996-45c2-833b-1243446c0452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaacfcb8-bde3-4db4-8d61-d70ffd139e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7277e567-be30-49c1-b234-f6c2be69a19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a053b67c-4460-4b99-93b6-8909548f1c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c63f706-8fe8-4df0-8be5-b6d81f1b79cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d51de1b-b06d-497d-837f-624053674da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bebe274-4462-44ca-bd35-f29300a9800a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d799a1fb-16e2-4562-b096-13065bf00fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b074a8-01b1-439d-8930-933c331bf464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e482d572-7296-48a6-b67b-fdc86569003e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f589ca84-bb51-46e0-a914-90ac10a34a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0a76a8-67d7-4d1a-98d8-f0a34cdbb053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73d5a82-b744-4f77-8e09-5a499471bd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1a4b64-2bf2-4f86-a159-9698727640a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c562f580-9943-47b8-9e6e-4209a06bbaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd40ceae-110f-49e9-ab68-3c7811fbe5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e41d225-259e-4f1e-b96c-65ad898f5c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c02010-e0e5-4646-9dce-c822b362a055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb748ce-f888-4f27-a9dd-ea51e8453a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 254c059a-4b79-4120-87fb-b88a07934bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1d01ef-3e41-4826-9a30-f3ea9b01dcd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1919b4-143a-4360-a63c-c88504968af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5764ca0a-6574-4e7e-8dd2-0d3949217814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ad1f70-9cb3-4695-89b5-186113a957d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36afa0f3-415f-419b-b495-3fc68ee93d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea6d5d0-4175-438a-8f3a-624734befe99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c962f7-fe4e-4543-96f3-1c6a171d4b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d858d69-c495-4071-a06f-55733699a98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89df5762-6b61-4650-92f1-825935f3c66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f673f55f-549c-451a-8d30-caa581cadcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c871ac4-2b7f-4a0f-be94-96f1b15d0e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16459cd-699d-46fa-b231-4f47f2d5e379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12de4649-3cf8-45f4-80dd-146fa8994858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 990a327b-f59f-4666-ae78-56fce0d349f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b95340-aa13-412a-8e44-800433a8eb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e46ef76-c951-45e9-8a3e-ef45020697d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6ae460-cf5f-4632-bef8-d16ce0f95239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcef64f-c41d-48c9-897e-1477d80d7c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a22dd4b-6848-4162-b080-89dcc400f683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1a866a-2ef2-4f07-8729-77f68115d09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 998f34ea-3214-4088-a6d9-8cb166469e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728d80a4-70c3-4d33-bd67-44fe83d2ba13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8163a723-d072-4969-ac56-da7699dda850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8dcc23-c4e0-4ead-82f7-3830021421dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc42b4f2-21ae-4233-aeb1-74dd3ddfaa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d986f83e-3897-4ed2-a58e-b3e7ea6b21bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bcd1b8-a565-4e4c-93ee-df1ab10d3262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3441cd6-404d-4d93-846d-061009ff5eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ff105d-2c92-4c61-95da-333d75d44f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdcfda3-6dcb-4c17-865c-5af09168acc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a939bedb-fcb9-40dd-ba8c-3e4e69ca4878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4d540b-6fe2-48a6-88a6-7d604dd8c758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb42409c-1366-431f-a45d-1a611d6edf48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4498f9-37a5-4677-841d-1f456b38f225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa56d6e-3663-459c-a703-1cc0a86188b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98af3a88-0872-4b8a-9857-8eb73d5f6a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16edeeb7-f627-477e-ac0a-2b49e03191c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46cdb0cc-37b9-4375-b1a3-1f405b21b7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec47e89d-4ffc-48da-8463-ab40204fe741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17d967b5-917e-489c-9ea0-ecf4556dc164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea5c8ec-6772-40ac-b334-9ba3ffc51159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c03a334-0a00-4c55-8f8e-5ff4d4201c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e8b648-e4f4-465f-a58a-005f8d4825c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d935ccae-909b-431e-8efd-5b1e50b152fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e396f8ef-7488-4782-bb5b-92544f7d86c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e10c7cc-9306-4862-b8e4-37085b9a57b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4daa155-e333-4050-8fd6-ade85d107e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5565e069-49e2-4dcd-b862-3097fb4fce90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c38d4d73-5fa1-4809-94e2-51039fedac00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dda2aa7-c4a0-4218-a6d2-40f59cd46a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9f90f1-6840-4dec-af73-cfd6d833b6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31cda66e-6248-4f4f-a205-7c764527cdc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2dd3c90-6641-4cb6-bb25-36854d83c906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dacb9cb-eeed-417d-a589-eb132d13863f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897cfeb3-108e-49de-8772-394552f83cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96181c44-8b3b-44b2-96e8-38117c61b20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c07704-7fb4-4ead-bab4-d9975b4de96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9808266-d682-4af3-bd8d-07336de9aa0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6b8ee2-2b19-422c-b04b-9b64150e9d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a103c75-2922-4ab4-9c20-5150c3cc38b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617bf6d0-cef0-4e1c-a43d-94bb831a1d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1aaf22e-09af-416f-93ac-33752c185178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50a6ed1-790d-4633-bf24-e6f16a12ea83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371522d4-4bf9-453c-854a-5d688e014420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b81459c-95ee-4144-b786-c8264dda8c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 364f01bc-474b-43cb-bef9-068a7c3f59d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aae3838-5199-4d3b-966a-c45d3247180d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b32c7e01-146f-4de3-bb57-3af1136ec788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 560ddb5a-03cc-4895-ad5f-69dbf951be63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af590e70-9732-4c92-8a51-4fca10bd7ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c582030f-31ea-401a-b72e-956c6f3b4971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 003f34e6-b4a5-46a9-a515-fcddf70b53b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6296b129-432a-4857-882f-69b9460244a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f3f42d-fc84-4cfc-b9a7-4bf0cee31cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1084ddb6-5863-4b5f-9b9d-91cd8bb2ea0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae3b7b39-836b-445b-ab49-c863ee91c6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea97315-5b21-40c8-bd92-d6f68890d986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce4385e-4c6e-4a80-951b-9791c642f0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ee6d19-b0b5-4686-a7ac-8443fd1e3032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5fc422-948c-4c99-a801-662979685e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e80b6f-0403-401d-bbff-af12512bf80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4708b2-222c-4fee-82ac-9e0febb2c8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4acc5274-2e4f-4ec8-9a36-29097808fa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a8ac1c-3139-4d7e-bcb1-2da24d6c4a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835ab605-3519-474d-858f-1bac3ead8794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac9a757-3fbb-4c54-a69e-7d9145ae82af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c8d23a-b0c2-4817-8c7a-03ce679f7b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546ab966-d799-4450-8109-cf9605412c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e049d0a7-47ea-4f88-802a-7551f11dbc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a888ee7e-bbd6-4cfc-bb33-06a6c4e30532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da0e5f1-9c71-46ce-bcd0-9945d2edc1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0494a963-4195-459f-9c38-7ec483068fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299c7c45-4700-44ef-b74f-a41a6b6643df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7abf1e76-72d4-4d01-924b-91d5261f157a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a780a95-59fd-4e8a-b911-f67c3f18114d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b3bff5-e290-4ed9-a2cb-7635e08835eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cba1524-e924-4681-8cd4-249b35d3c214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0798f5c9-da12-49ec-98e7-c01dbb213d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 032271aa-a04a-4ad5-a3ba-fb63ea96d912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9719a4ff-3649-42ca-88ab-4653fc18b3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c10488-662d-46ab-a655-08232cbed5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 792f3967-3439-4935-8d01-c48c8bb363b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9c7afc-b395-4c80-b414-51ece654eaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204caa61-fd23-4c04-b2cb-8f8bd129816b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2109f04-dd0d-4121-8e2c-63251c16fb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0ba8a0-0f29-4b79-9ffe-576a6f947df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4541dd-5aff-41ed-8a0a-e9c079a3888d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6d8e43-5595-4663-a3e1-77328d26557f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e382c18-fb4e-4426-b643-78446894301c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09fa3157-27f1-4c75-8e26-49285dae4718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1663dab2-dedc-4c41-b6c0-c0d7481c0818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360a17ef-9c73-4961-84ca-bf2fed4d652f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0dad933-61ec-4ca6-b3ed-0166ec63e0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd786dd1-8414-436f-81a8-271bf6fbc08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d182d140-89da-4692-8350-ae9b511a408b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45f5f8d-fb0d-4db7-b9dc-1aece9d78c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33538ed-bc13-41d8-b50d-0913a42077c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb35505c-2595-40d4-b9e4-ddb3a0eef71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9958b4a5-9b54-4585-a531-b6144921083f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 103a8d09-3800-4754-bfe3-d1ce0c1bf6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 420c2d61-4027-43b0-b302-e5708dfd4f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c7d989-9bbe-4a9c-b985-642fdccefaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f28720-338e-4934-81a7-025e17bd8748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36b53af-56f6-4d50-a570-28b80bf85cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa1cccb-a972-45ae-93e7-f5cd65bb0a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb02e43-bc54-466c-b51f-566efc6ecb50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49d4b1a-91d6-4220-b926-d812b5b59281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51622cdb-c511-4e9a-b5f4-05e7aca77283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e04bbca-7efd-435f-b82f-151b14c4a688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ed741b-9e07-49c0-bd31-d011b281a9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac7c532-35d6-4204-b94b-610d79a8521a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f85d22-493c-477f-9521-c91f6f8cc0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff09d5b9-7f98-4827-9c92-2b56bd7309f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6977fe-a721-4c28-8a91-a9b9ecc5253a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb603f88-f42b-4797-a225-cafc427a2390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e8f2ed-201b-4ec2-a1b5-6e0835d086d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11df4ba9-2249-4fd0-83dd-51a05d5c5b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2fceec-36df-4c9a-886d-55408a170692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862a3fcc-3aab-4334-a96a-9a0841ccde76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a10ace0-1282-4900-93d8-e88cab567c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f67ff3e7-2810-4f68-b54a-71600f4f96da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb239ac-cf43-4769-bc4e-1715b16fc886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8786d119-afdd-4827-b194-b2f0d2e1a4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73928faa-b2a1-4b4a-a62e-beac89675c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f31569c-51ac-4d28-b551-f09763eacb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef10d1b4-4ddd-4af3-9209-7b1419e19586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f347127c-4742-492f-8737-d695245784d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f7eea8-490f-415c-83bc-b480fde9c900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f279e4-c86a-454a-9f89-1bfdba2a9ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af92cb54-8d1c-492c-a31f-dc6dd47973c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d51e359-b994-4015-b9b7-c250a8920430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cefedc5-9593-41b3-a737-3c462fd51afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885cb715-d29f-4f9e-af35-c14ca9466a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49b7a46a-aeb3-4490-a443-788430deb841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46384c93-4614-47ac-b1c1-8e21e6728098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf3524e-8c9c-4891-bfae-599f7447951c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d0e1206-e81a-4e09-ba83-b67a9778334f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f3217a-9879-4dde-aa94-04041ada3cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ed7140-b6e4-4cae-bbf2-b881df8c56e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df629a69-f6ed-432d-9d78-750a3228cd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304e4fb3-3c3d-476f-be7b-df206b9917ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d92658d-a32f-4608-8736-5c59ba1851b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9535fd3-5ead-49cf-a302-31a0047e2b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3912d94c-02d7-4daf-9785-90f2eeb98f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee8db1e-e7ed-477a-9b43-89bfe337133c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b90adbb-62e8-4aca-bf56-05409c0317e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2faf96b-03ef-4603-a6eb-92bd93bf1d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57e5084f-be51-4c1d-bbb3-215dd54a1d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f52d0e-be2b-44c3-bc11-0f3bd020a76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3de2d281-c625-4280-a82f-efc81c52696a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f73e6ff-f4b7-4adc-bb68-ea7a017aed73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f1b115-e94f-4a5d-b07e-492167fdb5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de8dbc0-38ad-4cf2-87b9-67035f10f001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23473516-d3de-428b-9f93-f2ce79abd997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7bc9487-1575-4e03-b1bc-197937293b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf4f972-7933-4259-be48-77e0de9c8dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 711246ea-1de1-43aa-a1b9-0cbe0908396f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 467e7b64-9842-48db-8f44-162b8eea49ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8126f2-f4bd-4154-8fd6-bf3d701e7d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57344ed-578d-43a8-9f5c-07543075134b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59aca5f6-a500-439b-b3c8-dc5a5d4dd1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2fa0bf1-7201-4585-aaf9-16a63715ae5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e2bb17-046a-4d9a-874a-3eef16d17d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5ec284-0053-44a7-a219-cc5803c6f393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b28a20a-f947-4699-99c4-de5cb3bef38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e97a7542-6712-485f-a9e7-b3cd233a71cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3234aea-04de-4a9b-8d3f-2cf099e53d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af4aa925-a959-4dbf-a304-fcdfa338d642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6035c4ba-2a0e-4bdd-a3f6-d18e5fa46902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 635dcd26-2207-46ca-a024-64ff43211fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 014314f4-94e8-446d-a433-1de776165fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d03a8392-99d5-4cff-b33e-c06797436da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83f7a3b-8cbf-4fcb-bd45-f34492494fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2116560-28c3-4205-b238-208f65fcb6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb879c1-6a47-4182-bf10-03c65999d0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abaa620d-2969-4f36-9032-2e903377403c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86023d6-6f93-492f-9e70-4c663fc76ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a99f114f-ea04-49c5-a611-fb97458f9f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a94d7e9-928e-4198-b8f8-f5a030b5460b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6b70cfc-4e0b-4aa7-a562-287ef3f5d7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf570c2-9d1f-4292-aae2-434cb072328f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0e8852-dc53-47ef-bbb2-47615279cb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab850349-c420-4382-a2cc-a26b796ab918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe00a9e-7269-46b4-bb2c-47c99b4d7504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae1135b1-f031-4d79-aee4-b9d529dc0b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25c3ae5-7ff4-4da0-8573-70ee8e402af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e1665a-37cf-440a-9373-12f3820ebb80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e11bc35-02cb-4198-9be2-9af3bba021a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067a926f-04ce-4008-93a9-51b73f4c1ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b3de8e-27c0-42bf-8092-8dec5a12df8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784af6c9-e334-437f-bd62-69128521babb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28728a4a-d9f4-4549-91fb-2fd7ceecb071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa7722d-b06f-4b15-80f8-ac4ebcc07b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f934131f-6e83-4168-8fdd-4871011e8a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06db7656-984d-4de6-ab23-fc68173e0db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25c08c9-0c43-4b2d-8458-16ed7acc9bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25aa068d-3931-45b2-a69d-31ab94922abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be55a477-2e89-4366-b41b-6ab64e730bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572f0641-874f-4ca3-b6b5-183ca991142a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e58dc1-eb47-4417-b016-f4b0b0196832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a2ded1-040e-4fce-984a-30ae7c1f40a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a1bb6a-ed01-469f-abb5-cdf43fe8af5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e646030-5f01-487a-91b3-da46fa28405b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98c69f0b-75d4-4b48-aec0-260db2f73d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aaa3534-0392-494d-abdc-0d5868d82005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef9d8fab-4138-4e37-b770-e33d5b3242b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ccd04f-85ae-4d75-b6b2-259e324331cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9603af10-113e-40ff-9061-e73a6227c859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89479516-7b23-4338-a68b-d2cb2275be86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff53710-505a-4fd5-b319-fa51dd6fd77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89945be-71fc-49c5-b49c-3bfead55a53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6668cfcf-3740-4871-836c-85cbf72692b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27d52e7-ef61-4ce4-b2f2-69187e68022a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e07897-7905-4a39-8937-87e6e91d22e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e1a2bc-900b-4a2c-ad07-5b9f2751a2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c73cf2f-70e2-4fcd-8442-716f7f7371da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bccaedce-aebe-4095-9cea-936385860467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375ee7a8-a67a-432d-8be2-a6a03461b741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9642bd41-380c-4bd9-925d-70c3db51daaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50617b62-598c-4a41-b2b1-46086bd07641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e31d93d5-8730-46fc-b5a1-b06d51dafdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49235e5-2653-4a3c-abcc-48af66667dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a435a41c-33ff-4792-be60-b87e31105e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8517ad5-6cce-4f1d-9815-6a9a366f0991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac0e33e-b3f9-4e03-8dde-018be891ef82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2fd1dc4-dfff-45fb-8a80-21a15055a418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74b027f-2211-480b-84a0-d134a79c77a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ace4906-ee96-431e-ac21-1752558bc367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e21717-dc87-4915-8e72-60d2fe92eed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419a8c1f-576d-4fd4-81f9-dbc2aa2ef1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecfbd4b3-c161-495f-b23f-1c9c78b784b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482a329f-fc20-436e-927c-6cd75460e97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ec3188-aa97-4d94-9692-a5859a6407b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619d63c5-424d-4496-b50d-4e3406489740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e73e9e-49a0-4a6b-a6d9-ac96c7992bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8870f30b-0c34-4c28-a9b3-768e9ca561cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10c00647-9155-4ac5-8743-747b20283246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a886b8-0bb0-4eb6-9a84-252f6ae55be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78529c08-6f1e-47d3-8fb7-447b5243ba3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdaf2f4d-37ff-4a12-a6ac-51747b3958ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bdef057-df1c-4fab-bbff-dc2d9fb8127a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 398149c3-a9aa-46f8-9c00-18d8cb0177ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1058b9b-5779-4c4c-b25d-ecdebf608087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b043e2-b21e-4391-a168-f6bbb2b4ff80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a317dc33-8280-4e53-8c7a-d1b9647dceb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b734704b-2af2-49e9-9507-9da12a17fbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecfc0e7c-232c-4543-a2c7-a2cbe21dfbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6508eb13-914a-4f01-8113-dc59f4aa72f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b7a418-f547-4adf-9172-19c2cbc875fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7a8969-eeb7-4a5f-96cc-a21e7128ca06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a91ea56-c123-4a67-92e6-10ad230af15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d35f0238-4f41-4333-9e52-7ad331363daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a389df30-40eb-42ca-8056-0cac94bc7fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12be71d5-bee4-4859-8f49-f3e5cc2257ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be86b286-ced4-4303-a7fb-a0a06c50758e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bd941c-0779-4ecd-9ee8-e007fa3341cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7467ed0-c055-4516-927d-ad2b28834fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ebe59f-ce67-4c76-a861-3edb241e97d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d98bb1c-f1fe-4b3f-ac43-44cc8be43c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fecf57d-9d54-4361-88ba-31807980ced7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e36293c-ed97-467b-bdfa-30e2885d7b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661182b6-7421-4388-b478-7fbdafa3ca92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c53c04-4365-4ee5-96f6-56fa4c992662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c57f838-3695-4d92-836e-7b5271033893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e584a2d8-770a-41b4-abd2-e3f7fa441f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41fc7a7b-4450-42f9-ac53-00452ee08de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05176477-0af7-4e42-8d46-e1606810f2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bee03e9-d8ea-46b5-8727-b946c5559104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c9be86-52c4-4ded-8da4-b03035180461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3559d25f-8b76-4efc-89c4-80d35ec34487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa36f2d-2bf8-42d8-8151-900840ac33b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c0f46d-a7c7-4b49-9cb7-2fdea1cbbd07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b835a59a-2061-4677-89d9-78ae77f7fcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4c08d1-1660-4348-a244-b7c903fd0c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6e8d33-ee0f-41da-bc9e-6cab87a5b3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc9d481-75bc-4be5-afaf-656b0f4204d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac17b41-ceb6-45dc-be8c-9c451f748308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3180c9-d543-446d-af74-adeaa6a831bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498a6880-9b7e-4130-983f-a7dd5840c568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523152e9-3c5d-4ed8-925d-0a1d0f71bb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 160479ca-2357-4574-beeb-9328dfa174d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ce8756-b627-4131-bbc9-78dacd3381de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e32e19-1e99-462f-a908-0f0c825fab71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01a7d98-0a17-4bc2-b2ba-cca8784e5587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1154606-c4ca-405b-aa46-bb6c1c9ff780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3980feb-54f9-45b2-b5f3-59713d617522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3c8e83-759c-4e8c-840e-fd6679f4f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d6d8cbf-5111-4a89-8389-c32cdec0afa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3692e384-c8b8-4d35-865b-946c1b7633e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89e0ecf-df8a-4e9f-a001-3f9ed1b19ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606db7f5-ea3a-4875-ae8e-fa3455f35999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957251c8-a6de-4db0-859c-b4a602529f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a53dfe-f066-4609-b984-64ed11f239d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141b3d48-a123-44c0-b458-970a3090768c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dde07c83-38ca-4864-81e5-8619f6d02d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2cc799-45ab-496d-b0c6-0f0b5065c992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fab3104-8f33-4384-a816-645160e66f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b7daad-021d-4072-88ce-c00d5149246e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d4dd4c-9db6-4b10-a5ef-373feac86596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703eebc5-1e83-4399-9c07-8ab930284cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12922a01-7e74-4342-b750-ef39b796c722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f48285-819d-44d1-9979-1e22c9855cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7300c031-dcf4-4c1a-b2b1-8b50e2f3fb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1053a633-e478-4975-8c30-bffcb8b3b469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0cff83-623f-4a99-98a1-0362c3621e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 800b6473-cf58-4e55-b2e6-c3575341a619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc87fe1-2fa7-440a-a967-511268b8d96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8e8992-1354-43e7-aa63-4c08e949d404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25015595-c3bc-4018-bd0d-47df62e47b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54108883-ec11-416c-a966-f39022cd7088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9591a62-84e3-44d1-b09f-eeede68e5646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f186731d-ffa6-4565-bc8d-d800edc4c908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224e6c63-dbef-4d53-9b1c-e6d0ffc066d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8857cd-8082-4f9c-978b-594ced13b591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a86c7d0-7c3c-4502-ac8e-a4d093460d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7a8949-3d45-478e-8014-cd95493ab3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc0ac37-45ab-4944-b0ea-aec4fe8f76e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c356a10e-c4c3-42ca-afac-16b3c7bc12f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29920db4-3b90-464d-8b53-8f5ade0fc3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c9f1a8-9778-4cb1-8b4e-3b09de9a1019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05595e21-424b-4478-aec6-172c43dda746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f090ef-7111-4248-9ced-c6d013be0341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3547fcde-6a61-40e2-a922-3fef9244054a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fc419d5-4c0a-4ef4-8774-bf76305ab668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14829134-292b-4836-aba0-c8f74729dfc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3905d19a-e53a-4b5b-89af-94a42882fa5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bde2b0-e8a9-4f9e-9aec-71e965e2427c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d20151a3-ac24-4826-bc64-570c182e6b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ac464f-5d1f-43db-8fea-aacf38c29715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1ba2f1-3807-433c-afe1-b64e26bbe59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40467dad-2572-4792-a0d9-02d9bb156b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3949aca0-4cfc-47af-9a20-b7215ae915c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a65d6e-75d1-4478-a94c-ec3bbc46497c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b85ef4-76f4-4559-83e1-1db7392b8fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7fc04ad-65cd-4b61-9682-0978af339d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2957e99d-7f6a-4bb9-97b3-0186665cfec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bea2ee-a222-4281-beb4-47eb7643801e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d2e406-0c30-4497-ab38-b2b9ab026f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c0c65c-57b0-489e-a5a7-ecf79786fa9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad04dc8-e5bd-4ae9-892d-f0b029370722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d5d198-747f-4533-932b-3676c14b8562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e779d958-7f26-49be-84d2-d91ef2795557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f910ba-f3ed-44ae-960f-04b4b7101544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 679ef115-ade4-4b00-bb7b-91047b6bd69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57df22f4-2283-42d4-9e81-11c0e690f363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3142f94-1c6b-40da-9924-53c58141b073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef141f8-bfc3-4706-8fbe-4c967a097fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1218f87-d9ff-4eb7-b215-635990526028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f0a080-2070-41a3-8528-ac6a4a05fe1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81000c9f-b2e9-41b1-86b7-3128fc9723cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2ad429-7a63-4f86-970f-330ac83fa238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376be0f2-2698-4ef1-bf30-65cc8643a274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a173def5-2f7c-4da0-8a49-9e4beb6dfb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9d4c022-2aee-4217-ae68-d60954f89053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f152cd0a-6f1c-45c3-9d02-50ff6c3fb248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98145a75-35e6-43a4-b692-946ce35133d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de8d5dd-d2ce-412d-b0f8-11e52632959b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a531a67b-2679-457a-88d9-164b53c718de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b163f4ef-4472-4755-85fe-6ceba9ade72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a6509b-55d0-4abc-979c-f0bdaafdf2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f893b037-7cb0-42fe-97f6-8e605617a883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7471dbe2-3ea2-4cc6-9ade-2c55ffd946f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 660546fb-bc74-4935-9912-dd7b4df8c7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d659c8-8086-407c-9183-7834c525de5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f3ced4-cdd0-4435-a7eb-785523e8d27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df150ae8-a418-4e11-a71a-e89752678de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f063e33d-8889-4f4a-9cdc-c3409d8ec87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d73b7ee-e814-49be-8f92-f1057d224339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d41d33-00c4-4025-a930-8318425a854b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf62b49-14c2-4ecd-8b74-21efcb4058a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2c9802-22c2-4f05-ae31-a71263ce76e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f355b3a-b916-42d3-8e83-9d902f7dc118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a0244e-8f88-45bc-bd92-7573db53b57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d5eb40-f769-4e85-92c3-05fcd5e7a7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff11911-0fd8-4b70-b677-a56595fa27a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9438ba-46f6-4647-b3d4-be11c328362a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d85b5ce-ba09-4bbd-85a2-f0b6fc92fcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b002f5-3888-4518-b2ef-0337ca4a0e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11271b8c-f11f-45d6-9e7e-3ecb07686d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b49566c-fb74-41a1-bdee-4ab7f8282856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17594142-8704-42ca-aa78-06610a004b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd6d0876-fcdb-4ad7-94d4-8422b826801a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 734d8080-774e-4f9f-a0ff-8cc3371d2c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a907759-9016-4790-a637-a1416f35d305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebfffdb9-d6a3-4b8c-a216-d77618952e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a9f127-e5de-4e56-8e37-338457d10e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c24d02-7e07-4188-bff3-07ef1c3434ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58fd14ac-a18c-414a-a571-b59e09f22e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0aaf6b3-1761-4afd-a13a-4123313feb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f040cc1f-a733-42bf-ba9c-e743b7aa41ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5121de31-c062-4100-9139-69750ccef8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2f48e1-c1eb-451e-b7b4-b617f1b3f1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636356d1-df9d-47a5-a812-6eaf6db4c605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94691130-655f-4fde-b8ae-61a911bace8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cfb742-d461-474e-9513-9a40d0687e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb96683-18c6-48c5-b29a-aa4e77559517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 066aaa95-ee75-4e98-be2e-1c7323f4ef58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc4c062-5bfe-4fd1-81fc-17e9f0cc1b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eccfd258-9972-4115-be0f-4de0b44ee4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1303397-8ee6-4e2f-874e-2438f6f0329c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 637a9ee3-9fc4-4061-b853-66b2be798308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1295d6-9677-471c-999d-ae33f134adcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99fbb77f-69c5-4119-86bb-e89da7558136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9293f2c2-6815-4678-99b3-5dc0c177a9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a464be4c-3da0-4761-8f4a-079f53d4f3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba3ea4c-559f-430d-b9c7-acb7bdb08e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dbc2de8-e215-4cdb-930c-e9311a6e1aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80dc36b-ffd8-4e69-8c04-40ff803b1a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b0604e-0391-4990-b24d-d627bcf00081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8f7441-ccc9-47de-8c9e-6bc7d570fdfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f51407-3a7d-4123-aa04-834e2c9f6be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05680ee-3f8a-40bd-9204-6ec66b063645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ec480b-58dc-44f8-8eab-aabd13dcf594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31289f26-4111-4ed3-a5e3-e711e9061f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b23e8b3-e83c-4e52-b90d-37d6f66c0aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f116880f-6d84-44c7-be70-c7062bbd9670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20597baa-32c4-4e42-b2c8-d65be1b82916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6a5859f-a8e7-45f3-9317-4fb1d2989e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8197d0e6-74e5-4014-a6c2-4338c2effe8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bedcb7-1633-4b38-841c-3965422cde36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41303215-9d7b-44ec-b7b6-1b8be54324ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d52aaee-0f1d-4c7b-bc25-785876dd0616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e50ed98-5b61-489c-8b83-1ab5aaeb8444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6e708b-bd9d-428f-8052-710f81325d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bbc215a-9ed5-4304-9b37-4c9ee3b9fbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbaf5f29-eb88-4738-9e75-98bdb6ae3651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76bbce65-972f-4fca-898c-19d36dc18134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58af6d4b-5b73-42d3-8258-44ac5633ce6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 435aeb4b-d02a-4af5-a7ef-a804206675fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1cf2ec-9f90-4d56-8bdc-606c9f42bd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ceadd05-3908-4ebd-ab00-e7cdad01f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de56ecf7-32e8-44d4-9293-7dc88bd177bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8d4a06-cd2d-4c94-853f-d9ceb51e202e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a34a7248-041a-43b6-975d-5d16eeee73fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d62642-f1e6-4e46-a8ed-f9077dc686cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e17208fc-b56a-40a7-96ea-4b251b52cc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146e6aa8-4915-4ff8-a410-60fb73ff9946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee5cf03-5ed2-4e0a-9fe5-88f526c50b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6bc76aa-197c-4233-a8fb-ab38813544ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac4a37a-5880-4bed-97e9-bed15be10823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b38f6cfa-320d-43dc-ac1e-3e4a873f357c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598f2bcb-0571-43e6-8d1d-a94a26d4409e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d00555c-d197-4f74-a1ae-0c253bab07bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adc1a2d7-3933-4b99-873a-9506e51e70d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29efada1-4ad6-4e54-ad01-47a0586cccf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2358284-1f29-47d2-953a-81966a16edcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03384fb-0cbe-4cec-95c0-25170c154716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6750e20c-de00-4dbf-9834-0f23d7461228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb33a1fe-ea02-43c9-9ba1-b9317c560e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97236043-4bf6-42b5-b812-96285458cac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6274aed-6e87-4299-8372-b70c394b4d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd05bbb5-4e27-4eb5-996f-05a5619f1e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b191859-53a8-4108-8598-277342816f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45f0d0c-dac9-4653-94a3-4edcb5387242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88822019-5595-40a1-9c86-43ef0eb3803b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f0286b9-90f1-42bf-8b34-57bfdd7b042b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58c96a0-903a-4c54-bda3-1c46dc97940f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c583e0-8b17-4ad0-aadc-d5449b617cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d600256d-f343-45b1-ab20-82772d2e493e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1939144d-0cb7-4db1-9114-52b796f14fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d900331a-af44-4aab-962b-14855ffc62ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32fc528d-52ec-473d-ae51-4b11a762caaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebcd9439-7d2c-4f4b-9927-149c61bb8a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 840dbd43-5298-42ca-b66d-a326f5dd9d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da310d91-fc06-4d18-a955-e20dd25946c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601d54df-e9a6-49bd-99f8-ec6bbb395a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32ffd1a-c2b9-49d9-b74f-54aa0fdcfbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe298fa-d201-453d-bf78-b618234c8bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb05af0d-3701-4f26-a199-ef0823e9480d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44426b73-eda8-4e15-a147-f71ff4d32c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611395c1-72ac-4f8c-8574-b385410ab820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf0f8df-289f-4e95-9c90-85f8955c9b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0849ef56-cfde-4e51-abee-6fd122cd7250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c21c66-72de-4050-82f9-798eb96daa47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c447f1-c402-4fa5-b83a-d4a679f83a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e26f15ad-4503-43f1-8c6a-3d7edfdfabf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ef32e1-8343-4ea4-88b5-6c1346ca60d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951e015f-a700-4ef2-a5de-2853082beb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b6487a-9cfa-4f9e-96ec-1e5ae4a3f8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05716f5-61f6-4911-ad42-7e6845d53c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8de3c00-f89c-497b-81d9-8830670cb93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e91a32a-1c8a-4745-88ad-060052778a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e7b81b-b1ec-45a6-a80c-84f6db4d6a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91d6f64-594b-44a0-97ac-6effe97b0a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 674d598a-8878-4c69-ab6c-52d44e42255d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9faf6338-64fd-409a-a605-98d293debcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d96c4505-7328-4e55-984c-50aeba2c68a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32ff680-6d1d-4be4-9435-21a4a6f57049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c561edd3-f6d5-4bc7-80e0-935f6f62d3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce819996-e707-474e-87d6-a2c13a33df04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c376bc8-9a87-494a-b5f9-abd808911ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4159b28b-b902-49b2-9b4a-530317f1a1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cbe764a-a7ff-4064-8e0f-7b87b8a64d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3ba92d-a7e7-44ac-bb8d-a8f075dfd22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c705733-eeb5-41b2-917c-78b5715c94b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db45872-d023-4385-b5be-ff49e5601b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3f1288-4350-41ea-a813-3cd69c9ea0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723e125f-bf62-4e6f-94c8-5027827056da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88eb878-7e90-4c17-8679-4292c72b33ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9bd787-8a15-41db-a989-bd17e563749a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 243fc16a-9937-4d43-a235-79364974c257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f505e17-693c-4957-ae01-ae737bfbbc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8345c358-39ed-452d-9fa7-0d40ec9818c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9a9d75-0f6c-46c6-bf04-1d0f83dbea16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39eda025-38d0-4234-8f43-58eb22f79403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ab0e57-acd5-4a03-bb27-1bc5eed48a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ccddcc-a768-46d5-a53b-9f4811e4cf71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2f4597-d224-49c4-b59d-06734331ef3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26589f63-5ce8-4743-90dc-6b8c31e97875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94856d84-59f5-4a42-b3e5-1bf15d9e18b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3d7732-0169-4a6f-aee6-c1d1d3d4cc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c35a8df-3398-41ac-b8de-8c6087c1789d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7b979a-07ed-49e3-a6f9-5995268ce77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5396fe4f-0e01-4d0a-a25e-5bbae7be9bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5765866-6e12-47d4-9de6-2c1e920457a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 165918e2-920a-4dd2-889a-ff7acb24370f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a64d81d-9ee4-4877-b4c9-31cb9ef18fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f087e08-a2d9-4e0e-a49a-800988a579e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f5f576-ef4d-49e3-8547-5c4766d0005e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed967cf-0b95-4280-949d-50956c723f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2c34a1a-48e4-4ab0-a35d-4e28b0cc9e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f0e9ffa-9b49-4bcb-a930-be9a94c9f36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f94ce75-0f9a-4483-b5e4-4baca9bf6c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89620fa7-e8f8-4c8b-b4d6-c36fdffcb534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9fa8be4-eca2-4d1a-a05a-39d4a9535279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa088e0-1f6a-4591-a53e-7a556555e183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a7f4b1-62f3-434b-ab72-382e28854304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bdc61e0-b182-4779-b6ea-ba930047a689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ac5fea-2dda-4100-9ceb-d12d4bc61140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a323db3-833f-47dd-8f28-a45bfb49344c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35be6985-b41f-4c47-861a-e264ff7b00f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87323495-5f9f-4b7d-8dc4-a031022c2eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846caac5-a92e-4261-b4cb-256e7bfef645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556c1854-aeea-4132-a771-70330bb7458c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c49587-e558-45f1-8053-61d69c9f4651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c8c6fc-7207-470d-a82d-03a24bf9aee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b162a2d3-3f1a-4dff-b4a3-2a65d1c51ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446eb305-056d-499f-8cc0-88bb318b4b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c60f2f-dd18-436b-a692-ef6bb01eb988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf10ce7b-f789-461b-af27-277f17b88eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaaecd25-71f2-4ab9-b976-e964e3e95cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d8c654-853f-4b34-abf2-75f709744bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6141d3-c667-4eb2-9d47-e9e2ad088913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98987158-5f64-499c-9dff-a696a12fa5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a265954-ff91-4e03-a4d5-b9921a9d6e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c520cc6-9064-47ed-90a1-7e0d01e84520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5e0d2cb-4e5d-4ab7-889e-ffd28c9de9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963b5038-ba3e-434b-ace4-8fb20c7938ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1413cbfb-358a-4ad2-87de-d9dc9a8e6dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b20800-3c6f-4099-bf16-d4c493f23acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69becac6-2efd-4374-9df7-709994cfe37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772c59e7-734a-420e-a39c-743c0c91856d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9029ae-b056-4d4e-bb74-0a6e925232aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd376d33-7b4e-4cb5-a384-d4637a35c92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5e842b-c0cc-49d0-bcb8-003b8b028225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc6b36e-0088-4ecf-a833-b5b6f9ebb044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a790265-b9ad-4a49-8333-921f97e0b7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa0b1bb-f4fc-40ab-ba1c-b907875ad58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c298da-49a0-4f88-be98-56d9d5f90730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46369fe-2a99-442b-9038-b8012d210bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b2f807-492c-4094-b53a-e1618e04b828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82d5b072-fcd1-4812-8e41-8096b7192f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48fc34c4-8013-4980-8860-66a1e23ae4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d09408-2c8c-4e7b-8ffc-0655b609e0bb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(6688, 24), y=(6688,)
   Test:  X=(1673, 24), y=(1673,)

⚠️  Limiting training data: 6688 → 800 samples
⚠️  Limiting test data: 1673 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2457, R²: 0.0024

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0844 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0840, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0841, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0769, val=0.0845, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0117
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0090
============================================================


============================================================
🔄 Round 15 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000250
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0816, val=0.0784, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 15 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0067
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0051
============================================================


============================================================
🔄 Round 16 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0718 (↓), lr=0.000063
   • Epoch   2/100: train=0.0827, val=0.0725, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0826, val=0.0728, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0729, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0825, val=0.0729, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0823, val=0.0732, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 16 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0072
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0410
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 18 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000016
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 18 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0072
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0018
============================================================


============================================================
🔄 Round 19 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000004
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0802, val=0.0829, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 19 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0056
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0038
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

📊 Round 19 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

📊 Round 19 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

📊 Round 19 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 24 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 24 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0059
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0114
============================================================


============================================================
🔄 Round 25 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 25 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0078
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0049
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 26 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 26 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0065
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0046
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 29 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 29 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0054
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0052
============================================================


============================================================
🔄 Round 30 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 30 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0065
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0015
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

📊 Round 30 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 33 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 33 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0023
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0135
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 35 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 35 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0047
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0048
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2458, R²: 0.0024

============================================================
🔄 Round 36 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 36 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0067
   Val:   Loss=0.0691, RMSE=0.2629, R²=-0.0014
============================================================


============================================================
🔄 Round 38 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 38 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0057
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0168
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2458, R²: 0.0025

📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2458, R²: 0.0025

============================================================
🔄 Round 41 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 41 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0066
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0168
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2458, R²: 0.0025

============================================================
🔄 Round 42 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 42 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0086
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0099
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2458, R²: 0.0025

============================================================
🔄 Round 45 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 45 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0048
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0076
============================================================


============================================================
🔄 Round 49 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 49 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0023
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0167
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

============================================================
🔄 Round 50 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 50 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0047
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0161
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

📊 Round 50 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

============================================================
🔄 Round 57 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 57 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0065
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0006
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

============================================================
🔄 Round 58 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 58 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0061
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0023
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

============================================================
🔄 Round 61 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 61 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0061
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0024
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

============================================================
🔄 Round 63 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 63 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0041
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0095
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0025

============================================================
🔄 Round 64 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 64 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0036
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0054
============================================================


============================================================
🔄 Round 67 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 67 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0056
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0024
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 70 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 70 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0072
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0185
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 70 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 73 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 73 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0038
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0034
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 74 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 74 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0057
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0025
============================================================


============================================================
🔄 Round 76 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 76 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0034
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0124
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 77 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 77 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0061
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0014
============================================================


============================================================
🔄 Round 78 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 78 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0006
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0018
============================================================


============================================================
🔄 Round 82 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 82 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0079
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0087
============================================================


============================================================
🔄 Round 83 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 83 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0068
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0056
============================================================


============================================================
🔄 Round 84 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 84 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0026
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0146
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 84 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 87 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 87 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0077
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0054
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 87 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 92 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 92 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0068
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0013
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 92 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 95 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 95 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0015
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0184
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 95 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 99 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 99 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0038
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0100
============================================================


============================================================
🔄 Round 100 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 100 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0049
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0046
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 102 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 102 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0044
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0010
============================================================


============================================================
🔄 Round 103 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 103 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0034
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0103
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 108 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 108 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0033
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0090
============================================================


============================================================
🔄 Round 109 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 109 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0043
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0005
============================================================


============================================================
🔄 Round 110 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 110 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0045
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0036
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 110 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 110 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 122 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 122 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0093
   Val:   Loss=0.0738, RMSE=0.2718, R²=-0.0234
============================================================


============================================================
🔄 Round 124 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 124 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0044
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0040
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 124 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 126 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 126 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0049
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0025
============================================================


============================================================
🔄 Round 127 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 127 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0074
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0078
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 128 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 128 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0024
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0129
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

============================================================
🔄 Round 130 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 130 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0013
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0020
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 130 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0026

📊 Round 130 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 133 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 133 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0039
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0046
============================================================


============================================================
🔄 Round 134 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 134 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0050
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0020
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 135 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 135 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0030
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0088
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 136 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 136 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0042
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0049
============================================================


============================================================
🔄 Round 139 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 139 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0056
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0004
============================================================


============================================================
🔄 Round 140 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 140 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0036
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0081
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 140 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 140 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 140 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 145 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 145 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0042
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0034
============================================================


============================================================
🔄 Round 149 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 149 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0009
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0200
============================================================


============================================================
🔄 Round 151 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 151 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0047
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0018
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 154 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 154 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0022
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0153
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 154 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0067
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0052
============================================================


============================================================
🔄 Round 161 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 161 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0056
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0027
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 161 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 164 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 164 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0011
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0166
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 164 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 166 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 166 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0033
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0039
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 168 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 168 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0003
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0537
============================================================


============================================================
🔄 Round 169 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 169 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0048
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0017
============================================================


============================================================
🔄 Round 175 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 175 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0068
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0054
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 175 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 181 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 181 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0072
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0309
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 182 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 182 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0059
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0008
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 193 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 193 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0037
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0100
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 194 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 194 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0003
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0038
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 195 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 195 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0097
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0203
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

📊 Round 195 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0027

============================================================
🔄 Round 200 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 200 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0065
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0015
============================================================


============================================================
🔄 Round 201 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 201 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0028
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0004
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 202 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 202 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0045
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0022
============================================================


============================================================
🔄 Round 203 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 203 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0050
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0038
============================================================


============================================================
🔄 Round 205 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 205 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0082
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0298
============================================================


============================================================
🔄 Round 206 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 206 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0083
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0420
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 207 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 207 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0065
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0094
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

📊 Round 207 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

📊 Round 207 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 216 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 216 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0067
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0106
============================================================


============================================================
🔄 Round 218 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 218 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0061
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0116
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 219 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 219 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0031
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0099
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

📊 Round 219 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 225 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 225 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0020
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0069
============================================================


============================================================
🔄 Round 228 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 228 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0075
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0168
============================================================


============================================================
🔄 Round 229 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 229 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0062
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0035
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

📊 Round 229 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

📊 Round 229 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 236 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 236 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0063
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0010
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

============================================================
🔄 Round 237 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 237 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0058
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0004
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 238 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 238 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0064
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0092
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2457, R²: 0.0028

============================================================
🔄 Round 241 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 241 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0053
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0040
============================================================


============================================================
🔄 Round 243 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 243 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0049
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0054
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

============================================================
🔄 Round 249 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 249 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0089
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0276
============================================================


============================================================
🔄 Round 251 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 251 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0028
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0110
============================================================


============================================================
🔄 Round 252 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 252 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0069
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0033
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

============================================================
🔄 Round 255 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 255 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0044
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0175
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

📊 Round 255 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

📊 Round 255 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

📊 Round 255 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

📊 Round 255 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

============================================================
🔄 Round 262 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 262 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0076
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0075
============================================================


============================================================
🔄 Round 263 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 263 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0046
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0066
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

============================================================
🔄 Round 265 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 265 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0030
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0093
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0028

📊 Round 265 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 265 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 265 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 270 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 270 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0052
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0040
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 270 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 274 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 274 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0027
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0080
============================================================


============================================================
🔄 Round 275 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 275 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0055
   Val:   Loss=0.0674, RMSE=0.2597, R²=-0.0526
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 275 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 279 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 279 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0068
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0048
============================================================


============================================================
🔄 Round 280 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 280 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0014
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0179
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 280 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 284 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 284 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0058
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0029
============================================================


============================================================
🔄 Round 286 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 286 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0069
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0129
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 286 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 290 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 290 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0054
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0031
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 290 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 296 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 296 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0035
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0065
============================================================


============================================================
🔄 Round 298 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 298 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0032
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0012
============================================================


============================================================
🔄 Round 299 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 299 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0022
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0029
============================================================


============================================================
🔄 Round 300 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 300 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0041
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0052
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 300 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 307 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 307 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0073
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0329
============================================================


============================================================
🔄 Round 308 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 308 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0059
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0013
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 311 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 311 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0045
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0039
============================================================


============================================================
🔄 Round 314 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 314 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0031
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0123
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 315 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 315 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0065
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0061
============================================================


============================================================
🔄 Round 317 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 317 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0058
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0002
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 317 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 321 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 321 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0033
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0117
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 321 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 324 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 324 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0025
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0139
============================================================


============================================================
🔄 Round 326 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 326 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0075
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0135
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 326 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 329 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 329 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0068
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0208
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 329 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 332 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 332 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0061
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0051
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 334 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 334 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0021
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0140
============================================================


============================================================
🔄 Round 335 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 335 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0028
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0031
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 335 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 335 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 340 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 340 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0075
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0051
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 340 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 344 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 344 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0057
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0099
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 344 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 346 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 346 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0046
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0060
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 348 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 348 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0038
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0204
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

📊 Round 348 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0029

============================================================
🔄 Round 352 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 352 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0015
============================================================


============================================================
🔄 Round 353 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 353 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0087
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0197
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 356 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 356 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0024
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0118
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 357 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 357 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0059
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0049
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 357 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 361 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 361 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0010
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0033
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 361 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 365 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 365 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0045
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0104
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 365 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 369 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 369 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0042
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0080
============================================================


============================================================
🔄 Round 370 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 370 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0049
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0010
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 372 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 372 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0061
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0137
============================================================


============================================================
🔄 Round 374 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 374 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0041
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0082
============================================================


============================================================
🔄 Round 377 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 377 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0039
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0096
============================================================


============================================================
🔄 Round 378 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 378 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0025
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0012
============================================================


============================================================
🔄 Round 381 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 381 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0039
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0068
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 384 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 384 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0057
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0112
============================================================


============================================================
🔄 Round 385 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 385 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0013
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0020
============================================================


============================================================
🔄 Round 386 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 386 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0058
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0054
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 387 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 387 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0046
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0066
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 388 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 388 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0063
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0012
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 388 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 392 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 392 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0042
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0088
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 393 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 393 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0056
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0090
============================================================


============================================================
🔄 Round 394 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 394 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0066
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0112
============================================================


============================================================
🔄 Round 395 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 395 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0065
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0008
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 396 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 396 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0060
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0011
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 396 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 396 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 400 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 400 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0030
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0129
============================================================


============================================================
🔄 Round 401 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 401 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0055
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0037
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 405 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 405 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0078
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0082
============================================================


============================================================
🔄 Round 406 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 406 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0038
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0090
============================================================


============================================================
🔄 Round 407 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 407 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0058
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0018
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 408 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 408 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0021
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0117
============================================================


============================================================
🔄 Round 409 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 409 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0031
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0097
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 410 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 410 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0010
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0195
============================================================


============================================================
🔄 Round 411 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 411 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0020
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0141
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 417 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 417 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0017
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0040
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 420 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 420 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0046
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0036
============================================================


============================================================
🔄 Round 421 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 421 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0072
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0061
============================================================


============================================================
🔄 Round 423 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 423 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0043
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0085
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 424 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 424 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0067
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0173
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 424 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 424 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 429 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 429 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0020
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0009
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 432 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 432 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0052
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0035
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 435 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 435 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0058
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0027
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 437 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 437 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0085
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0074
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 438 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 438 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0082
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0070
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 438 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

📊 Round 438 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 443 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 443 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0033
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0081
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 445 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 445 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0051
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0845
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 446 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 446 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0043
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0080
============================================================


============================================================
🔄 Round 447 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 447 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0070
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0019
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0030

============================================================
🔄 Round 450 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 450 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0022
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0012
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 450 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 456 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 456 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0072
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0088
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 458 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 458 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0042
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0091
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 460 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 460 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0087
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0105
============================================================


============================================================
🔄 Round 461 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 461 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0049
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0005
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 463 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 463 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0069
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0021
============================================================


============================================================
🔄 Round 465 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 465 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0072
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0191
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 465 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 468 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 468 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0077
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0089
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 468 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 468 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 468 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 476 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 476 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0058
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0257
============================================================


============================================================
🔄 Round 478 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 478 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0076
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0172
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 479 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 479 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0027
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0137
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 483 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 483 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0067
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0017
============================================================


============================================================
🔄 Round 484 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 484 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0038
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0034
============================================================


============================================================
🔄 Round 485 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 485 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0066
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0001
============================================================


============================================================
🔄 Round 486 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 486 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0067
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0011
============================================================


============================================================
🔄 Round 487 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 487 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0060
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0020
============================================================


============================================================
🔄 Round 488 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 488 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0036
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0119
============================================================


============================================================
🔄 Round 489 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 489 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0062
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0304
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 489 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 489 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 495 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 495 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0044
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0055
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 495 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 495 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 495 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 495 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 501 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 501 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0047
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0024
============================================================


============================================================
🔄 Round 502 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 502 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0026
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0118
============================================================


============================================================
🔄 Round 504 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 504 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0058
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0022
============================================================


============================================================
🔄 Round 505 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 505 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0070
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0110
============================================================


============================================================
🔄 Round 506 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 506 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0028
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0069
============================================================


============================================================
🔄 Round 507 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 507 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0030
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0048
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 510 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 510 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0041
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0082
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 514 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 514 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0041
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0101
============================================================


============================================================
🔄 Round 516 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 516 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0068
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0073
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 517 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 517 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0076
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0040
============================================================


============================================================
🔄 Round 518 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 518 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0059
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0028
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 519 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 519 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0039
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0101
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

📊 Round 519 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 523 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 523 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0062
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0017
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0031

============================================================
🔄 Round 525 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 525 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0037
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0110
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 525 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 529 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 529 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0057
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0012
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 530 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 530 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0033
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0018
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 531 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 531 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0046
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0028
============================================================


============================================================
🔄 Round 532 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 532 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0035
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0086
============================================================


============================================================
🔄 Round 533 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 533 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0079
   Val:   Loss=0.0686, RMSE=0.2619, R²=-0.0156
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 533 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 536 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 536 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0072
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0019
============================================================


============================================================
🔄 Round 537 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 537 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0015
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0079
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 537 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 537 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 542 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 542 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0030
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0017
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 543 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 543 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0074
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0087
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 544 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 544 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0026
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0124
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 546 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 546 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0054
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0011
============================================================


============================================================
🔄 Round 547 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 547 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0055
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0044
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 547 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 549 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 549 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0005
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0036
============================================================


============================================================
🔄 Round 553 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 553 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0080
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0139
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 553 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 553 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 553 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

📊 Round 553 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 561 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 561 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0027
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0107
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 561 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 561 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 565 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 565 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0063
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0067
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 565 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 565 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 565 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 574 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 574 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0061
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0066
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 577 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 577 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0051
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0061
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 580 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 580 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0024
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0003
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 581 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 581 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0036
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0107
============================================================


============================================================
🔄 Round 583 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 583 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0054
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0192
============================================================


============================================================
🔄 Round 584 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 584 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0036
   Val:   Loss=0.0654, RMSE=0.2558, R²=0.0073
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 585 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 585 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0062
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0110
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 586 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 586 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0058
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0160
============================================================


============================================================
🔄 Round 587 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 587 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0067
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0128
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 589 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 589 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0037
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0099
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 589 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 589 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 597 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 597 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0085
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0086
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 600 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 600 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0059
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0423
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 600 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 600 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 600 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 600 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 609 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 609 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0044
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0092
============================================================


============================================================
🔄 Round 613 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 613 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0049
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0024
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

📊 Round 613 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0032

============================================================
🔄 Round 618 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 618 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0044
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0084
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 618 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 623 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 623 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0068
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0011
============================================================


============================================================
🔄 Round 624 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 624 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0020
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0212
============================================================


============================================================
🔄 Round 626 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 626 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0075
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0119
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 627 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 627 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0086
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0104
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 628 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 628 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0028
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0032
============================================================


============================================================
🔄 Round 633 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 633 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0072
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0019
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 636 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 636 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0049
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0032
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 637 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 637 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0066
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0069
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 639 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 639 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0016
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0016
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 642 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 642 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0016
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0045
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 644 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 644 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0069
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0023
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 644 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 644 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 648 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 648 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0055
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0040
============================================================


============================================================
🔄 Round 649 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 649 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0081
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0060
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 651 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 651 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0097
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0103
============================================================


============================================================
🔄 Round 652 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 652 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0062
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0002
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 657 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 657 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0063
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0116
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 660 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 660 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0067
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0043
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 660 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 660 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 663 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 663 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0073
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0614
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 663 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 666 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 666 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0033
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0105
============================================================


============================================================
🔄 Round 667 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 667 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0059
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0029
============================================================


============================================================
🔄 Round 668 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 668 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0066
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0028
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 670 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 670 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0029
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0045
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 671 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 671 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0059
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0011
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 671 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 671 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 677 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 677 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0028
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0044
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 677 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 679 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 679 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0001
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0036
============================================================


============================================================
🔄 Round 681 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 681 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0057
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0043
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 682 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 682 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0039
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0026
============================================================


============================================================
🔄 Round 684 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 684 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0062
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0043
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 685 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 685 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0038
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0072
============================================================


============================================================
🔄 Round 686 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 686 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0046
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0067
============================================================


============================================================
🔄 Round 687 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 687 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0059
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0033
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 687 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 687 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 692 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 692 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0042
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0034
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 692 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 694 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 694 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0050
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0053
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 694 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 694 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 699 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 699 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0043
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0104
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 701 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 701 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0071
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0027
============================================================


============================================================
🔄 Round 703 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 703 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0053
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0052
============================================================


============================================================
🔄 Round 707 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 707 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0039
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0121
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 709 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 709 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0041
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0096
============================================================


============================================================
🔄 Round 710 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 710 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0032
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0009
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 710 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 712 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 712 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0059
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0023
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 712 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 714 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 714 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0077
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0119
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 715 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 715 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0049
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0011
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 726 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 726 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0042
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0047
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 728 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 728 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0023
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0055
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 730 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 730 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0031
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0145
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 730 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 733 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 733 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0062
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0018
============================================================


============================================================
🔄 Round 736 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 736 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0084
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0132
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

📊 Round 736 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 738 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 738 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0079
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0296
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0033

============================================================
🔄 Round 739 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 739 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0050
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0067
============================================================


============================================================
🔄 Round 740 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 740 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0050
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0073
============================================================


============================================================
🔄 Round 742 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 742 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0087
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0109
============================================================


============================================================
🔄 Round 744 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 744 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0027
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0023
============================================================


============================================================
🔄 Round 745 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 745 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0056
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0043
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 745 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 745 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 750 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 750 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0030
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0063
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 752 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 752 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0055
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0043
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 752 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 754 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 754 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0038
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0024
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 755 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 755 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0033
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0137
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 760 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 760 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0034
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0112
============================================================


============================================================
🔄 Round 761 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 761 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0043
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0113
============================================================


============================================================
🔄 Round 763 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 763 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0040
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0035
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 763 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 765 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 765 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0044
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0072
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 770 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 770 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0039
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0030
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 771 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 771 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0022
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0153
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 771 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 771 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 774 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 774 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0025
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0105
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 774 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 774 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 774 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 781 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 781 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0065
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0054
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 781 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 789 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 789 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0072
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0378
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 789 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 792 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 792 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0065
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0067
============================================================


============================================================
🔄 Round 793 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 793 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0043
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0099
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 795 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 795 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0047
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0082
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 795 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 795 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 802 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 802 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0064
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0019
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 803 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 803 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0063
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0020
============================================================


============================================================
🔄 Round 804 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 804 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0038
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0094
============================================================


============================================================
🔄 Round 805 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 805 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0041
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0083
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 806 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 806 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0072
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0060
============================================================


============================================================
🔄 Round 807 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 807 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0019
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0048
============================================================


============================================================
🔄 Round 809 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 809 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0055
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0008
============================================================


============================================================
🔄 Round 810 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 810 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0059
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0158
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 811 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 811 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0038
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0115
============================================================


============================================================
🔄 Round 815 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 815 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0034
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0105
============================================================


📊 Round 815 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

📊 Round 815 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0034

============================================================
🔄 Round 819 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 819 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0056
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0041
============================================================


============================================================
🔄 Round 820 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 820 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0061
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0002
============================================================


📊 Round 820 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 821 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 821 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0046
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0089
============================================================


📊 Round 821 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 821 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 821 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 821 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 821 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 830 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 830 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0021
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0368
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 832 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 832 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0071
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0180
============================================================


📊 Round 832 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 832 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 837 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 837 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0016
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0150
============================================================


📊 Round 837 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 838 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 838 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0043
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0109
============================================================


📊 Round 838 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 839 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 839 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0038
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0063
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 839 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 846 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 846 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0038
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0125
============================================================


📊 Round 846 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 847 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 847 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0030
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0131
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 847 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 851 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 851 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0064
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0003
============================================================


============================================================
🔄 Round 852 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 852 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0032
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0136
============================================================


📊 Round 852 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 852 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 855 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 855 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0047
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0072
============================================================


============================================================
🔄 Round 856 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 856 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0101
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0248
============================================================


============================================================
🔄 Round 857 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 857 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0031
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0144
============================================================


============================================================
🔄 Round 858 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 858 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0009
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0100
============================================================


============================================================
🔄 Round 859 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 859 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0049
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0079
============================================================


📊 Round 859 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 862 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 862 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0037
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0026
============================================================


📊 Round 862 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 865 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 865 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0011
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0055
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 868 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 868 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0044
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0075
============================================================


📊 Round 868 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 868 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 872 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 872 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0065
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0043
============================================================


📊 Round 872 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 878 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 878 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0041
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0020
============================================================


============================================================
🔄 Round 879 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 879 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0026
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 882 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 882 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0070
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0002
============================================================


============================================================
🔄 Round 885 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 885 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0084
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0070
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 885 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 890 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 890 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0017
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0144
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 892 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 892 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0024
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0110
============================================================


============================================================
🔄 Round 893 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 893 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0079
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0054
============================================================


📊 Round 893 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 895 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 895 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0071
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0032
============================================================


📊 Round 895 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 896 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 896 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0049
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0026
============================================================


📊 Round 896 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 897 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 897 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0041
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0097
============================================================


📊 Round 897 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 899 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 899 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0076
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0023
============================================================


📊 Round 899 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 900 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 900 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0040
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0121
============================================================


============================================================
🔄 Round 901 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 901 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0014
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0244
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 901 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 903 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 903 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0026
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0156
============================================================


📊 Round 903 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 904 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 904 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0050
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0079
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 904 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 904 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 904 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 910 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 910 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0050
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0053
============================================================


============================================================
🔄 Round 913 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 913 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0063
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0002
============================================================


============================================================
🔄 Round 914 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 914 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0035
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0128
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 914 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 914 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 917 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 917 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0042
   Val:   Loss=0.0953, RMSE=0.3087, R²=0.0102
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 917 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 919 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 919 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0087
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0080
============================================================


============================================================
🔄 Round 920 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 920 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0063
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0145
============================================================


============================================================
🔄 Round 921 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 921 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0054
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0000
============================================================


============================================================
🔄 Round 924 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 924 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0050
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0043
============================================================


============================================================
🔄 Round 926 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 926 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0079
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0144
============================================================


📊 Round 926 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 926 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 926 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 926 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 932 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 932 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0029
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0166
============================================================


============================================================
🔄 Round 933 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 933 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0056
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0017
============================================================


📊 Round 933 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

📊 Round 933 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 937 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 937 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0050
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0078
============================================================


📊 Round 937 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 938 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 938 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0015
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0132
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 940 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 940 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0025
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0100
============================================================


📊 Round 940 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

============================================================
🔄 Round 943 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 943 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0072
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0326
============================================================


============================================================
🔄 Round 944 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 944 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0083
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0277
============================================================


📊 Round 944 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2456, R²: 0.0035

❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
