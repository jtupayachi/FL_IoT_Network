[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d464bf66-82af-49c1-90f6-7812573efb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cafab2f-2789-47ec-bc24-f8647d437918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d13b0f7-b8c8-48c6-8b17-4fda3d15668a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0b0281-cbcd-45e8-aecc-f437f41590e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15c875d0-3e19-412f-a018-288f12fffe6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321b79a4-eb67-4d02-91f6-191fb8a422af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0cd0bd-0905-4b90-885c-2a5988bcce2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac90b733-e9d7-4365-bed6-cf5468f6733a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d262be4a-7351-4b8e-9e8e-6a343492313b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8feac9e4-00ec-4b86-b877-90d6c50e10fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e8a5741-6118-4123-9e2b-8c7614f268ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 999d9300-1e82-4477-8ec9-d2e9b35c6f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3170ff6a-b4ab-43b9-a4eb-6343ceb2c1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfe1635-7b8f-4023-92fb-3ab197e4e0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a889b4d6-7065-4c67-b093-d6f16d4f4e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba63820-10d7-4eea-9a92-c79e0972c80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2157e4-c40e-4fba-a31f-5e7df1189078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fdb018d-43d7-49a5-854b-fc3bede1f51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96521674-a7ba-4c3a-a0d5-7d1a9f776a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b1d61e-6e37-4b28-aec0-095b55844d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef15346e-44ef-4801-8e8d-3a52d7010ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5067a7cf-73ea-4328-99f2-2349373724a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353cdb40-5f5a-47f7-985c-8d4c8d6fe430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e3b437-f6fe-447d-a064-a534fcac3149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad6f2ed-322b-410b-b594-b828f91ae32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4ff3eb-6721-4335-bd2c-2e7840044b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd60fb3f-d245-41fe-9e00-adca93e1afcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7048e14-87ce-4c6d-a1eb-653fa83420f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d626b8da-ad5b-4e99-abb0-bfcbeab94ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4e9136-09ea-4ca7-b534-58a29797a4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16562502-60ab-4733-891d-53b84ce30640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff19cbb-0e2e-426a-84c1-fb4679de0f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74f3189-f5df-4e80-80bd-27afa097ae20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f53883-74cf-4f5e-8d55-ce322767e4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60cdb02-ed84-40c9-929c-c4904ba10fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cfc2cd-fd6b-46e2-90ca-51b6057bfa0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3be5cf-eaa4-4985-85c4-e309250afbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd1d91c-0d68-4dec-9dbb-ee2096c74db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b538bc07-b61c-4802-83c1-f2f509841796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd52454-7316-4ec2-b92b-e0d202172f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c27617e-da75-45bd-a6c7-26effa87038c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d30776a-51ab-44dc-a958-bee4fc658a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc31346-b219-41f5-b02e-59b1a1a811e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbaee08-a6e4-4fd3-8a85-2c299fac7a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb942e11-a687-433f-8a13-0b2260ffec5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b07bce-0009-4973-80a6-70aa6893c2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bb18e4-f598-40ec-84be-001a0e94bc2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc1b55d-74bc-4655-a8b7-a7af6e51e05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25534a79-3bf1-4c06-abb0-1ab67f01c9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3ac97e-aa03-445f-91c0-55b885559ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35230938-6af3-4d75-b9f0-cfb884a2b59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8980b0c5-7bf7-4cf4-ad0a-63e47203e6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a7dd36-e55f-484b-b821-9660a974d2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b695c7e-11a0-42c8-9b9e-4a37b4574c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b45352a-154b-4869-a129-dcf98b946e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46550f95-2235-45c9-974d-c893470c8332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5548bcd6-05ba-4f2f-bf31-3d52e175c6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebec61ec-947b-410e-8e32-3a24fc82accf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6b8866-8c7f-4c6c-9d2f-65f23669c9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cedc4eb9-d986-4057-8bfd-d841ec67ce8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c669d9-2921-4364-b96e-b5b327c15584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9a3e7f0-436c-4827-a228-a8833e56f5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f36bf1-46a7-4c61-982d-c88a3d3ed938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5bbd04-97cf-401d-a509-5a6e7ccf2534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414b728e-1ba7-4223-9890-10b45efc44ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67754c7-5f4b-408b-b8f2-89439db855f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfa7021-8492-4a3a-96aa-120e91f81a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c39eab8-2c6f-4eb8-b2cd-75845f9a08ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91b7276-4051-4456-80e6-39c503514f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d96a5c9d-fbc1-4b1d-bab2-ab173ea47f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486b9e77-3e65-4ec9-bb1a-d8132d1a48d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227cd1bd-cbce-4c72-a3d2-920f3aac03f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751b5bda-8447-4730-9bc1-4e0fb4d73446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702e11e9-b175-46bd-b373-98c7439d1f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 583a5dc1-b10d-439c-acf2-d625ce9ae300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01aeed5a-266f-416b-bbbe-f803a8947f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb293d4e-11cf-4fd4-8fdf-2f8753289414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17cba1bb-58cf-41c4-8d95-14193020c4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee49d6a-6094-4d96-8663-be08a7ae3c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41648bc9-f8a2-411a-8de5-ff2c6274e30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbde71a8-4057-4138-8c77-4b5852c2b597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef68077-7285-4157-b015-c128947316ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9e11cd4-a454-4473-8e3d-7a0053b0e385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50db4254-bf0e-41bd-b9bb-bde0efa4ac8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6a19ba-ed1b-4601-9ca9-7447b5eb42b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1973401-f15b-4d7d-8030-54eb3ad0e04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7381834f-555a-47e7-b88d-05ea4e1dad4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21cd7e5b-b9f7-433b-973f-4484bfe908ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d5fdee-8f8c-4991-adb4-e8ecb3cf6eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248ec55e-eeb7-43c2-a864-02d73d442080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2725d240-67ff-4a44-9460-4f3e028ba4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93ec125-5d1d-416d-9e6b-766fdcae057c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1182053-99b1-4f8a-a65d-f83e6799ed1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88eb37d0-b586-427c-951f-2ffa4049e083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77431974-38ab-44e2-b2ef-859577410820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da15c3f5-524d-41f0-b98e-5b57dbf83043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1dbc061-df5c-40c8-b922-5af9232738bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c50e21-29d8-4a93-b787-f87dd278525a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825383ac-5fe3-4696-9e97-a9174a51bb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae174f8-7e17-4ae8-bdb1-d1990041c246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 213d6a32-4969-43eb-80c8-0ebebfbabe72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835441e4-6085-4958-a283-e4b077dd7245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7df44c6-449e-4085-8b64-469fe84e63af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6236e7e-9dcb-4843-b018-15a50a2110b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e82b219-2115-43a4-803f-9e5490ca2198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e212aea-a81b-4a23-9639-c9d5b33799c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42fb9cbd-aa23-4c06-a4f0-48cbbc6f5057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd8e3f4-29b3-459d-87cc-a035d7ca96c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf81381-acc4-4e7b-bc01-70c559537e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b9fc43e-0923-4bc9-905c-95818a5e4921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4591569-3f99-4a81-bb29-ca23b555a69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b69862b0-17d1-496f-8b7f-be79c0e0bda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3975af1-3586-477b-8013-6892740fac60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba91d86e-ed43-46cc-8af2-f6c6640efd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 730336df-2add-404b-8bf3-da20e93f6e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01bfb89-ea3f-44af-870c-3dd46db078fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25cadda7-4cec-43d7-829b-97c146cda8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae65830-9885-4f4f-a100-0791f4f54210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83efd8cb-9ac4-4a14-93b2-0d73e3d43301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29df0783-b142-4822-ae96-0ebc25d944bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5931374-5020-43fa-8e16-94732e1bcb37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b84538f-c7af-4b0d-8df1-e495ab1daa57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c4ea289-e80e-45b0-a6f6-5586cc1b453b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf5ebb5-65e6-4e37-8442-6fb82c0fe25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfb13de5-a9b7-40d0-bb02-66eaf7bf770f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359c89fd-9149-4cb0-9006-aabd3ccf24d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e2d45a-b622-4d1d-b14b-52401380f0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de09b59-3909-4a49-a9cc-8fdf5b174776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879c9670-b3e2-40be-92f5-3b5dce0b5d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699cd7e1-e895-4801-ab7f-bac1c5a420ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16e9298-00c0-49a6-9e38-0a6559f1dd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53057d9-9fc3-49aa-ab95-10fe96c96e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57159262-df6a-45c1-9c0a-916982ba0d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f977f36-c4d5-4d83-9bbd-ad0c0e3a37be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a588adf-a00c-44fe-8e8e-202d2b5c536e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b927645a-718a-42ae-a973-c73a000b574b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7c0928-f845-464b-af33-e8204f1ba0a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc06dacc-eb6a-41ab-8662-e10e5ba87aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d37b91-65af-499a-a8d8-39485c0c0cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a3391b-c2e7-4ad3-a19e-426770a64b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b36f1a-43e3-46c9-8cd6-e0e1761bb1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e83894-e48b-4738-95eb-9f1a6ba51671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25859fc9-1ade-425a-9b60-71abed5fa3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41300146-ccf4-4dfa-9983-574e424c3fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6cceb9-52e0-44bb-b187-254207e631a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89c331c-dfdb-44fa-aec1-be052082c8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db8d341-8944-4943-9e54-edecc8119e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe8e8285-f5c4-4b2b-9e47-23d45925e55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70680264-9bb4-4bcf-9adf-be436b31ef0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5771055d-43ab-4855-9096-489a077f6aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d21128-841f-4377-b0ff-2e19158033ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38646807-4154-4d28-9312-340cbcbc0878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6650c932-67bc-4e37-b023-3125b615c413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9198f7-8a32-4601-ac10-c62d7f199dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81949d09-ab99-4dea-9e84-cc3a8bf9baa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 168c28b7-d2ca-41e9-9a90-99aab48e45ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a923e5-0950-4b79-8384-ee56c9e36eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 106908dd-6cfd-42aa-9a52-b6c4a93fab2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ecb1869-7619-4af4-a5dc-67210cf970bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e6131aa-f338-4560-b31c-a7b88cb9a2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bdf047-2974-4cd5-b49c-1da93f575446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46331b28-bb23-493b-a043-7e3a493580c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9aab9d-2291-4cf5-84f5-904e4235314c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d6bd21-379a-437c-94cd-529a95588a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d47fa24-9cbb-4021-867c-c3f815957e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305483e0-5df4-46da-a389-6733cda7cb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d28f2cd-6fa4-4d17-8c28-9798897e38f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26f4d5c-5ad2-48b9-a044-ba274e97d1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46855dfa-e608-4c7d-9c7b-8636f1754df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea508e3-53b7-498f-8c45-2000daec4228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e2d9c0b-e73c-4b8f-946a-eca6e96a3dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c8f1b9-e296-4027-9a19-60774d2ab474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c940addb-b46f-4606-951d-b8c2401a94fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c45818-e0ad-4297-ae4c-e800ff960f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b6dd1b-c883-448c-87f0-62fdbbf6aea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830260c1-ff37-4337-958c-3bfe7851a88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c5f7a6-fc09-42cb-91d3-1e215435dfdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c135cf5-9044-40f7-bd9f-5be2c7723600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0f2b23b-a7d1-493a-b994-2cd3c78ba50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eadacfbc-c625-4177-a1cb-7280c4075382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5696de38-af53-46d5-b255-ec202929f477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b93fed0-495f-41bb-bd2d-90a41f64a29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990cd4e5-51b2-4067-b698-78ff4df6f0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f36ef02-9c43-4216-9a5c-1e6137eff975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4594b30-50d7-4710-9aad-4c257972952d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc29bd9-ae15-41b2-8501-5017661dfe69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33cb6863-f3b0-487e-a60b-edc94bb3e513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4afb740-4b12-436b-8a8b-5f4ab3b236eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df77212a-65bf-4b7a-8f87-d3a806eb836b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f513770-b764-4349-ad96-b6fc216d952e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1756dc1-38e7-47b3-a55c-26d75c7796d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7abc4964-5800-4cb4-b7d8-c24c1ee11718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50a8f84-b41c-4380-8353-20336fa28847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 439cf4b2-6f38-4b31-8a91-ab3365a5b0de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2bf8c7-5b9a-4671-b3e3-a4965176fe1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48bf6b2b-e41a-4600-95c2-b65b4ba1a99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8486b792-5407-4f49-9b8d-b4ff9b308023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d592821-62c9-411f-a422-fff850ce3478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8845a268-fb00-43df-9e8e-f61fec05e00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bfb49f6-b707-4ab2-9fcb-68021f1c23a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad77f145-40b7-4354-bfae-dd6fa6d81506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee63e303-e137-4501-988b-e43fd13f4171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5337460-546c-47fd-8908-a13ed64a87de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50343625-3c66-432f-9b82-9819368f20b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c96916-e3ae-4069-968a-f17d8d9488c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e411d00f-dd5d-44fd-88ec-ab26ebac0e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3afea27-4547-4b5e-aab4-856bd9089932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6669681-82af-4c68-b215-aca34619b10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498de019-0ca8-4e38-a1cf-2fe558edbb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbf80480-b35a-4168-a727-77bd994d1b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780c63e5-10a5-422f-8dbd-d070eae8f6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 665094a2-946f-4994-92dc-af1ea8919296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8c2b92-1221-424e-ab66-a3e784912bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ef4260-1f73-4b52-8df8-3968aba47adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c38d069-7058-4f1f-b8df-7c831fff2f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cd8fc6-75eb-48b0-8ed1-01e56d515c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a445c6-800f-4127-9901-d0602acbdb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb715e7-9afe-4b00-b62b-5da03a8fabf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67e428a-5256-4752-94c3-0d1c31cb7da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384fbe8c-f5f9-4646-aa5e-97db1332e4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c4a079-6925-4c41-9eea-cbc4c1508fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7230fa6e-309a-4fde-a252-ea4208052984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed9b2fe-70bb-4ea8-9338-2b3223bd8255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0adef8eb-2111-448e-b6ee-1e8dbe2d38b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8426dae9-b92e-4a93-9794-7a975378330f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b0bf84-fa4f-4155-a0df-916cf036bbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8dfa075-36f1-45d4-b09a-49e9358f9c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67bd4a42-fb8b-4e47-b6b7-8f9d7dd41eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a9ec59-7a60-48e3-ba7b-5ad6c8db91f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dae9613-3820-4fa2-ac3d-c6a765017034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae5634a7-817a-4934-b569-9b5eed4f7699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece1feab-c593-4805-8154-2423762cad3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9822403-938e-41da-83a7-10f4d3236a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdc2987-b274-4da5-a735-b4c3ef3e01e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121359e0-4a21-49b6-951e-0ca0c250eec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b87775-f4e1-41b8-80a0-53a272b477fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd040478-8d42-43d9-98c7-8ca92710b777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d543ec-6aa0-4e2c-9647-958059a2d150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20992919-c7c6-479d-9ee3-42b2d674fff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc9c16f-cb37-4fd4-9501-05dea0454e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4230002d-b616-4037-b638-e4d20ff322a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1fa4f1-cb6a-45f5-bcf7-1f4ecd324fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc33ec84-f157-4568-b3b5-36c338941c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4af032f-ee40-4cae-a2ac-fbbaaaa3ee06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5caff5ad-90f0-49b4-b0f3-ca7e87d3f965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b39b625-b242-4d79-8919-9e8eb51e3a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e9ee9a-091c-4098-9f51-7ae31f62814b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25046da7-7243-4846-914f-f1d7a8e4a469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8d07b5-add9-49fa-b20d-98101119b5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65913835-1403-4199-af9e-551cbd5a1ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3027144-1f29-4f23-9c7f-86006dd002b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ba86e2-8234-461e-903f-7372bfdfd5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602859f2-f053-4da8-bc92-171d07f91e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9993202-140b-4cd8-a904-2ad2ab0736b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82612614-1fee-4c42-bd3d-77ad523b19ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96003ba5-955a-4931-b73e-afd418f9b3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b887b28-249b-4696-8d41-e869051690be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e93b4ff-c5e6-4fab-a1e2-4627af94d0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b338f8ee-518a-422a-980e-522c409216f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3985001-f7d2-426c-9f7e-951e1be81204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29256724-8fb8-40f1-b64c-9c8e76b4a575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00259d2-4262-43f9-9a70-e1115f55b876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f990006-e504-4cf7-a743-62572c7d5a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf06300-62b5-44e2-8a28-70793f5e747b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14948e6-a2ec-496d-9201-d3ee5f3907b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e02c5a-2073-4e76-93d4-66cc6d57c03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c7ac10f-19f3-4081-8e9d-2ca30aa2821d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7535283-eaac-4e1b-9a1e-3b881867e882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84844749-c335-425c-b64f-a9db213a5fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a66c43c-becf-4fa8-a7c9-a7fd84bd611a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6c6663-585b-403f-8e24-9b005fc6a8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4bfd3a-5060-4286-a48a-2b8ce8008955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db794a7-817b-4b36-8bd0-04731965f507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7f9e65e-2f2c-47e3-a1a4-21ca689d4a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148f0ed9-6542-4300-a4d2-75970425899b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df43c555-f0d7-4009-86da-a3b678f168ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b2088d-cc35-46a4-99ce-a47689d9b33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361073e9-71cb-4a0a-807d-b966af79ac50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf48326-3efa-46f0-b080-efd54c8a0c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4fbe7f0-e069-42c7-8eb9-a1ef65ee7bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8530330d-38a8-4264-b36b-b8823ec90076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d04d18-b05f-419c-8b5e-85cd37c97263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c17ef32a-9112-489d-a155-7700692118cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201bebb3-3d83-484c-87fc-3e1ff600e420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 384fcce9-8c2a-4c06-8494-0985d41583d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb03694a-a52a-4c6e-8906-c366ee6de7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c997f47c-e6cb-4ff8-a13a-fe7b89205cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0defa33b-cdaf-436b-ac48-da4b67764f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11df84a3-fb8b-4ca4-b94b-2104b7bc7cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b188fb-bc4a-428d-8095-234220410407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e1c6cb-4666-4e57-b7b9-24f424d6d0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4a7ea98-30fe-46fe-be9b-d21ff172e326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab34aef7-562a-4fa1-8b76-708354b12250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603142cc-4a1c-4342-9e8b-f713676c8dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2cb0e2-9771-4ff6-b98f-30da4f83b77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4b5189-07db-45aa-af13-7cbb14915135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb998a03-fec4-4d26-80e5-668539e31db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1013517b-b54b-48da-bee8-ed9e0c90ad8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6e43bc-bc07-40d4-8e1a-14d903924064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86b0aa7-41d3-43fb-9947-f08a7660fce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3403d0a7-b29e-4dc8-b2eb-361fa50ced62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f56676b-f8c7-4906-ba75-d007446f7b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d2dd95-233b-4f1f-ba85-196f8f7a0bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71409327-c264-40cc-96ba-4c173c9ac088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651f3cff-8713-455d-b9eb-6c04ff710ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ddf86f-b712-4d51-808a-5e6c4d8088e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de51dfd-7968-44a7-9cf6-ddc86e730030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf562aa-8c60-48fa-a929-d68ac1c532ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59613a17-0e59-4b8e-99bc-92839e4036a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71c1eba-fbd3-4020-a0a4-935310e88ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b927d33-34be-4845-a2e3-5db7ea00d458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 667fe183-1f66-4b77-bfaf-7c3cce7ef770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca5bba8-8901-405a-b359-c12737824c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200e3d5a-b26e-4ddc-94b0-63b1b5994108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8230ec34-4248-4b1d-aaa7-ca67fc83940c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a6ef8e2-4a4d-40e5-91ec-de206ec98f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1405f8-fc38-41f9-9d0c-dd1204b36798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a78d593-3793-456e-954b-6a44a08e74c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5fb3b34-dfca-4539-8b65-ebb9bb133ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822ca7b6-9400-443d-9d10-99a19ab2dc5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27b2f2f-f88a-44f5-bb69-d7e84836d748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8dc151-07e8-4a74-9f4c-ea7188376272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589d16a3-fa14-4993-bfb7-6acf821911fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5a5ad2-1996-4695-8dd5-54093691ba0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5c9ee7-9786-4aff-b80e-4b43e8830b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e563e2af-4abe-42c6-9633-7bb5758f0c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c63f5f-d3d1-46a9-abb8-d61cb4df1dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c26b0891-614a-4292-959c-d79b51ae582a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68769747-50c7-4201-8ac2-539a7459bc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc50b77f-d870-487f-b042-d3e57d706a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80dc9ceb-a4f4-4d63-97e9-a872e18056ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f947ab-efce-4dab-a2be-61f44d894873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8015dd6d-6a9c-4854-aedb-2e8e4a149f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3088f0f7-168b-4060-9f7c-bda14581bff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ebf24e-898d-48a6-a82e-375394f57408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e7fbc6-3c74-43cc-82c6-45737f6c16dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb364f8-bee0-491a-a0b7-0277739c15ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11d03d6-0d42-4c1a-93aa-83e37e7a558e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb1d5e5-7d19-4051-9016-c50ffd942e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53b89a8-8e4e-4fb7-92ba-6bb7c2b0b283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9c0f5d-82f4-4056-bc51-980bbdf1b7fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826e9829-6602-4fd7-b859-63ee95b72edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536a2695-3b65-445a-ad64-2a0d7811f6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f7b561-6557-4acb-8a5c-6a0f8fddf8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2740fcdb-e07d-4172-b553-e7c892102ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf5b65e-3cbb-4b6d-80e6-542d719a548e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe91058-d652-4a41-8b16-d47c4f7297bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bad61d7-2ccb-44b2-a29b-1c6f8f0831cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23292100-299a-4bab-90be-44527cdc76c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325895aa-52d0-41a4-a6d2-10e2ba3d8612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0e15ca-b3e5-4b5b-ae54-280cfc51c385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c5efd6f-a826-4711-82af-3ae9d3653fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39ad3747-d9d0-4f29-a6ff-6ae46bddb10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20c3ab7d-f238-4d31-bd1a-1da04c092344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f583ac-1f75-4205-b94c-e6d2a2299974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e382e503-6a9e-4d12-bc8e-1bc37e36c445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c8d812-8952-4a11-8b1b-95b1c598f871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62919db-fd3e-499d-b23a-c0259a70ce94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0cddb35-111b-42a7-b2f0-52bd5cb1da72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158c3a1a-1de6-4546-a344-cbf34ba04da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88becd51-7458-4595-ac65-2b057f70c50f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88040f0f-2fc1-4cd8-a774-46cf2114042d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d8fcbf-27a5-42e3-83fa-3093bc5dbd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7542145-d5ab-4ed8-853c-8d2f39132979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f1c6afb-a7e8-4702-b755-a03e7a1c5304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62da06f8-49bb-4144-b013-3a6b66dbbee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7f17f7-f6fa-4e90-be21-a80480cfebf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e200bb6a-492b-4ecf-a420-ec9dde197a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bc0b18-c1b6-4cf2-90f4-476fe65a9aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ec15e8-da33-43cf-b37a-6f2bb410a640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc27f695-7362-44f2-a348-b2796d14d3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d95b17-0a9c-4595-b7e9-ada09a13b67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3665de18-230d-4e76-b2a4-e498db01d558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6ab1f1-ad6e-487a-a189-61a919d574a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6865bd-af6e-4745-bb84-f77e73be24a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1792312c-4cbf-4216-aaba-f10ae3cbc8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637ea686-c6ed-4599-93e7-3367046601a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3403916b-2c04-4ecf-98f5-f78ef465bc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141d2151-156f-4ec7-b717-1bb629665913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f679e6-70bb-4dc9-bd4f-4f8cb152a8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b312c5-900c-4197-ae05-08e79025935a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8c40e6-aa04-4e56-803a-4b32d5db4b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d71f1f1-28ae-4fdc-9547-98d6162b5c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd4fb99-0acc-4b8e-a53e-53b458000979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f880cd4-aa4c-4ba8-8844-416c4055765f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c9179b-e29c-4de6-a7bb-9b6a18fcf141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9105b7-4330-410b-84dc-ffafd6bb21e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b961d867-6b70-451c-81e0-5b1a84b42de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e23f36-fe0f-4d4a-9c36-375e71e83e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b147d89-902f-4701-822c-6f876d2d25d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25161b45-e7b5-402f-b85c-221c67a5fc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9cb5921-9b75-422d-8e78-2b2b07ed813f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c180fd6d-ab48-4562-bceb-0cdb5c4dee59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc56b25-81b9-4b34-a115-382b2f358c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6de07a-ee05-41a9-b948-e5a4ff8b8bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455d1d30-c9d9-4ca5-8bb4-c41ea1290737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b310b7a6-44c3-410c-b958-6dee4b501456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33f245c-ce07-411f-a09b-9397b375eb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd4f542-c0f2-49a3-9c34-0d98212924e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd5b41d-5a86-4ab0-9398-3e10cd0e5904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61de1693-85c6-433c-bcf9-0d018614e9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ccff60e-1834-4a89-94da-6940f2888c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c339944c-5eb3-49fd-92fd-ad0f61ee0e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b56175d-2b79-46a0-b13a-6f6b30776306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 355695e6-91ce-412b-9a9c-548aecac648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9b839b2-0858-44ec-8c73-415ced35abc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f1b0f0-82ed-491d-8deb-b266ec587d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc34015b-5c3c-4980-b04c-2879d4a2562d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ccdf39-b342-4953-bb3a-09a1cc37fc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c079a543-c56b-4a67-a00c-d669ca2eabf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef5913d-409a-410c-80c3-fd91e8248837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb1e792-f123-4df9-8eed-9caa322031a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4ac46c-b486-4fd4-aef1-6cb9384c54fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76390c0f-6f47-45cb-a8d6-b2a7059a5e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e37cba-e283-451e-a6c3-7f91c3d42aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50709a7-95b1-4b90-9912-f5f46f714e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318a7f7a-4473-4321-adb9-c12c27ffdea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc941cc9-f55b-46b5-ac93-45d41fe664c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 694b1ab9-3fe9-4fce-a6cb-7229b8f5de41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e42299c-4804-45e3-9231-7ac40ba6328a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f67c49-a9d2-48ce-a87d-01a1daf21cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7debe86d-094e-42f1-86f8-7085c9a1696f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd09de22-010c-429f-95a1-d77e3e43bc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9749c6a-c5f7-4990-b9ee-1ae85f1f64b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d3d743e-bd83-4129-9e58-68060de44c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeef5bd1-acc7-4aae-bd20-c83f65086e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89d5731-5b5d-4501-af7a-11a038d0d314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7340530-e460-420f-9c73-52a7a87ba060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9c999b-e6f9-401a-8499-6b5c137096f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e8da84-1a61-4be8-b10e-89be15cf044c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21011e1-ed5d-45ed-b0d6-ac82f255ec9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5375b76a-4069-4e5f-9a4e-bf66b8cb2b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbacc645-3bfd-4ae6-9b2d-bcd348944205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68d8020-3f3b-48a1-a28e-fb4750b81d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae563f21-e1ab-412e-b035-7697d7873603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15450653-e3af-444e-8df8-532940988e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe65d52a-8476-4e59-b102-c6fd694a500d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e9bdeaa-8ada-44be-9521-bc0fc0dde796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a24446-95c6-4ecc-918d-59f97d277684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b933387-4557-44a8-90da-36466dcd57c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598e7cc1-5913-448b-a917-195ae15f1e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d031bced-7fc4-40ea-bbf6-338f780a2e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be71d11-b7b0-4761-b284-a09aed4be228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c61b8c4-3bb4-4b5f-ac54-18174ff52c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dbb72d9-d090-4ca3-a915-09fb8767e289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0109b8e-b84f-4217-9feb-7502c3e2e1f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d007c604-2380-4467-b711-a652df878369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6da0ac0-e32b-4365-a8ab-4b2585dff97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62c94b92-c82c-4c24-a369-39c7d409aa2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15bd4d71-6004-4602-8a10-b779042633b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6447c8ad-7376-454f-9511-9f160961ed28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c499ecb-7913-4f68-beef-2e4fc3764e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8c6d9d-aae7-4f79-98b1-d8f011f5b0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120d1013-3680-481d-9f07-87f3c74a4186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f88f4a5-c3f2-4cb4-bbd8-5489f30d804b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa310107-af8b-4303-8b72-f4f9f0b807fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71022c11-0eba-4393-8c66-26ecddfa2590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2dc7f4-883c-4dc4-9da2-bd4652e6df6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f7fafec-67fc-4ff3-b0d7-5aa303c25a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0de754-f26f-4105-98fa-780286e72f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0e6b32-7ce1-4b3b-80ce-adb6046dcc29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3b08ec-05a8-4006-9870-d85ba9f06440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933f0f33-f5f5-4054-bcf9-5bdec0277655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214178fa-0980-46a1-bae5-43f59b4484c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2b05f3-680c-4090-8844-2e31372fb39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945b1378-566f-4341-bfe7-0085b37193ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bacf07b-b12f-40cc-8e7a-85c99f45dbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d9ddbd-3303-44ac-9c7b-85d53eb1ef51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5154d5ef-5c15-4758-b3a1-2f46e6858a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b1ec40-3a19-4d45-86ba-0fbd5649cf1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a3aec1-420b-424a-af25-65f0d7b22f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136583cb-d61b-45f2-a194-d29080cd654d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36998496-8b99-47f2-acee-df3f920b7d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2f7cd9-eeab-4f0d-a8c7-25314e7c45c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32fa7617-2343-4bd7-9cd6-8a30a67fe2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba7dbb5-0b3f-45c5-9ede-65559f317451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d01991-27ea-480c-86a6-91a9d5e0b618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80aafd4b-4b3b-420e-b1fe-f8f5b6eb3a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fbee07a-688e-4dae-af5b-a3a3744b6897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638fdfc6-d6ec-4054-a4d9-ca44309c2eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b040281e-6873-4f5d-86ff-347dfd1a2171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef4cbda-fbc2-4ef2-b278-3daa61698d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4318b769-7d0c-4a16-b248-f52806b1c9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4259d157-4e58-4ab0-a261-43a6dfdb22a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97abadb7-559f-4cab-9f40-98531488b1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bfc1d6-eb99-44c8-9981-1fa51ac9da84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e727604-7b26-4be0-8f77-39d2103f7ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1175ba22-2b4c-47df-9ceb-e3dde5764b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc3f718-1c1f-4c97-a186-f9e939a354ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed36e2c-5abe-43f8-b3bd-dcbaa1dbfbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2999b4c2-c890-4e2c-99f6-2e6e5a9a280b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b2c969-f9f3-4826-87d0-fee1ebab3cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5cf778b-cf17-4cda-8c24-745ecf859dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a1731e-1752-47d6-b137-003725c7a5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b405feb-6316-4acf-abe5-067442538d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ae53380-6591-46bd-b528-7757ecd5b4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174cf099-a318-4456-a594-8392f949681a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960ddbbc-a287-4f26-985d-f19b12078813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b8ed2a-b52f-4a39-b03e-f28de1ac65e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4710e5-b21b-41f5-9611-d4545e4746c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6041e9a1-1971-46f0-b314-9913171fff2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b8d4ee-7aad-4fc9-93f3-2f0bee9bdba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5072b157-0d56-4bec-9531-720ccd235812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeeb5cbc-918e-4085-b967-9e4747f6768f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23241727-7c7b-4672-a79c-dc0a45edf15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c457bf71-7040-4924-8b95-1b08a5ca553a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4403e720-587c-4457-9525-034053e25030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715d184d-d266-41de-b3f5-622ee06cd35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3d19d9-f82b-4270-875c-e68b2493204e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be491a66-fc40-4b20-a371-6ac6322a4b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d31fc03-5a66-4645-9d7a-d23b51af2afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35cf505-424c-49f6-b56f-f0af2970deb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7f5556-2685-4015-a286-742cf588e666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75979065-ea22-48e7-89c4-175a1105b0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2bcfac-d70f-49c3-8eca-19c07d3e7b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376a94f2-2778-4649-843e-d40726022c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48429b7-6adc-47df-9c68-588e9631750c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd09f93-43bf-4e32-890c-a0a452bc2842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f43dd8ca-68ad-446b-83e5-4618db1a87dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a869543-fe05-4368-8baa-4fd42fd7ea3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe6d38d-8c3b-443a-b574-ffa461ec1120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baba5dd6-19bf-4cda-a6d0-f1722047ab8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5c9c46-524c-4ef0-8725-513ad09a3455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4450a426-9fb5-4e0e-959e-8d500d44bc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688eeafd-20e9-4ce2-8d00-d298784a0ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bbeb37-f309-4dbf-b505-af3e4dc7ec05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47aa1403-988c-4750-bc67-d5aad31643f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f02a463-5fe9-4bc1-93af-1ed8326cd76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9021a90a-3c8c-40f7-82cf-38152db3a496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44c1f8e-d589-46fa-b3a5-843e19bac8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e89743-99f7-462d-92fa-e065b30eec96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885a0c02-1d51-40a8-9db0-abc0f9db529a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de7f04a-f2c1-4405-b9c1-98c130ef37a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116180c1-21b4-4f9b-9148-8375adf3eb0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148e59fc-6cef-4c8e-ab0a-04ff1fa613b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d368838-2448-4074-b985-b243d324114f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 882bff63-08ab-400c-9016-f2bd30284889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1783de-a099-48f1-bc08-09ea6a9ca777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556b9775-4ab5-4f14-8f71-f85003322331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fbf483-dd15-4e4a-9287-3e7d0dd0c45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062ebf78-c5ca-4508-8fc1-1e34546ecd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7b79d8f-73a4-48b5-886d-24340285f105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b36160c-8774-471a-aac0-28bf2c7aa494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a930cb-1fce-436a-8249-0f546f9383b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a921024a-8306-473b-9789-b955b4612901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6adfaa10-15c1-4a56-b7a9-3732e0b0d2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30ad089f-cce4-4ce7-b96d-90b955f58e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c2fee0-805d-49fe-841f-a623696c38eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a44769-b6bd-4e97-8f4d-913cb743c688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7562b795-aac3-4b4d-bb9c-a634353be20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f526f28-912b-4995-937c-121a7be0ddbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77039e4-7b57-41ae-b219-7f28375a9806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e553938-fb03-40c0-9fda-11d01a49ed01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2ae4a0d-f7ea-458e-ae8b-96d63064f588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b788c196-c22e-4632-ae22-d82b9fa6c68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea0c3f4-3804-4ad3-b320-46b4c261c43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7095181c-db88-4aae-9621-210d1157ebaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d5bbb8-98c0-4fd4-8af0-b45ef4207238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72d3f05-306d-47c2-ab76-cd838cac2861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1baf5e8-dd4f-4853-9631-7a08faa76e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd3d1ca-1e3c-46f8-9965-927de37d8a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b66fe2-669c-4ba7-b336-c82b194431b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246b72f7-4a5e-4b08-9a0c-875adba97290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53341cd7-2553-4fdd-bca0-6ae21e9b7289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4110bacd-0d64-492b-8d9e-3ee08cd1dc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c895ada-300e-485b-ae65-e46b2e327e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd2becb-2ae3-4af5-a835-2090d867db1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb965b3-721d-4c4e-a493-2f48708210ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99d3c25-d1b6-4ccd-b107-d3e32e533900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db3fb31-f8d0-45ae-9ec1-7c0cc05e2f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 390dd86d-e882-4569-b3fa-698ee7507a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffff98bd-e198-4745-96da-499a4ab4655a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edce28d7-920f-4e2f-89a1-71f9b98e0595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2909eb00-e27a-4334-b1e9-df2dfbf83897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7af412-1ae8-44eb-af94-9590499b3d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 631de0f3-972a-49ec-aa35-a035396c8186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497505d5-a758-42d3-9ad5-b5a4522fb8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 853230d2-22f1-4c73-a636-eeac9e13f4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee5baa4-2901-49cc-a23b-6332fe735db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9361f48-ba3b-4a33-89e8-fb8f82a9a87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6e2fd3-1e95-4a1b-ad36-502406764298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01a7cb8-ac7f-4c7a-933a-35ed1db94caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e20d7f-72de-4dab-bb9f-1f9ddf184e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefd74fe-934d-4159-9a01-f265f642d159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79ee4ef-8724-4486-ab24-c0832a6059ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff5d960-a307-4c10-a0f3-ba0cc70f8846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c6e150-3325-4a90-8869-778a1aa96924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75815329-12a0-47b4-909b-212df7760ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9c7296-5287-49d7-8392-fd3482142fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a17edc-5d60-44c2-a6dd-f9389c89657f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab8e1b1-6981-44af-acca-011dc383de73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc2743d-0ab7-49d9-85ac-a701d353ebe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9204235a-0dac-46bd-a010-287dbc200d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c332ede1-f450-41f6-a46b-1f20fcfaa6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d417dac-6fe0-446e-8416-9460cca769f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8149d0f-d77e-4894-b5bb-675ab2108f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5e6f9f-8615-4b8d-b03f-3b42d684f76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4371e70a-40b0-43ca-9b6c-6534c387ec05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84ad608-cfe7-4ef5-ac95-763f94540121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99393ad6-3b5a-44b9-b95b-5a2d9f548431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c9f2a3-ad32-4c8a-8c00-b6caacb5535a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53937f68-992b-46b6-adc2-a0187c725413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f099968-0171-42ed-bcc0-919f14816098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2f5666-215e-414a-b098-a7eb67c13fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ac2673-8ab3-41c7-bcf2-992eaffad432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf98bbd-e2d0-47c7-ac56-08d09d9dd4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e951ba9-ad91-4329-8b03-c0698c9e4014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16f71ad-f1de-4bf0-af91-9bbd1b531af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1407f770-4bbb-49c7-bf1f-5b06169c544c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc07643e-210d-4814-970d-921eb1d5c96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd8d6e2-f59a-4d4c-866e-1eca6ff4d877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6217c79-913a-47ee-90ce-6bd2575b58c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18ba88f9-5789-482b-a2ee-444e21532412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ff41c8c-580b-4080-a6da-695926193480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 499e34a6-fef3-4e99-ae36-89aef701a46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a88e176-37d7-4dd6-97db-07dc99d8e643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b25b2018-006d-413a-a5ec-1a1f841456c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f247c1e-49d2-4469-ae8c-9e56f3846d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87ac256-b75d-4fba-843d-8bfee2d81f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4820415-90ba-43d5-be5c-0c427ff4312f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f296262b-1939-42e4-9590-1757ad48f99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efa5911-10b8-4655-94e7-1ebafdedc4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57d7a30-3e28-47aa-9cc0-07bbaf29c795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebc1276-cd1f-4b0c-a7d1-3c15f5ffc069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04de73cd-0290-4765-8b03-77907566823a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd45fbdd-e8f2-438f-adb0-87c0c8143273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5839b2ef-1a28-4548-8f52-a268f09c100b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7615efd-dc01-4647-83ab-f466750a95bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09837dd-5721-46a8-b1c3-92a47e44f1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0781f0-565f-4d47-bb6f-84248730d5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1d0844-417c-4323-bade-86f95265652b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c62f975-beb4-4ed0-873b-e47f0902da25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a873c54-2f4f-4fa7-9a57-d1deff2d169d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e04f207-e05a-419f-8383-d35cc713b29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee77d83-1bc9-4428-a95b-63825dbbf505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6d651c-46ef-43a6-834b-b8b1b80d7113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b536a7c-3e2c-44d6-a93f-f88aaf954579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bba6271-61a6-4869-aa4f-dcab030abc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b840c74-4fc4-4e36-8c6a-752ac4c3fd0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43f8381f-2b16-4c03-8f26-e8282ba589d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3ceef2-6140-497f-918e-a2b0268bf1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b27fd0c-dde4-480a-8cdd-f4812f2844ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c00ebf-4931-42ed-940c-ae8da1879f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1efb963-4a6a-404a-9e77-679a474a3fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e988a6-4a87-4699-b199-876467e8ed08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f5dc3a9-7cca-4c0d-b442-cdb3b9ff7dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20019528-0175-4a19-9990-de7085a7f520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4cfc4b-e904-4c4b-9df0-61938e73fe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96dbe1cf-01d6-46a1-bd20-4d52baba0dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87dd207a-0667-43d8-92d5-f840e21777bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16408122-4ccd-4eaa-a126-e852605b1fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8facb0-55f6-435a-bfa7-60384b50923c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524413fe-199b-4f8b-b5e8-fa3a86b1bb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8078198-babd-472e-a01b-fbf35a2c1a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1eb51a-5e80-4018-9e3c-6392e0084dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926cd849-1284-4d79-b3e6-9777cd5bb76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34574d92-7262-486b-9ce4-5e0df4c3d7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a7b53f-eaa8-4d5e-93ff-4ba1c80f01f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 794f0468-66f5-4215-afee-ec9e566d7559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe97421-fba8-404c-86f8-25f90975dfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5cbd611-250d-4bf5-82dd-71df5ec87596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483fca9d-9b58-4e31-a0c8-e597223aaa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c38497-1eb3-4c42-8edf-2515119baba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86dd4632-0f16-47ee-bb16-96353b6ecb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ddff23-e1c0-4ec7-a143-0027823e94f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20fb9f37-0a76-4ef4-acbe-1cd97bda372f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3da8baa-3313-442a-856d-154bfd660971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8ba150-583e-4e88-93b2-c6874c1edf99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4ecd4a-85bb-442d-8ce9-f42c8d65dece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dbc0e2b-8a7b-465b-b871-5baf36475b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 597e2f42-ba2c-4df8-99fe-dec006332309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6acaf118-9b18-4078-9704-84b5d7c859a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40624f3-dbb5-4842-8027-e668f4a51aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80bd1ad0-6b2e-45bc-a88c-f90e6bcde4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57006785-7cfb-4e78-bae3-f8df4f7f1623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d104eeb1-4c6b-41f9-b909-3afc9d3fd106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6e9082-a128-452b-a448-ce27eb35c47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad344c25-87e5-498d-bca3-dbbf8aa82c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90fb1db-373c-4dcc-b216-88e207bf0cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942bc3fe-8b07-47a1-9146-d7165eedbc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaba679d-1479-48ed-970c-c6e565e161fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7977f3f1-91f4-43d4-9360-306102f67b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ab3268-a4c7-489c-b396-54943429d14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7094b53-26c3-429a-8a56-f7021a3a05b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bbfc41c-f3ba-46db-8183-0b59147ad9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5480af-8e4e-4bb8-a62c-8e382471a281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6d7661-7d31-4c89-9547-7b1a2169c680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95353d0c-2da6-4924-a327-7844ea5e30b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce829d71-b121-4996-999e-e2eaf70045da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6044b37d-76df-4cef-8075-4a9040c4288c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8501c180-a41a-487a-af42-a8e158b05e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1dc84d0-cd3c-433e-b68a-ccfb32787664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e04ad43-899a-475c-8fae-4b3e105d0a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea76e1a0-5f0e-43c6-9e96-bcbfc8df79ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ad86bc-fe37-49e1-b4cc-40b55620d769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7901f2-788e-459d-912e-3bc3948bbfb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc2863b-164a-41ff-9a14-6abdf1d72730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b573af29-c94e-4bfa-a4d5-84c370f9731e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d1541f-7697-473f-9cfa-5185395c0efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5387a7c9-01e2-457b-96be-b8f385ae1369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be75ed02-9e06-4e6a-b06a-57d9be6059e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80ac4f2a-99ab-4e36-b1f3-feccb2a2c042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fcfd9d1-4b3a-46a7-a6a4-01a4c7b3d98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62be8dba-9992-4a4f-aa9f-c1d4a55a3ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33ee4e3a-ccbe-410c-8671-ef2d16c27c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b665d24-98c4-4942-8b52-2428a882fce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c512e4-010a-4d4e-9b19-8c19f99fe95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d3889d-d60b-4c86-8b35-f6f06069a529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08ad0a1-1b20-4919-be39-570fb69229f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08ca377d-9d32-4687-bfe5-077cd220a175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70adecab-7baf-418a-b301-8f27f18baaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c2181cd-f8bc-412a-990b-f26b49287dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e50fca7-8b06-45dc-a853-a0338dc7c3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050d1cd5-64f5-46db-bbaf-334818dc2bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b007c163-2c7c-45aa-9fb0-a96081bd2118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8938706-95c4-4c6c-914e-d651d0498854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab73dd0-4666-4e55-a07b-965f71b05ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e7946c8-987e-4e85-9b0d-75d27b639810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1513d6-df9d-4f63-8359-0ff8da0eb504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5fac586-d09c-419e-a3df-ce5915a16b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a45f2c-2c0d-4e09-ae77-775c47343337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf6c81a-75a2-421b-a1dc-2b3764f5e765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a4eae4-70a5-4549-a574-44b4e9509e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d23fdd1-570a-4282-a947-0bc75dd09b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9db16c-93e5-45a9-a8ee-ef3cde0429fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85627c74-189c-4ad0-b406-5561f058de1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91965a6d-0ff3-40ad-a7e2-36e5ecb35cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c79de60-062c-46b8-8497-b068b12e34e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf9f9d1-c8cf-4355-a981-3fcd8c3a70ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36eb913c-a4e6-45a9-a9bb-091ebe65e723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ab9194-e6d8-40ec-b881-d12ba6915f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbaccd0e-b4ae-4d9f-bdfa-1b634da8bd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9cc4b9-b9c3-4b04-8605-89f17683d573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c45dd99-4644-40af-90ba-ab6d837dcb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e26bc82-bea4-4be8-845a-c2cc76627323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf591aea-f164-40e6-a3dc-b4bbe2f5d3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e402afb4-7930-453a-985e-72d93d1610a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0dc151-b3fb-44a2-93e0-59d1536e3b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5e8a02-f488-417f-a3f6-22a9b7d2ab8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bdce7c-915b-4820-ba31-d76631d8d745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 462e6be3-bb9a-4706-a971-8ff9e3d4f38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d090bb8-2507-4a82-a62d-a66e8e8a763d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de795f81-dba9-4b5e-ba84-191f3b1fe4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab783dd3-d5d9-4b01-ada3-20f67c14be94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10f671a-58fa-4f32-a4de-6d74e44fb7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00dde05-7a77-4258-b9c1-943c2f05365d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b266a8ed-434d-4c22-b5f7-50782ddb422e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff064f8-d643-4f55-88f3-0c2ab52cfc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f85730b-c0c3-408e-810d-de3722529c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3fc2bbe-bea0-4865-a5b2-811f324e009a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf9226d-a5c8-4e9c-998b-b446d5cf4f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3f49f0d-f15f-4dec-97f2-1cbf1722c474
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(5148, 24), y=(5148,)
   Test:  X=(1287, 24), y=(1287,)

⚠️  Limiting training data: 5148 → 800 samples
⚠️  Limiting test data: 1287 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0755 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0855, val=0.0738 (↓), lr=0.001000
   • Epoch   3/100: train=0.0855, val=0.0734, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0855, val=0.0733 (↓), lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0732, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0852, val=0.0730, patience=7/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 2 Summary - Client client_12
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0049
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0097
============================================================


============================================================
🔄 Round 4 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0941 (↓), lr=0.001000
   • Epoch   2/100: train=0.0812, val=0.0965, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0982, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0812, val=0.0990, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0988, patience=4/15, lr=0.001000
   📉 Epoch 6: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0797, val=0.0963, patience=10/15, lr=0.000500
   📉 Epoch 14: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 4 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0063
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0636
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2522, R²: 0.0011

📊 Round 4 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2522, R²: 0.0001

============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000250
   • Epoch   2/100: train=0.0841, val=0.0808, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0838, val=0.0809, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0837, val=0.0809, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0836, val=0.0809, patience=4/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0833, val=0.0810, patience=10/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0047
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0202
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 8 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0937 (↓), lr=0.000063
   • Epoch   2/100: train=0.0807, val=0.0935, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0806, val=0.0934, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0806, val=0.0934, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0805, val=0.0933, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0803, val=0.0933, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 8 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0017
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0040
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2519, R²: 0.0024

📊 Round 8 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2519, R²: 0.0027

============================================================
🔄 Round 12 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0820 (↓), lr=0.000016
   • Epoch   2/100: train=0.0838, val=0.0822, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0836, val=0.0826, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0836, val=0.0828, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0835, val=0.0830, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 12 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0248
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2519, R²: 0.0011

============================================================
🔄 Round 13 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000004
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0826, val=0.0888, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0826, val=0.0888, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0825, val=0.0888, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 13 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0005
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0076
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2519, R²: 0.0011

============================================================
🔄 Round 15 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 15 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0083
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0146
============================================================


============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0085
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0030
============================================================


============================================================
🔄 Round 21 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 21 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0090
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 24 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 24 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0026
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0031
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 25 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 25 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0031
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0012
============================================================


============================================================
🔄 Round 28 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 28 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0021
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0045
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 32 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 32 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0065
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0021
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 36 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 36 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0025
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0014
============================================================


============================================================
🔄 Round 37 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 37 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0006
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0108
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 39 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 39 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0045
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0014
============================================================


============================================================
🔄 Round 40 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 40 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0034
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0023
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 42 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 42 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0018
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0136
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0018
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0041
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

📊 Round 44 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 47 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 47 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0064
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0002
============================================================


============================================================
🔄 Round 48 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 48 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0008
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0071
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

📊 Round 48 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 48 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 52 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 52 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0007
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0364
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 52 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 52 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 52 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 60 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 60 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0013
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0118
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 63 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 63 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0043
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0063
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 65 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 65 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0022
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0008
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 69 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 69 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0005
============================================================


============================================================
🔄 Round 70 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 70 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0034
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0025
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 71 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 71 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0015
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0051
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 72 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 72 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0027
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0087
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 74 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 74 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0084
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0007
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 75 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 75 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0006
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0066
============================================================


============================================================
🔄 Round 76 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 76 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0020
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0006
============================================================


============================================================
🔄 Round 78 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 78 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0048
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0023
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 79 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 79 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0016
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0042
============================================================


============================================================
🔄 Round 80 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 80 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0031
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0044
============================================================


============================================================
🔄 Round 83 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 83 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0024
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0009
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 85 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 85 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0006
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0103
============================================================


============================================================
🔄 Round 87 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 87 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0026
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0001
============================================================


============================================================
🔄 Round 88 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 88 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0002
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0087
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 88 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 88 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 93 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 93 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0043
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0070
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 95 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 95 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0016
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0023
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 97 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 97 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0052
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0083
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 100 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 100 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0032
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0027
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 100 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 100 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 105 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 105 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0025
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0012
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 105 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 105 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 108 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 108 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0025
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0009
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 109 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 109 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0049
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0105
============================================================


============================================================
🔄 Round 110 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 110 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0000
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0083
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 114 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 114 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0010
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0043
============================================================


============================================================
🔄 Round 115 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 115 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0003
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0143
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 115 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 121 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 121 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0009
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0202
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 123 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 123 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0043
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0149
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 126 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 126 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0064
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0177
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 128 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 128 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0006
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0248
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 130 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 130 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0034
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0074
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 135 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 135 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0010
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0236
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 136 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 136 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0016
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0204
============================================================


============================================================
🔄 Round 140 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 140 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0033
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0060
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 142 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 142 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0011
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0250
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 144 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 144 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0000
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0113
============================================================


============================================================
🔄 Round 145 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 145 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0040
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0005
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 145 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 149 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 149 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0034
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0068
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 149 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.1029 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.1029, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.1029, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.1029, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.1028, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.1028, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1029)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0032
   Val:   Loss=0.1029, RMSE=0.3207, R²=-0.0083
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 154 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 154 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0021
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0017
============================================================


============================================================
🔄 Round 156 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 156 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0004
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0175
============================================================


============================================================
🔄 Round 158 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 158 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0011
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0909
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 159 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 159 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0024
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0229
============================================================


============================================================
🔄 Round 160 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 160 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0025
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0030
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 163 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 163 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0004
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0056
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 166 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 166 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0001
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0089
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 170 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 170 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0023
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0017
============================================================


============================================================
🔄 Round 171 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 171 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0011
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0078
============================================================


============================================================
🔄 Round 172 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 172 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0044
   Val:   Loss=0.0671, RMSE=0.2591, R²=0.0067
============================================================


============================================================
🔄 Round 173 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 173 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0017
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0085
============================================================


============================================================
🔄 Round 179 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 179 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0000
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0175
============================================================


============================================================
🔄 Round 180 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 180 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0000
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0097
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 182 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 182 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0033
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0014
============================================================


============================================================
🔄 Round 185 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 185 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0012
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0108
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 186 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 186 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0016
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0042
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 189 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 189 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0027
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0023
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 190 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 190 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0002
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0084
============================================================


============================================================
🔄 Round 191 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 191 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0009
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0096
============================================================


============================================================
🔄 Round 192 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 192 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0021
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0195
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 193 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 193 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0029
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0041
============================================================


============================================================
🔄 Round 198 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 198 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0050
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0093
============================================================


============================================================
🔄 Round 199 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 199 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0110
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 201 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 201 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0017
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0003
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 205 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 205 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0039
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0038
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 206 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 206 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0023
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0029
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 208 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 208 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0013
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0137
============================================================


============================================================
🔄 Round 209 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 209 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0001
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0122
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 209 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 213 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 213 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0032
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0016
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 213 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 215 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 215 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0028
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0022
============================================================


============================================================
🔄 Round 218 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 218 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0013
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0019
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 218 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 223 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 223 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0041
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0048
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 227 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 227 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0029
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0065
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 227 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 229 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 229 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0022
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0006
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 230 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 230 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0017
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0121
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 232 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 232 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0012
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0056
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 234 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 234 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0001
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0076
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 237 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 237 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0014
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0011
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 239 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 239 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0029
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0032
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 241 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 241 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0007
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0170
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 241 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 247 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 247 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0044
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0097
============================================================


============================================================
🔄 Round 249 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 249 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0016
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0012
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 251 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 251 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0053
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0027
============================================================


============================================================
🔄 Round 253 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 253 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0006
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0095
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 254 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 254 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0013
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0033
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 256 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 256 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0006
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0041
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 258 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 258 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0002
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0052
============================================================


============================================================
🔄 Round 260 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 260 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0005
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0047
============================================================


============================================================
🔄 Round 263 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 263 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0036
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0317
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 264 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 264 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0029
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0070
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 265 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 265 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0008
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0180
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 265 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 268 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 268 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0000
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0168
============================================================


============================================================
🔄 Round 270 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 270 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0034
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0061
============================================================


============================================================
🔄 Round 271 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 271 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0016
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0014
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 271 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 275 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 275 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0022
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0032
============================================================


============================================================
🔄 Round 277 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 277 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0001
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0502
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 278 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 278 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0021
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0032
============================================================


============================================================
🔄 Round 279 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 279 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0059
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0380
============================================================


============================================================
🔄 Round 281 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 281 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0018
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0010
============================================================


============================================================
🔄 Round 282 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 282 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0008
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0081
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 282 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 282 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 282 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 288 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 288 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0006
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0142
============================================================


============================================================
🔄 Round 289 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 289 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0011
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0021
============================================================


============================================================
🔄 Round 290 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 290 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0002
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0125
============================================================


============================================================
🔄 Round 292 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 292 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0043
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0109
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 294 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 294 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0025
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0361
============================================================


============================================================
🔄 Round 295 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 295 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0034
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0011
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 301 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 301 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0001
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0088
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 306 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 306 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0009
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0322
============================================================


============================================================
🔄 Round 307 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 307 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0003
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0383
============================================================


============================================================
🔄 Round 308 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 308 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0032
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0051
============================================================


============================================================
🔄 Round 309 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 309 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0016
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0344
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 309 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 311 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 311 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0016
   Val:   Loss=0.0945, RMSE=0.3075, R²=0.0000
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 311 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 316 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 316 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0044
============================================================


============================================================
🔄 Round 317 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 317 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0023
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0306
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 317 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 319 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 319 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0011
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0025
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 321 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 321 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0031
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0051
============================================================


============================================================
🔄 Round 322 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 322 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0008
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0178
============================================================


============================================================
🔄 Round 323 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 323 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0002
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0100
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 323 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 325 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 325 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0014
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0016
============================================================


============================================================
🔄 Round 327 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 327 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0038
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0089
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 327 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 333 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 333 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0011
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0192
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 333 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 333 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 336 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 336 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0010
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0090
============================================================


============================================================
🔄 Round 337 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 337 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0011
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0009
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 338 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 338 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0021
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0003
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 338 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 341 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 341 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0031
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0082
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 342 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 342 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0005
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0087
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 342 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 348 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 348 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0004
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0045
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 350 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 350 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0027
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0051
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 352 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 352 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0039
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0329
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 352 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 355 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 355 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0010
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0109
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 355 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 362 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 362 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0008
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0089
============================================================


============================================================
🔄 Round 363 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 363 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0003
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0057
============================================================


============================================================
🔄 Round 365 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 365 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0041
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0101
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 367 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 367 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0010
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0054
============================================================


============================================================
🔄 Round 370 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 370 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0011
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0065
============================================================


============================================================
🔄 Round 374 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 374 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0041
   Val:   Loss=0.0926, RMSE=0.3044, R²=0.0047
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 376 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 376 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0036
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0075
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 377 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 377 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0009
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0030
============================================================


============================================================
🔄 Round 380 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 380 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0006
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0063
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

📊 Round 380 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0016

============================================================
🔄 Round 385 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 385 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0028
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0057
============================================================


============================================================
🔄 Round 386 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 386 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0082
============================================================


============================================================
🔄 Round 387 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 387 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0013
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0003
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 389 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 389 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0014
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0115
============================================================


============================================================
🔄 Round 390 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 390 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0001
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0223
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 390 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 390 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 390 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 390 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 390 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 401 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 401 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0018
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0015
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 401 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 401 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 401 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 401 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 406 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 406 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0039
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0082
============================================================


============================================================
🔄 Round 407 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 407 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0009
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0303
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 407 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 413 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 413 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0010
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0060
============================================================


============================================================
🔄 Round 414 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 414 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0014
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0138
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 414 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 417 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 417 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0028
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0035
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 419 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 419 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0013
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0036
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 419 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 425 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 425 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0057
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0232
============================================================


============================================================
🔄 Round 427 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 427 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0050
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0114
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 429 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 429 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0013
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0011
============================================================


============================================================
🔄 Round 430 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 430 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0054
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0096
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 431 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 431 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0037
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 431 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 437 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 437 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0017
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0007
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 437 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 437 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 437 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 443 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 443 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0008
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0063
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 450 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 450 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0018
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0013
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 452 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 452 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0002
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0063
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 453 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 453 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0021
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0023
============================================================


============================================================
🔄 Round 454 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 454 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0043
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0049
============================================================


============================================================
🔄 Round 457 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 457 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0021
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0035
============================================================


============================================================
🔄 Round 458 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 458 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0042
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0066
============================================================


============================================================
🔄 Round 459 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 459 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0021
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0000
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 459 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 459 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 459 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 459 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 467 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 467 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0010
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0028
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 467 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 470 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 470 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0017
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0344
============================================================


============================================================
🔄 Round 471 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 471 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0003
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0145
============================================================


============================================================
🔄 Round 472 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 472 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0017
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0011
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 473 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 473 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0008
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0032
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 476 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 476 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0008
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0097
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 477 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 477 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0008
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0037
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 478 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 478 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0017
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0013
============================================================


============================================================
🔄 Round 481 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 481 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0023
   Val:   Loss=0.0817, RMSE=0.2857, R²=0.0042
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 481 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 483 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 483 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0030
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0031
============================================================


============================================================
🔄 Round 484 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 484 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0005
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0040
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 486 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 486 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0010
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0084
============================================================


============================================================
🔄 Round 488 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 488 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0015
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0008
============================================================


============================================================
🔄 Round 489 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 489 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0030
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0052
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 491 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 491 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0020
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0132
============================================================


============================================================
🔄 Round 495 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 495 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0006
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0164
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 496 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 496 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0006
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0115
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 497 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 497 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0012
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0403
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

📊 Round 497 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 499 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 499 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0010
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0131
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 503 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 503 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0001
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0224
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 504 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 504 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0049
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0025
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 509 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 509 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0297
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 510 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 510 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0020
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0026
============================================================


============================================================
🔄 Round 511 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 511 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0011
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0008
============================================================


============================================================
🔄 Round 512 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 512 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0016
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0002
============================================================


============================================================
🔄 Round 513 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 513 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0006
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0150
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 513 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 517 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 517 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0026
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0050
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 517 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 519 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 519 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0007
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0027
============================================================


============================================================
🔄 Round 520 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 520 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0002
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0168
============================================================


============================================================
🔄 Round 522 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 522 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0003
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0167
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 524 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 524 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0007
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0133
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 524 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 526 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 526 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0012
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0072
============================================================


============================================================
🔄 Round 527 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 527 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0030
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0057
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 527 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 527 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 531 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 531 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0074
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0151
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 534 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 534 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0020
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0067
============================================================


============================================================
🔄 Round 540 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 540 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0033
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0021
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 541 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 541 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0036
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0198
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 541 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 546 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 546 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0037
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0199
============================================================


============================================================
🔄 Round 548 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 548 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0070
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0191
============================================================


============================================================
🔄 Round 549 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 549 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0005
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0115
============================================================


============================================================
🔄 Round 550 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 550 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0017
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0147
============================================================


============================================================
🔄 Round 553 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 553 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0001
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0052
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 553 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 553 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 559 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 559 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0007
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0023
============================================================


============================================================
🔄 Round 560 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 560 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0049
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0112
============================================================


============================================================
🔄 Round 562 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 562 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0064
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0101
============================================================


============================================================
🔄 Round 563 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 563 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0032
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0059
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 564 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 564 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0040
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0086
============================================================


============================================================
🔄 Round 566 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 566 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0036
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0015
============================================================


============================================================
🔄 Round 567 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 567 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0021
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0004
============================================================


============================================================
🔄 Round 568 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 568 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0001
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0069
============================================================


============================================================
🔄 Round 570 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 570 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0033
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0051
============================================================


============================================================
🔄 Round 572 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 572 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0023
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0019
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 573 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 573 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0014
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0005
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 574 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 574 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0069
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 574 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 574 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 577 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 577 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0014
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0117
============================================================


============================================================
🔄 Round 578 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 578 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0003
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0073
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 578 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 580 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 580 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0036
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0175
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 582 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 582 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0022
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0039
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 582 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 585 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 585 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0022
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0022
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 585 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 589 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 589 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0007
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0088
============================================================


============================================================
🔄 Round 590 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 590 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0051
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0041
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 590 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 590 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 594 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 594 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0037
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0085
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0015

============================================================
🔄 Round 595 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 595 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0012
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0157
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 601 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 601 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0028
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0048
============================================================


============================================================
🔄 Round 602 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 602 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0037
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0031
============================================================


============================================================
🔄 Round 605 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 605 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0027
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0195
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 605 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 607 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 607 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0004
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0046
============================================================


============================================================
🔄 Round 608 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 608 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0013
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 608 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 611 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 611 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0016
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0032
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 612 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 612 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0044
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0035
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 614 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 614 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0017
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0177
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 617 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 617 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0011
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0038
============================================================


============================================================
🔄 Round 618 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 618 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0026
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0126
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

📊 Round 618 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 622 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 622 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0010
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0240
============================================================


============================================================
🔄 Round 623 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 623 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0013
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0070
============================================================


============================================================
🔄 Round 624 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 624 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0032
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0060
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 626 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 626 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0032
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 631 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 631 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0023
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0013
============================================================


============================================================
🔄 Round 632 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 632 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0007
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0076
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 634 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 634 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0005
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0091
============================================================


============================================================
🔄 Round 635 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 635 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0025
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0028
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 638 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 638 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0004
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0065
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 640 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 640 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0006
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0197
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 640 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 640 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 645 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 645 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0017
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0002
============================================================


============================================================
🔄 Round 647 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 647 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0027
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0055
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 652 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 652 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0026
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0041
============================================================


============================================================
🔄 Round 653 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 653 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0014
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0056
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 657 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 657 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0016
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0037
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 659 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 659 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0017
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0200
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 659 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 665 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 665 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0015
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0006
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 665 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 665 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 665 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 673 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 673 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0001
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0055
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 673 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 673 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 678 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 678 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0003
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0067
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 678 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 681 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 681 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0029
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0163
============================================================


============================================================
🔄 Round 685 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 685 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0001
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0119
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 686 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 686 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0058
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 687 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 687 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0004
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0043
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 687 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 695 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 695 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0035
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0025
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 695 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 697 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 697 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0003
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0069
============================================================


============================================================
🔄 Round 698 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 698 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0040
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0374
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 698 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 704 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 704 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0032
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0014

============================================================
🔄 Round 705 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 705 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0056
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 707 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 707 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0022
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0031
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 709 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 709 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0034
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0081
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 710 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 710 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0105
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 711 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 711 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0018
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0215
============================================================


============================================================
🔄 Round 712 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 712 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0021
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0177
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 713 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 713 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0062
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0086
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 714 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 714 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0027
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0010
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 716 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 716 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0016
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0172
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 716 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 720 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 720 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0035
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0067
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 723 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 723 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0028
   Val:   Loss=0.0871, RMSE=0.2950, R²=-0.0109
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 724 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 724 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0002
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0169
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 724 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 724 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 724 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 729 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 729 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0033
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0025
============================================================


============================================================
🔄 Round 730 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 730 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0072
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0160
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 733 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 733 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0029
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0067
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 734 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 734 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0012
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0104
============================================================


============================================================
🔄 Round 735 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 735 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0087
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 736 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 736 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0006
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0066
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 738 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 738 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0021
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0011
============================================================


============================================================
🔄 Round 739 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 739 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0002
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0051
============================================================


============================================================
🔄 Round 740 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 740 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0000
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0090
============================================================


============================================================
🔄 Round 745 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 745 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0022
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0159
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 745 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 745 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 750 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 750 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0037
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0012
============================================================


============================================================
🔄 Round 753 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 753 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0033
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0036
============================================================


============================================================
🔄 Round 754 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 754 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0040
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0080
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 757 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 757 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0012
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0021
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 758 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 758 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0008
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0073
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 759 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 759 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0004
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0065
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 760 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 760 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0022
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0027
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 761 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 761 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0013
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0013
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 765 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 765 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0022
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0035
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 768 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 768 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0034
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0088
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 772 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 772 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0041
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0118
============================================================


============================================================
🔄 Round 773 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 773 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0013
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0206
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 774 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 774 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0037
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0029
============================================================


============================================================
🔄 Round 775 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 775 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0024
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0039
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

📊 Round 775 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 778 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 778 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0015
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0023
============================================================


============================================================
🔄 Round 779 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 779 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0032
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0031
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 783 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 783 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0005
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0039
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 784 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 784 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0039
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0090
============================================================


============================================================
🔄 Round 785 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 785 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0008
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0033
============================================================


============================================================
🔄 Round 786 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 786 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0044
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0106
============================================================


============================================================
🔄 Round 787 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 787 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0039
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0052
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 789 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 789 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0065
============================================================


============================================================
🔄 Round 791 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 791 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0004
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0093
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 793 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 793 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0013
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0291
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 797 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 797 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0015
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0111
============================================================


============================================================
🔄 Round 799 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 799 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0011
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0150
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 805 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 805 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0041
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0225
============================================================


============================================================
🔄 Round 806 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 806 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0031
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0057
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 810 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 810 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0013
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0009
============================================================


============================================================
🔄 Round 811 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 811 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0046
============================================================


============================================================
🔄 Round 812 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 812 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0020
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0032
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0013

============================================================
🔄 Round 815 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 815 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0034
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0023
============================================================


============================================================
🔄 Round 816 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 816 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0023
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0022
============================================================


============================================================
🔄 Round 820 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 820 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0001
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0064
============================================================


============================================================
🔄 Round 824 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 824 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0015
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0009
============================================================


============================================================
🔄 Round 828 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 828 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0057
============================================================


📊 Round 828 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 830 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 830 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0004
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0072
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 830 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

📊 Round 830 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

📊 Round 830 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 838 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 838 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0004
============================================================


============================================================
🔄 Round 839 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 839 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0016
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0123
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 840 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 840 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0012
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0006
============================================================


============================================================
🔄 Round 841 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 841 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0026
============================================================


============================================================
🔄 Round 843 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 843 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0027
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0021
============================================================


============================================================
🔄 Round 844 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 844 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0003
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0270
============================================================


📊 Round 844 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 848 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 848 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0005
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0026
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

📊 Round 848 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 851 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 851 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0025
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0025
============================================================


============================================================
🔄 Round 852 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 852 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0021
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0027
============================================================


============================================================
🔄 Round 853 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 853 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0010
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0037
============================================================


============================================================
🔄 Round 854 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 854 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0024
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0661
============================================================


📊 Round 854 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 854 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 859 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 859 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0016
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0027
============================================================


============================================================
🔄 Round 862 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 862 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0005
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0067
============================================================


============================================================
🔄 Round 863 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 863 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0042
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0063
============================================================


📊 Round 863 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 865 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 865 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0027
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0061
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 867 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 867 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0000
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0047
============================================================


📊 Round 867 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 869 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 869 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0029
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0013
============================================================


📊 Round 869 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 870 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 870 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0001
   Val:   Loss=0.0787, RMSE=0.2804, R²=-0.0189
============================================================


============================================================
🔄 Round 871 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 871 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0016
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0053
============================================================


============================================================
🔄 Round 872 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 872 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0009
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0104
============================================================


============================================================
🔄 Round 873 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 873 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0046
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0104
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0013

============================================================
🔄 Round 874 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 874 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0009
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0089
============================================================


📊 Round 874 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0013

============================================================
🔄 Round 876 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 876 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0014
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0097
============================================================


============================================================
🔄 Round 877 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 877 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0022
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0025
============================================================


📊 Round 877 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0013

============================================================
🔄 Round 879 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 879 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0025
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0030
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0013

============================================================
🔄 Round 880 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 880 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0015
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0129
============================================================


============================================================
🔄 Round 882 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 882 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0020
   Val:   Loss=0.0766, RMSE=0.2769, R²=-0.0140
============================================================


📊 Round 882 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 883 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 883 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0030
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0063
============================================================


📊 Round 883 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 885 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 885 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0003
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0140
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 886 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 886 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0021
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0030
============================================================


============================================================
🔄 Round 887 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 887 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0009
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0007
============================================================


============================================================
🔄 Round 889 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 889 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0008
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0010
============================================================


📊 Round 889 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 894 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 894 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0010
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0239
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 894 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 894 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 901 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 901 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0016
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0022
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 902 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 902 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0039
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0198
============================================================


📊 Round 902 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 909 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 909 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0001
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0187
============================================================


📊 Round 909 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 910 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 910 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0001
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0052
============================================================


📊 Round 910 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0013

============================================================
🔄 Round 913 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 913 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0010
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0041
============================================================


📊 Round 913 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 914 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 914 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0013
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0002
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 914 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 916 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 916 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0018
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0027
============================================================


============================================================
🔄 Round 917 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 917 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0032
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0038
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 918 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 918 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0012
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0001
============================================================


============================================================
🔄 Round 919 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 919 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0073
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 922 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 922 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0009
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0017
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 924 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 924 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0119
============================================================


============================================================
🔄 Round 925 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 925 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0050
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0108
============================================================


📊 Round 925 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 927 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 927 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0002
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0038
============================================================


📊 Round 927 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 928 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 928 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0203
============================================================


📊 Round 928 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 930 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 930 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0012
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0142
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 932 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 932 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0001
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0049
============================================================


📊 Round 932 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 932 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

📊 Round 932 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 942 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 942 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0001
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0048
============================================================


============================================================
🔄 Round 946 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 946 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0003
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0089
============================================================


📊 Round 946 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2521, R²: 0.0012

============================================================
🔄 Round 948 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 948 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0018
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0006
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
