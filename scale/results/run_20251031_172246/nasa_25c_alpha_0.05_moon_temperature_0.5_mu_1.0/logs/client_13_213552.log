[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187b8fd5-108b-47ef-83db-195f278698c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 044e486d-4279-4b10-8645-95dcdfaf9ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba48d4f-9c78-4cd0-ae3f-204f88c20a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac47d438-12c5-462f-8874-8556af999dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d4b321-a63a-4358-89d3-4d6fdbf8f4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5bd17f-8acb-4c47-9c97-807d17d2853d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5ebeb3-fcc6-4d73-a558-1818ba355095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5334b300-7177-432a-8d22-ffdbc46da159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5da930-d6a0-48ff-8539-6787ec92a123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98b8ac9-563d-4a13-b660-ee45e2be9878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3116bb-a937-44ca-8812-24297b2d63ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75225934-ca81-478b-b3a9-12b8b00ff52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d760367c-a8f7-439a-bbba-751624568507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476c890d-e45f-4cbc-9a8a-51144e9b65e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84cc9a37-d68f-4314-b102-53deb86ab4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08fbffc3-8612-46e0-a946-a10fa131bd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37aae127-afec-4b93-9300-d57252c991b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8eab9e7-060b-40ca-ac80-7237cd4ba6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d92732c-f8bb-4284-a3e7-baa34f221eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67568b7c-80fd-4ccc-b978-625cb71ccb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f24f71f-57ee-4037-9288-c3485742448c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf6346b-fe9c-43ed-906b-7e43bacee853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c3e719-196a-4eaf-ac99-6dfd353244c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adaf627e-cb55-4ea5-86d3-1af9ff952246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a1926f-3c88-4539-aa64-9f8cd270d490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a54958-87ef-4255-a09a-c10323469ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ae55bb8-bc38-495b-966f-c7d80fb0025c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e96003-6f51-4750-9a41-8ab33c3d8f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec9b89a7-af57-4857-8623-63ab50c8f471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551ab12d-501b-465f-9f75-cc4ccecbccfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16d5a91-9783-44c7-8baf-3a1d92f3cb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8137ad1-471f-46c4-a367-37a337549bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b810c46-3dae-4766-a95a-d06d2126dc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71620152-6eea-4172-8f6c-93575c4a27be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b24f02b-c498-4d30-a8e0-ad734c526b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8ba0ca-5bd3-4100-8900-c714c2d0b83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33761592-1f70-4fce-a7be-b3f61b04a343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640e13ab-b67e-44a3-b74a-b3c4ebd0b26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03e93ac-262e-4e2e-9547-e697b221d820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24dff8d4-3d66-4094-a9e8-7ca096eb30ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be014674-983d-4637-9143-f198efd75a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bf07bc-5d4b-49d2-b416-eed969414670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736315fe-06ad-40aa-a39a-e15eaa816cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9e5b7b-0b18-466b-ac3e-94e5ae7a8fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279d1470-fa73-46fc-a402-389676b1e74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a3a405-1005-42e3-ba1b-20e177b00348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bc5ec4-7282-4502-b6cf-7225ec586e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd133e2-184b-47ef-bb56-b5f4d886a62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6224ed13-ecd8-4b1a-8450-4e807905b5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ece6748-8a94-4a27-9831-2cdbdbfe194d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10cceeea-8d96-4444-b197-955eaf49af4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dbf1338-5a79-43c6-8fb9-d20b750afda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db532db6-1785-4553-9fac-5de75522e9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4895ee5-0dc2-455b-83ee-8f0bcd404a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b299b05-3002-4303-926d-dafae0494464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c64977-18af-47dc-b836-b299038f899b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204a3a94-a2bd-4a86-9231-009b629474c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 679fb331-d3ca-41df-b46d-36fd2c52db1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e738875c-f2a1-40a2-a5cf-d545132808d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d2a4ec-b17c-4dcf-8084-8c0f01b29de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c58edcf-c651-4b76-8c57-c27372e68cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9b36dd-f745-4be0-82de-0aaee084f12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30365e4d-858b-4e65-9809-402f0910e42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac762edc-6ebe-45d7-9284-8ce3cd47dec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5afb1aa2-8613-477a-be63-e3d15baa7514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89833f3e-95e0-4e40-9eae-2c797c42b0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f86b64-36b5-4dc0-ab1f-1ba0b785eb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fae01cf-3389-4875-9976-bfc0b9910818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695177d7-650e-40a9-b443-54980b3e8800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5239fe0e-fc6c-4a51-ac54-79a570aa638a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820a931d-d427-4d5a-8e8f-7f1b46545d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceced52b-e8a0-4d7f-96ea-7bdd9ecb9913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b519166a-fff6-444b-b366-9ce0007ed521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b14afa-4c94-4823-b076-89cc29463ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbe08e4-6e24-4668-92e3-ad2a45ce6013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8965fe84-b948-4636-9c43-458c5936c7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcf0d7f3-4f14-4fb4-8689-0c810ef4a7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f26bea-0784-4149-8388-39d5a4068967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f60057-3d48-4233-9ca4-6b9f4d24f58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f2328c4-23e3-4021-b440-dbce4c97be8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d38aa1-6868-49aa-8ddf-faa8ba0ccd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878c7f9a-86c0-4f13-8baf-b7db8cf8fc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be6c2a5-c1b6-4fc6-b12b-d2bea8f2242e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6613dba6-9a75-4d40-95f7-c74d7871c7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20251405-a884-48a8-9d63-404cdab5eb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c6921f-39f7-45b1-9bc3-733799728e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7972ff36-162b-4787-b912-da934cafa41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ebd15f-a528-40b9-aefc-04fd4772b716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77093fb-a410-4a99-b32e-7efb089e2381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fa1ca21-b10f-4999-8051-5292bea07d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3196e7cc-48f8-4291-8e4b-d1b9fad9b569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7624f89-831b-41fe-8228-6ba5c7ac5650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395965d4-5f32-46e4-bbfc-44c644c7d82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e19f0f-725d-4d05-a481-fcb38c38c1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ab876b-dd40-4af1-ba33-3206a0ecd495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84abd1d-4ff8-4f03-8095-b7c65848dd85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3046a130-e355-4f6a-a209-9a09d5dad5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e829d7e3-02f0-4f01-9477-8a5a1ccb3630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6e4131-2f02-4529-8292-cf262e76c826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff31ddc-12e3-43ec-b451-da8250fcf699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c03919-ea7f-4676-96eb-3d5992184670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23d5c2f-6f8a-4c3f-8729-9c79d786ac96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37722f07-32f9-458d-8958-980b309577a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 779a05c6-da5e-4dde-becd-5409e0994650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddee2de3-38df-43e8-a49d-35f720cfc48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cd85849-f33b-4bb3-bc1c-6d559a50b1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573a02cf-bf33-4da5-a9ba-dd24fb3f2d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b153f4-b317-4eb8-ad76-5d623ec1d108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69655ca-404f-47bc-aacd-1d692abf0575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e726d6f6-751a-46ec-afa9-1109753a5932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a31657-48b0-4e2d-a20d-d7ac5b940482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05743901-122d-4e44-8cfc-49ae507b14db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c607b0-012d-42ad-a973-9a04e49eddf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e38f572-3533-412f-8b61-cb82b57af308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4162a067-b57d-4f34-bfce-0326d32e1a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fec8a0e6-ce8c-4d2c-9732-584107cbeadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2126a03e-b7d6-4584-ad1f-3affd47c4dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f59be1-626f-4a68-9dff-023e660c11d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af259f68-ffbc-4842-97d6-7161e19f3f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e7d3d9-dbce-49a5-8e91-940500f4a54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cce44eb-4510-4892-ab20-74ca24f3d735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b65436-3066-4843-b957-19a07997e8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68947afc-e02d-4b54-97d1-3f31e243a8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816c92b1-96a2-44eb-a709-eea12558571b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f96ac59-e976-4fc5-a9b4-ebcfb480db39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80425e94-fd4c-4f10-b182-15260176f845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a15878-746d-4494-90f0-4a6ffa217083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506a6cac-4e5f-4e71-8c4b-029c4bd0103f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff705303-7c79-4cc9-a54d-d73d38b3951f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38b63e2f-8c20-4660-b13d-e8d6ad81ccbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f916935e-bbfc-43ba-b7e3-86be188512a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 668961ef-d189-4f80-b26f-f8b162b9f385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6082a4af-8074-431e-b221-36548edccbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50a61d8-b807-47ba-ba38-c365d78843ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3919c0a8-2bff-4df6-9761-ecb6769b29ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 070eab49-3d53-4b99-b9eb-c70e3f09ab0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd85cfb0-5bd6-40d7-8eac-6f1e59ceeafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8f2d9b-c91c-4f2f-9fc4-bfcc44bca2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8b5ff3-d255-451b-9725-456f15c859bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce389c62-aedf-4040-8c7b-1f79cf91240b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc30efdb-3d0a-4b4b-8865-6296477dd81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8f41a1-b7f3-4a83-a857-1add51b6623f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457fa89a-db80-4edd-8309-c326eafa7bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c56847-2e4c-4c83-b69c-31411c69a512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76cbac75-0c64-4f18-a2f1-b9e824000bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be6bea6e-7120-477a-b9f7-57e2bce38a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42d5888-4913-48c3-91a5-3ccd8bebef39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1313c2-bb45-41e8-9b62-c3706f1ecf9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ae4bb8-3e88-4ee7-80cf-96e2cd76623e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38445111-e8da-4c52-a884-96cb7e3b5948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a03596-1393-4f63-9f10-2ac9533e48f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8517960a-ac57-4639-9f25-45161069c5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ac52a6-7b8a-4d86-9d53-8c16366a46d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be91cca6-04a6-44cc-bcea-ad23a90da7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055d25c9-9101-43fc-860c-0df2e31cb00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40728f2-6639-4b29-a4f4-f85b41985fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a84186b-f4f3-404e-8a65-f26965363413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8045db6c-4c3d-44fb-8944-406fd96e9c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebca957-fa6b-482c-bea4-319671698a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0651b18-6dec-453e-ad57-cb625d629de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9777c08d-7037-448a-bb9e-3730fa58ece9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f13d37b-e12f-41fe-8ff8-449c13854075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c0094e6-d22c-4f2b-9a8f-adeb664de7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b698f1-7ba7-4b5c-896e-6e1a5be896c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1050e34a-31c3-436e-a744-15e6d0a54784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456758f2-bd42-48b4-ba58-1bf211ceb650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb617f68-1f62-4604-8383-274016d57bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba8dd5d-6b81-478f-9b33-702c86f93260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12893a3d-49cb-4cb2-b118-dae2b21d7298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f920e3-7842-4c03-9613-d15be30d373e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a337ab-6ba7-4b5a-a282-8a28d9356fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 553b6e7d-597a-4d86-8304-630864e53390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9fe410e-6628-4c44-83e4-a981d3368c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c852f5-6453-46ea-abbd-84990a94836a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06dcd226-dba2-4ba4-8981-3da0b32a7ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1934d669-10ec-48bf-8f9c-01df995373fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd02ca17-de44-4f21-b2d7-071dd5f7e8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2ca09b-2f0c-4b67-a17d-47ce9dc3922b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6accbc4-73bf-4d27-bbcd-b64a0bf9aa40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57561274-dd92-452e-a75e-4ce04531ee7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3de435ff-58b2-4de6-9499-98bc133e4c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3747eda-8585-485b-a57c-7950f5f73e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad5fbf0-a993-4acd-90f3-7873fa069bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e41b9ae-4e5b-457d-b80c-278f1e0ad8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68bdb1c5-569a-4be8-8084-ab1a60fb9a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9e0ef1-3917-4bbb-94ac-361db25a6aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf3322e-346e-48cb-a29a-1a036d409366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77f068dc-ef7b-40d0-8eaa-2c8348c84508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f765e2-9b5f-4ab3-b6ff-07784cbb8cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320d6f17-297e-4f3d-baa4-806628b1f2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73bcfa7a-431f-4eac-9cc5-824d57ba7dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf3a376-632c-4529-983e-1a162d65d057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acee9275-74e1-424e-92c7-fdceca48be09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b9acc3-86dd-44e2-a9ad-a969419e4ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de627ad-ac9b-409a-9b7d-5b187b98ac49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02cf35fa-1b22-4a64-9520-668563426365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0102e436-72f6-45a6-adf5-824866a32059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4073197-32b9-4731-bf1f-16eef752ee69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ee9c62-f98d-45b5-a3f6-feb0aa36795d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc52f869-4933-4d13-8e36-2bbde6321322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee46ee9-696e-4b15-b6a9-c14a6fea0f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6529c968-705b-4537-ab14-fa90d0cd03df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14812d78-0b0d-479e-a774-6718fd8c097d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01445929-cf3c-415b-a917-0690bf531394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe7d1c49-6319-4822-9edc-d803d5bb8f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371079f9-549a-421d-9d5d-a7e3414db5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87409959-cd47-4a51-b4f4-aeb43fa10493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05d2620-4aa9-44f8-9c2d-597136bab095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec6f6a2-3790-4804-a06d-67a648922496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f49884-73ba-4b5b-acb1-5a257e3ed19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7d5ae5-b446-493e-8695-b6e01b906c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0adbe8-1c63-4144-b235-fef28fcee939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92374fb-91dc-4fcc-a840-62c5d9f8b1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493f9d87-3c01-41a5-8aae-910426032ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae6423a-ceff-4136-acc0-c8e32fd1e246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926b7960-4fbd-4f34-953a-a9d59359f859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a7c2205-ee14-460a-81d4-96e5f45ea450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdfcb10e-45bb-4f39-b324-febf5c1bb83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b92987a-2ee9-4f42-9727-d696c9d847e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00c9c80-ca87-456c-83d2-eca15a8d8b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4c449b-bcc7-4441-999b-14166b8af539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54922d82-589b-4af4-a10b-cef19719238b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4ea73a-64c4-4aeb-ba3d-78382e4ebb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42159b25-9083-4389-a43e-de056099e1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8accec-c8da-4996-a49a-956bd5b3792a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047837d7-2d3f-4993-bd3e-7e310a6a18dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4620cf53-f001-49fd-9fc5-6eaf321030ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7cca34d-3d52-45cc-ae3b-24471fc4a9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 125b2660-964d-41c4-a667-58492b40bfbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5f9d49-220e-47a3-a365-5afbcc90d38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892a341a-72c3-4989-b622-b8350ad6eb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2127725-f0f8-41ca-99ee-a2cfe843230f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b2d233-0bd4-466e-98e9-5b66ee4b6dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb80dd6-ce48-43d6-b872-db509006bf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ada3fb-831b-4b78-9fea-1675e82613f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8c98ad-81df-4496-9090-4f33f3e2c6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7aaa7f6-957b-4bd9-bf58-dafdc74ab8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298ba22a-53f0-4109-8bd7-c283fa7ed0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9329fdb4-9453-4106-b790-9db0be381099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0545463a-0cd5-4bfa-966b-5e5367c10713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a47a1b27-c7d6-4784-947c-cbd545699d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30aebe5d-f6df-4969-9750-458ba817b6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96be210d-d7fb-44bd-9894-482469a20178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f105db0-a3d0-49e0-b63f-4798b3e0e8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9831cbda-bc19-47d8-8f07-262c235245d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d41889-f1a6-4f2e-b193-576e5ed25bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd13226-ddeb-4c3e-a01e-e75d4ab24a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c544444b-3b57-428f-8435-46b515df85c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bc0d2a-a1d0-4140-92ae-e08090a3dd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9925d1a8-5e9c-404e-a89a-e03eadb9a004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82752a00-2002-4d35-a8d5-ea43a5fb122e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a6cec1-0cb4-4476-8dc0-beab4cecea39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717854bd-84d5-4626-a7e6-97ffa0687a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce42580-93b1-45f5-9464-93dd98487e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4413b785-fc78-48af-9015-0b7ab5c6dab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353ef67a-7bb2-444d-9394-842c80388a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f8c7df3-81c8-4b6c-a40f-d5eeb98805a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a79e1a3-9ef9-4af4-b250-0843c08f915f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5850b29-cbc3-461b-b9b4-6bd645b6758e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b33ed4e1-565c-4d16-ab90-1227523e58f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b82fa5d-55db-4a4e-aa78-10f95dd966f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1943e6b-a75f-467a-8a79-099ac8b2f53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a679e814-1218-4bca-8515-fe532f30d815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c64340a5-49fe-41a0-9913-6988cd82b760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e72c02-b5fb-4db0-adc4-a07d0d526e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8fad5ae-2ec9-4381-94e8-e05d9b8a9bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eb616bf-4fa1-42d2-8e7e-cc61a1b080ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf33b7a-c13b-44f4-9721-7d8d3a998172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b45be32-b267-4a9e-b784-facfd4388d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800d582e-9029-4965-8bd9-d8020a81edfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0aeddb-0575-4810-b151-efc3101fdd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c6a236-7487-4817-892f-480f63988a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a999d18f-fccd-4a4a-b53b-b72c687e975f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ae8209-bbb2-4635-8933-54096bcf7f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5987e7d-4cff-4bce-8dd8-30df2dab1dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30cb5e88-b181-40b3-b733-94c7fbc42d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52392bca-1ae7-43e1-b0f9-c6bd0b5945fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6403659b-924f-4ea1-b39d-0be844c59daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf19bcc-27c0-40eb-ac5c-03d36d6436d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c96bbc-9c90-4399-b8b8-0d94a6f81cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d74b91b-8bec-409d-baff-84316bdfda70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105f9c36-7b4a-44a8-8e51-47515146fe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426e9264-50d5-4392-b5f9-e8c75a2db621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d2e90a-7c99-44d5-ada5-9ca7db9f6417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde964d2-7819-4296-a942-93ba5335e560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe730030-0540-41bf-8e77-1071e20003f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c849c6bb-3c18-4289-ac36-6084f4fa6465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21ab95dc-7d06-4760-95ad-06ab995e2958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cfae7b-d958-4b52-9605-8ead4916835a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b3cd50-c0ba-49b8-96d9-11a14f4bbf33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272660c6-f25d-4d8f-b322-80bf80f47448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e54b989-3da6-46e8-b2b0-b26891529bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2505e0c4-3c4d-4760-b64b-7bfd64ec25ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4df49c-01f6-47e5-a5db-f2cd890b5ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d2d1b4-7ab1-4346-8ac3-5ae92dbab217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5785e313-b079-4903-b0e1-7e976d9d2dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30af915c-14f8-4280-8f90-11b2dd6a0f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f0da25-ea72-49dc-861b-636de5a6c11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53881fbd-4fd9-491c-81ea-d4f1a078f694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3391a9ab-91bb-4365-bd8d-eaf4704f4d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d165ed-9f02-4855-9ab2-4a558ca91506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e85931-f484-49bf-93c5-5bda9b04c47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9832eb4d-dd4b-4c6e-a88b-08f9c90737e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a1c2c9-f785-4cc6-9b6e-6b41ad4005ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9685de-c180-4878-8bd5-82d182976a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50051292-a681-4b91-b675-757480b8457a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1791f849-dcdd-4f35-8b8b-99298a21135f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b87b6c9-9ad8-4542-aebc-4a099a98619c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31603ea-06a6-4452-af4d-2be6aa268df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0cd63e-e425-40b4-b104-578e766150d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab69b9ec-5cf9-48bf-a3e8-36142728bb90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10daad71-7f86-4f78-be3f-d7eef9a70a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed9dd767-4744-4871-a6de-7759dfdb8b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317e8d10-db29-4493-bb0c-bdbf41b9a006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e054be-08c3-47f1-b7a3-78b51dd77552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd255ca5-9aaa-48ca-9ae7-3a14f331500d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38eba940-823d-4ede-b428-958098a676b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a68e32-3a18-40d9-a7aa-569cdf1c6aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b212984f-3976-4712-9ea8-42795667bc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58a0fb0-0fa9-4fd1-aff8-cbd53561a88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db55beb6-73b7-461c-b4bd-702cc8bacf15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75129f13-c556-49b4-a1c7-eefa3cb6b262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 802b53f4-87c7-469c-a5b1-38320a4b14ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ff472a-1412-4a07-9472-31cb1cadceff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f183ed-54ab-4a72-a5a4-4528ac51d3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e8aa2c-3396-491f-af98-7202a061604c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d374c45-4b53-4259-95f0-aaa453dac418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 756db9ad-e4dd-4166-9053-ba910fda0f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d6ce25-c86d-41bb-91f7-35b7f6461f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44027da7-939d-45a4-bfe0-af0c02808cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2852c64-5aa8-4ff7-9dad-831df3e55e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd9976f-344a-42a1-a336-48b02ba6a811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc16ce18-bcc3-4721-808d-9abea8be842f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd50430b-82e5-4b52-9065-ac464fd05349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6e8ba6-004a-4038-aeaf-7bdce5f2d78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7ccd0b6-ac31-45ee-a8c3-1ece642b4f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058950a1-2c9d-4488-b45e-de6728d5b9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe5a6b7-f51e-494d-8dbb-89d6dd3db20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98181f24-0a0f-44f4-bda2-8625a3207461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba2e1f0-f61a-477e-9c7a-1c6b598ee9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522b71b4-8b99-42c1-979a-b39581fc8fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2487d0b9-03ef-455f-b0b5-68a2c22f5fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89848fb7-9d35-4f6a-8bfe-36a30d22c748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e352442-82ff-4247-999a-7b7cdd2fd309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d1ebe9e-7738-46c3-9e07-ca59fa69a0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01221788-4662-47ce-abfc-83f849c3eac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8796a8d3-e2ba-47cc-a552-7d4dc0d3d1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51646223-4b2d-4b3f-8ba5-dfba05cac3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40a40413-f18c-475b-8531-42ee843d3026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03eeca78-53c8-4ba9-9bf1-77fc5be0f2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2658386f-ea5b-4b8b-87a9-2cd1ceb9f52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4341612-9ddc-45bc-a922-3f5f9c363e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24fbc49d-d078-4536-95d2-8d8c4e4afc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f5c10d-5c08-429f-9277-b6fbd8e4a176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015bdc1b-05b4-42b1-b4b3-4d3f30b9b6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86901202-9b53-43e8-b78d-f2330ce8f98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc049c3c-c7fc-4927-8dcb-edb01c4d2eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5ca17f-f1a6-44ea-a615-0bd6980a415c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b071ad1b-9067-4d46-8a18-8bd873587820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5dc3ac-7b70-41ff-b0e6-255a00446cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558591c3-56a0-4e11-85c2-e88d5a578a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb8d5e99-6dfb-4a8f-961a-7333f0081368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efec2d0c-d4f0-4ff8-9f9c-e3408500c88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ff8b87-c165-4150-ba99-dfd421402ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ad2863d-bda0-4375-ac40-f7bde303cdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e96c4c3-8dca-4cc1-9da0-7d32ff343664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae30799-403f-41c7-bcf4-c6c3c506a37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b28d0a0-d8a9-4802-b6ad-2c554ad44f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a3e7e7-c7ad-4df7-a7f5-5ad774e6ac7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2aebd94-f55e-4fc2-8dab-2b956bbcea4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72278d1c-e763-47e7-aeda-a7bd4503bc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ba9045-937d-4c74-a19d-de6862b6edf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd3f7b9-4cc5-4bbc-9da2-2c49cf7c35ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b6e48db-438a-4108-9bbb-79af6a672e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a30ca4-a2aa-436e-9b48-e5423ddef57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e9dac3-3a8f-416a-8711-0763f7e1208d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b583faf-c843-40b3-bbf4-e4a0e083c64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c94e71-b456-438e-8c00-524211d52731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a576d1-b2b7-48fe-b32b-8ab0200474bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873fdfe4-862f-423d-967f-f2812f5ae909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca8eaac-d37d-4003-8725-4c8cf3e356c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad37ab7b-8029-4433-8c59-6ad94c62c60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62733d6-3355-4753-b5c2-766aae030d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ff0515-c41e-4d13-a887-05b680055cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239e6290-bb46-44cf-8ae0-cfac37cc5e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d89c8e-eeae-458b-889c-9fea36ba6539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea00105-beb6-4ab7-94f3-276cb1857c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafddacc-435b-47ad-baa4-cae67a086600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4139ca-733e-4db1-9c22-5017fa158601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a3e8e1-5c88-4eaa-9431-a9387dd0832b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15aa4de3-f6f9-462b-ad10-99cf668deeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f25ca0-78de-46d6-85df-3763a6068925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7424573f-4568-4623-b85d-7a9fabaefc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab35ca8d-89f1-46d6-8654-24558bfd0195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23b0926a-932f-41b2-a8c3-893e5e974c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 710361d9-ace2-4653-97b7-ebeaef1c8ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc2aad7d-d148-4387-81d8-cff9d73c371f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7087e5-44b6-4649-b973-37e7531010a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b395e60d-fe25-497d-bdd0-75e4ef1db512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe7fd21-547a-42e2-b771-58a76eb748b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1819dd-a111-4362-911a-0b5c47c0a286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce27afb-6c5c-4cb4-bfe0-711a1ca918ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf37a5ba-bab0-4b30-b6ba-3f02e2ff597f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d171208e-615e-4e7f-bade-531a098fab13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f950ed-65a2-43b0-bb39-116f6e0fbbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00077468-3cf7-4fff-ab60-038703ee6061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47830ee2-0695-4232-bd97-46dc09c5e3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31535bbf-75be-4cd3-b348-b0f084541abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee5cd39-0ece-432f-84c9-be7df46fa20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65fd0ec-65ac-40b0-8feb-7d03db08d49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92836b97-3345-43c7-a554-b0c17dc389ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819f3c2a-022f-45aa-94d1-2a710fdaef32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f66db03a-c046-493c-bd0b-61c305d13964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eceb83e8-aa30-4260-9986-f6a4a628be4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95564cfa-afde-4f35-b64c-21d2dface759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72537c27-e233-473b-b2ec-b9490848b93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0cdd9c0-6220-42c2-b51e-68da71291db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fff50f-40fa-41fd-b7af-871231634596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04be4d21-bfb3-48ca-a65b-d935039dc78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464f3665-083a-4345-84d7-388e1ea85f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e21a739-1028-45ca-8dc0-3da28bd5d469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34626b9e-32f2-4320-9c32-71c8f4ce8ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79aa03c9-a9b9-4c9c-a3c2-3ac32c483751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad65ced-281c-46bd-9fc5-07a1867381a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48cc030f-b700-412c-8b01-3166128be7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8714f917-be81-4e9e-9229-3a5f2bcffb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0591fb-7f63-404c-b3e4-43086ddd1d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2e5a60-853c-43a3-b70e-b4d3f6047d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e6c2502-7746-46a1-bbb1-5fddb8703cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e61f07-5f5c-433c-8326-11f7336f94f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab4bcee-7451-4403-b17f-3ff5aedf197e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 814e1288-e121-48db-9c0f-b5d98af7ff91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6125b227-f8c3-440f-b638-8fa5def910d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ef4b94-90d6-45e8-85ad-72766a2f2d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d853cc8-1e3c-4cd3-a324-421b8dbfecd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765c68ac-80ed-4b58-b1aa-4822c3a1b879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4909782-2aed-41e6-b427-b8e5275f7a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2baae1b6-9083-4fd0-81a6-cf5191c6dfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e46a4a-7ec1-4253-ab07-5fce5984f807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20f72a3-6a76-44ae-9f10-c198509c7dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737714bb-e442-4696-bd7a-657719972f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acd2b03-19ef-474d-aa0f-eae2c5606776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ab2cda-fd1e-481c-a270-1912caf89893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265514da-878b-46c7-ab6e-d0fd5e126783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4fde22-b610-45a5-86bb-b91ea51419ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158e8ffd-02a2-42ac-b9a0-5a5b450b855b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5aa196-2843-4730-94c7-09619837370c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48474137-7a1a-4297-906b-8964ad94f1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26929eb4-1840-4386-aa70-b6bbbf7402ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5652eed4-f605-439d-8732-2a96a4e57eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0691855a-4eff-43ff-806f-6ccd4788fcd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2028069-3173-409a-b3fb-a41e911a7fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477eab30-ab4a-4b88-9947-f4ef847fce80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf049b9b-9bd8-4a4e-8cc1-0710783d39b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07199c05-34f6-4efb-841c-dd6bb1ca95de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812c3855-f801-43dc-9fcc-c7e84ad86665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b203950a-013d-47ee-8dd3-a54c8bcf0acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f802724-3444-41c0-a5aa-505eb4397cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc1085f-2fa4-44be-9c8f-79d37c9019a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b53cbd0c-914a-45b4-8e8c-4dd573703c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8666460d-3e3d-4cb4-88c8-232ec3dd2428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812e5a98-d2ba-45cf-8b01-f699dfcea2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593f17cc-3107-48e6-b3d2-4c40af729736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05fcb157-bdea-461a-b372-ab95c9eab3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110ee0ab-2347-4c0d-b219-511eae11dad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2accb6-adb5-4a6d-89cc-ffb3650d0959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368d7970-52b8-43c5-a3b3-4593849d41d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2993a835-bfa9-4fa3-8ad0-84932d866432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfdba33c-ccb1-4547-bfb5-8a7449e81f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 555f304e-5665-406a-9131-4a4aa6d85a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a86fb9-e02d-41fb-afc9-c38b9d92110e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ccaea0-126a-4fa3-a4e7-b2b0dc8c2484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa9c9b5e-9ae6-4ffc-b123-a2d5668e19d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49cb1dcc-e6c6-44ae-b45f-d002c381d302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6024fbc-1dcf-4e9a-8aa4-fb39bb709c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f59f82-10fe-4fe1-93bd-b84a03e0af53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dda362d-2011-4cad-a45c-eaa2bf107e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5beb348-5ce5-4304-8469-1f2f702f1061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00866904-c1d7-402e-97ab-4d2d2759b04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b5470b-86b9-4c21-9749-21cd4cc5325b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2e9cc3-5e36-4cf0-95a6-b10d0f0fe9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c677ed-9373-40c3-9af8-1a23b0cf6254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209c7fef-8aba-4e7a-84d4-539928dd9e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93141cc4-62a9-465d-8938-a07ee74efcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883e5d9b-e4fc-4086-9bb5-fe2cd53fca10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca833d2-1bed-47b7-a689-a6852451e712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5d3d01-17e9-4645-b980-8252f84eada7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c06aa1-596e-4b9e-a3fd-6aba78f9f8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0469292d-9f0d-417a-a2a0-416208450ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b236ab-9758-4115-9ccc-3403d4a7a2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec24417-2c2d-4598-b5dd-54438e3e64b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c2e766-0618-45f4-858c-1dc5c477faa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44fa18e-907b-4320-8b8b-7d000d02014d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c190240-9a49-4af6-9c18-39663ef3859a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf2f2ec8-ddc5-4e5e-9a9b-7c7086ff16e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010456f9-a1d9-4848-be98-ba897185e9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8826d9-21fe-4663-9b7d-bcb38f95bfd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a98809a-12d1-4570-9e27-1d06cee24089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c93e79-44ad-4ff9-894c-8e04d3b0c023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df27bb26-6ec5-4a6b-a230-dc5a2218fefa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bde27c00-8aaa-472b-8f7e-fe2c142af4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb81bae9-de34-4716-8f96-f7d8fd1e87a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a586e7-d92d-44fa-80c4-c8fd8352a8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6a088f-5a69-47e0-951b-e853babb5e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf030616-c6cb-4c41-a094-f70975e0e5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384bd40c-47f0-4552-ba9d-b8dd0a30ce05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1330f505-3483-409c-bab9-ea8933253606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb83519e-9c08-4150-a623-c984768487f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617fab8d-6682-4fb0-a3da-0df3c5d6dfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51040584-3d5b-411b-9423-e7d63b45ad5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc1adc82-e9cb-420d-b27f-035d0f9fa400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcc5528-5c64-4676-ae23-44d03f6503fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b477ba2-7f67-4973-bb97-941f10f0408c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef1226ed-5aae-440c-a1fb-a49401501521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa629de-110e-4c3e-ab7c-2faff45a73ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d281edf-de28-4f80-84bd-139f0b995743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 311044aa-ea45-4ee1-b139-43589ab488db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e3e929-a5d0-417c-9d0e-01b00d8c0d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc2c12e-7911-4f63-8b1e-871f8e1311ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51c3bc2-21cd-4e84-9320-61823e167390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fd65cd-e797-40f3-a4be-85f5dfad5fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25db813-8f3c-43c3-8989-4b5e378b7e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b334a5fe-6c00-4d26-b36e-c1e1e68a0b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf37e80-2ddc-4e9a-89e0-d833f4e399d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b25ea052-2457-4baf-b51b-170a14cdc17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7b2fb3-9fcb-4f4b-9539-6ad10a371f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e871a609-165e-41cc-a8ce-75fe9248c707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b65839-b393-4557-8902-81feb56fc6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9deb90c4-a1b2-4883-aa1a-ec3b8657b6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae0d0177-e285-4fa1-82e1-73ca61a046cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c580087-16a4-42e3-8f75-e416cfbb037c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60df158-fd38-404c-9fc8-0ccdf2aed54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f739da6b-0c10-4df6-b61c-cd6681feceb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0912a2e-1ea3-450e-8f7f-b8423cdace2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b448588b-712f-4b9b-8d07-9c5ed0511b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53dac580-7196-4167-a3a2-9000577796a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040aae12-52f1-4e88-98a4-5b4e9b5f3e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9328f34-c736-426f-bccb-0e0f3709d754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283da655-47f4-4a12-81e1-790b250f3dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1fff89b-a52d-4c86-b79b-023d535bfa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900ab239-392d-4f27-b933-7a470e03b7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad5ee09-dc87-429a-9b9e-ff31258308d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa0f05a-51ae-47d6-a604-c6247fa5f265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149409eb-e874-4ecd-a816-47aee87d24cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e141257a-70dc-457c-abe8-f98f41068b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e527d99-91b7-4109-8166-b715608e307c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ee91a9-9e89-49a6-9f48-190265b332a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e747b9-70bb-4e6d-8f38-b44742354385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097e4690-143d-4f57-bf86-33f993fe0235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1880f10-597b-42f0-a938-0029b966c845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5312a88d-2ac0-481f-b081-f2c09b157347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ce25dc-131a-4d5a-8692-6d17864d6880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ca77fb-3b28-4dda-8816-fd079f06c449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c722d9-ae29-45db-98a6-44b7ca4713b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e568ea1-1bf4-4ca9-8dfb-1b7f59ee7d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79cf7ec-508a-4ae9-ac30-6b498f7d1c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 559b14c6-5502-4dde-ae99-ab99ec1b403b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636be784-e496-471d-a1e9-06600f9ba893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4207ab0f-7130-44ff-a650-a476ae380a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fcb79a-caaf-4309-aa04-1b16a07f27ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce575f04-2180-433f-b59f-e3bc1590a929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ab9ebe-2af6-49c2-9905-10b85435b250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6047aa5-9940-4dc0-8828-4908ee4f31a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f132d868-41e1-45e9-8709-f3e14efa03c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a411226f-6877-4b45-b94a-d257559cb6e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb4b14d2-ed1f-4ed9-84e3-01f31af6a848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 935678b9-6052-4cba-a3d5-30d80cf234c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16165b1-3b3b-432e-9731-e1ad09fcc6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a1d8ac-601d-4055-99e0-dcb43be99764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3ca552-55ce-4830-b0c3-344a11f3d83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d896cfc-b1bc-4988-8d02-8fedecd38144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 189620d6-5017-4a1f-aaa3-b51db6e30e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e55b3e6-4798-4324-aaa8-82c89ecddffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c9086a-db25-4d3e-8242-147d15ba3b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68bb4d0c-3f7f-41b3-a3d6-298b4a0fece9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66eacc87-6f43-49c6-9872-de4c9b05a622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc98565e-a959-464b-92eb-027e14d71bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26466007-17b7-45bf-bdc5-0084d2845dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7643b421-9a01-4106-bcef-cf75f5167d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3953927f-56a4-4ec8-8763-5c65721a3c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5291cba0-78b9-4f0a-89fa-ef50643f8066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb22ac9f-10f2-4410-86d3-f56476c2cb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ec539c-939f-4d09-9349-9b8454b3783d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208f904a-e761-4bbe-8313-42ec68cf4afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b24f96-91b1-434a-ad25-aaa189d81f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7873780d-62f6-4c52-8e9e-057a5917ccf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d513ed0-2be2-427d-8637-50c29a4d96aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a16d0df-1333-4065-b069-e7fd42e9547a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa98a9e-ceef-490f-b9af-7c3814e63fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b13e9e07-fc26-4a75-be1c-e7a0135fd4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2699f9d-40d6-4143-80ab-13084830a578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c662fcd9-e82f-4531-944c-c79658e6b660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa3b62ce-7c35-4307-a824-b6d8a9263e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba935b70-d406-448b-a16a-a0d3149b85e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd7cac2-05e2-4efd-939d-958f5c3b2f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de881ed5-e820-4339-8e6f-f306571e8363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a19442-c47a-4b78-929d-30c2bac7848b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f77cf0-12da-418a-aa87-a79a77d7c649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4858559f-1a3e-4fcb-99fb-6fa0d836e1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a234ac-9e86-4dd5-a056-40287ebd56da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aacc09e1-3cb8-4b28-910c-961030846120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a581ba5-818c-40ff-8603-f9f6c5080d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54efce37-09b2-4204-9474-dbefe319c071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81396579-0c74-4be2-a50f-9615f5a0ecbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdff52d1-f46c-4634-99ca-6e7583a4f0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677a4791-c4f5-4b72-bb0e-8477e2323341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21125a4-d8a8-4e2e-92a8-e702c6e76aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dbc2bc9-e1d5-4089-aeb2-1b4e3064a5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29e2c8c-56d8-4b67-9210-acb904108578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b473729-e2de-4d80-b321-6dc14e3115a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d619ea7-145b-4d5d-ae18-dc4c36a3c57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412a9db6-2422-4999-86a9-ba38903e02e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f07b73-c15c-412c-9c71-381ac992f9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2177a5-60d7-45f5-876a-280d94b5d37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e874ecf-52af-45aa-bab8-d21df0ae4e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72fb1dd3-6b5a-4136-841a-f32e0fac5894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2cfa18-84be-4985-aaa2-74c9cd4f925b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac4a9e2e-a74e-480f-aad2-f0729b6d49b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ac9c41-1ff6-441c-8039-e2b663189271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c900332a-3719-4bb7-a361-136266d8a91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2c6928-ed74-4d18-92b7-dd104997aa0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7ffa3b-7393-45d7-be49-eb5d2a98ba98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e7522e9-1e97-44cc-844b-c561c1132f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f6fbe21-df30-41bb-b961-e46aa19fdfa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e19f94-062b-4866-970c-f08caf2233b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2faac2-a466-43c9-a6db-7f2c36d02ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d474300e-b69b-4829-9a64-0e0d8cc05835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e934bbd7-3cf1-4fb5-9b74-87dba729e2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c93c981-50a1-4bff-adde-840718d70963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51aa67f6-80d9-4d63-81bc-73822a58d7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cdda94b-2d6d-4793-ad7b-50cff9774bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0ec934-10c8-4a44-a5f7-1bd7f0ba062f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba16c8c-c755-4562-a0e9-66c87a1f9883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaca80be-c124-46fd-b4b6-6f7cbcec8f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b476f4db-8a31-4506-ac52-d65c170407fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd35d9de-bdf6-4fbb-9e91-f504db92e83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5a48ff-8b64-46d6-820c-75be251b24ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd66bf51-cde8-4193-ac53-9a16a31947ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6083b7e3-e605-4f51-97e3-e2f264811d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8116748-bf5a-4b04-9d42-b907389e57c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf462383-dfd0-476b-83cd-8f0513ec3a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34c6334e-e59a-4c78-a07b-875ec4066ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5cc907d-ed6c-464b-b265-9fdcdbe97ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a487d4-1251-4adb-b00b-f7b1b62dd9bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b172ae10-9465-4a33-bbc8-0659b4fbaa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2add628a-4444-4b70-b3b3-dbb0a8b02a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c2cfca-fb16-469d-9693-1c443df4c44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c6afc1-5f15-49c5-b675-7a1d96ff36a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addfd52c-140a-4e38-af32-dd0c1559f275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafcdb60-5081-4743-b302-c4577d05c477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e007e12f-3a73-48c0-9479-a7bd0c4fc47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f1e172-e7ec-485e-8f6f-694cbc9b4b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44889a64-1af3-4b15-8430-dc4ffa250728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad90c37-96a8-45cb-ba6e-0bb58ef1db8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 405383c0-4fb5-411f-bd7b-c2f17b0a25db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a075b69-f96d-40fb-8cdc-991c270555b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba9b017-a39c-465f-84ed-f081fc30ec62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a1a1a1-74e8-4b73-9f59-0fca5956948d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae15067d-2810-448d-8a77-38c9b8076412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8477a0-475f-4958-8303-89602a24d450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d76af5-73d6-419f-a70a-3ad585047beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc94f4b-abda-49a3-b172-fbbcbb9805b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2430c04d-1efa-490f-8168-1637ff5984e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0622da76-1f5f-4120-af38-55ec145858ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc5cf89-8ec0-490a-8748-26220ab8e5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a976fafb-8e42-462d-845c-3750b84e0fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118b9c94-6e3d-411f-af8e-af9cd75072d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4216a49-4a17-4842-a9bb-f31c1e72b5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8801a478-2d1f-4874-af3c-70dd7c382f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc63f049-f1b0-4019-a16e-b7e3dd43690f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 253bb645-4e45-40c5-9311-0f0d85b5c1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f406382b-771f-4a14-8b58-c3e97e163c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03cf76d-66b8-4f9d-a35b-1d981ff4033f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606474c4-b274-49b6-8826-dff18516ecea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee8d287-7292-42c2-b9e8-fdb5a7db4a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a7d913-39d8-464e-afac-1a0b3f8635f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08ca3f1a-4265-468c-ba7e-5fb5f4308de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1bb3f1d-d7cc-4654-a16b-a85fe0f9c6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe64973-3739-4000-8967-c23d3d66ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5113ec5e-0159-4d8a-948d-2c9feaa9c5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f18b9c8a-5c7c-4298-b3a9-1b83666b15c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c3f41a-ce7e-4121-b81e-3aad4afebd99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bda5c4-5d1e-48dc-bff4-cdcc146eb424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94b758c-6c05-46bc-b9ee-e685f7563db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde2880d-0171-4af4-9970-d9f11d1c2906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48cd83e3-0679-4219-97f9-bbac3bd30c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932e1c43-1346-4a4f-824a-096928c21526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d04b4f9-7921-43cc-b390-770b381f3999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437ac40a-892e-4492-9b1f-ddcb6fb6ee34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3da26c-d877-40ed-b569-79b3e921e6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fef4baa7-2456-4f3a-9d84-7882ab3ece5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b853ab3e-3558-4305-99c2-55edfb715bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af05cb94-82a6-461e-ba7d-37e9d25b343f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10b411a-1e25-4a43-b803-2a47e132ef35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f99d36d-52e4-426d-8ff3-8bd744ebae4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a79b530-7170-4728-8df5-c9c0ecb38c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d6f25c-ba21-4021-b639-4d0e9a902adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74860e25-5004-4fab-9184-71d297f13da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d3689f-ba08-40ad-a2b1-c551ce863053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0641d75e-80c9-4e94-8cd9-97f7934a5fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522a3e96-4b97-4001-b4a7-73502a3d010d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a2e99c-20d7-4150-9080-1e90949a8816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 503ec6a0-9c95-48d6-84b3-85af5755e67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70fe11f0-0515-4339-a886-245843109274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035a2519-8659-4840-baeb-f0899cf41598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f475f58-855e-4874-867c-db3456fdd622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae235f75-f5ad-4485-bb94-7b3c28dbcbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0f83f71-e17c-4c34-9d3b-bde8a3f6245a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1517737d-6569-4570-870e-865086e5041f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d95928-c7ed-4b72-aa84-279fd3f8d235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f7eaf6-2325-4f64-87ec-26e88133f747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbdc9885-e851-4b37-a01c-412287b8843f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02868765-d573-42ae-967d-a8e3918e3112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec10690-df64-4bd7-b2ed-80bbb28ae648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac051f01-f1de-4258-98be-46793b95ef27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af28709-aeb7-4757-8871-bb176797e48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42975da-563c-48b1-9b48-8601888be86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752ac9d2-c73f-44d6-9e04-f9401470b4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0304550-67c4-4e86-be3e-ab6bd3283b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bba046c-2383-4b73-8327-8698371008fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43777d3d-539a-4fcc-8b4b-51cb4d5cd44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12bc5dc6-de09-46a3-8457-caca23704aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f205600-6401-495e-8348-bbd6bfaa0665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f607e5-b606-4f7d-93c2-9f43741ddb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d071e694-5968-477f-a96f-b04ddba496f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a47d6a-1f04-4bf5-82ad-63cc3743aad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb526de-05d5-48c2-aedf-1a2cb0dc9e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd565668-ec64-4995-abf6-92e430e23561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c22215-cf64-4f40-bed2-466dbe9e5fb6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(3174, 24), y=(3174,)
   Test:  X=(794, 24), y=(794,)

⚠️  Limiting training data: 3174 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  785 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1760, val=0.0908 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0896, val=0.0861 (↓), lr=0.001000
   • Epoch   3/100: train=0.0849, val=0.0858, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0865, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0828, val=0.0861, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0821, val=0.0871, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 1 Summary - Client client_13
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0445
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0038
============================================================


============================================================
🔄 Round 5 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0861 (↓), lr=0.000250
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0824, val=0.0876, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0822, val=0.0879, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0817, val=0.0884, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 5 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0109
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0036
============================================================


============================================================
🔄 Round 7 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0777 (↓), lr=0.000063
   • Epoch   2/100: train=0.0850, val=0.0778, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0848, val=0.0778, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0847, val=0.0778, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0845, val=0.0778, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0841, val=0.0778, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 7 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0072
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0044
============================================================


============================================================
🔄 Round 10 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0837 (↓), lr=0.000016
   • Epoch   2/100: train=0.0836, val=0.0838, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0833, val=0.0840, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0830, val=0.0843, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 10 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0066
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0076
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 10 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2476, R²: 0.0026

📊 Round 10 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0015

============================================================
🔄 Round 14 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000004
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0830, val=0.0860, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0829, val=0.0860, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0829, val=0.0860, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0829, val=0.0859, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 14 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0112
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0175
============================================================


============================================================
🔄 Round 15 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 15 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0061
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0119
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2477, R²: 0.0008

📊 Round 15 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2477, R²: 0.0010

📊 Round 15 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2477, R²: 0.0010

============================================================
🔄 Round 22 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 22 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0016
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0254
============================================================


============================================================
🔄 Round 24 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 24 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0080
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0106
============================================================


============================================================
🔄 Round 25 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 25 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0061
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0092
============================================================


============================================================
🔄 Round 28 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 28 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0068
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0039
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2477, R²: 0.0011

============================================================
🔄 Round 30 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 30 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0069
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0025
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2477, R²: 0.0011

============================================================
🔄 Round 31 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 31 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0021
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0034
============================================================


============================================================
🔄 Round 34 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 34 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0060
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0105
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2477, R²: 0.0012

============================================================
🔄 Round 40 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 40 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0064
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0092
============================================================


============================================================
🔄 Round 41 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 41 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0096
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0098
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0013

📊 Round 41 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0014

📊 Round 41 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0014

============================================================
🔄 Round 47 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 47 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0084
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0013
============================================================


============================================================
🔄 Round 48 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 48 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0069
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0082
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0015

============================================================
🔄 Round 51 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 51 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0081
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0031
============================================================


============================================================
🔄 Round 52 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 52 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0094
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0087
============================================================


============================================================
🔄 Round 53 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 53 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0079
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0019
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0016

📊 Round 53 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0016

📊 Round 53 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0016

============================================================
🔄 Round 58 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 58 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0086
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0103
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0016

============================================================
🔄 Round 59 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 59 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0044
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0184
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0016

============================================================
🔄 Round 63 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 63 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0045
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0109
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0017

============================================================
🔄 Round 66 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 66 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0080
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0023
============================================================


============================================================
🔄 Round 67 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 67 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0076
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0130
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0017

============================================================
🔄 Round 69 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 69 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0069
   Val:   Loss=0.0926, RMSE=0.3044, R²=0.0083
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0017

============================================================
🔄 Round 71 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 71 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0004
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0049
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0017

============================================================
🔄 Round 73 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 73 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0066
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0072
============================================================


============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0094
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0044
============================================================


============================================================
🔄 Round 78 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 78 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0074
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0015
============================================================


============================================================
🔄 Round 79 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 79 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0072
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0048
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

============================================================
🔄 Round 81 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 81 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0089
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0010
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

============================================================
🔄 Round 85 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 85 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0099
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0030
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

============================================================
🔄 Round 91 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 91 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0131
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0209
============================================================


============================================================
🔄 Round 92 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 92 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0073
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0017
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0018

📊 Round 92 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0019

============================================================
🔄 Round 97 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 97 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0065
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0088
============================================================


============================================================
🔄 Round 98 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 98 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0109
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0148
============================================================


============================================================
🔄 Round 99 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 99 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0102
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0075
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0019

============================================================
🔄 Round 101 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 101 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0077
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0292
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0019

============================================================
🔄 Round 102 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 102 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0064
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0022
============================================================


============================================================
🔄 Round 103 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 103 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0072
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0077
============================================================


============================================================
🔄 Round 104 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 104 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0062
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0091
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0019

============================================================
🔄 Round 109 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 109 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0101
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0131
============================================================


============================================================
🔄 Round 110 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 110 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0065
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0052
============================================================


============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0063
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0058
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0019

📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0019

📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0020

📊 Round 111 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 116 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 116 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0119
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0147
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 117 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 117 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0060
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0125
============================================================


============================================================
🔄 Round 119 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 119 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0075
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0065
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 122 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 122 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0061
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0127
============================================================


============================================================
🔄 Round 124 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 124 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0078
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0033
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 125 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 125 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0075
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0072
============================================================


============================================================
🔄 Round 127 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 127 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0047
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0186
============================================================


============================================================
🔄 Round 129 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 129 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0059
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0108
============================================================


============================================================
🔄 Round 131 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 131 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0058
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0057
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 133 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 133 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0072
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0063
============================================================


============================================================
🔄 Round 134 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 134 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0093
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0041
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 136 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 136 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0102
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0046
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 137 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 137 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0071
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0043
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

📊 Round 137 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 141 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 141 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0023
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0035
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

📊 Round 141 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

📊 Round 141 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 145 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 145 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0075
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0025
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 147 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 147 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0068
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0049
============================================================


============================================================
🔄 Round 148 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 148 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0083
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0001
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 156 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 156 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0086
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0004
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 157 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 157 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0079
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0046
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

📊 Round 157 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 160 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 160 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0072
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0048
============================================================


============================================================
🔄 Round 161 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 161 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0091
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0007
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 162 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 162 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0067
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0102
============================================================


============================================================
🔄 Round 163 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 163 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0039
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0016
============================================================


============================================================
🔄 Round 164 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 164 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0064
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0077
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 166 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 166 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0054
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0095
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 168 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 168 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0073
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0054
============================================================


============================================================
🔄 Round 170 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 170 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0055
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0123
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

📊 Round 170 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

📊 Round 170 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0020

============================================================
🔄 Round 175 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 175 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0071
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0017
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0021

============================================================
🔄 Round 176 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 176 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0072
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0081
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0021

============================================================
🔄 Round 178 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 178 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0079
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0028
============================================================


============================================================
🔄 Round 179 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 179 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0086
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0028
============================================================


============================================================
🔄 Round 180 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 180 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0038
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0044
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0021

============================================================
🔄 Round 183 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 183 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0086
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0027
============================================================


============================================================
🔄 Round 184 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 184 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0090
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0018
============================================================


============================================================
🔄 Round 187 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 187 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0079
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0000
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 188 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 188 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0084
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0032
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 192 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 192 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0071
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0086
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 192 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 194 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 194 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0080
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0168
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 195 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 195 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0060
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0096
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 196 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 196 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0024
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0187
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 199 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 199 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0085
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0036
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 199 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 199 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 199 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 206 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 206 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0050
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0188
============================================================


============================================================
🔄 Round 211 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 211 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0056
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0145
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 212 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 212 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0076
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0067
============================================================


============================================================
🔄 Round 213 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 213 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0092
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0013
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 214 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 214 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0050
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0122
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 218 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 218 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0068
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0152
============================================================


============================================================
🔄 Round 220 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 220 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0056
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0097
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 220 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 225 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 225 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0073
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0079
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 225 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 227 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 227 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0074
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0038
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 227 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 227 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 234 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 234 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0050
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0144
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 234 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 234 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 238 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 238 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0086
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0021
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 238 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 242 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 242 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0073
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0081
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 242 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 242 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 245 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 245 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0055
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0146
============================================================


============================================================
🔄 Round 246 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 246 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0054
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0005
============================================================


============================================================
🔄 Round 247 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 247 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0041
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0067
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 249 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 249 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0092
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0007
============================================================


============================================================
🔄 Round 250 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 250 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0089
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0015
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 254 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 254 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0106
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0060
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 254 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 254 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 260 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 260 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0121
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0336
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 261 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 261 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0080
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0052
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 262 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 262 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0072
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0086
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 264 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 264 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0082
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0046
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 264 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 264 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

============================================================
🔄 Round 271 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 271 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0047
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0186
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0022

📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 276 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 276 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0072
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0041
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 278 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 278 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0070
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0003
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 280 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 280 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0075
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0014
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 280 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 280 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 283 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 283 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0080
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0051
============================================================


============================================================
🔄 Round 285 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 285 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0096
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0070
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 285 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 287 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 287 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0068
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0004
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 287 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 293 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 293 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0096
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0037
============================================================


============================================================
🔄 Round 294 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 294 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0069
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0093
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 295 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 295 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0048
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0136
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 297 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 297 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0063
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0088
============================================================


============================================================
🔄 Round 298 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 298 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0097
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0087
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 300 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0640 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0640, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0640, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0640, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0640, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0640, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0640)

============================================================
📊 Round 300 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0076
   Val:   Loss=0.0640, RMSE=0.2530, R²=0.0061
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 301 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 301 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0073
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0269
============================================================


============================================================
🔄 Round 302 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 302 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0078
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0047
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 303 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 303 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0073
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0063
============================================================


============================================================
🔄 Round 304 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 304 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0062
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0071
============================================================


============================================================
🔄 Round 305 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 305 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0068
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0027
============================================================


============================================================
🔄 Round 307 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 307 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0081
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0034
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 310 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 310 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0072
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0102
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 315 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 315 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0080
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0009
============================================================


============================================================
🔄 Round 319 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 319 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0086
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0028
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 321 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 321 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0083
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0039
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 323 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 323 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0079
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0035
============================================================


============================================================
🔄 Round 327 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 327 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0049
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0141
============================================================


============================================================
🔄 Round 328 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 328 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0073
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0097
============================================================


============================================================
🔄 Round 329 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 329 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0083
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0099
============================================================


============================================================
🔄 Round 330 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 330 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0079
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0002
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 331 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 331 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0073
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0081
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 331 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 331 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 334 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 334 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0083
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0074
============================================================


============================================================
🔄 Round 335 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 335 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0072
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0114
============================================================


============================================================
🔄 Round 336 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 336 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0071
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0031
============================================================


============================================================
🔄 Round 339 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 339 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0090
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0013
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 342 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 342 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0063
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0091
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 350 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 350 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0099
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0025
============================================================


============================================================
🔄 Round 356 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 356 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0065
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0097
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 359 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 359 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0081
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0016
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 359 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 361 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 361 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0079
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0024
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 361 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 361 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 364 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 364 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0072
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0066
============================================================


============================================================
🔄 Round 365 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 365 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0067
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0082
============================================================


============================================================
🔄 Round 368 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 368 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0052
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0141
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 370 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 370 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0050
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0076
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 370 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 375 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 375 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0049
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0238
============================================================


============================================================
🔄 Round 376 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 376 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0088
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0017
============================================================


============================================================
🔄 Round 377 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 377 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0091
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0005
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 377 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 380 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 380 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0075
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0018
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 383 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 383 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0088
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0011
============================================================


============================================================
🔄 Round 384 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 384 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0080
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0009
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 384 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 386 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 386 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0089
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0117
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 386 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 388 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 388 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0079
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0051
============================================================


============================================================
🔄 Round 390 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 390 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0072
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0085
============================================================


============================================================
🔄 Round 391 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 391 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0074
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0013
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 391 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 391 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 398 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 398 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0074
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0190
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 399 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 399 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0088
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0027
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 401 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 401 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0067
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0078
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 403 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 403 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0080
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0030
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 407 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 407 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0070
   Val:   Loss=0.0962, RMSE=0.3102, R²=0.0086
============================================================


============================================================
🔄 Round 408 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 408 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0089
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0013
============================================================


============================================================
🔄 Round 410 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 410 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0046
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0027
============================================================


============================================================
🔄 Round 411 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 411 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0087
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0047
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 411 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 414 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 414 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0063
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0114
============================================================


============================================================
🔄 Round 416 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 416 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0084
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0070
============================================================


============================================================
🔄 Round 418 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 418 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0053
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0454
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 418 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 418 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 418 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 418 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

============================================================
🔄 Round 428 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 428 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0064
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0086
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 430 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 430 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0076
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0002
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 434 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 434 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0068
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0069
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 435 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 435 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0072
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0021
============================================================


============================================================
🔄 Round 441 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 441 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0077
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0073
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 441 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 441 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 446 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 446 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0072
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0082
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 447 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 447 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0059
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0123
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 447 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 447 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 450 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 450 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0081
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0483
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 452 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 452 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0102
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0044
============================================================


============================================================
🔄 Round 453 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 453 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0054
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0084
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 453 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 453 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 453 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 458 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 458 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0087
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0023
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 460 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 460 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0088
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0005
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 464 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 464 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0056
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0042
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 466 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 466 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0064
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0083
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 467 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 467 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0058
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0104
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 467 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 467 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 470 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 470 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0066
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0057
============================================================


============================================================
🔄 Round 471 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 471 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0082
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0125
============================================================


============================================================
🔄 Round 472 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 472 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0047
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0095
============================================================


============================================================
🔄 Round 473 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 473 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0073
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0071
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 473 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 476 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 476 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0085
   Val:   Loss=0.0934, RMSE=0.3057, R²=0.0020
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 478 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 478 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0066
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0112
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 481 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 481 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0115
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0099
============================================================


============================================================
🔄 Round 485 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 485 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0074
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0278
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 485 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 485 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 489 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 489 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0042
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0060
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 492 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 492 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0051
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0125
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 493 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 493 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0068
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0097
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 502 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 502 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0067
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0084
============================================================


============================================================
🔄 Round 503 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 503 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0046
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0191
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 506 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 506 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0082
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0041
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 506 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 506 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 513 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 513 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0110
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0087
============================================================


============================================================
🔄 Round 514 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 514 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0035
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0012
============================================================


============================================================
🔄 Round 518 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 518 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0082
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0035
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 520 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 520 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0054
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0089
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 520 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 520 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 520 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0023

📊 Round 520 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 533 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 533 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0041
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0010
============================================================


============================================================
🔄 Round 535 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 535 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0057
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0123
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 535 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 537 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 537 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0072
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0042
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 538 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 538 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0087
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0010
============================================================


============================================================
🔄 Round 539 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 539 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0060
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0090
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 540 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 540 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0048
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0157
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 542 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 542 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0103
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0034
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 542 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 546 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 546 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0031
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0050
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 549 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 549 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0091
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0013
============================================================


============================================================
🔄 Round 551 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 551 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0063
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0113
============================================================


============================================================
🔄 Round 555 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 555 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0085
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0029
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 555 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 560 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 560 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0065
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0065
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 561 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 561 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0072
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0075
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 561 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 561 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 570 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 570 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0040
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0156
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 570 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 576 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 576 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0061
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0047
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 577 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 577 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0099
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0056
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 577 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 582 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 582 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0084
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0010
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 586 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 586 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0078
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0024
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 589 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 589 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0082
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0029
============================================================


============================================================
🔄 Round 592 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 592 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0034
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0044
============================================================


============================================================
🔄 Round 594 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 594 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0060
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0004
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 594 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 596 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 596 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0082
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0170
============================================================


============================================================
🔄 Round 597 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 597 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0051
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0099
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 600 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 600 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0085
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0047
============================================================


============================================================
🔄 Round 602 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 602 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0060
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0049
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 602 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 602 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 608 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 608 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0069
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0068
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 609 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 609 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0069
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0042
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 614 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 614 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0095
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0125
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 614 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 618 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 618 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0069
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0087
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 623 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 623 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0067
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0076
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 623 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 626 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 626 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0075
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0005
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 626 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 630 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 630 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0049
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0167
============================================================


============================================================
🔄 Round 631 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 631 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0105
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0045
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 634 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 634 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0073
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0041
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 636 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 636 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0066
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0097
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 638 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 638 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0067
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0101
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 640 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 640 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0066
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0101
============================================================


============================================================
🔄 Round 642 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 642 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0070
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0115
============================================================


============================================================
🔄 Round 643 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 643 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0084
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0033
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

============================================================
🔄 Round 644 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 644 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0089
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0012
============================================================


============================================================
🔄 Round 646 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 646 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0086
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0268
============================================================


============================================================
🔄 Round 647 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 647 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0059
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0113
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0024

📊 Round 647 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 651 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 651 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0045
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0047
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 653 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 653 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0070
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0089
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 654 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 654 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0104
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0066
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 655 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 655 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0055
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0111
============================================================


============================================================
🔄 Round 656 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 656 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0090
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0029
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 657 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 657 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0090
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0011
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 658 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 658 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0054
   Val:   Loss=0.0978, RMSE=0.3128, R²=0.0101
============================================================


============================================================
🔄 Round 659 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 659 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0037
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0134
============================================================


============================================================
🔄 Round 660 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 660 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0096
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0066
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 660 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 660 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 660 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 665 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 665 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0081
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0039
============================================================


============================================================
🔄 Round 667 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 667 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0074
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0040
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 667 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 669 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 669 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0047
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0147
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 672 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 672 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0067
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0091
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 673 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 673 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0049
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0112
============================================================


============================================================
🔄 Round 674 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 674 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0087
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0007
============================================================


============================================================
🔄 Round 675 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 675 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0053
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0049
============================================================


============================================================
🔄 Round 676 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 676 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0080
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0009
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 677 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 677 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0072
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0072
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 677 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 677 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 680 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 680 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0057
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0126
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 680 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 683 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 683 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0039
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0189
============================================================


============================================================
🔄 Round 686 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 686 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0061
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0044
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 688 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 688 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0086
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0065
============================================================


============================================================
🔄 Round 689 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 689 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0077
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0054
============================================================


============================================================
🔄 Round 691 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 691 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0065
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0085
============================================================


============================================================
🔄 Round 693 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 693 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0077
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0054
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 694 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 694 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0078
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0198
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 695 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 695 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0028
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0199
============================================================


============================================================
🔄 Round 696 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 696 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0072
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0071
============================================================


============================================================
🔄 Round 697 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 697 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0074
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0151
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 698 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 698 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0070
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0129
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 698 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 702 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 702 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0072
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0078
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 704 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 704 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0094
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0015
============================================================


============================================================
🔄 Round 705 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 705 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0097
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0030
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 717 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 717 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0072
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0054
============================================================


============================================================
🔄 Round 721 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 721 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0080
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0142
============================================================


============================================================
🔄 Round 722 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 722 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0087
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0018
============================================================


============================================================
🔄 Round 723 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 723 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0069
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0009
============================================================


============================================================
🔄 Round 724 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 724 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0093
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0002
============================================================


============================================================
🔄 Round 725 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 725 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0053
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0036
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 725 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 728 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 728 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0101
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0047
============================================================


============================================================
🔄 Round 729 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 729 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0071
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0083
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 731 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 731 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0089
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0013
============================================================


============================================================
🔄 Round 732 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 732 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0060
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0064
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 734 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 734 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0092
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0025
============================================================


============================================================
🔄 Round 739 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 739 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0092
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0140
============================================================


============================================================
🔄 Round 740 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 740 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0069
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0063
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 740 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 740 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 744 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 744 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0074
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0012
============================================================


============================================================
🔄 Round 745 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 745 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0078
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0038
============================================================


============================================================
🔄 Round 746 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 746 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0104
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0174
============================================================


============================================================
🔄 Round 748 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 748 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0071
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0069
============================================================


============================================================
🔄 Round 749 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 749 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0074
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0081
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 753 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 753 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0093
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0134
============================================================


============================================================
🔄 Round 754 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 754 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0094
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0120
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 760 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 760 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0065
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0076
============================================================


============================================================
🔄 Round 761 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 761 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0073
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0009
============================================================


============================================================
🔄 Round 763 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 763 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0053
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0137
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 770 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 770 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0071
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0037
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 772 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 772 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0074
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0034
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 773 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 773 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0069
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0085
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 773 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 777 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 777 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0052
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0060
============================================================


============================================================
🔄 Round 778 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 778 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0067
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0051
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 780 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 780 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0076
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0048
============================================================


============================================================
🔄 Round 781 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 781 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0079
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0051
============================================================


============================================================
🔄 Round 782 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 782 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0061
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0108
============================================================


============================================================
🔄 Round 783 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 783 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0094
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0007
============================================================


============================================================
🔄 Round 785 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 785 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0059
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0055
============================================================


============================================================
🔄 Round 786 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 786 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0051
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0127
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 786 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 786 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 792 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 792 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0055
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0138
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 792 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 794 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 794 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0067
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0094
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 794 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 799 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 799 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0079
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0019
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 802 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 802 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0072
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0067
============================================================


============================================================
🔄 Round 803 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 803 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0092
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0005
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 803 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 807 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 807 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0043
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0172
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 808 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 808 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0065
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0448
============================================================


📊 Round 808 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 808 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 811 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 811 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0078
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0019
============================================================


📊 Round 811 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 814 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 814 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0056
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0118
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 816 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 816 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0061
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0053
============================================================


📊 Round 816 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 816 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 819 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 819 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0098
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0032
============================================================


📊 Round 819 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 819 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 823 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 823 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0038
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0196
============================================================


📊 Round 823 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 826 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 826 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0045
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0069
============================================================


📊 Round 826 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 826 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 831 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 831 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0071
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0021
============================================================


============================================================
🔄 Round 833 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 833 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0071
   Val:   Loss=0.0931, RMSE=0.3052, R²=0.0081
============================================================


============================================================
🔄 Round 834 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 834 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0068
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0049
============================================================


📊 Round 834 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 834 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 838 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 838 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0065
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0106
============================================================


📊 Round 838 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 838 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 842 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 842 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0095
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0034
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 844 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 844 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0079
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0042
============================================================


============================================================
🔄 Round 846 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 846 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0063
   Val:   Loss=0.0847, RMSE=0.2909, R²=0.0095
============================================================


📊 Round 846 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 846 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 846 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 854 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 854 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0084
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0038
============================================================


📊 Round 854 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 856 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 856 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0064
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0106
============================================================


============================================================
🔄 Round 857 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 857 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0050
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0105
============================================================


📊 Round 857 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 860 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 860 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0080
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0036
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 860 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 860 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 860 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

📊 Round 860 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0025

============================================================
🔄 Round 866 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 866 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0088
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0017
============================================================


📊 Round 866 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 867 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 867 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0041
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0125
============================================================


============================================================
🔄 Round 871 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 871 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0062
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0036
============================================================


============================================================
🔄 Round 872 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 872 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0041
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0115
============================================================


============================================================
🔄 Round 873 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 873 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0079
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0049
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 873 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 879 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 879 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0072
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0044
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 880 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 880 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0073
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0013
============================================================


📊 Round 880 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 880 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 882 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 882 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0048
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0018
============================================================


📊 Round 882 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 883 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 883 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0075
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0038
============================================================


📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 883 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 891 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 891 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0059
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0125
============================================================


============================================================
🔄 Round 893 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 893 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0058
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0128
============================================================


📊 Round 893 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 894 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 894 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0071
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0059
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 894 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 894 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 901 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 901 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0080
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0032
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 903 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 903 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0058
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0101
============================================================


📊 Round 903 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 906 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 906 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0076
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0060
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 907 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 907 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0036
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0190
============================================================


============================================================
🔄 Round 908 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 908 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0062
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0099
============================================================


============================================================
🔄 Round 910 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 910 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0088
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0012
============================================================


📊 Round 910 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 910 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 910 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 915 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 915 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0077
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0036
============================================================


============================================================
🔄 Round 916 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 916 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0062
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0102
============================================================


📊 Round 916 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 918 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 918 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0055
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0121
============================================================


📊 Round 918 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 918 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 918 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 925 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 925 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0063
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0104
============================================================


============================================================
🔄 Round 926 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 926 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0088
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0017
============================================================


============================================================
🔄 Round 931 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 931 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0055
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0057
============================================================


📊 Round 931 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 931 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 931 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 934 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 934 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0020
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0175
============================================================


============================================================
🔄 Round 936 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 936 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0102
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0029
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

📊 Round 936 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 940 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 940 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0083
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0028
============================================================


📊 Round 940 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: 0.0026

============================================================
🔄 Round 944 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 944 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0070
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0083
============================================================


============================================================
🔄 Round 945 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 945 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0061
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0124
============================================================


============================================================
🔄 Round 946 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 946 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0088
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0018
============================================================


============================================================
🔄 Round 947 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 947 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0066
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0154
============================================================


============================================================
🔄 Round 948 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 948 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0081
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0009
============================================================


❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
