[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082b1588-d3e5-4e59-9c98-46eda724c1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085f873d-7bf1-4e17-8b0c-2eaf620e04e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6104ea-e0a7-43f6-9245-b2fb6ff58553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbe61ae-5aad-4846-b8e5-2b6876742dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd43a762-97f2-41bc-9ea5-37c3894b61da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b513bcf9-a307-423f-ad45-abd31839d162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d14165-7628-4f7f-8480-a4c5c0f9d6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9d3291-34bc-49bf-83a6-916142812eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c8a1b3-b7b4-4a0c-ae6b-f566d9753f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8a9561f-5087-4a37-8af6-d4e9371858b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c65d5250-3925-4558-88a7-7adfff771118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c097aa98-6994-4cd7-ad0a-4b64e11b250c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3831d19f-9cee-4272-b986-535e3df401d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc725721-eafe-4c4a-a913-e9b328cfaf74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a3ce87-7fa8-4702-be35-fe16e5bc466f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239851af-d84a-4d17-96d7-5abed99802c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aed7937-10cd-45b7-8c29-84e8ed295421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49de37a9-5341-434f-8e88-4c6c380c5f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6492aa90-f977-44a2-855f-e30d8de16f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3fc09f-5363-4e4e-8662-670be60502e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e682eaa9-b86b-45e7-a0e4-d3d7ea47903e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c562b74-e06c-4088-b732-6434c09304df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0077d240-e8df-4dff-9519-c5d2f519a0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffdaacbb-43bf-439b-94b1-02c82e809b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fac8990-14d6-4ccb-aeeb-b7e4839108b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1debf5d3-b897-44ac-afdf-4d9ee8b52040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3963d778-947e-4f84-94fe-4e40dec95d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e6e4b5-d1db-4bfe-9d0b-b4ddeec40c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5ab01c-d404-4089-a035-1ca78e48e674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfba8340-635c-451b-8ed0-d9501ea117cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de87105-43bb-4429-bb5e-e7840ac4cebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e97f6f1f-e3c3-4378-afb1-21323b7ccfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6693a8c-446c-40f0-bcaf-1f367862541b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 019ae521-d490-4d68-b493-15bca2c496be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49f0fe4-e502-45fc-a51d-9f973ed99320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c56066a-1e8b-44d6-8c4f-c897dc5e0bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38f035c-9431-485b-a628-39d10c26f42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977229d1-0979-41a4-8caa-aaddd1e11f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b11156-61db-492a-ba5f-44ff81b79e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fddc041-f50c-46e6-b057-357b9c566a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d5e562-1efa-4681-b11b-1afb7b83f8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a95fd8d-bb41-4f4f-82e5-0a35bd1db6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31cc2d9d-c64f-4b13-8fa2-c91f8ec2b59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee102a15-076f-4046-acd5-51a233684402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee16383-a6af-49f9-99d8-66121f6843f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f43ddff-13da-4a8d-b292-9c18d1bdbd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd0d7a7-1d8b-46fc-9c84-4832ca4c7257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bced5f1d-1917-466c-b72a-db43d25def2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb25a06-0c02-4a0f-8ed0-0705248d6848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b58a1a-f382-4ec9-9729-099accb417d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94b6a8a-8c5a-4630-82ed-7aac4f4bcbff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01517537-1190-414d-9b0e-ad43c116367d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055a25c1-72f5-40d6-bbfb-ca0df0b0d169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f56567-ed75-4043-b4a9-dee1ed963763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c262f6d-8a1f-4ba0-9795-f4d45c9b14c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee33183-192e-47f8-906f-29f03f74ef42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edb557c-2bf4-48f8-bd00-c604633dc1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf4b67cf-cb5c-4979-ad43-66ca546214df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c109dec9-1cf0-4bdf-a450-1d28fa71a52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f95cce5-21ab-42e3-8ddf-af1136e971da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e7002c-f8d2-48ff-b191-c5aa7d822b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 226b96e0-b6a7-4a77-b218-47f32d968bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c32fcad-791a-4edb-93be-82a88bc7f0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a41243-93fa-44f9-853e-4cb966030f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84f8684-b7b5-459d-83b6-d1bd263db698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b79a9bf-8612-43cd-8770-dfdb8608d7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb33994a-36aa-46f3-945e-4593acbe1bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ce027b-fd90-4fd0-b825-2454a48dd419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2581881c-b80e-4321-9bec-ffec3dd046df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3edf410e-64a2-4cf2-a9b7-180177d69579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70c2ea0-2b8f-449e-85e1-dd968e9b4bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98c171a5-c340-44cd-b654-694ac210d098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed0313a-22f6-40bb-8f6e-80f178703f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a37c187-370f-48c7-8da2-0d72778a838c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 258da7e2-ed48-4926-ba64-238d45382b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2561fef2-61de-4142-bde8-64e2c47835a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e638fe02-b023-4e13-b586-00caf569b7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21716bb8-4254-43e4-87cc-4d0c0c841df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3319e70a-d831-4694-b5e3-147fc921e685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c41f89-f7e8-4474-b994-be6c81a4bab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9460e253-e968-4005-8577-93addd7c8c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0409939-a4c8-4711-86aa-601100300aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99cee1f5-7277-4e01-93b4-362dd94c9de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b2f3c7-3719-49a7-b1cb-c6ee7a8cc0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1881b19-de30-4013-a3cc-3e116b25f34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09e696a-d966-467a-8028-22183b1947c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6216e03-8aaa-41cb-959b-9a7dc3ffdba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message defafcb9-43d4-4f86-8e97-697be78d3f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a083b8-ea3d-4cbf-a3d9-baa726476ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0711a04e-17a2-4a4b-991c-dfaff000f99e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a183308f-c0c2-413c-9535-f4667a4d9930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4561cf16-4136-458e-b4bb-2da65b70002f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0dddad5-6812-4cd0-8b16-e3c03af97272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4409fc9-2fe5-4527-bdb5-5ead8e270a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174540ad-561e-4d3d-816c-d4e823f5321e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3347bccf-c4da-423d-8534-6c4bb6c307fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c9db9be-4189-4bf0-beab-120eb2cbd6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b0917f-e92f-4c9d-b543-7308669936e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e186ef92-677d-461d-9586-b539e5dd4e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05c995a-b409-434d-90f3-cc0524896ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd1e512-fd64-45d6-9800-c1557b6740b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df624495-69d5-477a-bd71-e6c78c3c97cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545b3e5c-9628-4880-8419-50074c10baca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6450f47a-aac8-46cc-98aa-a59fbc756c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa841247-8532-49b1-bfc0-a1235ba5079c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0efb1b9-722c-4a2c-9597-6468b1d70c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440e7679-fe6f-4574-8fbb-833d626a8817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78b2a75-8c85-4085-9cd2-6431a44acf0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67154abf-c123-43a8-8f37-78fd82144bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e194f21-8454-4076-bc22-9939626b0936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a37e27-113b-4fb9-ad27-3a6e57e8d542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62fbb5e-cc16-45dd-b06d-0ebe48210f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a58a93-8f38-4c15-83b5-b4b96d0ac41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c47938e-cf47-4b54-91e6-bd69241679c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56447cf8-2de6-42b3-aceb-8c4d8fb1b072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35e64a8-80d4-40ef-a080-99572b74c9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06609696-0ef7-4468-8d17-d8eaf9be40f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de093dce-f29e-437a-aace-22ac5a9fc932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a1ca147-540c-434a-a2e6-68d8bcc31f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e87576-39d0-49b0-92d2-6be4c4c268ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2effb75-2977-4b1c-988d-ca620fc957ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8d32f8-fc14-4096-89ed-0e55c26588e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04c289d-dbe7-42cb-b383-c49e27bdbdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f2c10c-1416-4256-819e-cc70529f4a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aadb6bbb-b183-44bf-b58c-22d5baf12658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed9de24-276e-439d-94a9-d09e3ccad8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a84102d7-214d-4bca-9fc6-6cba00033d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e69f07-15d8-4c4d-8c34-75892c87cf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142566f2-a8fe-4f36-bbb3-2e47b0aab63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa4e1f57-2922-4ab3-ad0d-982675cb1d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34011d1a-cf87-425a-9317-26ffae884ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d4525a-770c-4dc7-a6e2-67962cb3f899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9753fbc4-8da0-4462-b5a5-fb83312e10a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc81fab5-dd19-4d95-87fc-07da6e46371b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f466bec5-f478-4942-bfa2-20efa752ae7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8945a3-a305-456e-a2a9-d5431ff4412c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7647a5-bf94-4e7e-899d-95d3e754c915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54294436-33d4-4d99-87cc-3a71c3c37c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ccf7238-f588-4b2b-b69e-b1bcdc03b0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2813b1e7-b911-4acb-a2b6-dafd467e6c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6591406-47a3-43fc-8c67-9690fb4f499b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4fb563f-b829-49f0-a9c9-4e27e1387ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae390de3-9fec-4ed3-b0ea-5e039994c171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7522aab-f560-409b-aa4f-0375738da8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1a943b-3810-48c7-b10b-3f3fba943b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877ad874-6eac-40ea-8115-70b7b8929861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99388a70-febe-4598-b420-9a03a70d213e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b4374c-f908-47c2-a39e-820ea1fa4cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8017098d-cb0f-4e78-8d3d-51d4fded7a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39008b7c-ce95-4f80-a996-52962f819367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006ac1a2-2369-433b-9576-eccd6077d83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c80120f-4cb4-4b47-af39-468be10f144d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc3243c-00b1-442b-8805-36384c4168c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 508541dc-ff8f-4770-bb12-7680f12ea71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b94c43-6c61-49cc-bf35-e9d73b4758a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cedb7e1a-ea54-4b27-a86c-191a8611d47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2a5e3c-9558-4d96-a5ac-0c013b11ca69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 256eae11-4b75-4cf3-a415-1ae8824fb2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34189c45-9dac-4f9a-b7be-d6da3c1ee49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beebd5ae-7be5-4b35-9f9c-00ec6e11270a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85de012d-1bd1-4c3e-82cc-69aab2e7a120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fde939-1f0a-4ff2-b687-c4664fe0a41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d77e083-6d89-43c3-aa37-1c4560c42f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07156ba9-1ced-4d29-982b-592ce96ba92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ea94dc-0dfd-4eba-bd04-7cb658d5dc3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8559f39e-4ec3-45fc-b782-5b9cdf14419c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a365d3-df31-437a-8ba7-db0b1edc0834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca7de81-19ea-442d-891c-2b70b4ece686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c357ac78-2d15-4505-a6c9-78122948c1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29eaa33-3c16-4ab6-bdbd-c9c07870319b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bee07f3-c36a-48ce-a028-49b2c990e872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e10e52b-4b56-40d1-85da-15c9b53ca10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c9177e-8431-4714-8ec5-55ecedbbc562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9fc610b-df9c-4339-9b4c-4f69f1667b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 175d3546-be61-4238-b9c8-fde5aee7fea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa1d11d-32d4-4b9f-87da-0dec8b20a096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14280d1d-14f4-4dd6-a7a4-20d9cca42be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c31fbd-a05c-46fa-a256-0b80d0fbd7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc671ea-2c9d-404f-9a92-acaf1f6fb02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675abe9d-8512-4b2e-b669-30cc156535f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02e4261-0c94-4c90-93be-2456ffa42757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c9d448e-d97e-4a25-ab4a-f0d8793b6393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547e5a88-af3d-4c52-a623-67d8a647d6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f20e0fde-5baa-4a32-a0dd-6040de272045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e620cbcb-c89a-4d31-9a12-f3855c8a6b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771a66d5-6730-412a-8dd6-06d18680dce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f878d4a-02ce-4b61-abdd-3f0811eb508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c865599-52d2-4f11-8810-0248c64218c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7568d2-1864-40b0-99bb-2dc422781b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20c95e06-fe9e-428b-9f67-9146308f7661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96028785-e9b8-4d4a-8451-13fab095c176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4ff5d0-2d35-4cd0-8b52-dd7e1e8ab389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944140e7-6835-4719-b1bc-9a98379ccb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3982ed01-a6be-4117-b74d-d037884cc255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ae80fc6-a55c-4cc8-b6c8-33f8ea8db6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d945f1cf-841c-4917-9da0-65f3f8e89f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed60eb61-6f59-4e05-bd9e-0c78d2945eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7501a50c-3819-4308-b153-b6ebe3da1938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc45391-0965-4c4f-8a53-25e703eaae5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cb7128f-f6e9-41c4-ba71-d0f7dd749723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8727150c-3738-4ecf-803c-54eef4ad70d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0e214e-89cd-4fdd-97c2-2c3161a00f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4255ed3e-09d6-4475-8bb1-9c16aaef8368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f50b29-bbe6-4394-8d56-1b3719f9529e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45e84b5-bb10-4b26-b146-1808cf22b0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a08420-ed27-4725-8aeb-b57ce14e9a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2a9c05-15d2-40c1-83b8-d74606ad9cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d6e5fa-5717-4c73-9d91-2a43065a9176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab71b56b-773e-48aa-9449-d4bf9c95f598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 044bf983-5878-48e0-8b4c-7a12afcd7e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a5dbe5-0407-4df7-9c0d-eae96906f00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272bcda0-168f-460e-a090-9cbcd5f406e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd52e4f-e19a-46c3-9880-30e2745d69e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a224e8b-c76a-46dc-b957-3a043cdb11f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789e468c-3590-4e96-9372-46af75764aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ea8289-5a4e-4ad5-b58f-e1a1424ea8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372630bc-91a3-4073-b66c-62ea4e2ab71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d03f40-c4dd-4a11-8f18-8f5ea32c5301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa63714a-54c1-4de6-8212-71a1dd47877b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccda25e7-6fb6-4fdd-b825-6462a6b90c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b707ae2-afda-44a2-a035-2f62acbfe582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b60fb54d-7680-4c0e-82a5-b39e4a727a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14384355-5d72-4ccd-be73-8cf2107950fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1d5581-54a3-43a2-bc72-d823e34f0c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e4527d-0d7f-4625-aade-0d522a2972f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a07379e-4df9-4671-b9f4-23504cdf4b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 434b7b1d-4b1e-4581-93a3-0cc8fa040ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df62c60b-bb43-4b08-8b41-cc167c77367d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7044e5e8-b37c-4275-9705-231f24e392a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47562935-dfc2-4362-a6a4-c50962c311c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a04872d-03c9-463b-82fc-8e76ebd24650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31585f9-1261-4e5f-8ef5-f025dec605b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb3500fc-b3cb-4dba-ac12-90f66fbad306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b187539-a411-4460-82bd-1e10c090912f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6667abbc-8933-4f3a-8926-f561d1b05cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd6ad67-ffcb-4c23-a810-a8c4f9864a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a19633d-cc9e-483b-b97e-8278194c8ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6feb2cce-f009-4178-aadb-d98bff6da403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 560e3a75-b587-4a66-82eb-70e16742c749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28cfe238-c968-4578-af5c-c38c00079b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0c040e-68ba-4331-926a-02d3acadc83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39964bab-d402-48b3-ba21-a13effebe146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef417d4a-f3a1-48bb-8c74-1bc21149fb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2d3c28-13e3-4818-b575-563629f1f42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0345286-a33e-4e14-823d-d7e491fc8de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68846fb-8d7c-4c38-9e15-1a07748fa701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 053d34cd-efcd-420a-b49c-0ef3c6b91ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeea9a2a-e7ad-44e5-a1c8-c3f4ccb67848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da8fe9dd-3237-4bfd-8577-b44078d25785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33405c6-c340-400b-89c5-fb80ce65735b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e672fb-5507-4eef-aafa-b85942fded46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd629e4e-a032-4239-82b8-99bf11f0d598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75693a92-aacd-4be3-947d-de7911a0770c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2597334-b33f-4b83-bbeb-c4296e6c7a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6530f7-f8a9-4a02-9748-8b3d0df415ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5810a670-5266-420e-9f04-d105772ec4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85867faa-2e60-4704-841d-67de09a51368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dec6cbb-ffaf-4fb0-a30d-8f015420d8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efdd8076-0b24-47f6-bdf8-d5349b0ee1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ebe64d-9423-4893-9dd5-0969394e39fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c932ac90-b586-4750-bc26-9506e6cb5dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9442a68f-2c96-48d2-90b0-cf2a6b98c80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216d437a-2a60-4147-9eb7-55931c08954a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11cbbf43-61bd-41f1-98d2-42ff880c38db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936f666b-2e8c-4a2d-a20a-b8f126aa8dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63c7dcd-f7fb-4e6d-8e18-b2a25659e25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49ba9f6-e19e-4c51-b10e-e4480cf21c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6dce2a7-e053-47d1-8d78-30b2fd316397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a86ae388-2283-4452-9bd9-acdcd478d70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a93a885-0a54-4dae-b207-f05bc9f126b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331e02f5-f4f7-4589-8e62-d7b8e6d7c2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486ff26d-a679-4d1a-a7c3-f62a86211b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f684934-6029-43c0-aed6-ff685169729b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9cae5d5-76bb-4fe2-ae84-389ca74c5212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1bdbe3-9d83-493a-8159-910e1d1ba37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 871f167e-1f37-48b5-b36e-befdf7e1104f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40cdbcd9-2399-439f-b8f3-9b275d07d654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e92469-8bd0-4830-a76f-5f692862a527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2dcb071-9557-49ac-8be9-635b70d01145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e04d64-eeba-4acb-86d2-ad9ab4c79b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b25f49f-39a4-42bc-839c-a0305db0de87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675ab1f7-df92-4db6-ad3f-09d127dde2da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d242307b-5f93-4133-aa07-f6da175f3946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b00b7cbe-f032-475f-9b58-a0de934c749c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3341d2c-da6e-4cef-9e75-d0f6c7054497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4ab9d5-643a-49ca-b17d-759107d3a178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5328c7b-dd87-455a-951c-dc097133a241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055d192c-da75-4761-b169-9d0545a54083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a5de9e-4cf5-40a9-b435-a30e0f227ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd92fa42-2b70-49b3-8a45-94bd52080703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca14975d-26ac-4e40-b399-89c6d8bf8d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddb4b6f-dca3-4068-9e85-498605ae47b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b837a75-967c-479f-80b7-8c4634d53ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d974b0-842c-4259-8c97-0d2854ca5df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0bb69d-2ee5-4f44-8591-330e0dec4bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bf225a-33a3-4e90-b503-0bd52ce3da28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33df648-386a-43ef-a62e-0550823e3a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74d4c7ea-2c03-41bb-acc6-50c532a0ce47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa20571-b974-4542-816e-af00579d1bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bddc7f0-60f8-4081-8752-e0223472af91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f480fa53-1314-45e9-b2c1-39fe12103d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54362695-fccf-4bea-8882-52694454a595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b6e31e2-05a1-4764-b435-f845034277c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2f969d-b50d-4d9d-a57e-74f354cdc2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359e511e-578d-4b63-a62e-c0747de07306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1552dc8-f0e4-4d65-8e92-7e284de23783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83bce5c5-1008-4e37-9ced-684f440d8364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f42710e-d209-40d3-8f98-8ba51d3ad127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be89d09-33e6-45d0-b2f5-16985410ac77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca91eba-37b3-4b58-9b1b-77fed70fbfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d979a53-914a-421e-8cab-dc2b39b85482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18deeb6d-24b2-496d-a365-2568a661c459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be67c857-fd2b-4623-b71b-89906d8527da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ad2f5d-b0eb-42ba-9e66-0353f7426c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3730abf7-cab0-4df2-b8d9-1c4cb3b1831d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f3e883-9415-4813-b313-904adcb1069a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e65d03e3-da6e-471a-a586-b9556f57e8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed567799-7632-4cbc-9b1b-8352bf4d8bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d34c69-5ee4-40f2-9003-43d51ee41b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4820ae74-09ea-4faf-8df6-2d09d055baca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9e5839-c331-4bcb-9ece-e970ab3db852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0716ba6-5fa2-42ba-b633-4c0a4abb061d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6207d7b0-6b7c-4308-a2f4-90a048e60f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8a205f-de0a-4e32-bb02-a2d1f6d25f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c6a02a-ea3a-471c-ae2c-3fbc446c5688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ee062b-a27f-4fbb-9ea5-21405ff33a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5d8609-a31e-4895-b58e-079e286dab2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2e8c29-3574-4827-af19-39fa360af607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608312c9-6bbb-4937-8dab-8178aad16e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4aa7a9-3bd0-46df-9aa0-90b5b78eecb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0e96cfa-f7f2-48cf-86a0-d34ce144feea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45cd0e3-3684-4fe5-92e9-1b1e78925a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04194f51-21ea-4f9a-b193-7e0449bb8352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae199b84-bd9b-4661-964e-d9d3dfb907e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94164991-eabc-4b34-8a18-9a5451e96992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 258ebe8f-4b7e-44f6-9292-840c8553177d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac138b6c-e064-41e0-9d52-6bcfd276e538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32629923-392c-4a25-a64a-6aeaba0d44ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ce0951-8625-4d3b-ba4a-7fdf69121212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cda9fa-77a2-4d8c-8965-4119c446c229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e72273-b90d-47c4-b490-b52fb2824bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f4bbe5-45c6-46c7-bb68-6839af2dfedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a59144-c004-45a0-9a16-4431862b65c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638ee05a-6273-4e2a-9430-d791bbd9b758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b9db53a-1ff1-4237-bdb4-a99ff3254e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6dcce8-a8f6-4915-ad1e-ebae9921dfd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26685738-264e-42f8-9a14-13c9bd78a3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772fb2f7-a8e1-42c7-9f39-4668c1d90270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6cae8b-56bb-4d5a-a273-425548549e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c88df5e-358e-4f9d-9088-01a7d13a8b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7e7d39-71ba-48af-8d71-a9131d23497d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0fb823b-625c-4bd3-bfbd-4031344642ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84694351-b41b-4edd-ac78-9b5c3b4e34b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5add7c-65ab-4395-8d10-0c3e3d631ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c6cf6b-a31b-4522-8b8b-67f90b21d296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9296af-a92b-4f43-9570-53bbf9a36af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d009d6dd-2c6b-483e-8dee-43d6e5c3cee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b58d9d-ed01-4cdf-8b71-458b762a8265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ed2f23-cec7-4299-90a6-f05a0f0b317b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 973007b6-f285-4591-a60b-7c655ca23f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ba7253-ddec-42ba-bf49-a96c945ec3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb1dd78f-2d5b-4325-a390-dc2f92a44947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ef7742-fe57-47d3-9410-b231b75f10b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92da9be5-21f0-4671-95b0-77c3ad8e1f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b38bb76-d964-4935-bba1-83b288076412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a3951a-a977-4726-acde-95feae1a6171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfecddba-2a36-4ade-86e1-db1416b6e206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12f15f7-892f-47b0-8a03-a91de2cf1373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2168233-ef44-4036-8bec-99ae5291926d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db902723-ff75-4267-ab2a-18d015e9fa78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c17dc380-e1d6-42ca-9905-e5911abdcd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13348058-d076-41ce-98a5-903129916db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e336aa08-2fb8-4b4a-a50e-33b7298a33b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a9031b1-0206-401d-820b-1b968b514570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262154b4-7c27-4d0f-a465-b4bb4018da2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9123238a-24e1-400f-b699-342dc9079919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10212ca-a840-408e-bb0b-d46279d0023a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15815970-998e-4faf-8f23-0b7d0883b13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb2447b-faf4-4bfb-b97f-5e2ec0cd6eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eecb727-1a9e-45c8-b932-2678c3b4d304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97964c44-8745-4436-95cf-e3bf28b45f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a3c1fd-977c-4a61-a3c3-3e6c4699ff05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2268ff5c-e024-4fe4-accc-e5b8a1000de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d604750-4eeb-4a9c-9513-6a8d1399dc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71262d90-24ae-4be8-b5a6-c9eeba0f2820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c1e2a8-fada-4b0e-be34-fce9decd4865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5c9130-a2d3-4206-8e0c-2f8948ff2506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a43f72f-877f-4db3-87c2-699866d58b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207d82be-c8be-45d5-9771-6412f27b52e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c4688f-520b-43dd-b75d-72d6353be50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1551fa48-6c1b-4b35-b3a9-a9252642188a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16feaf02-1bc4-411e-9179-7b932c837100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6145e70-48cb-4480-bc4e-c31bd316f4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d8b8ef-bbe1-4035-a269-5897506d0cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae341e07-fe60-4e52-8562-bfaa36d6fd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e42993-df12-434f-b596-8707f553687a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cb9a86-c28a-4e78-ab74-6d4b159caca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790f7d76-3394-4a4d-a021-b0a166b13d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78114b4a-d177-463e-9b55-4117c71e5792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c80826-5733-48f4-9b36-c7e210084b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f977ef-e044-4e19-a4b7-5a4f3f25d5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93edcdb6-81ff-4ee0-abb0-a9061887d211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcb0aa76-9d54-474c-a79b-636540ec0474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b244244e-011e-480e-b96d-1e8beb5e052b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff4fe09-f063-4d6e-acfd-fd316531abcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c06ff290-ba81-48a9-9dd8-ee0bb0517bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70639d61-4f92-46de-8373-2b09fdab44f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fdca7b1-e5c9-493a-89cf-e277841208bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56b94365-51a5-404a-ba9c-c523647300b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6128204-ad07-4483-aac6-3c75c688dcaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c11d23-d08a-4f5f-abf4-ea12b19c5f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08052074-6129-49e2-9b3b-33e4bb5ce0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc5f373-a1d5-4cd3-96ea-255cb23eb96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48dbba32-60c5-423d-b97e-6073f03cc83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adab0f72-49a6-4bf6-86b8-28bc880c1d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b836ebcb-f654-42fc-bd09-a323c1384d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e65045f-a054-4b17-9bed-76af94e2742b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34e922d3-049b-44c8-b185-4ee1b22870b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e2cb3d-2b4f-4c0c-82fb-2c4bbd6c9e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba6fdd9-6eec-402f-a465-b64864d4b114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9fe1461-2679-457b-ac83-69d389396663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f73c0cc-c2a5-46ca-b957-55a9b0216f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff14d43-9459-426c-8cf9-791c5f832f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a77418-7772-4fc2-827e-9007883fd1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47872df-9d8a-494d-aebe-702e25941326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3ca458-4a05-47ee-8837-4c288d16ee60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012db292-58bc-40b9-a91e-3dd38ac95b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db63756-e945-48b3-948a-9d9edd0ae7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4187df6-971e-4a5f-8316-9f69df030fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ba4e86-5297-42c4-ac7f-ab5dd883efa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a0290ee-94ca-4eeb-9513-f9ab8126da23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc4472a-4189-43d5-9c0d-4a835603e447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52584214-2c52-4890-b736-8dc9b28798e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35825353-6763-40ed-8103-022dd17934b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3f3d0e-98c2-4c9b-95d8-28349c845ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06728127-0757-4f41-97fd-3b344ce54f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53988cd5-7ea2-4de0-9472-fa9f0c66b8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7b2582-64ca-4a5c-914d-acfa27c5e923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 420326be-0a02-4eed-b2c0-47a683474042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c4b505-ddf3-4f26-8b36-cb2b615b3605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3f1f94-1c72-43e1-8d36-f258e19063aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce0105bb-f09c-4847-994e-4677d7340c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a153fd6a-d2ba-4355-9f93-6e2ab62e7d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2f6df9-b378-4062-aa1e-334823886a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a097964a-f896-42be-9d2d-f5ff57f952b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc18092-5478-4ebd-8317-c3fc06279a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d91079-2be3-41ed-a367-95fc1439ce53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080e34b0-c3da-45d2-a56a-9a6fe1cd5506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05665a98-7406-464f-948c-a59fa12cbcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87cb50d9-648f-45f9-a8db-eef839cea17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2410152-9032-457b-88db-03a06799622a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c0f766-969a-4dbd-a78d-247f46a595cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1fd8c7f-06af-414b-9d82-e69ea03ad2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e258eb3-1e51-4487-b25d-374e16a7eed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c597865e-3625-45f2-abb2-7bdba882a08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60086d8-63b9-4a2a-b51b-137a75262c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288a0cd3-4f0e-4a5e-9557-8a3ccd6cfbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3750fd6b-f4ef-4f50-803e-e74e53681abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2cce3b-320c-47b8-b70c-724031ca4c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7adc236-82d5-4fa1-a44f-39fa2c2facf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad597456-cc67-4168-93c9-8e7b6fffda2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f197c5-446a-4458-9d0d-615e24d51788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b028fa5e-3904-45c0-af2c-8152454e0e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171fc0f2-c320-413f-8559-665c2984cacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b01fc8-d571-47ef-a73f-a8c9a96d349a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe311093-e96f-4c6c-96c5-a9ca7ee0379a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27445dc3-bbad-451f-985b-3fa0e1b41bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b53bca3-e1eb-45e9-bb34-136094a7c415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f20572ee-697f-4350-944d-acf4bfb9e448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cca0c1f-ce84-4885-8df7-e1e4fc84ba46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823fabf1-d5d7-4eea-86ed-f59a1e3cee3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c1178c-e0e0-4e6f-8201-47ecdafee2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5edd8e5d-6c21-4caa-baa3-b31349952208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74491466-3054-4b49-a790-5e53f537ec41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e791e1-f884-43fa-a853-a48d57ae30f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686bb7a7-ae5c-47e8-941f-2ca40751e4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f92e91-30e9-4a06-a805-be4b9ab3607e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5809b13e-c34e-443f-8f1c-91be1f436190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd8c6de-0123-4b20-9f2e-e290fdaa3ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58565c4c-85ad-4a16-8d91-4966f44e961f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a76f60-5df8-4c82-8f45-a705bdeae52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5234d9b6-693c-4f23-a3bf-be9c959614c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc31f88-b080-4553-842d-12d557660dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a02c6cb-c442-4b85-9b3c-e8a3912281db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c0699e-bf22-4e18-ad58-ee8abdee004b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d5db7c-5a74-4f7c-8147-e86d59bd1219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0dd3e6-5376-41b8-8b71-0b74c7ea9300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f6a3c4-0612-4738-a09a-8f9eabe22a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc31dafb-2d49-41b1-8d94-094150f128de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac98eab6-e0d9-4f17-916d-696c423bf547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef47d7f9-4b47-47bb-b957-a67a40ce2dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a55982-389f-4e5d-abac-70d5b18d12fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6838c83a-32f8-4e93-a54a-8fd39f3dc71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911c6b16-4cca-4104-abd9-716693b42785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74b72d4-108e-422a-9a54-fc43a413fa01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706e7297-addb-4e89-8bc3-b406b5e8d825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08093c27-84c4-4f74-93f4-c68452a29fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929d4fc6-4a38-4bf5-8058-ae903fd022d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a9b6bc-6331-43ba-a030-183b3881b89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc58599b-6750-4538-ab87-8f6e8e5129b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d73695-449e-4d4d-b59a-6b06d43e0100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b03b724a-35cc-4afd-921d-e8c748de1043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d45d430-db3d-4c68-acc0-b9d421d60293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb1f5aab-d481-47fa-b8ef-c67be3b59e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e132b8-190f-4810-8ec3-576bd4587457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82416cb3-0b3d-4dd8-a0e6-8e9c8ef4bc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0ba3f7-18f9-4878-8b65-56410078841b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75fb0e82-216e-4308-9740-5d29807c06b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fdefa83-eaae-4403-b95b-053fda7e9c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ebf742-1fbd-4f63-a2b5-cba9a331aad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873e0bc9-1d8d-4239-b15a-bc98d59e5eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2424839e-03a4-402f-81d3-5755ef6c1a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173681b8-c627-4ef3-85bd-96eb55768393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b253c3-dce9-491b-a22f-b3507730b4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd9e851e-17db-42cf-8ff6-4012109ee53e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc65eb05-75b6-4276-81b9-d875df49cb5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99897f29-d06a-4658-8e8c-55185c300234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214e585b-3bb5-42ec-ae05-f43255edc6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c361cb21-2bae-4c9a-9f70-6352fb6c9cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54cc4435-bc54-4a12-89a3-128f7555f2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14ba56a-0afb-4f80-ae41-6e28d4c83e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e30b11f-d65b-47e3-8ff0-f202f6607f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message defbc5a2-2e33-4f7e-9a98-199a88c264c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd71261-adda-4784-a905-8134101af915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de455b9-05a4-4d80-b385-23b1cd97c927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f67a33-6937-4b26-9f21-2f320b3842a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d352b908-6a36-452d-8909-41fe5ff07a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a4ea73-285f-41da-a6ec-cf55f925db60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86bc5f31-bb87-4530-b98e-cc322736f9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d9b9c0-3118-4f7f-b73d-0abb298aafbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c409218b-7416-45fa-b07e-3448f58fa97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef30f4ea-609c-4f56-95ef-7c81631fd59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5937c76-d773-437c-bbfe-29c8ee36d658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231dcfa2-21b6-4b87-b8fd-c580957df6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b872622-99eb-40a9-9445-b7ba223aadca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90dfa5b3-eb0e-4501-974e-34e3e45b77ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2b8d6c-52ff-4bf6-a514-54f5080e4153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d55edaf-5e4f-4bed-8ebf-2dcbd7b27948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ac33fa-9320-49f8-a9ec-7917cdcfe834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f36f23a-2443-403e-b83c-ea9c965ed552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31145f55-25a6-4003-990a-af8485e76776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac8a499-8188-4dc3-8725-f1f259f14c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a424f179-2aba-4156-881a-95d9b8b173d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b915c15-25bc-4285-bd01-ccd564ca0825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66940326-a036-44c4-a5e6-62704d43ec3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de9681e-3a15-476f-bfb8-7d85204f8238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 449fc812-520e-4fc3-a94d-c0cc2e311b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e711ae3e-23b1-4ddd-8f53-440710411fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c564be23-c681-4795-8c29-eb24fcad6620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0e3eff-b31f-4de9-8e01-d1a2a2d5586e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8141c332-2a1d-46c1-9557-3649b8d22d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b0e0af-4a8b-42a2-bb1c-919cb69bc189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f60a4b-cffa-44d0-9b64-2748719d5f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cfeb30-78ea-477b-9bb1-5d952a4f8a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b8fb69-0e72-4aa3-882d-f3f1c7693786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d6a573-79a2-4cfb-b343-dd0dda1b872d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bfe4a5-a2c9-43e7-9395-bc2bf29e1371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e52711-c5fd-4492-962b-4476888380e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7069a3f0-0d17-4c74-86ad-621634b12749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ace466e-3257-41dd-8afe-835d56878ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a99919-5cc2-4c37-b6dd-ec32913dfd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1300d7fc-3c03-401d-bad0-cf9a1f24b51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505970a9-f564-4152-a28e-87fad1f478c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe42927f-a3a2-479d-926a-a24dcc67aa6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53bb0d0a-b6f9-4ced-98c1-0da09bad81d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b07a14-8334-49c6-83c7-8be4061051e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820df382-00f6-4d96-b8b6-09617b644abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bf94fc-e994-4013-a1cb-980fe7a8f43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1a9018-b277-4419-8560-cfd201d9a6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12cdc3c-862f-413e-b5de-6a2f14c9f224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f5adc5-cb73-4c87-a7d9-a36b5b69abf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9934b060-371f-4654-b421-15f5e275a785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a84941-fffe-45a9-8cca-29f25070e512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782b1595-c5fc-4525-87b1-4fbb268a559d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b714a8f7-3040-46c0-9d60-c1840934efdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f97b0c-00f0-4bbc-93a1-87413470fe3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6a6aecb-6e5d-4598-9aad-440af7359661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad5a7f7c-f8de-4b27-8a87-b9e85ef618cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84884d81-d977-4142-b773-dfd34da0b735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446824ed-6e19-43ba-8a93-d12a4f4f8445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273b7226-7ff3-49cd-b7c0-abd2b67f18b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93db2e27-7915-4cbe-963d-1fd97dee8073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1e20331-4639-4e27-a932-da68c8e3dc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae54323c-46bf-4e9c-bd25-35ebdf55db42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c78e137-53bc-4c09-962c-cd0880fb5c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e6045e-65ef-4ffc-ba5f-91a50c1a1308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d57cc4-ee7d-42d9-9631-72d83972e06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f61b7c-a4d7-4cc5-a97a-90b96482c906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b6db3b-b60b-406a-9f2c-db603cb7479c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 658a718e-7ec1-4b76-acbd-6cdb1f174fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9db2ec0-fb2a-47e2-9d96-16e8830ced82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6320c45-b03d-47d2-b5b1-b8203ecf9779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de76552-0993-4fb6-b262-0fadf3cd806e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f43fb0-e05d-4a73-954a-6b4ddb84b259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803f5ab9-113f-4d51-af2d-37ee5178e9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ef47ab-abf0-4db4-a70d-cfff3c64897b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8626e0-8051-4582-a28d-080ff29f681f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545264a8-5c1c-472e-899e-74c216e28c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22cabc7-c0e2-4473-b941-f37986b73c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d5042c-374d-4e7e-8fa6-087a82d41f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20bdcad1-249a-4c19-bff4-00a6236954d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d359964-a083-484b-9833-db6d3a065f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5546a8e-9d83-4e33-a642-f1379aa138e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e199e2c5-a3f7-4909-85a7-3fc4589c8d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9063b129-a002-46be-b306-6fbff9478069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676800c3-baad-4d02-9822-817f200e1321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e135d7-347f-45c7-94f3-e073f5908054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d0fa188-054f-41f1-b98b-fddf894f77ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f6aadd-3edd-4a33-abc2-756a430f67f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21da0938-dbad-4009-b29d-64fd8115f5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87511271-2872-4cf5-b298-1ad0fc059b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b79f3c-35b7-4948-bf04-e1db8179a638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5883ad11-bf0e-4080-a15a-e984546ec122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8641e68a-f279-4743-a2a5-50ce52181801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa27768a-84fd-48e3-8a2c-72884bb4c3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0db20a4-67d9-46c0-a380-42c01e2be24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ab9aae-7b26-4c9e-ae7f-2fa6b70eeb03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3437fd-4345-44e5-813b-0ffae52d324b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4847e0ab-5542-43cc-afac-03c4bb22111c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0f34ef-e22d-47c3-ba7a-2b4ca8f8576a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7051dc51-cc2b-48f4-836c-b8d83d599dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc400b8-d0f4-4e65-a02c-34bbe693edd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99adfa65-3b85-489d-bfb2-9fe5aafa97de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d93790-e4fa-4b6c-9294-1f34139f70d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eefb746-681b-4f88-ae3b-fc5d5fe09a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0f9390-6672-47af-adfa-fa6af57d90f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e3b504-48e8-459f-97e1-3af1ddd451f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782620ad-0197-41cc-a0c2-79e1708bbaec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25093afd-d57e-4a03-b400-220395ef07a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b971b8-f200-4340-9d00-dde04e300771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1dbddf-eef1-462d-8ee3-81c5ef36f062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea270e2-0518-4372-81ed-6f770682c74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfdd0fcc-cc70-4367-a956-834676e53c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19047fcf-d538-4e93-8d99-394087936b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d247920e-2ba6-4c65-9640-c3c6e3debb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cae494bd-becd-449a-ac69-3702cb24d6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f09e8d-9a6b-4dd5-991b-33505a41f2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210dba8a-050e-4211-b91c-cb1f93e94639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c9c671-f0d6-44b7-b779-e2686fbbccaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad008db-8b29-4ad3-9eee-5d355d940ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f78e95-8777-453c-8086-bb68013d57ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 966f0f53-02b5-4688-b9f5-7d8e1ecd5bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536d3e68-1891-470e-bc6b-fd555e42fa5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dba0511c-ed78-4614-a9e8-c493648805ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64793fe4-6bc8-4f12-8f53-b140ed894251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e857a6c6-3076-4131-9ccf-b8577300070e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3756a28a-87ab-4782-8ca8-46f5b551013c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37876708-69f9-4fce-9aab-f5825675ffd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5bc88e-49b1-4de3-a504-9035ac6d4f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 709f61c0-06e2-4a96-b711-806721e25b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd4db60-07e1-42f6-abfc-3952e3afca47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896aaf3b-1186-4827-bf69-d08726988f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95ac2377-cdb5-4fc4-9999-a594d4dc2485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9acb2a81-1908-4af4-8622-3e020ad39f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4dc132f-7ba5-4a55-834c-c017b53062cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3041265-c5de-4f00-b95b-1c5fdb715678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dee97a3-73a8-4362-9a85-5dafafdb7e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84d266d-65e1-472d-add3-5028d69facfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42089d2-ec53-4761-90a3-6a0ced9f55bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be1c7639-c08e-4ea3-b976-01d96978188d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8191c3b0-ef13-432a-982b-1932c8485800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0855ddec-f7f1-4711-bc4e-35552340b0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5d8592-7930-45af-ba13-79b5e588d558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e897f356-b374-432e-84dd-ff5bb279a0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9edc8572-3bbe-4478-8f4c-d38e30c8deec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde0ad2f-8881-4216-ab20-9fdb9c7a5eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f98434e-5d18-4290-a1d6-0bdacfec82b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708bfaa3-bcc9-40e9-938c-a2d02f4c20e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0011d0-86e6-482f-ae67-a3f8182df3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac79f3e1-b58b-44b8-a0a7-12f74bfc0ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b43ec82-cb72-426d-9ed8-9683f74c7ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bccee7d-20d5-4982-a80b-345c2c8b4ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6c4275-434f-43e5-9185-1a01970c8520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69de15ec-54f2-4325-864b-ae8adcebc6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819ea175-1daa-4ca0-8566-13766ef12895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439fc21c-a11b-4986-99b7-275d5059f6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4b49f0-32b0-40b9-bf32-c65f4e891bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b33d215-1767-47b1-93c5-2ff5808e3175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bdaad8-94fb-4f18-ab28-b8b4bc2a78f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca745df5-193c-495c-b7d1-632bc7b326c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437e0f40-27cb-4197-8207-31d4de024a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74119f51-e7ff-431f-bd7b-77804f297e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87b00730-29cc-4ad9-a5c3-70972c39c1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2301a0d2-2dce-491a-a508-b87e16598556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc994049-e7aa-4084-8d90-26ccf65b41a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68dea4c-f5d4-4ed5-93d7-25517ba5ccce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c629419-8db5-4f83-9e51-1751a4c54835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa278f0-8677-43f3-a57c-307994b3e4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59498c45-cc7e-46ad-9674-fd77d51c27ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd21bffa-135f-4d51-bc48-eaade746a1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd4efec-f533-46cc-893a-6b745f010313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad468c85-168d-496d-89f0-287d80830863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d3733c-ee1a-4077-a200-cfa92625eefb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d0fade-2d3f-4ebb-9e7e-bbd8d9051e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f36a4f-c121-41a1-b8d8-6083432e8975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d80441-471a-4923-a619-12eab52a8685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fecff3-eeb9-4a59-994e-292405df21a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19107a9b-82e2-455e-93c2-1478bf85a02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cfa846-8287-4591-93f5-6aa32586b73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb3e2fa-e867-47e8-aa97-8c02b09bed6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c13ee1-3a04-4a34-8128-2f5136798872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9edb3ba-643b-41f8-b23c-4a0e5227acb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777adf35-d8ce-4a87-8e3d-ef9ed7b6f9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23ce2e2-aa41-4a82-97e2-76e2631c70c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788f2a05-9212-456b-900b-68006c26419f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e40f9f0-ac49-4a9c-aa56-3797c5fa91f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f578d9-aa63-4aa5-aba2-eec5b5cc3bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc919c24-3da4-4519-90e3-e150f32ae60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9669a13d-44b0-436e-a801-92baf7425337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e5b312-ff2a-47f6-93d0-5f046caac158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f65d71-41f4-4663-b7c9-e3304208c8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56b481f-aaaf-4a82-a6d8-2b96af45d4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a710ad33-7890-4bdc-bd4c-1912ecc4307c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44137df2-277b-4a56-915e-e3a6e0c3edbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6215077-d29c-447a-b7a9-d84649c49c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a796c410-e1a9-466f-aa6d-1319f6e06d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd8a1b7-0f5e-4818-9b39-b10361982703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aebb993-ca85-4b74-9821-66a9c9686a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f38eaf-04b2-4845-beee-fd23cd31ecc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da895188-4bb2-43e1-912c-5d3e4dec99de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43cf9536-6cd0-4fde-a0e8-e6a0ffe61ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a769f8-a91d-47f5-a7a9-d10671abb10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5525fb-ea0c-430c-9071-4926133a4586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d054745-9184-4dcd-a82a-52c6db39fc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e662fd-f119-471d-bf80-09a474852b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db71f88c-b9ca-4f23-8b1d-a7e662a53d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4a9154-b13a-4ae3-9df6-4b5a3e39471d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358a0ec3-e9da-4382-b119-8b17107fdefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb03fcd-1929-4629-9a30-a0cfab64f319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a9c44d-570e-4edc-a7c3-803bc577cf9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af29fc2e-75b7-489d-9ff4-2872c7132166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0747ccbf-7d67-4642-9ab3-1e950d9e3b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96cc29f2-dd22-49cd-b079-fa78da12312f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e687c24f-c584-456e-9006-7cf644add99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad87f64-3bc8-4973-88e9-4ce7e2fab260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c38192-272d-48f1-97d8-7f3daee2e8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894e8b20-0308-46b5-8f71-85b231ce15c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b2246b-92b8-4436-afb9-f078351b153f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84de5a18-4da2-4e5e-af85-65291cb93767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c2e021-8837-46b6-9e84-68fdd4755dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2c8852-7e92-4835-b8b8-1b53144f681e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44d560f-7e20-43ad-b32d-20672600d977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be201de5-76dc-497f-b6a7-544f65c2183d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(5733, 24), y=(5733,)
   Test:  X=(1434, 24), y=(1434,)

⚠️  Limiting training data: 5733 → 800 samples
⚠️  Limiting test data: 1434 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2493, R²: -0.0087

============================================================
🔄 Round 3 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0835 (↓), lr=0.001000
   • Epoch   2/100: train=0.0879, val=0.0830, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0881, val=0.0833, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0877, val=0.0832, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0873, val=0.0830 (↓), lr=0.001000
   • Epoch  11/100: train=0.0860, val=0.0830, patience=6/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 3 Summary - Client client_14
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0054
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0017
============================================================


============================================================
🔄 Round 5 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0807 (↓), lr=0.000250
   • Epoch   2/100: train=0.0886, val=0.0808, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0884, val=0.0808, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0883, val=0.0808, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0882, val=0.0809, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0876, val=0.0812, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 5 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0008
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0040
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2486, R²: 0.0012

============================================================
🔄 Round 7 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0856 (↓), lr=0.000063
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0864, val=0.0857, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0863, val=0.0857, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0863, val=0.0857, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0860, val=0.0859, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 7 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0006
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0155
============================================================


============================================================
🔄 Round 8 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0892 (↓), lr=0.000016
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0857, val=0.0891, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0857, val=0.0891, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 8 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0025
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0016
============================================================


============================================================
🔄 Round 9 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0820 (↓), lr=0.000004
   • Epoch   2/100: train=0.0872, val=0.0820, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0872, val=0.0820, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0872, val=0.0820, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0872, val=0.0820, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0872, val=0.0820, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 9 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0031
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0028
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0031

============================================================
🔄 Round 12 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 12 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0049
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0068
============================================================


============================================================
🔄 Round 14 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 14 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0028
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0089
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 14 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 19 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 19 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0031
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0011
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 20 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 20 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0013
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0081
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 20 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 26 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 26 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0015
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0368
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 27 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 27 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0029
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0057
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 27 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 27 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 37 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 37 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0040
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0003
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 37 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 37 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 37 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 46 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 46 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0024
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0053
============================================================


============================================================
🔄 Round 48 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 48 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0008
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0135
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0028

📊 Round 48 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0028

============================================================
🔄 Round 52 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 52 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0035
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0003
============================================================


============================================================
🔄 Round 53 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 53 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0062
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0074
============================================================


============================================================
🔄 Round 56 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 56 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0052
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0061
============================================================


============================================================
🔄 Round 57 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 57 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0018
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0088
============================================================


============================================================
🔄 Round 58 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 58 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0030
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0127
============================================================


============================================================
🔄 Round 59 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 59 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0052
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0042
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 61 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 61 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0028
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0041
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 61 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 64 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 64 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0027
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0001
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 64 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 67 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 67 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0058
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0096
============================================================


============================================================
🔄 Round 70 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 70 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0013
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0039
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0029

============================================================
🔄 Round 74 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 74 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0037
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0078
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 75 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 75 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0015
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0078
============================================================


============================================================
🔄 Round 76 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 76 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0022
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0033
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 77 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 77 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0041
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0002
============================================================


============================================================
🔄 Round 79 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 79 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0028
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0075
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 79 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 81 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 81 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0033
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0054
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 84 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 84 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0025
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0051
============================================================


============================================================
🔄 Round 86 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 86 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0043
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0025
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 89 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 89 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0037
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0007
============================================================


============================================================
🔄 Round 90 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 90 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0004
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0145
============================================================


============================================================
🔄 Round 92 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 92 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0041
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0005
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 92 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 95 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 95 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0005
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0061
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 96 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 96 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0039
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0011
============================================================


============================================================
🔄 Round 97 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 97 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0047
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0088
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 98 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 98 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0038
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0075
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 99 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 99 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0050
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0065
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 99 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 103 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 103 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0029
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0057
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 106 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 106 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0046
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0024
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 106 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 106 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 110 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 110 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0046
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0017
============================================================


============================================================
🔄 Round 112 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 112 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0031
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0040
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 113 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 113 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0032
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0173
============================================================


============================================================
🔄 Round 114 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 114 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0037
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0025
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 115 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 115 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0053
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0042
============================================================


============================================================
🔄 Round 116 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 116 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0070
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0134
============================================================


============================================================
🔄 Round 118 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 118 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0021
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0079
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 123 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 123 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0033
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0022
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 124 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 124 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0010
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0096
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 124 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 128 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 128 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0034
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0094
============================================================


============================================================
🔄 Round 129 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 129 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0021
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0057
============================================================


============================================================
🔄 Round 130 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 130 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0056
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0100
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 130 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 133 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 133 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0030
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0051
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 135 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 135 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0041
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0004
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 138 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 138 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0020
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0009
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 141 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 141 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0037
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0035
============================================================


============================================================
🔄 Round 142 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 142 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0022
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0059
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 143 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 143 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0049
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0100
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 144 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 144 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0039
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0010
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 144 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 146 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 146 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0020
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0260
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 146 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 146 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 153 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 153 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0063
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0095
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 154 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 154 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0021
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0074
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 156 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 156 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0027
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0062
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 156 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 159 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 159 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0053
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0039
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 160 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 160 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0072
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0094
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 163 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 163 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0038
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0017
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 167 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 167 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0057
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0091
============================================================


============================================================
🔄 Round 168 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 168 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0031
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0052
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 168 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 171 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 171 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0039
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0002
============================================================


============================================================
🔄 Round 172 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 172 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0028
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0062
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 173 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 173 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0036
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0014
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 175 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 175 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0045
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0007
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 175 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 175 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 180 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 180 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0042
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0009
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 180 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 180 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 184 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 184 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0050
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0151
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 186 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 186 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0022
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0058
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 187 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 187 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0046
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0058
============================================================


============================================================
🔄 Round 188 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 188 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0023
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0080
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 190 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 190 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0005
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0148
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 191 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 191 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0036
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0015
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 193 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 193 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0033
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0041
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 193 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 198 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 198 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0032
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0042
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 198 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 198 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 198 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 198 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

📊 Round 198 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 207 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 207 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0040
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0010
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 208 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 208 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0045
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0087
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 210 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 210 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0039
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0006
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 211 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 211 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0009
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0026
============================================================


============================================================
🔄 Round 212 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 212 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0017
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0248
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 214 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 214 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0041
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0015
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 214 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 214 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 217 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 217 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0045
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0088
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 217 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 220 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 220 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0048
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0043
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 220 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 220 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 227 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 227 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0020
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0043
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 232 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 232 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0026
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0670
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 232 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 235 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 235 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0007
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0138
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 235 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 244 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 244 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0041
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0002
============================================================


============================================================
🔄 Round 246 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 246 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0032
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0076
============================================================


============================================================
🔄 Round 248 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 248 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0031
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0047
============================================================


============================================================
🔄 Round 249 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 249 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0017
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0098
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 252 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 252 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0042
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0069
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 252 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 254 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 254 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0051
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0089
============================================================


============================================================
🔄 Round 255 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 255 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0051
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0034
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 259 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 259 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0038
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0024
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 260 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 260 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0014
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0093
============================================================


============================================================
🔄 Round 261 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 261 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0041
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0186
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 263 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 263 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0044
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0008
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 264 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 264 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0009
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0087
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 270 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 270 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0038
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0197
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 273 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 273 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0027
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0054
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 273 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 279 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 279 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0047
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0214
============================================================


============================================================
🔄 Round 280 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 280 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0016
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0072
============================================================


============================================================
🔄 Round 283 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 283 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0064
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0200
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 284 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 284 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0003
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0026
============================================================


============================================================
🔄 Round 286 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 286 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0043
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0026
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 289 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 289 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0049
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0018
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 289 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 289 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 293 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 293 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0032
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0021
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 294 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 294 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0012
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0129
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 296 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 296 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0059
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0066
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 297 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 297 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0026
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0033
============================================================


============================================================
🔄 Round 298 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 298 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0029
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0065
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 298 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 300 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 300 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0023
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0085
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 300 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 300 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 304 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 304 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0034
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0033
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 307 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 307 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0039
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0052
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 307 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 309 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 309 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0042
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0001
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 309 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 309 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 312 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 312 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0028
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0067
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 312 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 314 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 314 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0016
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0024
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 314 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 317 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 317 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0035
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0067
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 318 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 318 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0055
   Val:   Loss=0.0716, RMSE=0.2677, R²=-0.0217
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 319 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 319 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0024
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0031
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 319 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 328 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 328 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0059
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0063
============================================================


============================================================
🔄 Round 329 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 329 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0050
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0202
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 330 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 330 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0033
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0112
============================================================


============================================================
🔄 Round 331 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 331 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0037
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0026
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 335 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 335 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0033
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0045
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 338 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 338 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0052
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0103
============================================================


============================================================
🔄 Round 339 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 339 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0031
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0538
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 342 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 342 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0018
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0101
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 343 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 343 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0053
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0033
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

📊 Round 343 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 350 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 350 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0022
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0091
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 353 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 353 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0037
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0031
============================================================


============================================================
🔄 Round 354 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 354 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0036
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0028
============================================================


============================================================
🔄 Round 359 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 359 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0031
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0027
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 360 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 360 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0022
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0022
============================================================


============================================================
🔄 Round 361 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 361 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0015
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0106
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 361 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 365 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 365 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0046
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0004
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 367 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 367 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0091
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0249
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 368 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 368 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0059
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0151
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 369 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 369 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0056
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0055
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 371 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 371 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0045
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0165
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 374 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 374 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0037
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0030
============================================================


============================================================
🔄 Round 375 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 375 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0048
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0008
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 379 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 379 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0044
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0134
============================================================


============================================================
🔄 Round 382 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 382 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0030
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0102
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 382 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 382 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 389 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 389 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0067
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0249
============================================================


============================================================
🔄 Round 390 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 390 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0016
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0076
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 392 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 392 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=0.0026
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0005
============================================================


============================================================
🔄 Round 393 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 393 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0031
   Val:   Loss=0.0965, RMSE=0.3107, R²=0.0042
============================================================


============================================================
🔄 Round 394 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 394 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0044
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0003
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 397 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 397 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0061
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0197
============================================================


============================================================
🔄 Round 398 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 398 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0053
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0061
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 400 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 400 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0039
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0440
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 401 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 401 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0033
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0026
============================================================


============================================================
🔄 Round 402 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 402 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0041
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0020
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 402 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 404 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 404 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0044
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0019
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 405 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 405 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0019
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0117
============================================================


============================================================
🔄 Round 408 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 408 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0040
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0029
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 409 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 409 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0037
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0112
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 409 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 412 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 412 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0054
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0045
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 412 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 415 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 415 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0023
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0121
============================================================


============================================================
🔄 Round 416 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 416 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0050
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0015
============================================================


============================================================
🔄 Round 417 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 417 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0041
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0006
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 418 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 418 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0018
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0032
============================================================


============================================================
🔄 Round 420 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 420 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0041
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0015
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 420 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 423 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 423 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0064
   Val:   Loss=0.0998, RMSE=0.3159, R²=-0.0051
============================================================


============================================================
🔄 Round 425 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 425 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0002
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0157
============================================================


============================================================
🔄 Round 426 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 426 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0043
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0006
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 426 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 436 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 436 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0025
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0083
============================================================


============================================================
🔄 Round 438 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 438 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0047
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0017
============================================================


============================================================
🔄 Round 441 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 441 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0036
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0020
============================================================


============================================================
🔄 Round 443 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 443 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0016
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0109
============================================================


============================================================
🔄 Round 444 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 444 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0041
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0057
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 444 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 451 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 451 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0046
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0093
============================================================


============================================================
🔄 Round 452 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 452 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0019
   Val:   Loss=0.0964, RMSE=0.3104, R²=0.0055
============================================================


============================================================
🔄 Round 454 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 454 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0017
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0091
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 454 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 458 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 458 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0056
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0094
============================================================


============================================================
🔄 Round 463 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 463 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0013
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0003
============================================================


============================================================
🔄 Round 464 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 464 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0024
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0063
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 464 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 467 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 467 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0058
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0057
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 469 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 469 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0056
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0033
============================================================


============================================================
🔄 Round 470 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 470 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0025
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0050
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 470 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 472 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 472 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0046
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0011
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 476 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 476 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0033
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0095
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 479 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 479 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0005
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0042
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 482 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 482 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0026
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0077
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 486 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 486 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0040
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0009
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 490 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 490 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0034
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0021
============================================================


============================================================
🔄 Round 491 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 491 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0038
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0023
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 492 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 492 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0064
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0062
============================================================


============================================================
🔄 Round 493 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 493 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0035
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0040
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 493 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 498 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 498 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0049
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0024
============================================================


============================================================
🔄 Round 502 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 502 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0001
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0135
============================================================


============================================================
🔄 Round 503 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 503 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0033
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0006
============================================================


============================================================
🔄 Round 505 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 505 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0041
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0045
============================================================


============================================================
🔄 Round 506 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 506 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0045
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0027
============================================================


============================================================
🔄 Round 507 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 507 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0050
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0036
============================================================


============================================================
🔄 Round 508 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 508 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0004
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0140
============================================================


============================================================
🔄 Round 509 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 509 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0061
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0069
============================================================


============================================================
🔄 Round 510 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 510 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0067
   Val:   Loss=0.0876, RMSE=0.2961, R²=-0.0076
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 511 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 511 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0026
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0080
============================================================


============================================================
🔄 Round 513 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 513 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0029
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0027
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 515 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 515 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0065
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0105
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 515 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

============================================================
🔄 Round 518 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 518 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0064
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0074
============================================================


============================================================
🔄 Round 519 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 519 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0053
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0019
============================================================


============================================================
🔄 Round 520 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 520 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0022
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0101
============================================================


============================================================
🔄 Round 521 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 521 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0024
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0019
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 521 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0026

📊 Round 521 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 526 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 526 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0017
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0016
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 526 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 526 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 534 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 534 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0026
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0095
============================================================


============================================================
🔄 Round 537 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 537 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0047
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0118
============================================================


============================================================
🔄 Round 538 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 538 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0023
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0012
============================================================


============================================================
🔄 Round 539 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 539 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0023
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0129
============================================================


============================================================
🔄 Round 542 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 542 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0002
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0050
============================================================


============================================================
🔄 Round 544 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 544 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0040
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0016
============================================================


============================================================
🔄 Round 545 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 545 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0021
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0108
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 545 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 550 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 550 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0043
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0279
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 551 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 551 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0047
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0002
============================================================


============================================================
🔄 Round 553 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 553 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0017
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0097
============================================================


============================================================
🔄 Round 554 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 554 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0038
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0044
============================================================


============================================================
🔄 Round 555 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 555 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0058
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0127
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 555 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 555 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 562 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 562 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0016
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0123
============================================================


============================================================
🔄 Round 563 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 563 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0032
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0042
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 563 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 565 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 565 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0056
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0043
============================================================


============================================================
🔄 Round 568 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 568 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0036
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0075
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 569 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 569 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0037
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0046
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 569 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 574 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 574 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0072
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0103
============================================================


============================================================
🔄 Round 576 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 576 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0031
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0182
============================================================


============================================================
🔄 Round 579 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 579 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0034
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0059
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 580 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 580 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0046
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0025
============================================================


============================================================
🔄 Round 581 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 581 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0056
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0030
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 582 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 582 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0026
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0071
============================================================


============================================================
🔄 Round 583 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 583 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0016
   Val:   Loss=0.0953, RMSE=0.3087, R²=0.0007
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 583 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 585 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 585 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0052
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0199
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 587 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 587 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0037
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0161
============================================================


============================================================
🔄 Round 589 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 589 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0044
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0265
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 592 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 592 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0009
   Val:   Loss=0.0952, RMSE=0.3085, R²=0.0055
============================================================


============================================================
🔄 Round 593 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 593 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0044
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0037
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 595 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 595 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0055
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0154
============================================================


============================================================
🔄 Round 598 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 598 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0022
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0074
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 602 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 602 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0039
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0049
============================================================


============================================================
🔄 Round 603 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 603 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0042
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0003
============================================================


============================================================
🔄 Round 605 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 605 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0058
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0036
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 606 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 606 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0051
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0046
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 610 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 610 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0030
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0051
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 615 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 615 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0010
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0011
============================================================


============================================================
🔄 Round 618 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 618 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0006
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0158
============================================================


============================================================
🔄 Round 619 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 619 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0011
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0015
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 625 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 625 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0054
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0285
============================================================


============================================================
🔄 Round 629 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 629 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0049
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0032
============================================================


============================================================
🔄 Round 631 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 631 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0043
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0018
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 631 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 634 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 634 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0053
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0031
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 639 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 639 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0020
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0128
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 639 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 641 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 641 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0013
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0004
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 641 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 644 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 644 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0026
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0101
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 644 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 644 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 644 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 644 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 652 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 652 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0039
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0017
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 655 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 655 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0061
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0064
============================================================


============================================================
🔄 Round 656 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 656 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0052
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0094
============================================================


============================================================
🔄 Round 657 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 657 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0009
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0000
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 657 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 657 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 661 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 661 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0025
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0119
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 662 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 662 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0050
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0042
============================================================


============================================================
🔄 Round 663 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 663 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0047
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0010
============================================================


============================================================
🔄 Round 665 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 665 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0058
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0071
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 668 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1017, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1017, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.1017, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 668 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0038
   Val:   Loss=0.1017, RMSE=0.3188, R²=-0.0018
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 672 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 672 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0163
============================================================


============================================================
🔄 Round 676 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 676 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0033
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0107
============================================================


============================================================
🔄 Round 679 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 679 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0053
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0290
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 681 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 681 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0029
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0087
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 682 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 682 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0041
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0118
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 685 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 685 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0038
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0025
============================================================


============================================================
🔄 Round 688 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 688 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0038
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0006
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 688 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 688 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 695 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 695 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0049
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0242
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 699 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 699 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0064
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0114
============================================================


============================================================
🔄 Round 700 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 700 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0059
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0056
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 701 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 701 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0037
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0011
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 702 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 702 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0025
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0095
============================================================


============================================================
🔄 Round 704 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 704 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0044
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0025
============================================================


============================================================
🔄 Round 705 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 705 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0043
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0012
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 706 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 706 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0044
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0020
============================================================


============================================================
🔄 Round 707 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 707 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0020
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0113
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 709 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 709 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0031
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0074
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 710 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 710 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0020
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0029
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 710 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 713 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 713 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0042
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0008
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 714 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 714 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0051
   Val:   Loss=0.0953, RMSE=0.3088, R²=0.0003
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 715 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 715 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0040
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0063
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 716 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 716 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0069
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0116
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 716 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 716 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 719 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 719 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0033
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0062
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 719 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 725 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 725 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0030
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0192
============================================================


============================================================
🔄 Round 728 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 728 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0038
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0044
============================================================


============================================================
🔄 Round 729 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 729 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0045
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0010
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 730 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 730 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0014
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0134
============================================================


============================================================
🔄 Round 732 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 732 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0020
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0033
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 735 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 735 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0034
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0087
============================================================


============================================================
🔄 Round 737 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 737 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0028
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0071
============================================================


============================================================
🔄 Round 739 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 739 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0050
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0208
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 739 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 742 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 742 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0053
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0026
============================================================


============================================================
🔄 Round 743 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 743 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0007
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0161
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 744 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 744 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0035
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0055
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 744 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 750 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 750 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0036
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0144
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 755 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 755 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0066
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0066
============================================================


============================================================
🔄 Round 757 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 757 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0043
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0034
============================================================


============================================================
🔄 Round 759 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 759 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0046
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0069
============================================================


============================================================
🔄 Round 761 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 761 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0033
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0036
============================================================


============================================================
🔄 Round 762 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 762 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0044
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0037
============================================================


============================================================
🔄 Round 763 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 763 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0007
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0139
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 764 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 764 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0034
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0206
============================================================


============================================================
🔄 Round 765 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 765 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0027
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0065
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 767 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.1017, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.1017, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1017, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 767 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0052
   Val:   Loss=0.1017, RMSE=0.3189, R²=-0.0098
============================================================


============================================================
🔄 Round 768 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 768 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0044
   Val:   Loss=0.0985, RMSE=0.3139, R²=0.0003
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 771 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 771 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0017
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0068
============================================================


============================================================
🔄 Round 773 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 773 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0036
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0022
============================================================


============================================================
🔄 Round 774 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 774 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0055
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0011
============================================================


============================================================
🔄 Round 777 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 777 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0031
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0025
============================================================


============================================================
🔄 Round 781 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 781 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0055
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0019
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

📊 Round 781 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0025

============================================================
🔄 Round 785 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 785 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0053
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0044
============================================================


============================================================
🔄 Round 787 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 787 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0057
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0088
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 787 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 787 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 795 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 795 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0028
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0092
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 795 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 798 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 798 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0057
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0243
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 799 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 799 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0040
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0034
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 801 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 801 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0028
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0084
============================================================


============================================================
🔄 Round 802 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 802 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0025
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0104
============================================================


============================================================
🔄 Round 804 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 804 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0040
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0017
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 807 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 807 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0054
   Val:   Loss=0.0977, RMSE=0.3125, R²=-0.0058
============================================================


============================================================
🔄 Round 809 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 809 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0005
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0019
============================================================


📊 Round 809 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 814 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 814 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0030
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0080
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 814 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 825 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 825 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0029
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0017
============================================================


============================================================
🔄 Round 827 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 827 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0054
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0043
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 827 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 827 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 831 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 831 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0005
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0182
============================================================


📊 Round 831 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 831 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 831 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 836 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 836 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0043
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0008
============================================================


============================================================
🔄 Round 837 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 837 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0063
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0046
============================================================


============================================================
🔄 Round 839 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 839 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0036
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0049
============================================================


============================================================
🔄 Round 841 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 841 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0016
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0110
============================================================


============================================================
🔄 Round 843 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 843 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0052
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0064
============================================================


============================================================
🔄 Round 844 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 844 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0081
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0113
============================================================


📊 Round 844 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 846 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 846 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0019
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0042
============================================================


============================================================
🔄 Round 847 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 847 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0037
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0033
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 848 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 848 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0048
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0001
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 848 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 850 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 850 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0075
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0107
============================================================


============================================================
🔄 Round 852 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 852 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0033
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0063
============================================================


============================================================
🔄 Round 853 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 853 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0065
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0096
============================================================


============================================================
🔄 Round 854 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 854 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0038
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0010
============================================================


============================================================
🔄 Round 856 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 856 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0054
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0041
============================================================


============================================================
🔄 Round 857 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 857 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0032
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0073
============================================================


📊 Round 857 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 858 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 858 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0061
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0081
============================================================


============================================================
🔄 Round 859 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 859 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0026
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0436
============================================================


============================================================
🔄 Round 860 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 860 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0061
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0064
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 862 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 862 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0043
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0037
============================================================


📊 Round 862 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 862 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 868 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 868 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0066
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0098
============================================================


📊 Round 868 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 868 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 868 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 872 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 872 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0036
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0060
============================================================


============================================================
🔄 Round 874 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 874 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0037
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0022
============================================================


📊 Round 874 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 877 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 877 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0024
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0107
============================================================


📊 Round 877 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 878 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 878 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0046
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0021
============================================================


📊 Round 878 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 878 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 880 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 880 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0034
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0068
============================================================


============================================================
🔄 Round 882 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 882 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0041
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0038
============================================================


============================================================
🔄 Round 886 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 886 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0023
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0108
============================================================


📊 Round 886 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 887 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 887 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0042
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0071
============================================================


📊 Round 887 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 889 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 889 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0039
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0015
============================================================


📊 Round 889 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 892 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 892 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0025
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0150
============================================================


📊 Round 892 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 894 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 894 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0051
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0002
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 898 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 898 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0030
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0082
============================================================


📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 898 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 902 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 902 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0029
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0096
============================================================


📊 Round 902 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 904 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 904 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0035
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0044
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 904 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 906 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 906 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0015
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0107
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 906 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 908 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 908 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0037
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0062
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 912 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 912 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0028
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0049
============================================================


📊 Round 912 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 914 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 914 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0047
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0156
============================================================


============================================================
🔄 Round 915 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 915 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0052
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0003
============================================================


📊 Round 915 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 916 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.1024 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.1024, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.1024, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.1024, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.1024, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1024, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1024)

============================================================
📊 Round 916 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0017
   Val:   Loss=0.1024, RMSE=0.3200, R²=0.0055
============================================================


============================================================
🔄 Round 918 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 918 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0029
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0035
============================================================


============================================================
🔄 Round 919 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 919 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0024
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0114
============================================================


============================================================
🔄 Round 920 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 920 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0053
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0157
============================================================


============================================================
🔄 Round 921 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 921 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0028
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0099
============================================================


📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 921 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 926 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 926 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0029
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0059
============================================================


============================================================
🔄 Round 927 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 927 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0048
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0031
============================================================


============================================================
🔄 Round 929 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 929 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0056
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0101
============================================================


============================================================
🔄 Round 932 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 932 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0022
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0002
============================================================


📊 Round 932 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 932 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 936 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 936 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0032
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0073
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 936 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 939 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 939 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0030
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0092
============================================================


============================================================
🔄 Round 940 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 940 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0053
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0099
============================================================


============================================================
🔄 Round 942 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 942 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0003
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0047
============================================================


============================================================
🔄 Round 943 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 943 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0017
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0098
============================================================


📊 Round 943 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

📊 Round 943 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0025

============================================================
🔄 Round 946 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 946 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0030
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0088
============================================================


❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
