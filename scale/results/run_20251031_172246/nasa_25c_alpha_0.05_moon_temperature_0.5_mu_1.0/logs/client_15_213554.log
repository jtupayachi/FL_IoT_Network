[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82122a64-9df7-4b43-b135-f4e358a330bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d129de-86a5-41dc-8d24-ee4806500fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c437d4-ef52-454d-867d-fd79b94d9277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6848792a-c6d2-47f2-b518-3281dc63e3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e3ba19-59b9-4797-a4f7-5b494287d10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c2598d-0a97-4b73-bea7-d8a522f4d7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7d551e9-53e0-4234-90b3-be8df5fbf063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9cf86f1-cd7c-4539-84ba-82d864b8cdef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eea1150-e816-454e-9b0e-383cd208aea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d03c4d-c0b9-4d4b-807b-27521cbf226b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138c3513-69bc-4117-aea4-0ab97f58448c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ee9a5e-f796-4918-ae87-25208e4a2d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6037bb7-91a8-4326-93a3-b94ebb64bf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151efd1d-8213-468f-b9e9-946c81ccc96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0471482-0b9e-481c-8934-d0e6b2474f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abe5e12a-f3c3-4219-8ef7-c36daff20e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e9bf71-1b84-4cd5-b78d-986b54f79cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0268a4e-65fb-4f27-b4bc-0a8795963038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a18e347-3140-4bd1-89bf-9fd506194477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c13d1989-b849-4636-b8c0-bf3514b6ecaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0816337f-6ac8-4125-995c-4769d4569906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ab3d77-6ecf-4f83-81c4-2f1872b04135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d2b45c4-3e18-4980-a092-4a60c5e0192e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7942c357-22db-46b9-821d-65b36a90b2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e85c5be-4a98-432a-b8c7-d92d18eef403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68db835-b627-465e-bfad-d2c50865a690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f450df-bc86-44f0-bd4f-069ac0ac1f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc90cb1a-32a2-4d4d-b0ac-0f4c96912848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbf213b-e55a-4bf6-941c-cd127b02d770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7515b11a-7a2c-430c-a496-80f869bfdea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9ed4d36-d042-4d84-a204-f3832bc600e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed8d36c-65b6-4e51-bdd8-827cdcc638b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894b3abc-9ed6-425a-b526-07e614c53fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f39e325-a6c4-4c0a-b102-1ba142d8836b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd70d894-142a-4345-8026-16d0ec179afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389b253c-a6e5-4879-931b-c43b4fb443f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f05132b9-2bb1-40d5-b2ea-7466424aeb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69cd0ab9-f29d-4c66-9dd7-9d4337bfcd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac85423-e9a2-4f85-bc4c-c33686b3d05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 513ef62d-0a7d-4dc9-9072-036bf7d3973e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec25f3b-1646-4256-9f2c-36b2d376520a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d53e3a-a804-46aa-a4bf-bfedb5b365e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1b6355-cdcf-4363-9f07-64e7d59a6edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acfd9e8-4f96-4d63-9a3b-7f0d4279e294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c0348a-7f10-43d4-ac51-0d99c8fd4b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1a4b16-fc64-4167-9b38-152ad99ed679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4922b7af-1866-4a27-9795-7ac06d22e842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd8f422-f406-412b-bde1-5303e90aeacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc04c369-1f44-4340-b6b9-47102716f91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a2bb9b3-6070-4d29-90d9-5cfc31c3b8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b192c2-248d-4740-b415-14f533d459dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec517bf-bf1f-4fe0-be34-7688acc3297b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c76d96-1efe-4530-8cfc-15fd2d3082e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78361c9-a990-4ca3-8c25-cbfaf69b1250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3cb7f1-2a73-4944-8749-fc6308a83a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c53d7ac-4829-4f73-8283-62ed3a4a3d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b66fcf2-31d9-4478-8a59-9bf99c07f93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787e7731-da37-45f8-bfda-4df75b329357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86b983d8-c8d6-40ba-822b-63f641575f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae5c83ef-b2e6-40d9-8ecf-b87cd9f4bca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8957d9b-c29f-4bd1-bfee-df0fea587c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569d61cf-57db-4f5f-9c12-ddea7ef44d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347a587b-d5dd-440b-b6fd-68b2060fc46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62563aea-97b6-48d7-9d5e-ec58c731bba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690e1504-6874-41c5-904e-a7633e696f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d29f21-7ece-4c29-ad3f-22b347cddf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65dc8766-18e2-4a94-88c0-9d1c8ae7b265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72883f3d-2501-4d8d-8097-c498af74a9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa8545f-3cc7-4445-8c39-8a021919eb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1bce66-acfa-424b-a302-5165ca71e319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8605ab8e-0257-43fd-ae75-c5114fc91b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40ddeab-ae08-4ac4-9c97-dbcd5d66c90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83019bfe-51e2-4cb5-8b9f-6de5934e8807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50edc77a-d34b-439e-8cbf-27d1c6e0c7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dd9fed-d4b5-4478-8c2e-72ac36d3d2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 015eaa00-a3d4-4100-aeab-d23f2ef20007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd8db8c-9079-4875-ab97-7f754e5c9c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9357adb1-d9c4-46ff-ae15-0e386877f1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea000d97-d70b-47e0-9a7f-1331ec0e2c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc1cbfb-36a4-4a9b-a3d5-2f6a423a6f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25afef1-6854-4ff4-ab1f-beec3209a43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6916941c-3202-4f30-bdaa-ccfd688b0076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c36f39-09c1-466d-968f-ee55ddf3f099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e65983e-3ff9-4b3e-9e09-cec8276d9bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6ad066-cbb1-46e2-8744-20852338dc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a375c6-ee8a-421d-9548-0fb6f30593ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ef5d7a-9dd1-4a20-aad3-48aedc7e9269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61de06f-a51d-4f7f-9287-27317cd38453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623c46e5-70cb-4736-bb9d-460e4db28c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539b76ec-4439-4fd4-975a-008c4ddfa040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15770949-9717-4901-a2aa-5a1dbba8f443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81313ae8-c062-4aa7-9a67-8ffcb58f69f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ba8d71-6a21-4452-94a2-9b66567187f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab66f07-e95a-4be7-b48f-6c4ce12868f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f8bc67-aa7f-46f3-9ae4-f3fce375d314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dab7b9-33ea-41ec-805d-8665abaa8722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f80f96f6-663c-417d-b949-c5c820f96cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 229d04ac-a6d4-4744-92b5-80b4cc3459c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c04914-77f1-49f0-a556-fc49e8861a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ffa42e-aad4-43f0-85a6-b66eeafcd364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df179fa8-1aba-4772-a2cd-c00e0cc8ad41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 162391d9-7b8a-439e-9a4d-a9d5b1f63e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41eda0d-e590-40fb-92ce-79cdbd1cc814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7e2445-fa7f-46c8-8a72-145ce7c2ed12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32274d5b-2061-4ac4-93a1-f94389b4e2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfea165-eba7-425a-bf52-70bfb030ada7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114a8e90-7d62-4d18-8555-0282f28ab1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980ec601-ed20-4370-a626-7d6d0af44969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae002a1-6b6e-4ff9-94de-965666df295b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e0274b-e1b0-4dc9-bbd7-5c836a045c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d5376a-ba56-4470-b347-8143e58540bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ef0299-ad4d-471a-a561-98f85906b182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b19029c-1671-476d-89c4-c68904b58aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b660aa9f-7ba1-4d8e-82d9-07ceea59d224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f746a92-6be9-4b10-87ae-e2d5528a1898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9006e517-5c16-4417-9aa0-5b8944f66659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806436ea-afd1-4553-a630-e40fb4cbcdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0f6ddac-216d-439b-b8a3-812b31fe20e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3140c1-3cdb-4208-8865-33a7f4532db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8927ff5-4ef6-4c8a-be1f-c6b61c906371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01878f03-09d3-4923-b207-e1681ade7595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 268b03b9-7a92-4c22-bddd-14889abef40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2821c7-6164-4770-a721-218f3016113c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1592d1f-1a47-4d17-82dd-7b8aa3675554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615ebc20-89d8-4213-9b88-6bf06a99b58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17649be6-a117-460d-b15b-331797824c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32f53424-d301-4dbc-9927-5417b739e564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37773391-8efc-440c-9755-9c79b3f8f9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d165fa6-1592-4e6f-9095-52d1232ce6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67875bae-f361-4b94-bf39-0cabbe30c37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 776ee317-f0f5-42ae-a084-4158bfeba0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f3674f-d872-4c24-9a00-662e756c205b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a783a8-28f7-4ee9-ab6a-1cbd43442d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f1cc9b-bbb9-4db8-ba77-c997b149e1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b107ad80-97ab-41af-81a9-351e0e41d4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21447fc-a553-49c2-ae7f-4890b792fdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ab58b2-36c8-41f9-aae1-bb1f253ba550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136a984f-3a45-4797-b9b4-5c06368fe37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a932e7-8b19-4e5d-8a3a-da16e217c045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0d1ec4-c0bb-47be-8580-c8037293eba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc95e5f-474f-40ad-ad29-33ebf167d1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f15ecc-7659-443c-bca2-9fd31db3a093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5812098e-3f0d-4c1a-a5ab-5a5b86d1d9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3934b3a5-4981-47fc-945f-53c402b57bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19380723-f7f1-4964-812a-7b551d302971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f95bc8-52a0-4471-970a-d19e9f9d9910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d1f89e-c121-45f9-b955-5026cf655c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a096d5b1-162d-4bdc-b3eb-edfa2ae0b215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d15bb9c-7996-4ca4-8afe-9d7339424058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b654c3-5efe-42ae-9146-89d5d0996658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ddae06c-488e-4084-ad2d-f2ebdf5839a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8838dbda-d6f9-4aa4-9473-7aac6587b6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3738532a-e0b6-4757-aa70-5abc7f8954ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5d6930-c41b-42cc-8702-a605107005dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77242023-7b33-4234-b8c0-59a9eadc196e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c56a529e-3120-4cf9-a36a-5dbd140e3ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43347354-2324-4c8a-ba3a-4af739308947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be696b35-8551-4e7b-88be-643cc93a3318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94f0385-fd43-4a86-8247-d0689b013626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec5ee46-2da1-47e8-8dee-fa158460a02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7663e9bf-d260-4fcb-87fe-3c3dca3cd927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca275da4-3405-41d1-b83b-d67d24a946e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6130cc31-d4d2-4f23-bf4f-8d3609650aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dacc0707-e3bb-49d2-8dcc-a4d9a52a5472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c95c3cd-9f04-4452-a02e-5d1c9993ea0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abeff44-d890-487c-9b8f-d72383a9dcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940457c8-0a50-41f9-8906-66e297c2ccac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fcbe9d6-9a17-41ac-95c3-de6d050ca647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56ab9cc0-7305-45c4-913b-8b1beae9c753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54db34ab-57c6-4830-8912-6a2b4b375dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d36802-e11e-486d-b679-f82088316d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f87606a-dddd-4e91-826f-f777192becf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198b87bb-b902-4b39-bcfa-8b30e1640761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fbdea1-b986-4b97-aa38-bdb8238a9a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5843f1f-0b36-499e-9c4a-cc1dacad4ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f09a8b7-a7eb-4831-93c3-151ed6a1daf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4faab8-495c-46b8-93b9-039dbbd36814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e035d0-bcac-436a-b333-a359323d65fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca07e1f-5468-4093-b917-fc32120d4206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6498d375-146a-4910-a378-73a738e32fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2558300-e4f1-4955-9f2a-945d5fcf7c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8f10b6-7d3d-4263-a7b3-b0c63f7bcbcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d4fef4-dda1-4f51-b39a-0385431256d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f8fff4-962f-4489-96e5-29807f7bbd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08dfb205-1c1b-4c46-b873-5fb2519face8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11169b6e-1414-485f-9834-c8f565967b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d2a333-b392-461b-bc50-fc5daab3b822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc23d3c-0665-4480-ad4d-820a223b78d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45592429-70cd-4b6d-8110-28f96ab64679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94bf2b60-214a-4a83-a0d6-c344832c4ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ac96a4-a977-4102-9b3e-a86c3655f05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05ca214-4463-4727-9cc6-ccf732c79411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6389bb5d-52e0-4d99-9deb-8f19c347e422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60430510-a8c9-492e-8435-f030c9633cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b66cfa70-18d8-4cd1-b674-17575752cd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f014853d-fd4f-4b70-9385-25a5a20d4385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4c3d1e-2f80-463e-8e16-81549e669bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5b315e-5267-492a-bcf7-f98a505162ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d54ede-1fef-4d34-8db9-1994fb136965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4355dee6-eeb5-422f-8b9e-8ab62634b953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ff62c3-95c4-4346-9486-4a4048949ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 268d00cf-e2c4-4564-92f1-e3bd01c2bbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af378ce3-4d7f-43be-86c0-5a9a7a93be9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ac7a5c-56d8-4b86-b774-4f7c21d05093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579a9340-a2eb-4787-9411-bcf8a1ce7316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1483b7-641a-4413-a6a3-399a649c12fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d046d0a0-e980-41b9-acd5-3cdb3ac077fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a18fb5a6-2de9-4474-98c1-92193ccef2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c221484f-450a-4876-887c-1e14305b9720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65ed8ae-c16c-476b-b09e-83a91bd6888a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64a3ca7-5061-4c88-9bb6-6c7788509019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7395ee-0eb5-49ef-b8ae-e2be458d8017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36a0589-3a6e-4b06-99a9-64f42a3cb333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f45607-332f-4782-b8de-76f98ebce09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9ab7f3-c7c7-4968-8386-bae819039c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb19b26-9b31-48d8-943e-d81dc44de58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f580bf48-209a-4089-bc0d-0190d8e78544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6bab7f-b989-43e0-9eee-9e14b29037c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171e153d-5d0f-47fd-b6e0-57e41d2d5e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18fb66bf-b761-4861-8aab-8d24e31c776f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772c5aca-e8eb-40ee-932b-300f6eba26f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728f9455-4da9-430d-ae28-7d510e0ff75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4ea2d2-ef4b-41ae-af2b-ff92fb9b587e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ffeaab-a9e6-405d-b0b1-d2a5b6d0c36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3656b860-b7b8-4828-88d2-3b4a036eeba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3172457-7aee-412e-b781-ba1354b5b3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8713ae-7ba7-4b12-94d2-0d48cf996d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736179b1-05a0-484f-9a17-3adf652ca00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bb0b69-df90-4800-a4a8-ce9435591f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76622c40-15dd-425d-926a-b2f91b9df9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10c0722-b62f-4b34-a533-38738b9e109f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 161c4304-9273-4856-8775-7f6791ac53a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26941dbd-b6e2-43a0-abc8-5ff5a650f5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75346c7e-d206-4fd1-9a32-792ba1337a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b05451a-0761-4f0a-b049-5f40a728958d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175e19f6-44c3-4705-a16d-27ac4a98dbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d6d2d5-d637-46f9-8d81-4abafb82c3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21317551-386f-43fd-b398-be72538051b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d270ce3-0e86-4c50-8425-b5a089d3dd20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c3b6a34-a4e2-47ef-9d14-9d5ccccdf1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3b536e-cc47-4fe9-ade7-aa38764aa2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f023064-c5ac-465b-bd1e-4984887b289c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 179b7fbf-964d-4208-959c-96a8c0def29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e95fe7d-0cd8-43a4-9d09-a0f67abe0e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b3ed44-fddc-4cd8-9815-a97bcfeca1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471cda55-ed19-4ae3-a426-5f6174a3bc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddffd70-d033-4677-8a70-767689595b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa6e6fe-f764-4613-9ead-bb1a7aba802c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc4b4f3-3a6e-4b03-8cb1-d471c4ba097b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086483ab-1f4a-42b7-8c0c-7c8cd5bdf7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d288b761-7743-450a-bb18-d25542b313cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14be781-b3e5-413f-a536-121cc446b973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b9d5e1-c12c-4090-ab26-e71d938239d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04719ba-fdc5-4100-aef6-a466a49de8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c53f066-f8b8-44e0-903b-0bc711b722dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac8947d-83d4-4f7d-b530-6889ab31ec95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029c8d9c-ed4d-44bf-b41f-73646e1a14b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5657290-3c7f-470c-810c-11edaa946b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f4479c-5c19-4856-a2d7-47c334d14659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17871ef5-1d0a-4797-81cf-63129df3cd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8987837c-563a-4562-8231-d0867b8e4168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf134ca-80ad-4948-8b6e-98653ead81d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f694ed08-0ed0-4de1-9269-4281a7d412cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3d0b87-5700-41cd-84e2-e889efacc641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e23f2a-c437-4124-9d59-ecd9210e548c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfff683a-79ca-4980-9ce4-f0e45fdf64b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6b380c-ee2d-4e87-9741-8802d7aa6395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d8e647-3e0c-4a33-91d9-3230738af138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224c7af5-74ea-4a45-9dbe-9646f71d3d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e90a512-9a22-4665-98fb-0bbed2b04b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e52f4880-7ecd-410b-a4e5-ea488b36d220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbea5038-ca47-4cd1-94ea-e4ad4489f209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ad1598-03cd-4495-b559-fac0644e2791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 229109f8-78e2-4d94-9557-85719604849e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3918482-d098-40da-8d97-e01560e537f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06fd3c76-0e5d-4c3f-b864-7dfac4461f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbc6abd-f8fe-481e-8c5d-7fbb0e0f7725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a163b1b7-b097-4cd4-9afc-db8be21a92f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5c8ad36-af29-4fd6-98c8-52b41673c1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca07651-a019-4f41-b883-605d3278ecb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a0f463-b27a-40b9-b891-0485ad9c3e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b3bbe1-bac5-4863-8ac4-8300b5729eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0bb5db-efac-40b2-a9e9-3e3941156d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9ebcb8-cbcd-42d0-93f8-00761131ee27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744dfadf-1ee5-467a-851d-f0ca58330dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33207e7e-a8da-4b97-8f31-f5994ad79890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45cc17ae-3bf8-403f-b75b-1a769c34493f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9c4f61-2116-484b-978e-5b166f6b5a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987b151f-be36-4f51-9c7f-4860949f29e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585150cb-928a-444c-a903-31a7a42f710f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed984bb-e452-4ecd-8b67-2820fbed49d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd79b27-0b9a-4463-b373-d8cbfa1dfd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee625187-c5fe-44ba-8a61-9bf5affbf03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2791d474-a93d-42b8-976b-51de800286b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 211176f7-4f26-4cf1-8fa7-91689a4bd796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1713831d-e60f-4335-bbc7-206dd25cfc72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b079cb-b87f-4306-8a4b-5a40dbd4f4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f23c841-6171-475a-acf7-ab2de9cbcd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b77dee8a-42ad-4ce0-934b-3a2fb2f31a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc8369e-bd02-4da5-a812-ec1ed9e2229e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46e6de5-3a30-4fcb-8e7f-5edc91e9f42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8447249a-cf54-4570-9b00-f4226afffee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9450335-515b-4322-ad70-f39a7d6fdd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f63644-8dfa-48fb-9dd6-660652dba2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298f5ffa-d44e-4851-840a-99326a4c274f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5446def8-7c16-4c0e-9957-4f73f4120d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f5c7e6-57e6-4370-84bd-ea0088259921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf8ae07a-8531-4aa5-b432-0afe3c1fafbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea4a9b3-9ea0-4f5e-9201-c7cfa08b8d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab7cd24-352f-4258-bde4-f4a7b7f6ebdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87270228-f84c-46fb-9b91-86f06d8cceaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6fa57b9-9869-4775-bb43-9bc929d20a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658ef98d-7fd1-43f8-be70-ff4a8ab39346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec7bb42b-cb3c-45bf-b78b-1f328e2b922e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78ff2fc-7562-4242-9740-39c37cd4f523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61811523-603a-43a5-96ad-c048afa536cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2b0704-a7d6-4fde-99bb-efff133f6027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfc38f5-6a15-434c-8b72-18ea556a6f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baca0659-cb5f-4350-8f38-36bdc6db0de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c91cee2-b5e9-4c23-b292-a84e1299c9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f48b0e-05e9-4146-9340-cf089664ea37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 646c124f-1ed0-48f3-9778-8f07e364b8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9d26bd-0240-4d89-9438-cc4bfe282bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538cc2cf-bd3f-4c72-a8ef-e7030e1aefa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d387aef0-c952-4993-bd12-6777ef210429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ae0fc1-f90f-4d01-9cc1-fcb72ba152ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 218902f4-508d-4cfc-90a7-133b86a0b2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e88bdb-492e-4ab7-a0e0-23e43d942e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b2143e6-1d5a-482a-8e62-1417027af193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c7f76c-c4b3-46e2-9899-fc6e8beef1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea3ec9c-f190-4591-a60f-c02c58b45297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8909ace-accc-4b6c-900f-859eb7e3cbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acafa927-1adb-468a-ad6f-403f40eda504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b3ca36-095f-44b6-a82c-b287339217e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aeca86e-4468-45bf-b2e3-4b7253699af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bdf974c-d5c7-41c7-97bf-1a13bbb8511b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0adf69b4-4e5c-4f57-badc-44259fefd027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9404162d-92f2-4cac-aa4a-0920a5c846cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a88a43e4-dc5c-468f-b946-3b23ee2999a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d37a7f-6385-4f0c-a021-e94318d18b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a609cd25-8b8a-4513-ad0f-1e8c9b3e8f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2cdb006-6af5-4276-8d89-b002e9c4437a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc7f48c-0ba7-4dac-a8aa-3efa0d6d6d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9676f6b8-0e5a-421a-aec5-418d28ee60e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94761bf8-8ed4-4a88-b9e5-8c7751203cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6750feea-8d40-4391-89ad-8f843cfcad33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928d654d-5bc4-456b-9e80-d13a03bb0012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af809c34-18be-47fd-a061-6e006c452812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61570196-ebd0-49c8-9de2-b7a425278763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9870fe-7818-4d27-83e5-56a8d22ccdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8f77e5-c51e-4e0a-a8ea-03a687a48f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 072ab2fb-5a56-4da7-848f-57fab92998fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54832866-fc48-4a81-89f7-c2c50348ea38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d268ad0-9ef2-4f58-894c-a0095f46afc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4994193-2155-4ae4-9520-a7106b372b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3856fa53-1845-46d5-bf76-500245985ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61f391f-652b-4aef-a2cc-6ba46e9098ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1dd63d3-0465-4221-a2c2-460b7e9c5328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0d764c-ff68-47a5-a7dc-bf84dfec8b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6dde85-8ca9-411f-9abd-ab6d547602a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2739e4-afa9-4a2a-8c20-456d46325737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b10cada-f36c-4c61-a5cb-e8e5a653b413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6397606e-d068-4aba-9570-86b4290ca1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03248623-9977-4074-a90c-1107ed3eb3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6906f7b4-d475-42a9-b8a7-6191b3cc8c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79c7c8b-fd75-429e-9f17-d2b0253b0a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc810cb1-7300-495b-94eb-d816cbeac36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc4be5a-4141-42a7-a238-a31677ce38a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93bcdd4a-1e38-4cdb-87ae-1dd23830453c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b78c53a-0836-40b5-bdf9-abbd4e33a49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d58199d-3aaa-4481-8152-8e45e0bcb7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3622b149-c752-4732-9fd3-fe685a79e109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 133cfa7e-8b29-42b3-981d-9cd055ce8256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9696cc43-1779-4a31-8567-0491f6e10fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a20a3d9-9c4b-4cbc-bd9f-70cf573da90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24873ccb-5fbb-4e9b-9c6c-7fbe303abfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e70d926-7f25-43f0-b64e-160717acf79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f227ac6-3628-47d5-a107-2c0312908641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f95b46-0275-4f98-abc5-2018fd60574c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c70b12b0-9ec2-4598-8bbe-27f7e6d5b616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4793ce9-deda-4a13-b707-f5a4aed78e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b82853d-c95e-4034-b92d-b37eb9907214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a983c45-986a-43c6-b630-a19eb824c76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dfdcb16-1848-473c-9aac-98474d195bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81031f2-52cb-46eb-98f2-27d00341da50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab2fd29-96c7-42ed-a904-c2f04bbf0bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2669f1-ed21-4510-ad30-0778500f1636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40529f63-353d-4ce4-b42e-d800bfc9e573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97766b6a-64c4-4a35-a766-ec7b2a1f1938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d2673c-24e1-4114-8585-df136da0ce49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4fc60d-fadc-427b-b95b-9bd94b315cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fecf40d-22e4-4a6f-9b3f-3a4b33da9c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74c9d91-2ae9-41b4-94f1-ff4b3d308050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da72c019-ccc9-45f2-8691-199f9cb4635b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f800cf-f678-468c-9753-3c0251f002c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceec6014-728d-4646-a81f-6e83c71bae92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0751a6a-88e8-4eec-8175-1f9146eb6680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ecc4b9-81d7-4b1c-9326-6654037639e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623e7c4c-9320-4a94-bace-953a6609def3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a546f2-3021-48fa-964c-3b7a279f54e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c905f8b1-31f5-4262-9230-380f8faebf25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d7a76a-9535-46dc-89b8-d492b6b5c491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bec6ff2-60c9-4989-a07a-03254f09c204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c927ff-cc25-4d1f-a43b-7d8852c79fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea0982e-985d-4d7b-8b0d-b2621decf2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe795b6-eb44-410a-8eb4-cf850ef91d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0178e71b-8749-4d57-9b54-e19b6691871c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c44472-facb-4a05-aa22-b3c57d1a3d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06cfbbc7-8354-4fc6-92de-2ea9fbd2e2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2944764-152d-4461-b2a1-1463394f6ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285f1d54-292c-4624-9fd6-16ac61766d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f79d1ff-2f4d-4d9c-aea8-c28f9559ac8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 555389e2-6170-4366-9125-4e8040accd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733e0195-29ef-4d0c-aedd-93e81f369a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d660bd0-be30-407a-a173-0c4d8f30ddbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a07718-6df0-4138-aaee-34ff31476a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5076778-2ede-41a7-bafa-69188fb74b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c84be5c-d45e-4ecd-8643-391971a37839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b183f9-71f6-4dff-b298-deb6cf316b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e6ed74-42f6-407b-876d-bc37149e2d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de50313b-307c-40cb-a725-1306b4a14e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f2e5bf7-2a46-441a-9c9e-9fcd51bc5e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dded0e78-1257-4842-8ee8-ca22c5470612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e30fed8-52d3-4c1f-822e-cff5846ff979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 828af312-9798-4fba-9f04-379df7381627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b918c2-ed5e-46c7-8e28-b02d84a156ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c654b1f-72c1-42b5-bb42-4947b97abd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc8a8b5-be45-496e-982b-2b1b9def6d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db2b9c13-97d1-4d37-a2de-ea7f1a8dc1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f12ee9f-7ff2-4d51-9dc9-44fb5e27c090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0e9e756-7e79-4130-9b29-f9a181e6d1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537bd16f-1128-4792-979b-5c1b2db69859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8f03e0-4749-4d17-b77e-30829e8c0235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7ab2f4-949d-4d83-8f78-a77515d38502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d1475d-b51e-4d9b-8def-c804742043e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a29225f-cfb1-4be7-9e4f-c28b7b8e1836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8f36e7-6f21-4ee6-a94c-985ebf534376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe72173-7d73-4059-800e-56946aa129ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d87ed16-e811-456f-b9f1-2a46520ae089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2db360-082b-4f9f-af8d-2fcbf0a8077c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d87032d-9dbd-4b66-b489-5a50a538ace9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf6af55-bedc-40d9-a25a-f881ed9d0059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 133e7580-2f58-43fb-98ff-c9b30312e593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a0e5e2-4123-4acf-b459-247fe4f5d66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcf35c6-cacd-47bd-a9a1-524547cd8c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a52162-62f6-4d94-a5c0-6246b2174c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964206a0-9495-4cf0-b78c-effc146e80e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a4c756-4204-4da8-a92f-6df2ce22408a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29e8b7d-f0af-4c9a-bd1e-2811abad47cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1223bedc-5f4a-4e3f-8181-611619adcff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0a3558-9e21-43eb-bc4b-f1e151e4d212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e53e5c5e-6501-4cc8-a2f4-08e33f355243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33fbabc0-4e01-41c0-b5c7-d1d466b8dc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed993ae-446f-48f2-86e1-3af13d10f7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5d19d2-12bb-45b8-bf0a-5cca79b94f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74a4e45-ef7b-4531-80d2-449f68dfaf79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ab566e-4469-4f09-a316-ddaf4fa09c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd2e9a1-6ff8-49cd-a2b8-07adec779e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3b84d9-4fee-4237-8bf9-14fe8580443e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a748c8f-c92c-436a-a973-74d41067e2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a782291-901b-43ce-96b8-7b76723c92ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53d6fa5-352a-4844-82a5-5ab4121abec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ceb1c4-3b7a-4557-b6e9-7b45561c5176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db445d6-1e1c-476a-9bed-c39a36b3d7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a616c4b9-2204-4fb1-a2d9-3dc30dc0b931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2e211a-8072-4600-9a7c-869867605f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd26fdf4-2908-4d0f-a08a-99d300630899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 018a8e6d-3e49-4329-a416-37b3c364634e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8efe148-b072-494a-a405-7dc016331f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dc6b64-1677-4505-b516-03f7c97d0cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acdd3436-4b74-49e8-a2bf-1e08ef50487c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a62fb02-bcf0-4171-a6f5-caa67d9a0896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e0c85f-1cb0-4ddf-92fe-cb4d4adb0a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcdcc9ee-ade2-4851-848b-36c6dfdc645e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec3a00d-c418-448a-8641-cfe5775ed50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d041d92-bbf1-4b6f-9c31-10dd347496f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca777ba-9538-48ba-95b8-cab50051ea8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeef4168-3bb5-4151-b362-397ac72b5a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24753655-6c48-4cd8-86b1-42fa6a4ab92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ed5a5d-286f-46cd-834b-ecc90bdcb0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbc0b58-11c6-42c3-a7ba-d875f4a73268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682d39d4-a310-4286-bb4e-d90e09fac484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea9a48c-accd-40d1-b500-7ddff56feff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cab19ac-0e89-4c36-8e39-ac35c0af7abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3487162d-3148-4aac-9cc3-1ed77bceeb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81896be4-bf32-4841-857f-6d9a651dffaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408b71ea-3e04-4fe5-a338-263b89bbf90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1347762-72d9-4fda-b1df-a2307515f4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d8e45fd-e223-4bf6-8181-69ef722eff40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd02d6a9-e616-4dcf-93e4-d230ca417eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a06a53-ec7a-43a1-9276-35fdfab8bd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57fbf645-fead-44de-b4c7-61f99eb68b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c236c3-4660-46ee-b4a5-e2f5102be117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a026f4-9f7f-4b89-8766-9cf25db60d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1200435-c11c-400d-8111-5e31ce41d87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4de220-5c2d-4b6c-a7bf-7d37ab8c9ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b189efd2-0b31-4487-95c4-76b1df95317c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c55fd6-1358-4fae-bcb6-5d9a0e67e4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4878fe15-0314-4828-9e77-2e92b6abbdcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9699f4f-9570-45da-b5d8-ce17b0deaeb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f2a696-1964-4e72-8284-03887a5f828c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5671cc5-34fb-4416-adec-caacf6666f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e95eae98-afe5-4df0-839f-a31951d4f258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741d442a-4231-44aa-a6a9-b39f54725add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad487b39-e28b-4fc5-bae8-2bc26637d087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be32a60-6172-419e-8de0-61c8e42c3ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69556001-55c9-4a9f-a8e9-6e1c9d256d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b670d691-eda3-4982-8d79-4055758d1992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a90be0a-5113-4719-803a-21e135fa7324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eece9bc-4ebf-4bc4-9ad3-fc2f37f7206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e92836c-5514-4a8a-9505-08e641907f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e93ab0-dc87-4805-bcfb-87ccb89c13bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67587951-a8b3-47fe-8675-357dd3f9908b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ccf1af-d3cb-4410-b21d-01435480d495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1259d81b-9a7e-4bc8-92c8-1e8611cdc5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c36ccc2-4224-4cb3-9981-fb57c0643d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dec985ee-5916-4a0d-8417-5f3e05073747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73666b96-a02f-4daf-9c72-3a4b27ee6e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7384c3-37b4-4109-9f65-33dd9edde91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aab8904-64c7-4327-bb23-ecc4242ef98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7573d862-6da0-49ce-b92d-85d93593e5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fa0258-614f-4e71-96ae-de18b6b8fdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 207151dd-c385-497d-be61-2c7313b7db00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1577e93-0ec8-4e2f-a759-c1ba8df7ad73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffe4543-0c1a-490b-a309-71acfc2e0857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9daf6ad-6b24-4c36-a5af-267098a3f27c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092fc9e6-3771-451b-8809-12be14514098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e3611d-8d0e-4ca7-b465-773cd09aa6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa51cc8d-027f-4591-9cdc-49550b8808ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d26dd0a-b99c-4b85-995f-9e247b23b26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b0c15d-bc6b-46df-87b1-46d59f097249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da95d87-1281-42af-8b99-1058522ee41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b2b594-76bb-4dd1-815c-059387cebabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e49b11-4808-4bb9-8cd3-52ac674cb3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c28f11f-5205-4d59-992e-f70ed7ac1f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a24cd255-65bf-4b14-9085-db791cd8f615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4f21c4-d9d8-47a4-b7c2-76d40fb3a36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df26fc3a-6dc0-4931-881f-9c4c85dddc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dff505b-7b23-4d24-ba04-9ae9c9494a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e561862-07d9-438e-9c73-8d45a081fa2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a825a1ff-07e7-4733-a340-da5f73bf0477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0cbf244-0f36-457d-bd58-07e5f6724957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d111a2-5427-4f7c-b859-22f8abdc9d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b241ebfd-6e72-4d7a-97cc-a4a9b933caf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f0548a-beef-4813-8b5d-4f4d7efa55f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c0ec69-7c81-44e9-a39f-2e449b3e0266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 261e63f2-cb81-47dc-87e7-936fa1f9c795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15961b97-495a-486d-8cda-3deb15d12728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0754f932-e174-4637-ba74-a13593d32b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f783e7-03a4-4ff0-8d74-681b8ee6dbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b67c37-a160-491e-abe0-4bf447d6105c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8668393-5db1-47fc-9e93-5f860df32387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3164d3a6-4d48-49a5-8d5a-b18ed60b6878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bba07e5-7890-42da-8e6d-b33e5334a486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e9abff-eb8d-401d-9055-534a397dc76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80798a5b-2991-4047-9a61-ad02002b5fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b082ad-381f-4608-802c-f412ae980210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e55e190-296e-48ac-a4c0-347f4ead2c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea9b039-1b8d-4bc6-8b0d-5b0881b8eb35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e4524f-944d-4928-8dec-8977b5fe37ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee94777-a7a7-40f7-a3a7-b560278d0eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da086b1-c8e3-4752-a0f8-1108b0d952c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2d1a48-083c-4f10-95ed-1c5b43fa0ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2970d7-2e47-4f0e-a1ca-1f9a09a1ff82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bef49e2-7e85-4e8a-b83f-081fca9e1617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c901362-b080-4410-b26c-3a0900259643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b64bfae2-17b3-47db-ae0a-eb596803a8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de32fc4-690a-4a6c-9126-96aad74d00d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b751e2-267f-4fe7-b80c-852e09c65730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfbffa45-c694-4122-8b2b-66c6616f7fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442c9aa3-0ddf-45e1-8a02-37f655c2b660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f704c29e-14e5-47e0-80d4-418730d30ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c9baae-c07b-4c7c-aac4-d99dabf60701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcdc9da9-35b0-4352-841d-49cb4764d92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fca81510-01cf-447d-83f7-f8eb6482506d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee4b3da-50bb-489c-9517-529a35083d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee247b68-1454-401f-88a9-32ee24deba36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f471f08c-5f7c-413a-b8fa-e3b329977bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 879db8a4-75b4-43bb-a93e-64b88bf64091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76f31c00-b945-4c0d-b8f4-976caa2bbd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d40be03-aa43-4540-b3e1-16dbde5151d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c215933f-4522-482c-a9a5-5d466f82e191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90051f70-7f35-494a-ab65-4dcdb0916fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 261ae14b-a9ab-4a09-b44f-3f85ade2107a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d321bd-5606-4c7f-9aa8-9f229249b495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f497a30f-562b-4467-8eea-b34131e66e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e6fde7-7229-43e8-a0ee-2732a880d322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c87d0123-2dec-4111-a93d-a533b8bf651f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884038b8-dd92-4469-bed2-91480ad9e04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a94a06d-932d-4641-a1bd-fc0ccd613ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a1c37f6-62b5-455b-8b17-96c4d5938ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9b60d24-9d86-4a99-b78a-1c10979abea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1c6f4e-8b64-4ce0-aa89-ddfd225c76d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1befc2d-04f6-4f83-ad4e-5c65ea6b1981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b695bcc-3e78-4e35-95bb-f06a98e2e8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b59ce09-bf49-432e-9583-d199e0e924e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2058846b-68ad-4b7d-bcc7-8348a5b18fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8de5835-bc7d-4099-88a7-1ca3857436e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ab4b6e-6b9c-4449-a704-afed3a8e8e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc28f0c-d4fd-4400-9f38-467f11a22fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84cf3f5-427b-4e6d-bd08-4e188bf2b5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17229869-a23f-4ab4-8bac-e7bbbb66d3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d204c4-84bf-4059-a407-174498072b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 117e6311-101b-4209-ae00-a661b5b8751e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61556e9e-6054-4a80-bf87-7030fa2e5525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6869869-01b1-400f-9603-8cf113a45316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7a1ab7-ea70-48c7-9176-eea977dddfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ad80b6-66ec-4c5e-a863-b7cf5ad36002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075cdef4-5b30-4423-979a-af97bd344e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a98726fb-a05e-4ba8-b129-cbd2ee3a215c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de51b88-4ec8-41d4-8e41-82078f077bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36fad9e3-e0c0-49dd-b49e-f43acf16d498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940caef2-3446-4516-b1ca-ffcad494e241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1d43bb-b39f-46dc-9ad0-a3c91bc65658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 560c4b18-2a67-4e65-9f21-bb277d34e89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9438db-7853-4804-8dc8-1be328546eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd46b65-93b0-481a-b731-2abe77c9e35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1768c75-d8a4-4069-9c85-d87396332c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d90c6a1-d057-4bfb-a985-5648cd0fb6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b8526e-132f-40c2-9389-403501ed8552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69f5b9e-3875-4872-92a6-c61c41a2653c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c6a794-62f1-40d2-9308-fb967c1a5f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b37d7c-666a-45c6-ae45-b0c34a9d6473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ec8f9b-f260-4749-9920-60ed10120c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7f2a68-78e7-4705-b30c-1fbadc9961a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bbf9c00-fc8c-4006-92c3-1e990ce1f2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d603a5af-c05e-4423-b02c-ba16a4c2bd4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b85a70ee-26c3-44ec-9d7d-209052347397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aeaa074-3476-45b2-becb-c1e3c5feabdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be8c098-aa7c-4a07-9596-9831a5b38e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb553331-14ec-45c5-99f9-af8846fbff25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cfbdeaa-ef96-4d72-9e76-154912ebc839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bf8636-6a11-4194-b1b5-9f49227202cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0670dadf-aa54-45aa-8d9a-bc886c3b1edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb60618-60fd-4484-bffb-70abaef57a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c2ce07-c027-4e55-a470-6bdb3dffb198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0ac5a7-7d51-4a70-9fc8-bf8e24359873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97684d9f-9bbd-4c07-a08d-227283ba4592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19445ae-d6ee-4822-b206-15c378a8a5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1654e0c-f240-4013-8a16-44dc6d03dbbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73bb5b3-73e2-44d9-bd5a-680261193051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561e7077-f651-4420-bb45-3876a09e04ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca40f11-8f9b-49f9-924a-3b4954edddf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71edf79-90a1-45a4-b365-cf60b49f774c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e040a884-3d87-4af8-a18b-94dee3bc769d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d29fa557-6b69-4962-be7f-2802ab53fd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33815b67-f143-4bb4-9a76-40b7ce3953cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8b2602-df43-4519-8be0-c88b2447d32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d674d43-918c-4b09-8c3d-f013d4ee8d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f0b839-b309-4f64-a039-8a1a9d07b65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a31004-4665-4722-8125-a7f7303652f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db3db4dc-e638-4242-bc5f-f7822be24172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa861e35-9b1f-441f-86f6-c367bb861f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda9d146-0a98-4981-bb09-e06549cbab0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddeeb17c-af59-450d-bb05-8a8978a4c381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f05722-e3a0-403f-906c-8a5dd37a9291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20d3ca6-70b3-42be-ad92-04ac81a18441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c844f4f-ef60-42c7-92a5-efbc29d23868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5099e4c-57df-4cd8-8b92-11e02ce91bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9dced83-e31c-415e-b5f1-84f894b52c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29d431ae-47ff-49ba-8c8b-59cc0d6fdf1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60741454-8fa7-401a-9d59-8d52767490ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9b318e-45ef-4c72-8250-7c4c14c0a3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3926bebb-1db7-4516-9a1f-febbb972167f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692f0e87-5ff1-4e15-862f-132df263197a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df3d431-2faf-42ed-acf8-5dc6c0bc8352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c13f194-475d-4d0b-b423-8a0d75a39156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd56318-c306-49be-9c78-3770407001ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aecf2f15-389b-4b6d-9cf1-f81f735767ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124eb16b-0a46-45d8-b15b-a795c0f6c2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d701d4a8-cfc0-4ade-8b47-7877c2bf5b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064a3508-3dc4-4a71-9f05-b22c76ed9cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950b89da-f49c-48cc-9e67-a8a49e340821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdd5620-33d1-46b3-a1b7-f5a88b49bac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 490e7ff2-1523-4b7b-a22e-83259ca619d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed53b20-7711-4e5a-8254-eaaa49268523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eccfa888-0228-4570-87a5-7976e674c707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25aa8557-8422-4082-a3a9-987528557bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee79234-ca33-41b5-bdbe-b1b39033c2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8a1a3e-731f-467f-9daf-2e6e5139baa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3fd0a3-07e0-48dd-992a-e723d4c7f0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27bcab34-079d-49f1-8ad3-9d298bff567b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4edb5d5-1d5d-4bbe-9730-dff6e339e9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35129e6-3e51-41c9-b733-3fe6c0e81b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0f989e-4a33-4a5d-9bed-d356d28a3d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6749dc44-0315-4fb4-9558-fc59d0fb288c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1099a5-2f15-40d6-aba2-1ab447e46bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3fa251-5da8-43b1-9219-5fc4093e787b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ac3164-3ac0-4b68-8033-286578bf3ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec41178-5bb8-476e-be6f-a4f3f8bac0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54788b7c-154a-4b5e-9f4a-a57f0e0f71df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57f53fc-9239-4922-867d-35ab6481abca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 372e8936-371c-4ba0-92a1-94063393c72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b33356-feb7-4895-b48c-e3ae4ba1c139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08c3205-7113-4a57-aa9e-22f3a5af8728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed3d4400-dc12-4ab6-8feb-1845aad61e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c919e19-b368-43a5-acc0-a0da0a4f7226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399dbac9-9fdc-4795-8afa-a1f8fb5b1bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c804ff-2684-4df0-84e6-43a2efbc6284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813b3485-740f-43bb-9942-60fb1df54bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06179e91-e01a-4706-8fef-8771efb66ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7baffb2-faff-4489-98c3-ccede25d5fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8406c91c-07f4-46e5-969f-d0e3ea9150fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25bf8f59-7f1f-47b5-8257-b0d59dd997b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fa8550-18c0-4971-b68b-82f65b0a5c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b7bad8-1e0a-4f8d-8429-81f6820619d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b00a0092-8613-4ba5-8611-920fa620eac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558586bd-a8e9-4b1a-9082-b5620bb382ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda58276-8d3f-438f-884e-bf44edf3cbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192c6057-b95e-4548-be3e-c6ab843408aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4b943b-39b1-409c-ba55-60704f787fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3fdd092-18cf-4897-970c-a4131a423acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f327d7-7863-486d-bb24-287b0a1ec2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262cc2f1-a6a8-4106-a335-ab9bda3aca1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78522ac5-5717-4387-abf8-5bcd052f9cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fbd28c9-cf6f-458b-95c3-594ea035c1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8467e417-a1a9-4d2e-90fa-0dd7b8a8b0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de3f0b8-77d4-41c1-a1ad-ca144b66e7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b3d6fd4-d9d1-41d6-949d-9fd952cd989b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f26679f2-305e-4a84-b97a-b3cb0d011825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338d1b3c-572f-4f67-b6a7-ef6e4ca5c269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e471387-b8e8-4356-a9a2-86a6153e38ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb81f640-2b30-4628-8c98-58ae273dedcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77be03c6-635e-44da-b830-7efa0e06d1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d41ed54-02b5-4b97-a7e8-35e4ff3facde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bf35d6-a57e-4235-850e-231a303928b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38de3fce-6f9c-42a4-ac75-14495bee2759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 799f74be-44ff-4921-9812-165aa8215994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b9600d-5a45-4f92-b23d-d3b06889cf4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9dd0ed-dfc6-48d8-90d5-b7704ead5e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a26842-1f91-4c84-a0c0-851b9e924388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 647bb56c-f4af-4511-a9a1-0b4a76652f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9bf2d5a-ff4e-4ad1-ac50-dc92f6f881ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e7e4d47-aa17-43bf-afbb-33bb68f0725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d86099c-9874-4d21-be0d-33cb11729231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27d23b2-e6f5-4004-b36b-b03adde6276c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfb81a5-a90d-4293-8632-e2b110594706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c55dced-f8f0-48e3-a6e2-4d961fd45c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3dc942c-b737-405a-8e5a-3e2bc8b5a63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b437c7-aa12-4f8e-8e94-ae5231da30ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81bed9b3-2150-426c-9a16-4243c54e34bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27dac63-db4f-49c3-9da1-363871420a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e0e6d8-3320-474e-8c60-47503db37f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c12426e-a008-4acd-938c-f50637967f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7d7c4c-1a62-446a-9bde-6585f9b40e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440d9b7b-d5f0-43b2-8829-0c29b0afab2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2492a965-3c54-4161-9e5b-6ed08c906b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb88c880-06ff-4600-b0da-5c908341b9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6648443d-4851-4f2e-b9a7-4b0269622776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a5a982-0712-41a3-9cfc-909510064cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 760355a9-a61c-446c-b80b-bb11e7f8b928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6a38003-0393-4bcb-872e-ee61e107cdec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7816dd8-adcd-4b00-8b03-894890de514a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9fd3bba-8103-4c66-bf1d-f45fe2ccf6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8472afe1-250a-4971-b4ba-7cf2ae202e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a3eb68-7cfb-4827-811e-21d0576e14ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6afdcc1f-c073-4dbb-b2ce-c4eb0472fdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b003efa-ca78-4ac4-88a6-4dce5f9e47bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd8a0d2-53ce-4783-8446-583ff6ccb5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c5deb4-2f30-4a97-9b2d-67d6a1143c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 815d7ce0-0f9d-4fa6-afe0-f728b0843c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad60f9aa-4491-41af-95c7-78a5902b8fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ed5829-2a6d-4c14-9a87-75bea2f50bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80d74e6-63f7-42f1-b731-543a364db5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78eeaa6a-5cec-4ceb-ac08-77e590d934e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0cb01c-a02a-4f19-8f58-5a16627c34af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14c4c42-840f-45a1-a202-a64baa078a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed94fa4d-ed6c-474d-850f-bf7ffaedc0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f1c1a7-86ba-4497-b219-57b64ca2d09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683d9ecf-435f-4485-8225-10621eae5ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d065f754-12a5-483f-9ad1-888747372e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb11d53d-147b-41ec-b566-188872f26f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec6dcdd-1f20-4e18-9ec7-7856ae64da18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f66676c7-e6c3-49b9-b890-07c4bb5e4fe8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(4476, 24), y=(4476,)
   Test:  X=(1120, 24), y=(1120,)

⚠️  Limiting training data: 4476 → 800 samples
⚠️  Limiting test data: 1120 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0888 (↓), lr=0.001000
   • Epoch   2/100: train=0.0816, val=0.0884, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0817, val=0.0885, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0817, val=0.0886, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0815, val=0.0886, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0791, val=0.0907, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 2 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0095
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0016
============================================================


============================================================
🔄 Round 3 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0896 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0819, val=0.0891 (↓), lr=0.000250
   • Epoch   3/100: train=0.0815, val=0.0893, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0894, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0813, val=0.0895, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0808, val=0.0894, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 3 Summary - Client client_15
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0120
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0081
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2496, R²: -0.0024

📊 Round 3 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

📊 Round 3 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 10 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000063
   • Epoch   2/100: train=0.0832, val=0.0831, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0831, val=0.0830, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0830, val=0.0829, patience=4/15, lr=0.000063
   ✓ Epoch  11/100: train=0.0827, val=0.0827 (↓), lr=0.000063
   • Epoch  21/100: train=0.0822, val=0.0827, patience=10/15, lr=0.000063
   📉 Epoch 22: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 10 Summary - Client client_15
   Epochs: 26/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0155
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0141
============================================================


============================================================
🔄 Round 11 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0893 (↓), lr=0.000031
   • Epoch   2/100: train=0.0817, val=0.0890, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0816, val=0.0889, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   ✓ Epoch   4/100: train=0.0815, val=0.0887 (↓), lr=0.000016
   • Epoch   5/100: train=0.0815, val=0.0887, patience=1/15, lr=0.000016
   • Epoch  11/100: train=0.0813, val=0.0886, patience=7/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 11 Summary - Client client_15
   Epochs: 19/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0103
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0186
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 11 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0030

============================================================
🔄 Round 15 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0829, val=0.0860 (↓), lr=0.000004
   • Epoch   2/100: train=0.0828, val=0.0860, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0827, val=0.0860, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0827, val=0.0859, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0826, val=0.0859, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0824, val=0.0859, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 15 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0010
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0038
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0035

============================================================
🔄 Round 17 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 17 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0024
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0119
============================================================


============================================================
🔄 Round 18 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 18 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0048
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0143
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0034

📊 Round 18 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0034

============================================================
🔄 Round 20 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 20 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0005
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0042
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0034

============================================================
🔄 Round 24 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 24 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0043
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0179
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0033

📊 Round 24 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0033

============================================================
🔄 Round 27 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 27 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0031
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0138
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0032

============================================================
🔄 Round 29 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 29 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0061
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0335
============================================================


============================================================
🔄 Round 30 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 30 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0067
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0650
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0032

============================================================
🔄 Round 32 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 32 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0061
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0299
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0032

📊 Round 32 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0032

============================================================
🔄 Round 34 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 34 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0011
============================================================


============================================================
🔄 Round 35 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 35 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0029
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0132
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0031

============================================================
🔄 Round 36 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 36 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0005
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0053
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0031

📊 Round 36 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0031

============================================================
🔄 Round 43 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 43 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0017
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0080
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0031

============================================================
🔄 Round 44 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 44 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0020
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0112
============================================================


============================================================
🔄 Round 45 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 45 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0063
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0190
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0030

📊 Round 45 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0030

📊 Round 45 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0030

============================================================
🔄 Round 49 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 49 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0024
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0053
============================================================


============================================================
🔄 Round 50 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 50 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0031
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0046
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0029

============================================================
🔄 Round 51 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 51 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0022
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0097
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0029

============================================================
🔄 Round 52 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 52 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0015
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0007
============================================================


============================================================
🔄 Round 54 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 54 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0012
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0029
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0029

============================================================
🔄 Round 55 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 55 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0022
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0027
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0028

📊 Round 55 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0028

============================================================
🔄 Round 58 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 58 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0036
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0080
============================================================


============================================================
🔄 Round 59 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 59 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0014
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0002
============================================================


============================================================
🔄 Round 60 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 60 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0005
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0042
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0028

📊 Round 60 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0028

============================================================
🔄 Round 64 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 64 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0016
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0002
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0028

📊 Round 64 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 66 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 66 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0057
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0345
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0028

📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 69 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 69 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0053
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0200
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 71 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 71 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0027
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0197
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 72 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 72 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0006
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0015
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

📊 Round 72 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

📊 Round 72 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 82 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 82 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0041
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0093
============================================================


============================================================
🔄 Round 83 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 83 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0008
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0071
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 85 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 85 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0005
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0066
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0027

============================================================
🔄 Round 86 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 86 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0031
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0082
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0026

============================================================
🔄 Round 89 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 89 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0002
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0086
============================================================


============================================================
🔄 Round 90 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 90 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0050
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0098
============================================================


============================================================
🔄 Round 91 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 91 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0008
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0064
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0026

📊 Round 91 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0026

============================================================
🔄 Round 94 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 94 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0000
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0108
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0026

📊 Round 94 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0026

============================================================
🔄 Round 96 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 96 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0078
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0278
============================================================


============================================================
🔄 Round 100 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 100 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0078
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 102 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 102 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0035
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0069
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 104 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 104 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0021
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0030
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 105 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 105 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0004
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0057
============================================================


============================================================
🔄 Round 108 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 108 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0039
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0037
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 110 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 110 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0025
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0019
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 112 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 112 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0073
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0338
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 114 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 114 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0024
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0021
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 114 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 116 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 116 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0054
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0091
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 116 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 119 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 119 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0062
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0240
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 119 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0025
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0016
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 123 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 125 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 125 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0040
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0045
============================================================


============================================================
🔄 Round 126 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 126 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0090
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0442
============================================================


============================================================
🔄 Round 129 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 129 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0031
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0052
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 129 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 129 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 137 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 137 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0022
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0171
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 137 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

📊 Round 137 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 142 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 142 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0049
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0112
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

📊 Round 142 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 146 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 146 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0024
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0007
============================================================


============================================================
🔄 Round 148 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 148 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0029
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0146
============================================================


============================================================
🔄 Round 150 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 150 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0053
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0025
============================================================


============================================================
🔄 Round 151 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 151 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0000
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0029
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

============================================================
🔄 Round 154 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 154 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0036
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0140
============================================================


============================================================
🔄 Round 156 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 156 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0021
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0038
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

📊 Round 156 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

📊 Round 156 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

============================================================
🔄 Round 162 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 162 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0028
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0011
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

📊 Round 162 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 167 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 167 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0029
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0193
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0025

============================================================
🔄 Round 169 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 169 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0062
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0247
============================================================


============================================================
🔄 Round 172 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 172 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0005
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0053
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

============================================================
🔄 Round 173 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 173 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0011
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0136
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

📊 Round 173 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

============================================================
🔄 Round 176 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 176 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0004
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0053
============================================================


============================================================
🔄 Round 178 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 178 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0004
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0108
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

============================================================
🔄 Round 180 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 180 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0081
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0326
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

📊 Round 180 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0024

============================================================
🔄 Round 182 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 182 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0008
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0097
============================================================


============================================================
🔄 Round 183 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 183 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0048
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0079
============================================================


============================================================
🔄 Round 185 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 185 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0005
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0040
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 186 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 186 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0065
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0286
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 189 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 189 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0039
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0019
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 190 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 190 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0022
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0044
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 190 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 195 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 195 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0067
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0129
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 195 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 198 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 198 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0055
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0105
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 204 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 204 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0029
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0023
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 204 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 204 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 211 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 211 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0042
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0169
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 212 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 212 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0027
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0013
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 212 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 212 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 215 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 215 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0046
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0048
============================================================


============================================================
🔄 Round 216 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 216 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0037
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0016
============================================================


============================================================
🔄 Round 217 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 217 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0030
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0008
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 217 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 224 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 224 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0057
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0104
============================================================


============================================================
🔄 Round 225 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 225 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0031
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0014
============================================================


============================================================
🔄 Round 229 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 229 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0006
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0114
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 229 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 235 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 235 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0018
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0001
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 235 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 244 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 244 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0006
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0159
============================================================


============================================================
🔄 Round 245 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 245 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0002
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0122
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

📊 Round 245 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 250 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 250 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0027
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0012
============================================================


============================================================
🔄 Round 251 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 251 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0004
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0133
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 255 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 255 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0012
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0091
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 256 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 256 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0044
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0032
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 256 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 259 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 259 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0038
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0023
============================================================


============================================================
🔄 Round 260 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 260 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0004
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0031
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 261 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 261 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0019
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0068
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 263 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 263 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0047
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0116
============================================================


============================================================
🔄 Round 265 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 265 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0019
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0058
============================================================


============================================================
🔄 Round 266 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 266 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0026
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0100
============================================================


============================================================
🔄 Round 268 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 268 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0013
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0001
============================================================


============================================================
🔄 Round 269 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 269 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0059
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0225
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 272 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 272 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0023
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0040
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0023

============================================================
🔄 Round 273 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 273 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0025
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0038
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 273 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 273 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 284 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 284 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0016
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0076
============================================================


============================================================
🔄 Round 286 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 286 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0026
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0032
============================================================


============================================================
🔄 Round 287 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 287 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0024
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0030
============================================================


============================================================
🔄 Round 288 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 288 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0054
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0108
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 289 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 289 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0065
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0295
============================================================


============================================================
🔄 Round 290 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 290 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0014
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0086
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 292 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 292 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0045
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0091
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 295 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 295 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0033
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0008
============================================================


============================================================
🔄 Round 298 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 298 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0040
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0022
============================================================


============================================================
🔄 Round 299 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 299 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0055
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0155
============================================================


============================================================
🔄 Round 300 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 300 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0035
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0018
============================================================


============================================================
🔄 Round 302 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 302 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0026
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0040
============================================================


============================================================
🔄 Round 303 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 303 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0033
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0104
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 305 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 305 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0047
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0040
============================================================


============================================================
🔄 Round 306 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 306 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0026
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0015
============================================================


============================================================
🔄 Round 307 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 307 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0030
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0171
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 308 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 308 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0038
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0027
============================================================


============================================================
🔄 Round 310 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 310 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0021
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0153
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 311 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 311 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0058
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0162
============================================================


============================================================
🔄 Round 313 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 313 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0123
============================================================


============================================================
🔄 Round 314 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 314 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0071
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0149
============================================================


============================================================
🔄 Round 315 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 315 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0063
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0059
============================================================


============================================================
🔄 Round 316 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 316 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0023
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0032
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 316 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 316 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 320 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 320 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0001
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0120
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 321 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 321 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0050
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0094
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 321 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 326 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 326 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0011
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0095
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 326 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 328 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 328 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0051
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0093
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 330 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 330 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0030
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0029
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 330 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 333 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 333 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0041
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0020
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 339 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 339 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0032
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0016
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 340 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 340 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0011
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0101
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 341 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 341 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0009
   Val:   Loss=0.0918, RMSE=0.3031, R²=0.0112
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 342 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 342 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0040
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0027
============================================================


============================================================
🔄 Round 343 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 343 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0007
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0122
============================================================


============================================================
🔄 Round 346 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 346 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0046
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0047
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 346 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 349 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 349 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0064
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0152
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 349 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 352 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 352 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0056
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0127
============================================================


============================================================
🔄 Round 353 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 353 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0006
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0049
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 353 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 358 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 358 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0008
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0006
============================================================


============================================================
🔄 Round 362 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 362 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0057
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0093
============================================================


============================================================
🔄 Round 363 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 363 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0005
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0092
============================================================


============================================================
🔄 Round 364 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 364 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0017
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0074
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 367 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 367 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0021
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0031
============================================================


============================================================
🔄 Round 368 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 368 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0027
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0024
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 371 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 371 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0060
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0969
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 373 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 373 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0022
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0101
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 375 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 375 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0004
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0126
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 377 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 377 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0043
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0112
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 377 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 377 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 382 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 382 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0063
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0159
============================================================


============================================================
🔄 Round 383 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 383 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0073
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0221
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 383 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 391 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 391 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0091
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0475
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 392 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 392 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0022
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0054
============================================================


============================================================
🔄 Round 394 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 394 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0006
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0109
============================================================


============================================================
🔄 Round 395 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 395 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0056
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0378
============================================================


============================================================
🔄 Round 396 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 396 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0049
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0068
============================================================


============================================================
🔄 Round 397 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 397 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0011
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0082
============================================================


============================================================
🔄 Round 398 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 398 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0035
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0038
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 402 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 402 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0054
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0111
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 403 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 403 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0027
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0034
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 403 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 408 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 408 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0039
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0018
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 410 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 410 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0024
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0030
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 410 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 416 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 416 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0009
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0073
============================================================


============================================================
🔄 Round 417 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 417 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0007
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0119
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 418 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 418 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0045
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0167
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 420 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 420 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0023
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0051
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 421 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 421 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0032
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0216
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 422 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 422 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0075
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0466
============================================================


============================================================
🔄 Round 423 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 423 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0044
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0081
============================================================


============================================================
🔄 Round 425 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 425 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0021
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0001
============================================================


============================================================
🔄 Round 426 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 426 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0046
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0048
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 427 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 427 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0033
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0010
============================================================


============================================================
🔄 Round 430 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 430 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0023
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0047
============================================================


============================================================
🔄 Round 431 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 431 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0058
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0128
============================================================


============================================================
🔄 Round 433 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 433 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0065
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0099
============================================================


============================================================
🔄 Round 434 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 434 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0046
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0054
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 434 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 439 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 439 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0012
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0092
============================================================


============================================================
🔄 Round 441 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 441 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0046
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0040
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 443 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 443 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0001
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0114
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

============================================================
🔄 Round 448 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 448 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0039
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0011
============================================================


============================================================
🔄 Round 449 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 449 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0013
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0067
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 450 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 450 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0012
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0177
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 452 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 452 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0017
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0074
============================================================


============================================================
🔄 Round 453 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 453 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0020
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0016
============================================================


============================================================
🔄 Round 455 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 455 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0058
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0133
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 455 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 457 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 457 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0037
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0009
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 458 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 458 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0011
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0077
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 458 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 458 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 458 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 463 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 463 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0082
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0237
============================================================


============================================================
🔄 Round 464 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 464 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0020
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0170
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 464 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 467 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 467 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0046
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0137
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 469 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 469 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0035
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0055
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 469 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 471 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 471 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0041
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0054
============================================================


============================================================
🔄 Round 473 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 473 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0047
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0103
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 476 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 476 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0062
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0389
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 477 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 477 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0051
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0253
============================================================


============================================================
🔄 Round 478 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 478 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0020
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0176
============================================================


============================================================
🔄 Round 479 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 479 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0073
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0130
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 480 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 480 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0003
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0105
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0022

📊 Round 480 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 487 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 487 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0002
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0144
============================================================


============================================================
🔄 Round 490 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 490 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0056
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0162
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 491 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 491 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0060
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0093
============================================================


============================================================
🔄 Round 492 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 492 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0003
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0136
============================================================


============================================================
🔄 Round 493 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 493 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0041
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0027
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 494 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 494 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0022
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0035
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 498 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 498 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0032
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0024
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 499 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 499 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0004
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0088
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 501 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 501 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0035
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0011
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 502 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 502 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0000
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0072
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 502 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 502 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 505 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 505 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0013
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0179
============================================================


============================================================
🔄 Round 507 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 507 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0004
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0159
============================================================


============================================================
🔄 Round 508 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 508 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0020
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0062
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 508 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 513 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 513 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0007
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0175
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 513 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 513 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 513 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 520 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 520 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0051
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0120
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 521 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 521 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0020
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0044
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 523 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 523 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0039
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0017
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 524 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 524 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0023
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0166
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 525 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 525 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0043
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0038
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 525 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 525 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 528 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 528 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0005
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0043
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 530 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 530 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0015
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0054
============================================================


============================================================
🔄 Round 531 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 531 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0029
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0023
============================================================


============================================================
🔄 Round 532 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 532 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0038
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0008
============================================================


============================================================
🔄 Round 533 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 533 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0033
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 535 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 535 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0020
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0061
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 540 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.1011 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.1009, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1011)

============================================================
📊 Round 540 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0045
   Val:   Loss=0.1011, RMSE=0.3179, R²=-0.0036
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 544 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 544 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0028
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0030
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 544 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 548 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 548 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0041
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0036
============================================================


============================================================
🔄 Round 549 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 549 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0002
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0118
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

📊 Round 549 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 549 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 554 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 554 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0007
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0098
============================================================


============================================================
🔄 Round 556 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 556 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0034
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0004
============================================================


============================================================
🔄 Round 557 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 557 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0067
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0267
============================================================


============================================================
🔄 Round 558 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 558 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0012
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0074
============================================================


============================================================
🔄 Round 559 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 559 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0001
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0123
============================================================


============================================================
🔄 Round 560 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 560 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0001
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0108
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 560 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 565 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 565 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0081
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0281
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 568 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 568 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0080
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0361
============================================================


============================================================
🔄 Round 569 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 569 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0034
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0004
============================================================


============================================================
🔄 Round 570 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 570 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0065
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0154
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 571 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 571 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0049
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0044
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 571 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 571 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 575 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 575 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0022
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0152
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 578 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 578 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0912, RMSE=0.3021, R²=0.0066
============================================================


============================================================
🔄 Round 579 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 579 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0045
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0217
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 584 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 584 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0043
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0050
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 588 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 588 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0064
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0162
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 588 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 591 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 591 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0004
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0020
============================================================


============================================================
🔄 Round 592 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 592 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0004
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0023
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 594 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 594 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0012
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0078
============================================================


============================================================
🔄 Round 595 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 595 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0006
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0116
============================================================


============================================================
🔄 Round 601 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 601 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0016
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0063
============================================================


============================================================
🔄 Round 602 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 602 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0041
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0015
============================================================


============================================================
🔄 Round 603 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 603 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0079
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0369
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 603 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 603 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 608 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 608 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0048
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0134
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 608 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 608 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 613 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 613 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0001
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0117
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 613 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 613 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 617 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 617 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0014
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0039
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 619 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 619 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0023
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0010
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 621 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 621 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0038
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0007
============================================================


============================================================
🔄 Round 624 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 624 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0047
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0145
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 626 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 626 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0046
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0052
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 629 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 629 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0053
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0197
============================================================


============================================================
🔄 Round 631 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 631 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0024
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0024
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 633 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 633 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0086
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0393
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 635 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 635 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0034
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0023
============================================================


============================================================
🔄 Round 636 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 636 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0100
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 636 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 638 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 638 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0010
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0091
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 640 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 640 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0065
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0173
============================================================


============================================================
🔄 Round 641 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 641 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0064
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0194
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 641 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 644 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 644 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0030
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0021
============================================================


============================================================
🔄 Round 645 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 645 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0047
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0077
============================================================


============================================================
🔄 Round 646 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 646 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0044
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0072
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 648 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 648 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0055
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0076
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 649 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 649 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0009
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0117
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 650 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 650 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0019
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0045
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 650 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 650 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 654 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 654 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0055
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0217
============================================================


============================================================
🔄 Round 658 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 658 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0058
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0125
============================================================


============================================================
🔄 Round 660 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 660 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0031
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0016
============================================================


============================================================
🔄 Round 661 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 661 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0082
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0563
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 662 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 662 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0021
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0037
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 662 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 666 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 666 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0005
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0115
============================================================


============================================================
🔄 Round 667 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 667 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0004
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0077
============================================================


============================================================
🔄 Round 670 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 670 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0037
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0009
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 670 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 672 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 672 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0003
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0130
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 672 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 675 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 675 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0036
   Val:   Loss=0.0706, RMSE=0.2656, R²=-0.0007
============================================================


============================================================
🔄 Round 676 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 676 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0017
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0074
============================================================


============================================================
🔄 Round 677 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 677 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0061
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0238
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 679 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 679 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0086
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0324
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 679 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 682 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 682 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0020
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0053
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 684 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 684 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0032
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0024
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 685 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 685 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0060
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0224
============================================================


============================================================
🔄 Round 686 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 686 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0034
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0020
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 687 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 687 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0068
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0231
============================================================


============================================================
🔄 Round 688 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 688 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0030
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0002
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0022

============================================================
🔄 Round 691 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 691 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0010
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0100
============================================================


============================================================
🔄 Round 692 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 692 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0044
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0065
============================================================


============================================================
🔄 Round 694 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 694 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0030
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0138
============================================================


============================================================
🔄 Round 697 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 697 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0053
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0106
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 698 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 698 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0026
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0038
============================================================


============================================================
🔄 Round 699 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 699 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0001
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0141
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 702 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 702 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0059
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0262
============================================================


============================================================
🔄 Round 704 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 704 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0027
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0006
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 704 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 704 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 711 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 711 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0022
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0013
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 714 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 714 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0054
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0080
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 714 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 714 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 719 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 719 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0053
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0152
============================================================


============================================================
🔄 Round 721 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 721 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0032
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0117
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 724 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 724 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0055
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0172
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 726 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 726 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0017
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0077
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 727 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 727 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0013
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0073
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 728 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 728 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0047
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0044
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 728 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 738 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 738 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0047
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0146
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 738 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 738 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 744 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 744 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0046
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0045
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 744 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 751 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 751 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0025
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0005
============================================================


============================================================
🔄 Round 752 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 752 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0049
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0121
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 752 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 752 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 752 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 757 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 757 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0032
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0181
============================================================


============================================================
🔄 Round 758 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 758 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0026
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0033
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 759 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 759 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0066
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0182
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 759 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 762 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 762 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0055
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0106
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 762 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 765 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 765 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0001
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0094
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 765 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 767 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 767 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0027
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0025
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 767 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 771 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 771 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0033
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0007
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 771 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 782 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 782 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0055
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0122
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 785 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 785 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0055
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0120
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 787 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 787 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0039
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0018
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 787 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 794 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 794 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0124
============================================================


============================================================
🔄 Round 797 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 797 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0007
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0167
============================================================


============================================================
🔄 Round 798 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 798 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0047
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0081
============================================================


============================================================
🔄 Round 800 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 800 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0062
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0211
============================================================


============================================================
🔄 Round 802 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 802 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0029
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0022
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 803 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 803 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0071
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0260
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 803 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 803 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 803 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 808 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 808 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0054
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0084
============================================================


============================================================
🔄 Round 810 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 810 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0022
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0035
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 810 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 814 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 814 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0080
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0269
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

📊 Round 814 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 816 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 816 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0036
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0039
============================================================


============================================================
🔄 Round 817 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 817 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0041
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0037
============================================================


📊 Round 817 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 821 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 821 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0039
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0089
============================================================


============================================================
🔄 Round 822 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 822 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0006
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0060
============================================================


============================================================
🔄 Round 823 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 823 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0019
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0025
============================================================


============================================================
🔄 Round 824 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 824 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0016
   Val:   Loss=0.0799, RMSE=0.2828, R²=0.0057
============================================================


📊 Round 824 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 824 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 824 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 827 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 827 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0049
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0079
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 828 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 828 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0034
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0044
============================================================


============================================================
🔄 Round 829 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 829 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0085
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0367
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 832 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 832 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0017
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0070
============================================================


============================================================
🔄 Round 833 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 833 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0156
============================================================


📊 Round 833 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 833 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 837 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 837 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0001
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0090
============================================================


📊 Round 837 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 839 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 839 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0084
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 843 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 843 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0037
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0122
============================================================


📊 Round 843 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 843 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 846 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 846 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0022
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0024
============================================================


📊 Round 846 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 850 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 850 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0038
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0017
============================================================


📊 Round 850 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 853 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 853 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0045
   Val:   Loss=0.0948, RMSE=0.3078, R²=-0.0056
============================================================


📊 Round 853 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 854 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 854 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0015
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0054
============================================================


📊 Round 854 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 854 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 854 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 859 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 859 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0045
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0134
============================================================


📊 Round 859 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 859 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 863 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 863 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0026
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0034
============================================================


📊 Round 863 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 865 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 865 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0012
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0081
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 867 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 867 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0014
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0154
============================================================


📊 Round 867 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 868 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 868 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0027
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0020
============================================================


📊 Round 868 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 869 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 869 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0022
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0002
============================================================


📊 Round 869 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 870 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 870 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0029
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0029
============================================================


📊 Round 870 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0021

============================================================
🔄 Round 874 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 874 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0012
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0046
============================================================


============================================================
🔄 Round 875 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 875 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0040
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0016
============================================================


============================================================
🔄 Round 878 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 878 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0069
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0229
============================================================


📊 Round 878 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

📊 Round 878 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

📊 Round 878 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 884 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 884 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0025
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0024
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 885 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 885 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0027
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0037
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 887 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 887 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0025
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0014
============================================================


📊 Round 887 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 890 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 890 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0056
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0147
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 892 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 892 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0042
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0090
============================================================


============================================================
🔄 Round 893 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 893 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0005
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0111
============================================================


============================================================
🔄 Round 894 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 894 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0053
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0071
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 895 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 895 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0038
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0010
============================================================


📊 Round 895 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

📊 Round 895 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 897 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 897 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0035
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0029
============================================================


============================================================
🔄 Round 898 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 898 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0029
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0021
============================================================


============================================================
🔄 Round 899 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 899 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0013
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0026
============================================================


============================================================
🔄 Round 900 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 900 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0032
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0087
============================================================


============================================================
🔄 Round 902 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 902 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0017
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0079
============================================================


📊 Round 902 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

📊 Round 902 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 906 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 906 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0039
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0038
============================================================


============================================================
🔄 Round 907 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 907 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0069
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0289
============================================================


============================================================
🔄 Round 908 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 908 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0015
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0066
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

📊 Round 908 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 914 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 914 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0053
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0070
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 918 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 918 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0053
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0056
============================================================


📊 Round 918 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0020

============================================================
🔄 Round 922 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 922 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0020
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0050
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 923 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 923 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0056
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0116
============================================================


📊 Round 923 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 926 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 926 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0061
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0140
============================================================


📊 Round 926 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

📊 Round 926 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 929 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 929 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0082
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0343
============================================================


📊 Round 929 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 930 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 930 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0048
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0086
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 931 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 931 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0046
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0130
============================================================


📊 Round 931 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0021

============================================================
🔄 Round 933 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 933 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0014
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0059
============================================================


📊 Round 933 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0020

============================================================
🔄 Round 934 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 934 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0050
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0047
============================================================


============================================================
🔄 Round 935 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 935 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0062
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0269
============================================================


============================================================
🔄 Round 936 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 936 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0002
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0086
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 938 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 938 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0047
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0111
============================================================


============================================================
🔄 Round 939 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 939 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0016
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0014
============================================================


============================================================
🔄 Round 942 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 942 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0009
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0112
============================================================


📊 Round 942 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0020

============================================================
🔄 Round 944 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 944 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0014
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0006
============================================================


📊 Round 944 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0020

============================================================
🔄 Round 946 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 946 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0006
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0054
============================================================


============================================================
🔄 Round 947 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 947 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0046
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0083
============================================================


❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
