[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fecd902-3088-4d5d-b952-b3e372821203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01297807-ff43-47ec-ba2d-b9cfcec826a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 502d2bf1-2e0b-41a8-ae94-90bfe2996dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be0cb0a-7497-4dd3-b877-59f72ae62666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f018bd49-b5c9-4c37-a7be-08b75eba44ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 994f8fcf-6568-4877-9820-1e797179ef79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d783ae3-803d-44b0-a049-005735ff13d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f55a435-96d4-4e70-8390-f4cc6828587e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbfe93ce-4f71-43b1-a4ab-53ed9a4f058f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f4fad1-4ee9-4766-aefe-cccfbd7de710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d27400-b08b-40c7-9909-32bc7ed9a1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b8cdcb-b603-461a-bda8-2b57373caf86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd1c914-31f7-40db-a3f7-a7a84cbab1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15547d7f-37c5-41a8-820f-bc9fdaef4b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298e0996-887f-4229-8676-d3f160d29a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42322002-00a9-453f-a601-d8b82a4d4f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1994ad13-736c-4e5b-8f10-04bb46a15327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934aba46-c8e3-4281-b28f-af47c04dd1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d18113f-2253-44c7-90e0-44abf38b718f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0bbeac-fe39-413f-bbb4-f9e49822201f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc5b775d-2d3d-4077-8d13-6a3efd2a0631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e687e1bc-a12f-4f60-bff3-6661cfa59eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5411bf7e-9510-47ea-b411-5576de8b4a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c46f789-ab91-42c2-bbb3-9a82faeb8081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8d84c8-ca75-4a29-bf8b-42dd4894492e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd7e045-9300-4128-be53-989022db2a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf5a64d-59fc-44d4-8bda-9e306da8768a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff14497-27bd-4a87-ab8c-6d3af36c862c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1077a30-3945-4ad4-8e87-fc5c552a9877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c48794-4b9a-43e6-a926-92ce35ac7bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 127d27ff-21ee-43f6-836a-2cd4be04cacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672c75fe-e6d6-4402-b00d-a9bb9827f770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fad17f8-fb58-4f6d-b542-f0e350281215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c91f8a-60f9-4ce4-9f94-d25756f331fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ca12854-9fdb-4b23-bf87-cb8a97e0147b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936f6079-aa29-4839-b640-ad24fe04eaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36161afa-8361-4399-a22c-194068d2b0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7f8029-f4c4-4511-b255-17d9facae9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8378e5b-0aa3-48dc-b68f-a7b52caaa615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab7972f5-9921-4976-9ad7-c3cf115fd03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8f1edd-1579-4880-9baa-0f15ca2dce0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a020eab-c68e-4230-87e5-93120403df7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd138eb-3ed0-4cf7-8852-35f4bb96f90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40748a0f-3297-4be0-a360-75e4c61e5d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f00756f-eb93-4691-9c4a-740d69eedec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08540a23-68f3-498b-856d-3b7f1ca59cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec7ee78-2559-4f11-ace8-f3faf0966927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fe4cfc-80a7-4cc3-8501-af5e1109d778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683b8dfb-f30e-4018-8e52-7aa35e10a7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ebe7cd-f0c3-42ad-8cd8-c011098731b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeafd807-16d5-4e94-95da-e324ba522ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 176a5e9f-4fc4-4420-87f7-96c0c6248f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2204cc-9ea3-4a56-8088-51e29f6ef97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb478b1-c5f7-4925-bbee-0d41d432892c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71aa33e-dc89-4138-b68c-9e0bb5082f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95aae2b9-e74f-441b-a591-4323e575ad98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5363d5c2-7a35-4469-8b10-ca1dd7403fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc33eb96-a16b-4bfa-aedb-cd9d769833f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6bae6c-13bf-475d-b5a4-daa688f317ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63f281d-47e5-46b3-a06c-27a16c075cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43edc86c-3f18-431b-a84a-53779f8b5022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41b512d2-8971-4029-a136-91bbeea720dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa93e93a-d177-40ca-8dd5-28e28d2712f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b587fc-39aa-43f8-971b-257cecf308a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c96452f-929b-4c8b-9a70-a35c5cb7622e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 970924b6-6e43-451d-9f13-e3d9ad851302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 078b0469-a60d-48b1-b0db-19b51a42e508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e19503-f7b7-44e0-a1d9-a7cb47020fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25519c9e-524a-44b3-8da9-5c1fc46b80b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d22ffec-46fd-4ad6-b792-c6cef9dd6d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b1283a-cfdc-493c-bf36-ba0424f9bc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f6ec77-aa7f-4ea9-8ba5-43c952e4cc50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e3a1149-25c1-436a-a6d1-7e2dcb5030ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a175c94f-a096-4c61-acfa-8b65d03bba38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e86a990-a322-4a38-8ab9-2ded67ca63cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10383e2-e06d-4509-adca-8d22754437e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a5a348-3113-45e2-9af8-b1f9d968c462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdbd98d7-c085-4e48-b620-4b96a915b4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a949cf2-6263-41e6-b345-e1fee8b76211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4724f60-6d51-46a1-ac98-50178c0265fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a81500-88ba-4abc-98aa-d2f587a5cca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067ee7b2-1e6a-4c23-9293-f3cf4d564d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ecb170-d6ba-496c-9ba3-21c7a9e628ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 230e77f6-cb92-4ed9-bdac-2d2c2ec83274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd691fa-9ffb-41a0-967e-3aa30de3d4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de07c74-7c8b-4fbf-9301-1485740c613f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8065e908-efce-4251-b8ed-e375e9868742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21d1ea2-68a5-4de7-8176-eb061a221fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8957aae-41c0-4d60-9643-5a00a02b11c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdda1e9d-9252-46e3-b523-3189416d415d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28eb4b9e-70e8-4b84-bd8d-40fccaab8094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6427897-7eb7-45c2-a0f4-68dd67d2e70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cbe835-32b8-485c-b496-aa483169906f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842d1abd-53dd-484f-94bc-c9161ba9a992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615bb30e-c461-473e-acb3-c4e569af892e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d6b84e-60db-4be0-a653-170fcc80b807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f16b6d6-24db-4dd4-aa1b-af1d7c482572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e90541-2bbb-4fc0-9beb-913537d33fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e870f7b-9905-424d-a533-f236ae0a574a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeccc229-e959-4003-9505-4606c7ecfa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2b6911-90d8-4025-a569-3a1125b31e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff089a6a-5c66-4da6-bcf1-e512d56b30be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd17066d-29c3-4969-b882-23fc9aa7ead9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71fa0da7-fd6d-4627-8c28-f587c417dff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d2d231-0e30-43ce-b425-d20f2a9cfb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8225cd7-8936-4f2a-9dee-701449e002d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 809292eb-6ee5-4cb8-b7f3-7c52c8cbdbee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1460193b-4ab4-4792-968a-86138b712666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677bded1-bf0f-43cb-ad85-907011117715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eca2df7-93f5-4edd-b8ae-cd9168809f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b4e92c-3347-4f6f-b511-aa42bffe268e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d80df0-f377-488f-ba13-dbbfac46a87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c64b220-f0e5-4be6-9bdd-8079f52c0a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59cab810-def6-40d6-a6b6-7bc0e18161e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cf0b59-4973-4c15-93d8-605f8570c43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413afcfd-0ad5-42ee-a216-8bb00cdfb5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744ed514-cf78-49c2-9607-8bb332464bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4e2a01-5cb3-438f-a280-cf4c05cce95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a461a46-b78a-4aa6-8c89-5ce49766ebc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf42e8d-626c-4e47-a6b9-b6c00a5d4769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48530042-d771-441b-9f9e-b8824c72f4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df35b74e-c616-4328-bae9-0a1474dc8349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b4e41e-1a23-448a-8126-efdd11c1e790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 930546d2-366e-4523-9b01-9f27128c1e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e114d474-d712-4369-9dd7-487aa3c3632d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af677e7-ae72-4ed5-990b-385334bff967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb5841a7-8a0c-4ff3-8fae-c13584d3f87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6783055-14e4-4cef-bb07-d4d45eca0d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894d73e5-29c5-4b19-817c-e529ce10b5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7486d3b-0000-484d-a8b8-b40fa5febfca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd2284a-8a8f-46e2-859f-d5097e7702ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c028838-db7b-4917-bca0-4afcf8a47870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107d7a32-cf3b-4c7c-9764-d1e40fea4f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f66fa7f3-1962-46a3-8614-c8ec199a10ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d532263-10d0-4155-a557-d92f14fd070c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea5d1a39-e2a0-43f3-bb4b-adb7ff1909f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e05a83a-c259-459d-a3a7-e8d276be64b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1afca8-36c9-43aa-899c-3487840e2b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed6839b-8821-4cb6-a05a-07a42c4f3a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b453692c-0fa8-4d3b-b069-c647a15f253a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23739a59-f175-4ed2-9fce-43bf904a0a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b46b77e-fb4a-429b-b1f7-5dcdfef0e14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8f6535-80f7-42ce-9818-afbfda4fba64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e0c825-7b8a-4713-bf3f-293d6b364bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6508c312-b5e1-4195-8971-0bf34aba3341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cda7898-b400-48ad-8ef3-471caac24b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4b8085-4b49-4401-be21-3b596a5c9a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c854bd-68e1-45c0-9a79-744913edf9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145513cf-c6df-4fac-a85c-082c2ef8014a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e324c06d-8495-44a0-9847-e8231661b19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db66b99-1b51-4296-92fc-480e1799f2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a2805d5-dc04-4961-81b7-6cb66640aab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e652a8-4e90-41a5-946a-a8fea67b4ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32fde3a6-cec1-4594-9b09-cfe4ac0f3ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043703d5-cf7a-4cdf-89e0-2203ed446efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131244f5-d67a-4508-9cfd-11fc67d8cdfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f1dfa77-b1ab-4056-8427-c76f77165062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfde68d-c16e-4460-a741-3c542dfb339f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c73c82-7cea-49ab-b97d-de756d8d5a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bc7db34-9c26-478b-ac50-12736b04c484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cb92e95-665f-4070-8415-d8578d7e7259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8a9f12e-76ee-4d5d-98ab-0e7c01cb3a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a716f0-7eb0-4e2c-a488-f65f4d8bd637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd269563-2b35-439c-8efa-4f2b871028dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e59db9-2493-46f1-b034-a27533a3480c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02ee7e6-72ef-4b01-af16-f972e44507ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98b8ba99-52d5-4dd9-9330-98e150ed97d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92cbcba1-5e52-4f91-9aff-422af20a7ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e2581f-edfa-42e1-aa98-2d1529fd5499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20cbe5a7-c102-496f-b9ac-d7ddd93cadab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d38137c-cb66-4bf4-9315-24b546d8088d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b1a0f7-468b-494f-8486-02409cfe4126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 519dd0c7-87fc-44ac-b669-21f313bf319e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ab197f-ac7b-408b-abb0-9807b0122418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa76b10-c56f-445f-a27b-9f6c1f06ff56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1eedd8-33e5-4654-a957-7bc95d7da9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a46f2d3a-ac5a-4d9d-803f-71a2be974f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3283b0-b576-4b4f-9b69-68a541b3735b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8343018b-cb23-49f0-abf4-f3e0f23b0a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0712cb45-3585-4539-86ba-d701b88bab61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba2cfda-08aa-4ab4-bf7e-0e01ddd9b2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195284cd-4677-4deb-a99e-0c190282462b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63601131-64f9-4100-bb25-d90ef1362dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55af832a-2943-412d-86ba-9dc9be0ed7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b24b2e3-c02b-4fc9-ac81-39cd95eb960c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aabb4c9-2367-42f6-81b1-4c90cb9e028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d082dff4-d902-4ade-bea7-c716fe12e432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250393ae-e7e7-488d-a133-1768c98e082c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 408f122b-9dbf-49dd-a948-ee4af1969063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a73d78f-b3f7-476c-8819-ba8a4e7cb20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ac4ffe-70f5-4af1-83ea-422f1373a225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6d903b-14cb-4827-b955-d8e9270b38c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 830bfdb8-bf2c-4699-9cb9-87a6d83dd80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8366a510-a167-48c9-8538-11ec2ecda951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a81424b-d6ad-4eb7-8280-2648c97da670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c4ef5f-8a45-4c4f-b004-0e084a59703e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8847c07c-5ac1-4909-a69e-c0ddf96a9d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94da9758-b714-4983-b9e3-c1fa6235bc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a94b0d55-1e31-4fdd-9d46-9b571939fa6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0200ba2b-5587-4ad1-849e-31870eb70c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcad2ce-1b57-408d-b164-a0da2c0852fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38282a47-1663-4e31-86d3-7fee96ce8811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4eb983-d63f-4ed1-9085-7e101df895d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c351b666-fa79-4762-9363-26f88d33a31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f76e5c-3d97-4d11-9515-e44682722f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7f45f8-5726-4135-a0f5-c534b185f5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e933c3-5f9d-498a-8050-19c2000cb373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 250b397e-c600-4392-8a80-e3dc372c9a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e33b4c25-b2a4-4f61-a02d-31ffa173ec0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 512349f0-0267-45d4-b479-dd7be93059ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce3a6e8-1440-4009-b9a0-861ef6341b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766661d1-6b9a-41d0-bc85-cbc8ad73c377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab65c80-a808-4d89-ac86-635d7d7d3478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003fa3d9-4391-4386-948a-79aaf955cd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c3b03a9-460c-436f-8017-f26e8c812d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a931769-c3eb-4afd-be8c-f2e02abccec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c8f9bb-f771-40f0-84ae-25efcf23e28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640dbc76-8ee1-4791-bb2f-9fc5081dbbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d057796-db86-40e3-b2b9-0c301523c029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c5c787-b457-4f3c-9a2d-70e446768f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c4f6e1-3419-4a08-8f27-b48210fedf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847a36a1-d04d-4ca8-a00a-dcecdfebd759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3476ee-732c-4fca-aac1-0e666b96c950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e59fd1-d953-4d2c-9775-3ef81488809d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60ab656-58fb-4d97-a693-b39cb195cd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb1ea1ae-395a-4640-a1ab-99b1e30d7a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4b4d60-f750-4e44-bc1c-d5acf2497602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3497844-af83-49ae-90b2-6d245218a8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 401082f0-e198-4699-b278-874a5c885e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1693ecc5-8de6-4d4a-9439-9c46f7f7436f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91367d7d-3dc4-4c41-a6ae-c333196d984f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5573febc-762d-4072-b508-6a7ed5661b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 051abf14-34cf-4007-b700-3bb627c4eb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e411f0e1-ab6b-499f-bb08-16372208b313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6077abc-f966-4918-bec7-d87ae9865a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 044d2bbc-8971-42d1-b0b8-a9d458cc3bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f653f317-d909-4dad-a39b-e9b87f3a076f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56384a94-9e88-422f-8ebf-8b82e47b5504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3158a7dc-7337-4ad1-afb6-07e77e9276ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19697498-29e3-49eb-99f0-f2a8a48c565a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0241bc4c-5c30-4c65-a17a-b7e671990d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa052417-e356-40b1-8179-5eff6a7bca74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 286bb590-4554-46ae-b943-680afed77281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73b7158-eabc-49fd-b5d3-e01975ee3afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa62237-56d4-459b-b1fa-5f4599395533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04cf4677-760c-4d24-a842-37a0e01cd23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6376a41f-7f55-4ba1-b949-28bfc984c59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d69dcc0-daf8-4ff7-a5a0-e50d38bb7b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1cab177-a256-473a-935d-98a5cdaf4ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6082eeaa-53a8-46a3-89b4-8722efb62c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124a9287-decc-48c1-afa1-9291f5b18700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 319f0d04-1639-46af-b426-da81ede70b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48af17a-1001-441e-9366-7a8775dc3d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed6ac3c-2e38-4d94-9e96-30401753310a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7eecf6-7dfc-440f-932d-3dbd7501fe52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0672e702-543a-4e38-9b93-c8325a9eea1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d313edc2-9263-4540-82dd-91bbca525b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7bfd40-e333-418a-b328-c1125f00d33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b21e07-6d1c-43b5-87aa-47ad23402acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495510ee-26c0-4d35-9e77-ed0917797a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efdf35ee-89f5-4b3a-85ef-5accee234e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d56186e5-20c6-42de-81d6-74ee468c0fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f55b4d3d-db60-494d-b4ce-583db9f3d0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe94aab-d15c-4027-8cc6-db6cff53b24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c40c03-4092-4948-9f2a-a0fe1d0d1bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6442ed1-7ff2-4acd-a617-5bf9455f3e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7aa6396-a6ca-40b4-adf1-444234e56492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9d15161-1433-4e83-b84c-26157a30c297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea478ace-10ec-4ee5-bf54-d1f204d3581a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c40a5a2-3f01-41b1-89e8-5648cb8271c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5265ae31-285d-4096-99d4-2bc8e231d030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b06482-a67c-4190-b614-a2befc6b896a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a69c7f32-f3a2-4fa5-83f8-cc0220a39447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0649daa6-5642-479b-b0ae-afb5a980cb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a936931-a776-4664-a747-bff19e5216ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a03b29-8b95-4c24-b88a-975c9e45a9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a39b69-2673-43b6-b755-f7857a6385e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206fb74a-a96b-40a2-9a31-ffd3f9fbd1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a145cc-5624-4c99-ad96-d2adeb3f4c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba5b32f-f030-43b1-b46f-6ae0b1f0c3f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a86de7-48af-4ff2-ac59-cd07eb3afaea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b958eee9-d5a7-4d0b-9d12-b85b1f6b87ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2c3189-bb3b-4825-883d-ce354f4b8130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12b9b296-2a23-4513-8c28-8ee323c30bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e792abe-7293-4b16-9201-23c0cb17ed87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f4a633-0c1b-47ad-aeb9-66704d2ca918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18122d56-1d68-4270-904a-91c6ac5f499c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae3c71c-77d7-410f-a7f5-e5a0fece2b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603384c6-1e1e-4467-8baa-085ba7f9af98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8252b458-5257-4592-8d70-fea7a44bbb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d77857-eb86-4c87-bcd7-d57cc8a9ac58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fbf1fa9-8cde-4dcc-a0a1-72f7b178bab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0375b0f2-2f4f-43bb-9a3b-0eea3f2f3c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af2ef21-da03-499e-8c9d-c6e0d90af7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7880a344-b12a-4baf-add6-f2f16533b46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41b35884-c0f2-404e-a291-dc091ca8ad24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66762fe7-f1f6-4786-a2f8-eb63f56e2e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3764109-66cb-44d9-9067-fa53632ebaea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d943ab74-313f-4258-b018-26509f5d88b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 560bc984-eac2-4f50-92af-ec040b8c4ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b15d7ea-9d5e-41c1-8725-bedbc864bb6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d50ad2-4905-41c8-8a95-5e186bc240d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e93b8bac-113f-4d3e-b3a5-288e93aa504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4b8be8-f333-462b-9e15-4e692d4955c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3fb5d47-18ae-4462-9bbc-28d14409fe90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1d4f6b-f93a-4c3f-85b5-4c6faa0e9389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2931d9f2-8943-4887-94b2-b5574a80bdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d2b60e-be96-4456-9d41-7befc0c36a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9758e2-101a-45b5-9d5f-ddb64b62ca1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a12dfd-cc75-4289-9819-f60362b75df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23863e67-2ae1-41f9-90b4-f85c640adf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f37178cf-b207-40e0-8967-f4a91b54ccde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ed70dc-b567-4607-af15-70f80a938f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63fd44c6-3529-4418-925a-ebc16f72192c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e849c27-0c86-42aa-be38-e5629ad1b0ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fdd00cf-4601-4bcd-af4c-677696b3f2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9ac45b-cfcb-4967-9fce-7190600b9902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c921f83-6cd2-44bc-a9d8-139c82aef172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f213e0e-9761-42a9-9d86-4e6c8704a44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebaccbde-9fe0-4dbe-86e1-f9a3591e3c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6b21cb-700b-4e76-bd9e-5b4fdfd70134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08c64a7-1a3b-4d6f-b4e1-d700dde84afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b219ee-8a37-434e-a0f4-357dec77c55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc31d1c4-e38a-4bd3-8021-7d742dba49f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8138a3b0-b814-435d-a886-c024f801b1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247bc2f0-5b7f-4eb3-8f51-6b6330902cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 763975cf-2e82-4fbb-8f11-2c7c70c2775e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589155da-6cb6-4e11-9883-a6732c5d0ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 286c977c-deea-471c-a4f6-307978ca036d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e7d47c6-070e-4ccf-8b4a-928642b3a703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d03388-eddd-4f58-8590-100982563592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21949e1e-5953-418e-b0f8-6603874a99bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e772f2a1-f0fd-48fc-9386-5753fa12ad1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8247508-bf33-4c0d-b30a-2ce443c5875a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf19bdf6-b71f-4586-852c-48e71578ed7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae60fb4-bf9a-460e-b843-50e374e9910e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7150e8f5-0d17-473e-b03e-f83e294671e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9003169d-2cfb-4c33-87cb-a899613681e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac569417-df87-4722-a7c9-8f0a5ff11775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9a9b0a-b533-41d6-acf9-fe7c878e8d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b0ef1bb-0523-4f57-817a-1fd61a54efca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b8262c-361e-4225-848d-1d522a0e8f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15eae415-50ba-4c22-962f-607c58dff637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e27a5dd-d2cb-4114-95d0-65bdbfc5f1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bf67eb-d852-422d-9228-6717e6f17df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761aebcb-2b54-4a42-b20b-e43166e6c623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0df4749-b285-47b7-8cbf-7c13798b4d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70677509-7bad-465b-a611-0686e5ba4173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d1354f-2502-4ba6-9994-455c374682ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f89d843f-bdcf-4e8e-b651-dde2310c985a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b547af-8c1e-42eb-9885-5d8eb268a7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71856b2d-8247-4043-a271-93fe4e886684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caca83b7-b567-4c66-afab-6d3ea613168f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e11610-78bc-48f6-b0d7-bfb054547ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0abfc2-77c2-4dbc-8009-5379fa13d656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36834d36-b0c0-4dab-8889-7179ec5b3c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce97ee4-d181-468b-878a-2e02d6c23e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49863763-1c9f-411d-9a13-ca564a80a0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2524c926-f484-462b-b4df-0ae95d5b9aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a066c46b-339c-49f9-b647-4d2826ae4f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4665f8-39be-48ea-a0b6-bfc8d0ed80e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a893d3-5dd3-49c8-b5d3-378326d8b923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ecfe9e2-0215-4a40-b070-a391f60b9b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ba6e91-9e61-4a81-92e0-c1485061650c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2570762-9054-4dd9-bddf-0616727ddf22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d24cb2a-a87c-403f-9a15-9f550aa80f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6d7fd59-dbd4-4ac3-acae-e6dc42a2095a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5eb73d3-b691-4201-aa50-f396ff75f24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe372de9-d2f5-4810-8c26-5d03452dfc75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a91689-6877-48b0-8c24-e97937ae2af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8eb15f-f1eb-4df7-a0c4-e91a0d464406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37dd8306-7d54-40ab-819f-f76aa18d0e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4208f5-6967-45e4-9f05-c41157a760c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1a8158-fe54-41cd-b38e-fd9e354558ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5800c4-78ea-46b2-b4ac-83111994ec3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48fdf0d6-b3b3-4444-8e81-d06d6a9a0ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d885ed9-e29d-4b4b-a922-186d8df9a5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 530da93c-b206-4ba5-bc1e-771b05fc833e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1e8ea1-5630-43e5-b43d-d7da2c1945fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b42545a-cdbe-48df-adac-32ecd8041046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0ae0da-8cc8-41ce-a770-56ef94c59f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a498558e-b403-481c-8bb8-4f348761cf76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81b68b3-e82a-4f4e-8f30-b97bc3d2249c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51507b44-4d80-417a-889a-c2c9ba44780f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a481f6b-257b-4605-a974-aeaea87db5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c70e5d-e029-4f53-906c-725a449ea1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3159e8f-7eaf-4b7e-9589-a703a8367951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fabca4b-9ed3-44e2-9a22-5d20e036eff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a3164c-db8c-4076-888f-a7ef43f41a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6cd361-4d9d-4d26-a9ee-78d31c1d2839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ef5faf-c188-43a8-918b-44d4f7826836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab914149-7eb0-4fa6-a7c9-bacd0a90450c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb22cc90-2705-4080-ba5d-cc33192cb688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606413e2-85f0-4889-b763-b5d07144b3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d41d2d-6ca3-4468-a509-f3e6ce273700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78db7b3e-eec8-4168-89f7-8b31df7ab186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d87fc4d4-1e03-4216-b5b0-f55ba4507ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1b0a6e-56d8-4b29-8613-57c902128c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f71dcac-7908-4f63-9f2c-91b912d67862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90944952-7f10-4e06-8896-9196de7b193c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51a8708-9a6a-42b5-804c-c58109d225eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f48390-8725-48fd-b0fb-60187669ffa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee875ea-51c0-47d3-be51-92705d96a0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 747ce9e6-2bd4-47df-aee2-b66fe1396a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d68d3fd-63e7-45cc-93a1-8e92e4ded616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b098e273-4060-4974-83c6-6303eb0847ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84fc401-dd40-474d-bed3-6580f0ce6840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611b5f2a-77f7-4621-92ab-ea9f5ff36fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e98e623d-54fb-487d-9523-f1ba20bce61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e58d736-80d4-45f1-8ade-425267c4dce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd68c55a-c397-41b1-ae42-502b5ce3cb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b29a8c6-6aeb-41e4-a2c6-b47447e2caa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5922718-919c-45a8-b0ea-d6d80b99f023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a73f7b-af4a-414a-a2a7-8002f66afcae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17843c74-dfd6-4f22-9a58-b9b64b3b5660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57deeee4-78cf-4453-add8-939c57c12ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43dcc3d3-8f3c-4127-989e-b4816d5214d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba4b34b3-8ebc-4b21-a1a7-7e44b843cd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92bb5218-183a-404c-a6ef-484affa47987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8e4447-130b-4c85-bb02-6ff602f387ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d222e6b-93cf-4ede-80c8-31aeef099c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590657dc-530f-40f3-8d14-5fb6862b62f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9175833-95e8-4069-835e-b126ec1995e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92746cd7-3c6e-45a9-8bb8-6632aa3f7cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 102acf34-4f52-4044-9aaa-ec07d799a96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90cf0aae-7435-4c7c-aec2-0f95293e79dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf155ec-a52c-40f2-8e1a-4339c6246b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63695dd3-323d-4df4-a736-ff9c1d53eb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e3f5a1-1705-4248-9bb8-452c27a2ef57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e31b2a9c-10f7-4409-892c-827ff6edb92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60aa1bd9-ad9f-40bf-95bb-f2c6d778c55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01eaec94-a949-4719-a284-8c2cb89d9ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28fedcd0-7c58-4c65-b298-b5d6986de1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea70e09-4ddc-4ad0-b813-54c30bd1e028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2aec02-7e4c-42ae-9863-fff9623dd88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d292c19c-a2d2-4c33-bdf1-048f4f9b266e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4bf1cc-bdba-4bd0-93f7-1a34a01d08be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41618bea-7058-42c6-8b33-d245e842c33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd3393b-6818-4ef6-b811-52bc826dc208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae8f09a-1731-411b-b877-272f0029a666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84eee78c-cfc5-4e4c-92b7-674cfc211e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c68cdc-c323-469f-9c2b-7ff543774d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534b8464-78f1-494c-b318-d5443036099c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b36e1418-96f3-4427-a9f8-9774c2c9e381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3884f899-6a6e-4f37-ae53-4431a70afd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c6831e-1bda-4add-a3a5-3a107eedbd9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280348c2-8728-4705-92da-8776d73cfc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89ba146-7fef-49e3-9a11-91eb7f720fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bef4c44-d3d5-4e0d-a734-eb2151d092f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468611e0-5d81-4c55-86bc-ca8e825ca1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8568dd9b-8843-479b-a827-384665cb13c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26dac256-1678-4bf4-bd2d-2ca0e7cc2585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd664873-0838-4057-92bd-69297b52bc29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edfdf225-7835-410d-b037-d4a62c9afe79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bd22172-c1a9-484c-86b2-1200f162f885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11d8ee0-9c2f-4af3-9055-4b3c26ea4ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab51d4b-d2ef-4860-b346-6c6ff24101f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1de4e1d-bb4a-4555-9dcf-68f3d5ae012e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66246a46-0a6b-4c9d-bb41-25e1c79cf5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a723bd0-aa95-4d0c-8475-5571f5e68e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 923b3016-b157-4157-883c-231babb8a234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62efb086-3fe7-487d-a7cd-72cf8b02bc49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9688699b-c3c4-4e41-9f9e-ca5459f2f0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224eb37a-f4b4-4ca5-bfc4-25fdbd673fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f5d955-9a4e-4393-8abc-e4e71baf84b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca928e41-ae20-4b13-9609-166a4fb1e5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d753823-1cd1-4399-b3ae-b7ccc311774f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bb33e2-e7fd-4246-806d-d9aa33c71545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c300ac-3e8d-4798-90d8-f5fa198e7135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d20fe338-b505-4e3e-85f3-07344cd3c0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775b660f-ada3-4c22-bf45-1368ce5881c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b646c144-93d9-47a1-93fb-cd99d110ebb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fcb5917-b723-4370-8031-c4469af56a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97d2829-3be9-45ad-bd75-c091a6f7c075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9b494e2-bc97-4016-a3fe-06c1d62c0a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4cb32a-42e0-4ade-9c55-7fa45eba585d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd0a086-b64b-4c19-84d9-41a62377a51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e70dc72-8e2f-4c17-a458-a577916d70bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e649eeea-3575-4b26-99a1-71e1ed499e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e841e6e8-ca6d-4583-933b-098a59b9eeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d6f951-634a-4d57-85e6-19564ff7cfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b78b0fc-12d9-4d4e-a886-a2f52ee5299a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d84929-6fe2-4762-b918-5d802b4a09a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685d9501-aed8-4266-94e3-4410ad84361c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00db05fb-ef70-4a7e-a199-93c624374789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8678b7d-9099-4d34-b918-7a420dc61e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e28f5c-47b7-42c8-b7c2-f317214e4e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d1897e2-cede-416b-9db3-028f0506da4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc46b94-8046-4ea6-bec2-c65d9c7d36e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee53aa1f-2340-4ba9-a35d-2806bd69734f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf117eea-d365-410a-bb7d-2b15a4dd3e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e854098-2510-43a9-b812-df7b8dc587da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23794484-1ba9-47f1-b344-22c127bc4471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f10ff5-030e-40c1-a3a7-9bbabaf3042f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d40e44f-13ff-4c12-9c74-b5ccc5d879cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74e791b-3dc8-44a4-b8f2-f0e31c4b9c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88806ab0-91fc-4cd3-a876-474074b72aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6389c7b5-51c0-4bdd-8421-91a86caed7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10cde2c-c65d-4555-87ab-d9874b11369f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9693c1-a277-4a5e-bdae-c3ed34f82698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103ccd0b-bfdb-4ecb-a2fa-4b8972d44559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d050e1bc-4be2-49a6-866f-1d174e2853bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d99b340d-e155-48ab-ad77-cd63f26f2059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057031c0-16d0-48e8-8b3d-f2e8f589aba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10c3a88e-c69e-41ce-9d26-c4629717a834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7dbae2b-0455-423c-b503-35534fe1b265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868dcc39-b432-4991-aa60-f74a24cbc759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baceb959-50a7-42be-bca5-ad00eafc9cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb911922-0f54-40c0-8805-edccf8da7e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac435f63-f35b-47a3-9a36-a78de9a0bec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14bd4ae-4caa-4c3d-a95a-71b264c3d5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65b30e88-8f93-4342-875f-7e0c6c4a0b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b341911-b10f-4317-a8ab-55e69eaabeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc1c9b3-859b-4a4b-90ec-17167175ee6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8887d5b-e415-4965-9fc5-59efb789c41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01d222bc-4ef4-4742-bb38-37f583723f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53cd2155-8c99-454a-ac6e-c5094b36fd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5660dc3-75c1-4635-9bda-eb72192fbdd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ecae89a-ef1f-4229-9758-64a94ecc99c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6246f6d1-d3ad-46fc-ad8e-c029169e22f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f4a142-62d8-4151-bfe7-aab208002f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06aad6b2-0341-4cd8-be4a-3d007b377bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c85bab0-9b9e-41a4-b184-8df3e3ffe396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e3caaa-7051-40d3-b406-b24e1d65c97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e735f9e4-082a-49e8-bd5c-c58624ec2ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506fbdfc-8040-4298-9bf6-861ed9218ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bcc3fe2-4a75-4700-bcfe-a02fc7bb1969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfa0e39-ca0a-4e5c-b0fc-1e2f41ce4112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f9fdce-8b19-45fb-8d1d-fdd0209d930b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14285fe-3487-45ad-b066-1a0163b54079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6802e98d-5358-4ec9-881a-b114fe7c8d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7108f1d5-56a5-4386-ac0b-bdbdffabb49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58837ff-7354-4c5e-a025-a47426d0f109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9dd1ba1-96b1-4a55-8475-90d6fd64155c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c62fdcd-e905-4d82-bcdb-102aa772795b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06962841-2a4c-4f51-a2c9-3173c3d61653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c516bc-ed08-4b3e-8a36-be65bb2e6045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54bb842-7321-4190-a87e-1e3213994e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15535d69-ca33-418c-a701-2318f2657dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43545adb-5043-4fff-848a-493e9c4e8cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c599035-754c-4fd3-8521-e8aa60874b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f07d7993-2747-44da-bf3d-6518f2ba08cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0fccb9e-7bcb-41c9-a6d7-16a5c0ba1e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5e24f9-b846-4f61-a53a-c5f8074ce9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2369c1-15b4-47e8-9a60-cb1a2357f778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac2351d5-ea84-4ec4-8a7f-fb290cd3605e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c49a71-08d5-48e1-8c1f-a6ad527d7d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782880bf-2ee7-4aad-bba3-bd0509bea9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc163e05-bdf3-416b-a4dd-c85a79085e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5409d6c-f80f-4f8b-a9f2-c3a76728e3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6316922-5adf-4c7b-957d-01c821a70c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e52399d-98e7-463a-8a03-6a05c4b303b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407b4b52-ca62-4b13-b24a-46cc1ec9ce7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bab5bb8d-a0c0-4a28-ba64-5c1295c6e8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a166c56-a32f-4164-983f-7452b05fac55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e762f779-52b5-4339-a423-746085452830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b01195-64cb-4b92-96d2-4cc0e4147c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084fba37-4e7f-45a3-944d-7df5c043bce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a0d041-b088-47cb-bd85-21bae69ecfe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8008813f-9628-4cba-99c1-b1c7d15bee8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d2c666-4899-42bf-9cf7-eba5f0af9fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505a7726-d12e-43d0-b123-8361ddafbeb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74cc896d-1dcc-4c16-a507-0fc05a7867ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4033cad-c1e5-4fcf-bac1-f3792954a933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb908bc-6140-4860-8bcf-6fd8c4ac3caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7404dd0a-7f9c-4c35-9e0e-a2490b6005e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9748a2ae-eae5-47bc-a0bc-10855c7ea147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b789d7c-f571-4a1c-a373-acddd66f5e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5a033f-d353-4b4d-9d65-4b6959f1206e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a983306-aa77-409c-96bf-a06b0a9393bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4717fa5-6719-49e8-be98-dedfc62e6d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d40e881-25c4-4ae3-9d69-226b009767e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5afe3970-6f23-4a2c-bf14-5e6b98c80351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097dc5eb-51c9-42a4-b110-5343dfb23713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17de048-2baf-43ae-9345-c55880399064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f475e1-7cbd-4720-aa63-7c96f1897e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9bb9b5-39e6-4225-be92-03784d94c457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050ba1d2-58da-4d62-862b-0929fdc42fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac19fdca-1d86-415a-bbc6-b76c08968fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04303aca-2997-4ecc-9e9a-a0991845a74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d403962-8715-44ad-8667-ee9f5554789d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0b800e6-512b-489d-aab4-6586bf6c86da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd78a886-c5cc-4e00-a289-f9b8dc50f9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438254d2-847c-43b4-a408-2298bf757aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda060ed-ae21-49a7-860c-858060ac3e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ff6625-9fe7-482c-b6ee-60af2a9c1377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf227b1a-aef4-41e0-bfd0-c703e10bdf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4a43ac-9e9b-4bdb-bd0e-5f63148f9f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8f757f-c58d-4f1f-a44f-9d347bd6f8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47db59e8-8e41-45cd-849a-dba856dab0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33dfb004-c21d-4d4f-b01b-42f4a57fd2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9dd599-fa9a-476e-84dc-3f4a5432c68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc7c752-ecd3-4c5f-a505-dd94c7377c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea38192-8bc8-443e-8ef1-94780d66149f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff7ca7e-846f-4908-9965-ec9f22482b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835e4c38-2c32-4181-837a-47aa3c9af64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21cbd5cd-6737-438e-a7da-b7ed507275f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bddd29f8-2e5a-4ef7-be0e-1959ee3ea334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c188ed6c-e5e0-44bc-b999-e92582690a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414a675b-11ee-4dd4-bd2b-705354903de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce751bd7-695f-41a6-a3e8-491873256457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b260f6ef-7564-422f-8fef-0419967f599b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22ca300-db45-4a22-b663-539d8f234127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9482c58a-4c6a-4a4f-bd37-fd21cd17bdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f1a287-6211-4c8b-9a0f-8242218fa100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b4e4d6-93c4-41d7-a504-4589a4d2f551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0c9c4f-2c19-4634-83ec-3f7e01914d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4987d9a-d75c-44c4-962b-180dd4f27804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05bb337e-b8b6-4246-aa23-83e0819a49bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bfcc12-6815-41af-9ce7-a311dc6f6fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44047985-454e-4091-b7bf-8661596223cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872f08fc-97e7-48ce-b3e5-9a609905e24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e321265e-7afc-405f-9a15-3d6fb61003e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3515726b-d7c9-4567-9334-ee259738d773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e754824-2b44-43fd-974a-5471d63836c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f02de28-738d-4b9f-b8bc-a05baf149c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1042fc-0463-46d6-8f77-c0663f173d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6c5825-cd64-4f50-ac47-fed862f013af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d439dcab-ca2b-4c07-995a-4455bba09c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3defc72b-f77e-4556-a07a-916ffe5107d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bc7fc2-6c39-4d86-8ece-94bf0db84ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a20c7b3c-069b-4a8c-901c-91be31dadee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdde128b-1435-45f2-8528-8cd68fd10001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068d1676-2f06-4981-9daf-5729154f0fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffbd4181-fc94-4d10-a5e6-48f859d589b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70838bb-8c97-4b76-b424-fc05c197a98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f66d79d4-395d-4b90-8c95-0b3549ea4b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1737dd80-4d95-4644-8ba8-4ebebc4b44f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa22bd5-bf44-457d-baa3-e2025020022a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79555c7a-25c0-47c1-8703-7d51c46869ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca516e6e-5f50-4552-ac16-e28f1135b591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cafa5c5-a8c1-4d2b-9e6d-67157850f950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a62742-5426-4134-ae72-a5d4c272fc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab6ea8b-0899-460f-9c1a-78249f50821c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b54ddc8-42c2-4846-a002-530b3b316a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebba052e-347b-4367-9488-7f3742c6b642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b630f8ec-d786-45e1-8f4a-fbb650f4629e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1751c0ba-69da-4967-98ea-80398421bd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef5c67f-c3af-4119-8d21-0f9a80caba7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8be25e3-142f-4933-b40d-150362c2d42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f31f06-c8fa-42e0-a7e7-18ce3ef50b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6adf7399-eb39-4399-8a3f-af6bc9956120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f1bb84f-8599-4643-baf0-f1ef96d0795a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c9e1c2-c393-446e-898c-cb8932e41273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7cf40b-8fa4-4d25-9553-3eda39b0db7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c2a60e-d745-4971-bc83-50f8dc87cb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f66512-dfb5-4fb5-93e7-e9ee2628b15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0448f19-384a-4247-b431-902cde352949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44edf82b-74ac-4f4f-b8a7-4703ea50fe2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ec2763-b706-4ce0-8b13-c4566b60f141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f9100d-79cb-4c04-9cd7-f21cb4670223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e3ebc4-7184-43e8-87de-d5e6289aa948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc868c9-6d82-4367-9564-1ba6598fe779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a6c987-bf27-4458-87f9-31873a045730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12fc02c1-dbb3-47c1-861a-0ae3dca791b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8badad9-0a5a-4998-bd0a-1dd0358f788c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc37785-516e-4149-9cf7-7a5caa717a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812a4976-7e05-4042-b369-dacd2c245da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c15b809-cf33-4e8d-8436-0bb8f1d202d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce1158d-ba95-4507-b0bc-7441757c5e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008109b0-e7ba-4fcf-9768-3e6f37030df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a456411-66b9-4ba8-8d96-0bd5f8d35c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b8b9d5-7f92-4a33-b126-bd671c9f0116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30c2a82-2e38-43d7-bac7-169a078973a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58836e5f-5cb5-4a40-a7c3-616d4b8291fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de8aa526-9466-4e3d-80e1-e2d1eca3e9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8069530c-a60d-4011-bef6-95735ca17633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c96858-4c20-4742-8632-29a4c96c9cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e48e782-988b-427f-b2d0-36f332d1425d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ea8563-0745-4a3b-b742-5de383b1d6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c10f3a6-5c62-4379-b0b4-572f13598c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0583c2ae-13a7-4edc-80d9-8db5c54446c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7aa7162-6efb-4eb9-b4bf-a32cd7508649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bd7f94-0a69-49ad-b448-4d6c1a5ddd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8223039-776c-46b1-9f00-02f02be56489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92067f9a-541e-4603-b7cf-84dc9dd56caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ae91d6-5e78-4cfd-b96b-0114a8017a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd61d9c2-6a11-4b6a-bf97-0e408b6c9996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb4cdd5-ad94-438b-8b32-365ef7f4c77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d0955e-2b59-4856-aa74-f34e5b552074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b11400-6cd9-4f08-9caa-5b30c86f8770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c7bdb5-122e-4b02-b861-8ce9dc616692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d844362-9755-44b4-bae7-2312bbddfb91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a43529-d234-4f7f-a1f6-f94a2573ef8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f898ad53-b048-408b-a9d6-a8f405c6c979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9195c80-66aa-41e7-b6c2-9e2fe4e0fc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95ba6fc1-0676-45f3-9f8a-a005c78e56cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a855ce97-13e2-40ef-87fe-409bf77761f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edad4499-6f20-425b-9b16-bfd0a5c4e2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1527800-2690-445b-860b-c6d5c24d2bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc3caab-ed06-4a43-a5e8-d967df7db500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd64bde8-dad2-4c0e-b3be-b2216f1d2eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1706ea7e-8005-4c1c-8aee-cbfb6f8b7125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57bd6dc5-83c7-4da4-8813-2b7d0616127f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5df70f59-3ff0-41c9-ac17-717b7c1555c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d831a5f9-4ebb-4715-82ad-2345ac1e5023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76959e8f-780e-421b-b801-7d94e88352d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0526477e-9850-4f3d-8495-05127819f902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 711fe04c-4db3-4b3c-acd1-d9a1ec3144fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39734e60-688e-4aca-b768-b9c38d5cb3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5da78251-fcdc-425a-8a42-0dfc024c93ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f28feb9-b46d-4b51-a695-819f4a1b7a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96845c87-0b53-4985-aa5d-06b57c5145d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b64a1e-99d3-497f-b506-e2a034b2b1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417e3746-a15f-4623-a632-3d71205f4871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e6efd09-985a-4ee5-b3d3-a6481fd2e70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c231c6ac-ef76-41b1-aee1-0ab2b2148f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8474186-1e05-4f8e-8eea-9f6bc2544221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321229a6-a2b7-4753-b92b-f4134afa3d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec162f6-8504-4b2c-af42-4460851b47cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da426bb1-89c0-4433-b26c-838d9a4621e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7be2385-1d6a-4868-8a22-e9fb90b7712a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb724a5b-a200-4eda-a19f-471241def7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb54449e-9f50-4953-a860-089030ae1f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a3fcee-74cf-4b10-b1dd-1092037766e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9971e8b5-5eff-41ce-9b6f-d4ca94fb2ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daeb3ec4-5f2e-4f54-b455-892e16cf9189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa44dcea-ba48-4ce6-a751-6c21d5f8a574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b52a80b-4fbf-426c-8023-7009ec8559d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f60c8d-7e29-43ff-80ba-7f08753eb8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1795616-3f6f-4c1a-a744-410743a97828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922f0877-804c-42d9-9cb1-87bb1e954140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c3371e-56e3-4759-9134-cc086e25c099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9555dac1-f437-4751-8e16-f6835d4f4901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8390f94-c3f3-4884-a14c-88861c4a3f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ed13c1-e6dd-4aa2-a8cd-2ce426834622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdcb8bee-4f23-45ba-a896-5900022e00af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606a99a1-07d3-4c3b-8121-8e0fe1b0842e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14f80d2-9e7b-4ecb-8f71-8bcc6f693556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4abb8d2-b771-4f64-8b7e-ceb2c8672b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52b2b1c-d299-42dd-8921-809b843b055d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993efded-ee70-4fdb-a3dc-0cfa6340f6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d19bc3-b0d7-4f57-a3f8-a7ae94dd379a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1388da-48b6-4e12-b37d-dd3b9bc73bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc06672-5e8a-40df-8256-51af00ed3334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f417a7ac-0bba-4a06-a42e-facfbb68377f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f030c1f5-33d5-4ae9-ad7f-3ccec22b87be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b34c816-aff8-48e1-99ce-698d0ba95b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40eded11-cf81-4b7d-9d4d-1af28bd958eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5f1652-e273-4d25-aade-346888dddf1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031f1315-ca87-43b9-8013-dae312fbd7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f5fd75-9554-4ba5-adf6-ab25cd8fea8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe22c99-10a6-4970-890d-5bfd81a3d70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732c0b9c-85c3-43f1-af8d-9b87a771ca84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7dbe0d-d13b-4023-81bb-b8c76de19db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8767c8-5192-4e4e-8bec-c39e9f42c481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4b258d-cc4e-4e0e-ac6a-d62deae07d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56693356-155d-4886-99fb-67231484dc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48d4f24-5b96-4bba-acc1-aad3f1b5eefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2108334e-2d94-4abb-bb60-f7324f80570f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38778e68-eb5c-48bc-a9ee-b527c11bfd8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d630f74d-8a23-40e9-b158-73ca1e9a1523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09537d0c-b7e6-4f00-88b0-42d44dd90b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cffc19e-a342-4ffb-843f-9b8d2ce641e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ca2015-de10-4543-9be2-ec1011fcb5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5522c1c0-4d63-4a95-86e8-30d9e8a2cc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33241a5-4f52-4a8a-be0e-d7845aa89c0a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(3836, 24), y=(3836,)
   Test:  X=(959, 24), y=(959,)

⚠️  Limiting training data: 3836 → 800 samples
⚠️  Limiting test data: 959 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1746, val=0.0812 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0857, val=0.0797 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0801, val=0.0784 (↓), lr=0.001000
   • Epoch   4/100: train=0.0796, val=0.0783, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0794, val=0.0784, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0772, val=0.0799, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 1 Summary - Client client_16
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0038
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0038
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2387, R²: 0.0023

📊 Round 1 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2386, R²: -0.0013

============================================================
🔄 Round 4 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0775 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0804, val=0.0769 (↓), lr=0.000250
   • Epoch   3/100: train=0.0803, val=0.0766, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0802, val=0.0767, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0801, val=0.0766, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0799, val=0.0764, patience=2/15, lr=0.000250
   • Epoch  21/100: train=0.0795, val=0.0762, patience=12/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 4 Summary - Client client_16
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0055
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0220
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2387, R²: 0.0009

============================================================
🔄 Round 7 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0879 (↓), lr=0.000250
   • Epoch   2/100: train=0.0772, val=0.0885, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0768, val=0.0892, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0766, val=0.0899, patience=3/15, lr=0.000250
   📉 Epoch 5: LR reduced 0.000250 → 0.000125
   • Epoch   5/100: train=0.0764, val=0.0904, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0759, val=0.0913, patience=10/15, lr=0.000125
   📉 Epoch 13: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 7 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0033
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0136
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2382, R²: 0.0051

============================================================
🔄 Round 9 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0793 (↓), lr=0.000063
   • Epoch   2/100: train=0.0790, val=0.0793, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0788, val=0.0793, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0788, val=0.0793, patience=3/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0787, val=0.0792, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0786, val=0.0792, patience=10/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 9 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0016
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0001
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2381, R²: 0.0061

============================================================
🔄 Round 11 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0818 (↓), lr=0.000016
   • Epoch   2/100: train=0.0793, val=0.0816, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0792, val=0.0814, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0791, val=0.0813 (↓), lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0791, val=0.0812, patience=1/15, lr=0.000008
   • Epoch  11/100: train=0.0790, val=0.0810, patience=7/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 11 Summary - Client client_16
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0030
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0125
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2381, R²: 0.0064

============================================================
🔄 Round 13 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0734 (↓), lr=0.000004
   • Epoch   2/100: train=0.0814, val=0.0733, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0813, val=0.0732, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0813, val=0.0731, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0813, val=0.0731, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0811, val=0.0727, patience=2/15, lr=0.000004
   • Epoch  21/100: train=0.0810, val=0.0724, patience=12/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 13 Summary - Client client_16
   Epochs: 24/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0005
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0141
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

📊 Round 13 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0055

============================================================
🔄 Round 16 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0818 (↓), lr=0.000004
   • Epoch   2/100: train=0.0794, val=0.0817, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0793, val=0.0817, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0793, val=0.0817, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0792, val=0.0816, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0790, val=0.0815, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 16 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0075
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0001
============================================================


============================================================
🔄 Round 17 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 17 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0093
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0012
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0053

============================================================
🔄 Round 18 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 18 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0005
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0489
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0053

============================================================
🔄 Round 21 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 21 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0095
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0035
============================================================


============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0090
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0026
============================================================


============================================================
🔄 Round 24 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 24 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0006
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0549
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0054

============================================================
🔄 Round 26 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 26 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0033
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0215
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0055

============================================================
🔄 Round 28 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 28 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0032
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0291
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0055

============================================================
🔄 Round 31 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 31 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0036
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0191
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0055

📊 Round 31 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0055

============================================================
🔄 Round 33 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 33 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0029
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0244
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0055

============================================================
🔄 Round 34 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 34 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0053
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0104
============================================================


============================================================
🔄 Round 35 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 35 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0088
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0018
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0056

============================================================
🔄 Round 36 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 36 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0041
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0284
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0056

============================================================
🔄 Round 38 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 38 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0012
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0374
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0056

============================================================
🔄 Round 40 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 40 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=-0.0008
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0460
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0056

============================================================
🔄 Round 46 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 46 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0140
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0100
============================================================


============================================================
🔄 Round 47 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 47 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0016
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0589
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 47 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 50 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 50 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0109
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0020
============================================================


============================================================
🔄 Round 51 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 51 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0071
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0000
============================================================


============================================================
🔄 Round 52 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 52 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0036
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0180
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

📊 Round 52 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 54 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 54 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0132
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0026
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

📊 Round 54 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0079
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0027
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 60 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 60 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0043
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0128
============================================================


============================================================
🔄 Round 61 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 61 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0124
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0044
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 62 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 62 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0099
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0085
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 63 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 63 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0051
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0059
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 64 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 64 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0044
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0108
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

📊 Round 64 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

📊 Round 64 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 67 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 67 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0077
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0045
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

📊 Round 67 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0058

============================================================
🔄 Round 69 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 69 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0049
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0101
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 69 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 69 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 73 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 73 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0044
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0072
============================================================


============================================================
🔄 Round 74 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 74 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0038
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0137
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 74 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 74 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 83 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 83 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0090
   Val:   Loss=0.0680, RMSE=0.2607, R²=-0.0034
============================================================


============================================================
🔄 Round 85 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 85 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0169
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0044
============================================================


============================================================
🔄 Round 87 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 87 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0132
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 88 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 88 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0082
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0087
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 88 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 90 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 90 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0093
   Val:   Loss=0.0744, RMSE=0.2729, R²=-0.0039
============================================================


============================================================
🔄 Round 94 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 94 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0127
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0007
============================================================


============================================================
🔄 Round 95 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 95 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0078
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0050
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 97 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 97 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0018
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0302
============================================================


============================================================
🔄 Round 100 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 100 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0021
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0651
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 100 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 104 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 104 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0018
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0162
============================================================


============================================================
🔄 Round 105 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 105 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0037
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0101
============================================================


============================================================
🔄 Round 106 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 106 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0016
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0210
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 106 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

============================================================
🔄 Round 110 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 110 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0054
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0060
============================================================


============================================================
🔄 Round 113 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 113 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0412
============================================================


============================================================
🔄 Round 116 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 116 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0063
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0163
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

📊 Round 116 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

📊 Round 116 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 116 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

============================================================
🔄 Round 123 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 123 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0058
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0035
============================================================


============================================================
🔄 Round 125 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 125 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0030
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0105
============================================================


============================================================
🔄 Round 126 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 126 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0049
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0030
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

============================================================
🔄 Round 131 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 131 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0048
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0033
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

📊 Round 131 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

📊 Round 131 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 135 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 135 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=-0.0035
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0260
============================================================


============================================================
🔄 Round 136 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 136 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0067
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0016
============================================================


============================================================
🔄 Round 137 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 137 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0068
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0029
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 138 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 138 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0024
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0148
============================================================


============================================================
🔄 Round 139 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 139 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0000
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0351
============================================================


============================================================
🔄 Round 140 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 140 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0050
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0051
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 140 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 145 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 145 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=-0.0037
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0088
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 145 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 151 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 151 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0017
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0271
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

============================================================
🔄 Round 152 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 152 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0023
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0157
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

============================================================
🔄 Round 155 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 155 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0040
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0086
============================================================


============================================================
🔄 Round 156 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 156 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0088
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0087
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 162 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 162 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0060
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0018
============================================================


============================================================
🔄 Round 163 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 163 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0065
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0032
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 165 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 165 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0071
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0004
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 165 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 165 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

📊 Round 165 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 171 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 171 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0007
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0520
============================================================


============================================================
🔄 Round 172 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 172 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0010
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0253
============================================================


============================================================
🔄 Round 173 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 173 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0007
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0476
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 174 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 174 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0057
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0012
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 175 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 175 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0070
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0052
============================================================


============================================================
🔄 Round 176 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 176 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0014
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0201
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 177 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 177 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0071
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0054
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 178 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 178 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0069
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0039
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0059

============================================================
🔄 Round 179 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 179 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0045
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0036
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0060

📊 Round 179 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 181 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 181 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0095
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0111
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 183 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 183 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0001
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0352
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 185 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 185 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0109
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0065
============================================================


============================================================
🔄 Round 186 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 186 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0042
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0056
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 187 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 187 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0016
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0333
============================================================


============================================================
🔄 Round 188 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 188 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0057
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0017
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 188 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 190 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 190 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0066
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0014
============================================================


============================================================
🔄 Round 191 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 191 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0041
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0051
============================================================


============================================================
🔄 Round 192 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 192 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0028
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0213
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 193 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 193 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0054
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0014
============================================================


============================================================
🔄 Round 194 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 194 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0036
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0070
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 197 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 197 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0064
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0059
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 198 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 198 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=-0.0030
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0239
============================================================


============================================================
🔄 Round 199 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 199 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0007
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0212
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 201 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 201 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0017
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0164
============================================================


============================================================
🔄 Round 203 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 203 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0076
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0082
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 204 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 204 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0063
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0030
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 204 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 204 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 214 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 214 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0081
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0040
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 216 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 216 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0046
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0025
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 216 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 216 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 216 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 221 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 221 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0007
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0273
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 223 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 223 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0095
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0079
============================================================


============================================================
🔄 Round 224 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 224 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0017
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0173
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 224 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 226 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 226 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=-0.0011
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0184
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 227 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 227 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0018
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0139
============================================================


============================================================
🔄 Round 228 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 228 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0057
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0024
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 229 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 229 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0043
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0036
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 230 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 230 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0026
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0122
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 233 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 233 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0077
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0091
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 234 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 234 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0021
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0179
============================================================


============================================================
🔄 Round 235 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 235 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0026
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0121
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 236 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 236 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0006
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0197
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 239 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 239 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0044
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0022
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 240 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 240 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0034
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0075
============================================================


============================================================
🔄 Round 242 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 242 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0059
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0012
============================================================


============================================================
🔄 Round 243 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 243 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0051
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0004
============================================================


============================================================
🔄 Round 244 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 244 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0032
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0100
============================================================


============================================================
🔄 Round 248 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 248 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0038
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0041
============================================================


============================================================
🔄 Round 249 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 249 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0037
   Val:   Loss=0.0799, RMSE=0.2828, R²=-0.0066
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 250 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 250 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0006
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0280
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 253 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 253 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0067
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0080
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

============================================================
🔄 Round 255 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 255 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0062
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0007
============================================================


============================================================
🔄 Round 256 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 256 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0082
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0088
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0060

📊 Round 256 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 261 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 261 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0047
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0054
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 262 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 262 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0044
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0021
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 265 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 265 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0061
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0033
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 269 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 269 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0063
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0016
============================================================


============================================================
🔄 Round 271 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 271 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0054
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0017
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 272 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 272 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0033
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0071
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 273 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 273 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0022
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0225
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 275 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 275 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0011
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0267
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 276 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 276 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0028
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0200
============================================================


============================================================
🔄 Round 277 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 277 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0064
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0058
============================================================


============================================================
🔄 Round 278 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 278 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=-0.0007
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0194
============================================================


============================================================
🔄 Round 279 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 279 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0081
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0052
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 279 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 290 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 290 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0024
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0244
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 292 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 292 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0012
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0155
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 292 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 298 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 298 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0015
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0147
============================================================


============================================================
🔄 Round 299 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 299 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0064
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0050
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 300 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 300 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0139
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0129
============================================================


============================================================
🔄 Round 301 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 301 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0035
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0056
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 301 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 303 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 303 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0071
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0017
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 303 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 308 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 308 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0005
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0187
============================================================


============================================================
🔄 Round 311 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 311 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0057
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0004
============================================================


============================================================
🔄 Round 312 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 312 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0070
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0010
============================================================


============================================================
🔄 Round 317 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 317 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0078
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0074
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 318 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 318 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0022
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0102
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 320 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 320 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0081
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0096
============================================================


============================================================
🔄 Round 324 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 324 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0056
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0019
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 327 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 327 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0019
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0724
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 329 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 329 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0149
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0037
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 330 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 330 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0037
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0037
============================================================


============================================================
🔄 Round 331 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 331 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0014
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0142
============================================================


============================================================
🔄 Round 333 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 333 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0064
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0011
============================================================


============================================================
🔄 Round 335 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 335 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0033
   Val:   Loss=0.0673, RMSE=0.2594, R²=-0.0052
============================================================


============================================================
🔄 Round 336 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 336 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0006
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0257
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 336 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 336 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 336 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 341 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 341 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0061
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0050
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 343 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 343 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0167
============================================================


============================================================
🔄 Round 344 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 344 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0033
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0051
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 346 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 346 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0050
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0028
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 346 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 346 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 346 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 346 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 353 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 353 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0065
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0006
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 356 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 356 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0049
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0004
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 359 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 359 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0001
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0413
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 359 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 362 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 362 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0026
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0075
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 362 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 362 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 362 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 367 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 367 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=-0.0061
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0054
============================================================


============================================================
🔄 Round 368 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 368 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0072
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0085
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 368 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 371 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 371 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0083
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0045
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 371 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 371 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 374 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 374 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0085
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0012
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 379 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 379 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0018
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0227
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 379 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 379 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 383 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 383 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0030
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0220
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 383 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 383 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 383 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 388 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 388 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0064
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0069
============================================================


============================================================
🔄 Round 389 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 389 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0037
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0040
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 391 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 391 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0305
============================================================


============================================================
🔄 Round 393 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 393 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0010
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0136
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 394 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 394 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0040
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0018
============================================================


============================================================
🔄 Round 403 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 403 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0199
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 403 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 403 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 410 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 410 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0064
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0064
============================================================


============================================================
🔄 Round 411 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 411 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0069
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0006
============================================================


============================================================
🔄 Round 412 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 412 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0070
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0095
============================================================


============================================================
🔄 Round 413 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 413 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0004
   Val:   Loss=0.0974, RMSE=0.3122, R²=-0.0376
============================================================


============================================================
🔄 Round 414 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 414 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0101
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0144
============================================================


============================================================
🔄 Round 415 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 415 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0083
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0012
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 418 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 418 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0034
   Val:   Loss=0.0689, RMSE=0.2625, R²=-0.0048
============================================================


============================================================
🔄 Round 420 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 420 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0061
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0008
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 420 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 420 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 420 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 420 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 427 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 427 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0030
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0061
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 428 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 428 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0171
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 429 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 429 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0001
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0350
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 430 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 430 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0050
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0011
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 430 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 432 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 432 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0020
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0172
============================================================


============================================================
🔄 Round 433 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 433 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0065
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0004
============================================================


============================================================
🔄 Round 434 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 434 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0066
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0050
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 435 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 435 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0059
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0029
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 436 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 436 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0110
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0035
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 436 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 439 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 439 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0054
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0039
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 439 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 441 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 441 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0025
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0082
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 445 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 445 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0063
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0041
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 447 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 447 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0022
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0095
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 447 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 451 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 451 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0027
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0099
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 451 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 451 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 457 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 457 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0030
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0096
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 459 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 459 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0006
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0394
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 459 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 466 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 466 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0039
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0033
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 466 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 466 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 470 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 470 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0025
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0093
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 472 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 472 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0056
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0040
============================================================


============================================================
🔄 Round 473 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 473 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0019
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0109
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 473 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 479 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 479 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0054
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0756
============================================================


============================================================
🔄 Round 481 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 481 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0036
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0032
============================================================


============================================================
🔄 Round 482 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 482 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0008
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0148
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 484 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 484 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0094
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0015
============================================================


============================================================
🔄 Round 485 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 485 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0057
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0022
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 490 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 490 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0033
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0082
============================================================


============================================================
🔄 Round 491 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 491 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0001
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0485
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 491 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

============================================================
🔄 Round 494 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 494 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0038
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0019
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0059

📊 Round 494 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 502 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 502 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0051
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0023
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 506 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 506 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0063
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0059
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 506 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 514 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 514 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0007
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0323
============================================================


============================================================
🔄 Round 515 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 515 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0012
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0129
============================================================


============================================================
🔄 Round 516 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 516 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0070
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0042
============================================================


============================================================
🔄 Round 519 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 519 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0023
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0336
============================================================


============================================================
🔄 Round 522 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 522 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0076
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0135
============================================================


============================================================
🔄 Round 523 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 523 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0048
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0030
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 524 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 524 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0036
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0047
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 524 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 526 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 526 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0005
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0186
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 527 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 527 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0078
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0036
============================================================


============================================================
🔄 Round 528 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 528 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=-0.0044
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0019
============================================================


============================================================
🔄 Round 529 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 529 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0050
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0017
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 530 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 530 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0054
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0033
============================================================


============================================================
🔄 Round 534 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 534 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0054
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0040
============================================================


============================================================
🔄 Round 536 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 536 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0017
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0110
============================================================


============================================================
🔄 Round 539 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 539 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0037
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0105
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 539 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 539 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 539 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 539 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 550 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 550 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0002
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0304
============================================================


============================================================
🔄 Round 551 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 551 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0046
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0005
============================================================


============================================================
🔄 Round 555 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 555 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0004
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0278
============================================================


============================================================
🔄 Round 559 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 559 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0025
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0151
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 562 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 562 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0027
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0074
============================================================


============================================================
🔄 Round 564 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 564 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0002
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0329
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 567 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 567 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0006
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0262
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 567 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 570 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 570 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0038
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0025
============================================================


============================================================
🔄 Round 573 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 573 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0010
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0678
============================================================


============================================================
🔄 Round 574 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 574 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0013
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0137
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 577 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 577 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0021
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0137
============================================================


============================================================
🔄 Round 578 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 578 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0053
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0025
============================================================


============================================================
🔄 Round 580 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 580 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0058
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0016
============================================================


============================================================
🔄 Round 583 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 583 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0034
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0081
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 583 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 586 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 586 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0065
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0059
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 590 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 590 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0027
   Val:   Loss=0.0660, RMSE=0.2568, R²=-0.0166
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 595 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 595 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0018
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0097
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 595 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 599 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 599 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0017
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0123
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 599 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 603 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 603 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0027
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0082
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 603 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 605 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 605 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0046
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0001
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

📊 Round 605 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 609 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 609 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0020
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0120
============================================================


============================================================
🔄 Round 611 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 611 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0027
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0163
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 613 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 613 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0020
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0101
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 613 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 613 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 621 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 621 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0022
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0083
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 621 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 624 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 624 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=-0.0031
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0106
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 627 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 627 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0023
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0097
============================================================


============================================================
🔄 Round 628 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 628 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0061
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0043
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 630 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 630 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0016
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0123
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 632 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 632 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0068
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0059
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 636 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 636 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0075
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0089
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 640 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 640 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0058
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0053
============================================================


============================================================
🔄 Round 641 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 641 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0048
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0015
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 644 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 644 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0013
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0171
============================================================


============================================================
🔄 Round 646 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 646 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0022
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0086
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 648 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 648 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0007
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0166
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 651 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 651 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0014
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0401
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 651 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 651 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 659 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 659 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0028
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0060
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 661 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 661 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0053
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0040
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 663 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 663 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0089
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0062
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 670 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 670 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0043
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0042
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 670 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 670 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 670 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 670 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 680 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 680 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0053
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0035
============================================================


============================================================
🔄 Round 682 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 682 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0022
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0081
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 683 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 683 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0043
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0021
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 684 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 684 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0028
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0078
============================================================


============================================================
🔄 Round 690 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 690 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0037
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0039
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 691 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 691 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0047
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0001
============================================================


============================================================
🔄 Round 692 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 692 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0027
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0066
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 693 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 693 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0047
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0019
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 695 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 695 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0108
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0038
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 696 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 696 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0003
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0192
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 696 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 696 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 700 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 700 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0023
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0089
============================================================


============================================================
🔄 Round 701 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 701 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0054
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0043
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 701 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0058

============================================================
🔄 Round 703 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 703 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0048
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0005
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 703 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 709 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 709 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0031
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0044
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 710 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 710 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0069
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0039
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 711 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 711 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0008
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0340
============================================================


============================================================
🔄 Round 712 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 712 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0002
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0177
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 712 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 715 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 715 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0012
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0113
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 718 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 718 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0078
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0038
============================================================


============================================================
🔄 Round 720 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 720 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0050
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0016
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 724 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 724 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0011
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0140
============================================================


============================================================
🔄 Round 725 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 725 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0001
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0260
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 725 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 725 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 730 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 730 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0026
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0095
============================================================


============================================================
🔄 Round 732 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 732 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0024
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0380
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 735 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 735 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0039
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0011
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 735 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 740 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 740 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0002
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0183
============================================================


============================================================
🔄 Round 742 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 742 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0066
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0069
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 746 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 746 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0001
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0286
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 749 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 749 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0010
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0127
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 750 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 750 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0017
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0107
============================================================


============================================================
🔄 Round 751 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 751 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0073
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0047
============================================================


============================================================
🔄 Round 752 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 752 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0041
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0019
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 752 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 752 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 755 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 755 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0016
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0299
============================================================


============================================================
🔄 Round 757 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 757 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0080
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0039
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 757 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 757 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 760 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 760 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0048
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0008
============================================================


============================================================
🔄 Round 762 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 762 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0010
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0258
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 764 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 764 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0064
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0067
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 764 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 766 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 766 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0088
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0076
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 766 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 768 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 768 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0011
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0276
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 768 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 772 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 772 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0016
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0147
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 772 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 776 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 776 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0062
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0069
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 776 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 779 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 779 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0003
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0162
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

📊 Round 779 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 781 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 781 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0026
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0067
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 782 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 782 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0029
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0059
============================================================


============================================================
🔄 Round 784 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 784 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0070
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0004
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 784 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 786 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 786 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0025
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0070
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 787 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 787 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=-0.0125
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0012
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 788 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 788 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0045
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0010
============================================================


============================================================
🔄 Round 794 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 794 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0077
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0046
============================================================


============================================================
🔄 Round 796 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 796 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0052
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0042
============================================================


============================================================
🔄 Round 797 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 797 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0018
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0279
============================================================


============================================================
🔄 Round 798 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 798 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0017
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0396
============================================================


============================================================
🔄 Round 799 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 799 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0064
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0040
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2381, R²: 0.0057

============================================================
🔄 Round 800 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 800 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0014
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0331
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 807 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 807 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0031
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0042
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 808 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 808 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0073
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0025
============================================================


============================================================
🔄 Round 809 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 809 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0026
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0067
============================================================


📊 Round 809 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 813 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 813 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0068
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0101
============================================================


📊 Round 813 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 817 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 817 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0006
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0209
============================================================


📊 Round 817 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 819 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 819 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0011
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0774
============================================================


📊 Round 819 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 823 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 823 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0043
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0079
============================================================


📊 Round 823 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 824 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 824 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0031
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0365
============================================================


============================================================
🔄 Round 825 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 825 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0025
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0074
============================================================


📊 Round 825 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 829 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 829 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0011
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0621
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 836 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 836 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0037
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0022
============================================================


📊 Round 836 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 837 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 837 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0025
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0071
============================================================


============================================================
🔄 Round 839 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 839 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0000
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0277
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 841 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 841 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0026
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0064
============================================================


📊 Round 841 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 841 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 841 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 841 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 841 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 841 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 850 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 850 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0016
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0194
============================================================


============================================================
🔄 Round 851 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 851 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0044
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0013
============================================================


📊 Round 851 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 851 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 851 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 862 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 862 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0052
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0009
============================================================


============================================================
🔄 Round 864 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 864 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0063
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0181
============================================================


============================================================
🔄 Round 865 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 865 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0021
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0168
============================================================


============================================================
🔄 Round 866 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 866 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0038
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0021
============================================================


📊 Round 866 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 867 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 867 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0031
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0044
============================================================


============================================================
🔄 Round 869 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 869 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0001
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0299
============================================================


📊 Round 869 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 871 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 871 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0013
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0402
============================================================


============================================================
🔄 Round 872 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 872 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0006
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0206
============================================================


============================================================
🔄 Round 873 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 873 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0104
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0028
============================================================


============================================================
🔄 Round 874 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 874 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0008
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0171
============================================================


============================================================
🔄 Round 876 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 876 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0002
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0168
============================================================


📊 Round 876 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 876 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 878 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 878 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0050
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0022
============================================================


📊 Round 878 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 878 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 878 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 881 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 881 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0018
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0104
============================================================


📊 Round 881 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 881 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 884 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 884 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0006
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0157
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 888 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 888 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0028
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0048
============================================================


📊 Round 888 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 888 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 894 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 894 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0034
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0029
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 898 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 898 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0027
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0055
============================================================


📊 Round 898 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 900 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 900 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0250
============================================================


📊 Round 900 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 901 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 901 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0020
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0078
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 902 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 902 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0050
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0009
============================================================


============================================================
🔄 Round 903 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 903 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0101
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0001
============================================================


============================================================
🔄 Round 904 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 904 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0029
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0043
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 904 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 909 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 909 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0043
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0068
============================================================


============================================================
🔄 Round 910 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 910 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0008
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0299
============================================================


============================================================
🔄 Round 911 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 911 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0066
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0036
============================================================


📊 Round 911 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 911 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 911 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 915 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 915 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0009
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0140
============================================================


📊 Round 915 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 919 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 919 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0011
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0150
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 922 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 922 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0019
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0145
============================================================


============================================================
🔄 Round 923 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 923 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0161
============================================================


📊 Round 923 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 925 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 925 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0043
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0007
============================================================


📊 Round 925 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 932 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 932 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0037
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0014
============================================================


📊 Round 932 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 932 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 932 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 932 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 936 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 936 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0013
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0176
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 937 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 937 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0005
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0309
============================================================


============================================================
🔄 Round 938 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 938 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0019
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0178
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

📊 Round 938 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 941 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 941 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0003
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0454
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 942 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 942 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0010
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0437
============================================================


📊 Round 942 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 943 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 943 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0023
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0089
============================================================


📊 Round 943 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2380, R²: 0.0057

============================================================
🔄 Round 947 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 947 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0056
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0058
============================================================


============================================================
🔄 Round 948 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 948 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0035
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0036
============================================================


❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
