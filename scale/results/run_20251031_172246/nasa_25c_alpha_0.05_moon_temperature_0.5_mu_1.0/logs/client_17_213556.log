[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7aebad9-0783-4a69-a425-9dbe2201fb68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ce519c-ff2c-4aa7-8393-8e0fe9d41b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd11e52-149e-496c-b5e4-9ab378cf08cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783436bd-9124-4462-aa03-43df4c2d9932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e034d3-7e42-4de1-9a55-65c193bc395c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5dbaa6-b4c8-44a6-825f-256fd70190d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8c05fb-331a-4331-be46-0ab12ed2e098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00ec3bf-1f2c-4670-a63a-604279216e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e911268-e852-451c-b194-177f28c7ee9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d7cc64-6263-4584-ac80-60c1d100beeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199e1f1e-3d89-4858-8178-ea36057d0d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5303f5cc-2fd2-4c6e-8fdd-cd27847d655a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff3274a-5910-4b38-b472-0c6f27c2a153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce683d97-d6bc-4a25-a4eb-d042405a355a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 035d9fce-a107-4440-95cb-1d1d17689d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e225c297-acde-4d7c-b7fe-cba318835d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7afba5af-217a-4b69-af88-c399134d32bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f40df3-ca31-4bba-9822-98a6676f94ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f053c1-1f14-4878-b2f9-a559b2876abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08d3f064-b080-4f5b-9e41-6075f49d3c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d93721-dc5c-4da2-9892-31e250183aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfea75b2-00d6-4fb9-b03d-b4823903f849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3abc06-1211-4c74-8aee-550f2f8a7331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5dd056-6b50-4ceb-9bc1-f99594c3ebf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7274fa3-5f86-4588-afb8-e8aa96e72937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7181a8e9-71da-4f19-8983-694947e5ccc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0f8600-d6fa-49a4-aad6-0a3eaffd3d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b3782d-b1a7-4397-b136-5633638d7c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76feb1e-be8e-4d78-b372-753d5c005521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5dcee37-3c34-410f-9776-423284161363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6920458-293c-45db-9f3e-c062573ed315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05aa3af-64cb-4b2f-a9fa-0510050594c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a020a4e-2652-4aa0-a0c0-af57448e3c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d46682a3-5339-4e31-a3c9-f4f84468403d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93fc653-3b7c-40d5-abb5-9d7bddb3c9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2560997f-92fd-4447-94fb-a0471240cb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1056cb14-dd3f-4c50-a1fc-72fc91a719b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62932b18-a3ad-421b-9817-05b448dfe183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2028674d-2682-41c3-ac6c-e99748d45beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6b638bb-3824-4b30-b3b9-265ebb036cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2838e1b8-234a-4ec5-b86c-23630cfec8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda74b58-a83b-40f8-98df-3f1c22b69676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa4b311-c645-4605-a619-66b81f9eb3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc6d5255-1b81-43df-83b7-9c01e654c04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0f173f-6712-4a7c-914a-4b707f5987d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cbfdb49-8d5a-4412-9b7f-a54312372fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08bc03bd-6e20-4297-90e8-10e39ffaa8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6aa5ae1-98bb-433a-bfd7-2126b87c8190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd92952-68ee-4a69-bb70-de2bc4ad9a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d886de7-76f6-4eb0-b108-db634c671267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5246c8-d099-4323-ba4e-f967f80961c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8703b13f-838e-44b3-858d-4bdff5baa46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9823361-03b3-41a7-a640-1118a339b66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1d46747-619a-411f-896e-8a30c7c7b09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f5fe53-2173-41f8-a28f-678cee82c524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b22d413-0c99-4351-bec1-a6dce2b8509e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70018363-a4d2-497d-a618-cf6126175897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e970340-bd44-4180-a4fa-cb6d114b1061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c8a8fb-46e1-481d-bf60-d7f8405130c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26506f0b-681d-4dd8-901f-ec0d075e2229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8735b3f2-8c90-490a-bc56-3da5fec3b0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff94be4-e46a-4437-90ac-64ccc291fe73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cbe34f-7f7f-4cb9-933b-9dc2e44a0d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e611f6b-26d4-4203-a1ad-ca79a399efc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5736c160-9bb3-45e0-8e91-0c5cd451cb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c070f3f-1b14-490d-af2a-71b34ab444cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b15704c-aec9-4cef-8619-8085748531ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce7f8553-4efd-4dd9-8f3f-79c90b421365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21f063b-d4d6-4d3f-a37a-5b588a889532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da5ef32-78e7-47b9-a696-f6250bfc448a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81c4e65-f5af-410e-8406-6249edd76e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964faf38-a6cb-4e90-b011-9d2f76b04dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea67c2f-6677-43b9-9e5b-e868e66058b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 374d8eb8-c710-4859-9b6e-31fbd4849d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980e0388-0ecb-4f85-a6f3-282f168e6aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a650d57a-2d5e-4b5f-8054-a3c78f8ec542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d40d72-ce9b-48db-8647-4fd1c6876e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d19d9e-ea62-4002-8e8d-8ea92fb15881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef4c565-909f-4177-9402-f8e5f0f717da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f52c6e-1f7d-4c49-a43b-79026d03eb04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b4915a-ebe6-46d1-b623-5be77f652ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8741c6c9-66c4-4b5d-95ce-c2c7eb27fad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f18e9a8-ee66-40a3-b3ae-7faf6a316d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2a1f88-9613-4903-9bf3-8925410bfdaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9863e322-0eab-4688-8bf7-026f6b7fc74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16760fb4-c06e-45ee-ac45-a8142c25724d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd694c12-1ae3-44c8-a36f-b2a6f0e7a2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0229d0-1ffd-414a-878f-7940cda2447c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d2afb7-a95b-4633-914b-a3481776730b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea60612-18ad-4bc9-816d-bcd0246391af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc844f4-df0d-42f7-83a3-5eb44b352803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78420368-3006-4f79-8e76-9460db366d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eba806c-6eeb-4613-a4f0-be2a8bd3c8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 817c6de4-d51b-4e9b-9bb9-dba2827e2033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92c1e93b-d86f-4b6e-973d-0afdb56ab531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56068e1a-0f43-44fa-bfed-532109b2eb04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a725f528-d0cf-4405-81d5-9fb4dd1a5eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3f0290-baba-4b40-95e1-cbdae9dd5407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 977d3ebf-f441-40c9-b7c8-67d6011cd790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0008b369-0729-4ddc-98d0-fe5ad99b4c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0376c89-a3b4-498d-bc25-52f5920e7450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66dd7ff6-7f5e-45e0-8e32-e1a326874e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5e471b-c7fd-47be-9a7b-aca726327635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e75cc3-09e0-476e-8639-2575e7230e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18527167-8a41-4574-8f03-4a8628455315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8881d11-f4c8-4040-866d-f2fd72e7723c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2269b0b-9c55-4583-a582-0bb04ff66951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec268b0-78ea-46cf-b8e1-6f74db7b82d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6219ecd2-71fa-4fc0-b6a2-2258ae93d35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50c1d9ba-680b-4a11-a78e-602cb179c499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef2f2c0-8732-4366-9a47-08aeae31be01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b65ca0-2b0d-4db3-b4f4-d4455ecd352a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456d4112-92e7-4255-a4fa-736108588044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e9af26-777d-4d02-9e6f-2b61d21bf723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c23262-8e2b-49b1-8d20-9145b95d576f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9efb7a2-f284-48c7-a4a3-57f202fba4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca27b74-3403-4e5e-b620-bc7acb3e0fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b152bd34-6c66-46e6-a60c-d4dc78c6cf35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881cf81b-cd71-4b8d-bb73-c75795960b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ef5055-67d6-4ce5-8305-a7d7b4638994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237669cc-a924-4c8e-b421-f304afc85334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c288b7-b29a-402e-83c1-debca67685e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49fe37f-9f13-4a06-bfb1-f97d36d103e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02aa6dd-c2a5-4d1c-af2e-14701ff4e3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff5ec3d-df9b-44be-b2e6-84eda24b564f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5502c10c-6755-41c3-86c8-435ef760a3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9921b16-1e3b-453d-8881-834ba10ce1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac79f6c6-2bc6-4cb3-954d-404e53e90db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919eca9c-cf13-402b-b4d0-c7622e54af86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2909f4-213d-4939-a4d7-434e8b0ed84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84addca1-fa22-4572-bbbc-1e151dc87e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4790b262-07d8-4da4-85b2-40f79260bab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb27bfd-4052-42c5-a0ca-d9c66a6bec50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65af458-9574-429f-96fd-9dd71e9df02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e212869f-72b5-4dba-9131-c1ee9ec1ffed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d80884-b217-4dfb-83ae-a5e92472e968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce981d2-95d0-4ca4-b6e3-8ec3b0b93b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c910a0fe-dbd7-4b4d-bff3-06e090c32b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993db383-eb3d-4567-8093-04057ee3157d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28be0468-9a39-4124-bd73-4b4f07649c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3888b53a-7db8-40b4-89e1-0998ba6d231a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60036e00-cfb1-4621-b567-0619bf904c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d6fa80-b615-4f5d-bc97-f90d870d2db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d17f5866-2884-4cf2-88d2-ba8224f57fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a140537d-8d10-4e70-976e-1f0b5d94ceab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4f32d7-fe91-41e0-b710-1125e5da132f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c55fac-9a72-46ba-89f4-da2a7a5e95bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f37e5321-e301-45b6-be32-0a10e9636796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d85840a-57d8-48a1-bcea-579970b3416a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979abe13-3319-4594-9312-b39542026f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46769a50-6ce0-43a7-ae2c-dec75aebb4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9348ef-89d7-4c40-b181-2bc9fc4ae4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b464dd4b-1e4a-4316-b4fe-50f4ed6a5308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbba24ea-d776-450e-801e-07fe0f6a3054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ad89fa5-e02e-482c-a122-886c7b97285c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3710957b-ae63-42b3-be17-51e19ac09415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a259ab8d-d57c-40df-ac37-6f53c0d63c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30decc6c-e834-4782-8d10-13a376e22bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d83b0ae-6e80-43c0-8a54-24e328460775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d986a8b0-cbe2-401a-8e3a-a88476d1ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40961eec-c217-4a21-8707-926b1a197734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58fca7c2-98cf-4689-ab04-6a8707b9d6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c124ae-fae9-4771-ac09-aa4149fe93ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d6bef4-76e7-47e3-9c4d-54ff2e161434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe134784-6b2e-4b6c-8789-39b0124f8859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9063a4b7-2023-465e-93d2-ad4562bf0be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43fc2fa9-c847-409a-92dd-d9d3cbc89564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff72a208-6ef7-4cc5-bc75-15cada383cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989947a2-d396-4013-9b4b-cfb64b3441b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f683402c-0689-4c79-8884-0afddf3662d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3e7f63-5403-4e8e-a310-1a54586fd8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819fbab5-92d3-4a91-9bbc-ad23f13c7796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e499ef-acb2-4ef2-a602-10112477de97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4372e2d4-2c3e-49ca-bf94-1a78011c5d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4dc9f8-ebe2-4cdc-bcbf-4678bda84a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b46a18e2-84a1-4ca1-8820-53e03ae16294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a982326-5077-467a-83b5-f92d1949ba3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a691d92-be95-4c42-af71-32c00a1c770e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4a3805-a214-4a18-b4c3-08e9477cf87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a37fe2-5cec-406d-8bb4-262d42f32a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4ff622-1cbc-4cd7-81ed-3a60a515a90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec4dfca7-a372-4f69-a0e4-4182b69eaed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73babb0f-65b2-4fc2-b81b-14f221bcc28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a323a7-e9b6-497d-92f3-a01ea92326fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa233d6-9963-420a-bc6d-43d167291cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869178f9-b6ad-47ae-890b-56a32a3bc089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6107648-7ece-49e6-933c-f7b5f8bb8349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8692a7a-5caf-4170-aea7-0f4d69503691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beba521a-6693-470a-a0d3-529c658b5df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47f68960-4f0c-49fa-91be-40ceef78f687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1b5afd-fd13-4c5c-93e9-3dea488fbb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d505f969-131f-456a-a0dc-b114874fc999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 804e5817-e229-4ead-ab13-24d56d16184c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c09939-14a3-43af-b802-fb304e129ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6514de7-e315-4f3c-a5b9-db9a390222d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145e8791-e708-4b61-97de-3c24a505a10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999dd9d4-e404-44f1-b2ac-c3d79443dffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a4cc67-bd63-474c-b953-16bbbfffcae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5a9b58-79f9-4f65-a067-97b44537a342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297fa2de-ad41-4196-89b3-6cb004bba9dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 038caaa3-55c3-4e6c-b659-776bf0abd856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2cbc60c-1d6c-43b5-bc7f-effeeb1c3a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2962208c-b36e-4455-9155-21f41408852e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5005f331-1533-47d0-b751-c589f7298da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f724482-c44e-46bb-8243-e723042be4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a039286e-adc8-4b9a-9183-5cda610cd4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9419ae63-a812-4510-9913-e808df9e9946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080e23f9-cba2-44c2-add3-c1d90fc799fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d4cf7f-bc02-452c-a42d-64b256126287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db461b7a-831c-4e46-b35e-4015cc8e2cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b807a7-85ce-4c30-817b-6006b947bc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040aca93-8eb3-409f-9be7-7160c49100c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a6bf094-c440-4e21-bcee-cc5248e6433f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0be7c0e-d362-4a21-8e46-1cdca074cf95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a6a214a-a219-48b1-96fb-49717271f2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62ff0e79-bca6-4966-88e1-e863c654d608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6eca6a-1aab-4003-9efc-43baad488882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02013747-a02a-48e5-9788-938213d97e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682770b9-bb95-45b2-bc8d-75ea91d627ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f13059-c5d5-4178-a4f5-90a4fa070969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d69623-9115-4f43-96e0-cb1fedb0f1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e7ad7b-e8ff-49a7-94ec-86ed71d2f585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb310852-9a72-458a-95c3-12a9059ac119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec48bc7-3773-4e45-8c9d-de73dd2e9eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d7578b-2200-4129-81a1-8ca6f6d25625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08303d0a-58ca-4e43-844a-66b509b2c294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c645f13d-5cd1-4031-befc-86cdace18f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c47196-8ce7-48fd-ac25-f19e3d9878de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1684e235-403c-4e71-8a25-01289febff4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc081e37-cf3a-4956-ac4f-48f82a0d17b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f57dce-5125-4c4b-9a58-ef8828078e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ba334e-0c90-4dfe-9db0-7ff611d8a71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801655f0-f6e5-4bc9-bff6-33c3ad7ad598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb5b99a-9ca3-475c-b9ab-36f10b87275f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b4f76f8-8249-40c8-a6f8-51c12cbb3243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66171500-b9f3-4b10-8398-3d6fbdd9900b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85368cdb-fe72-435e-ac83-53334417b5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb641b81-d70d-4be3-ad4b-a65e696bb6b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1202967-00fa-44d9-880e-536b21913ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3e0b4c-e960-45cd-99f3-c8e5ed904977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2bbfcc3-d8f4-4e38-99b5-df2d9f141e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0173b989-073c-442c-8f61-20ce25131272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2541570-84c4-4ca4-a613-e506dc4daf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5762c5cd-d14f-4ccb-b801-08ba6a03b4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45eb7bda-0681-459d-b399-25bc6cb3dd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 471e94f0-1dad-40b4-8d5f-510b60161125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97dc85b7-2d94-4f89-b031-b95c0930a807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b176a85c-75b7-4ca0-beab-76a4f3f3f6b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3a5743-c7b2-477d-bf35-ea88861c91eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee8e06d-9d50-4fd4-a593-36299df76b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a11a27b-b904-485d-84f5-68298e5bba68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ebf6b1-f00d-477c-bc88-1042fd63879a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2dd82c-051e-427c-8d2b-09030e826e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72142b93-285c-4f6c-a79f-c769c64137f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33d171f-4e9c-46de-b7f8-d6556a41cb8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8fd1e5-fe04-429f-b1a0-496ab7f7ea18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5688d705-a973-4331-9e9c-3d31b0c60980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd5dbca-1c5b-47e8-8240-e0118b85fe73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494ddae3-edc5-441b-908f-9fc469927d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8065c065-a5cd-4908-b649-602c45e84197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3efdd870-f8cd-4978-8aa7-552cff0f9f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62673c0-7903-4d69-af18-4387c3f03a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae85c48b-f4bf-4077-b7f1-edc1f9e0211f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10517199-1f4c-4b74-806e-fa01f9bfcca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca30a30c-adc6-46ca-a17b-207bd12473ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8c101f-f5dc-48b0-82e1-84081ef73eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89783861-3961-46f8-8757-77a04d3850bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f34a74af-0776-4990-82a8-a94672cd22ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e023fe7-18c2-42b3-ad93-146491a4afb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c522d54f-0397-4de5-827c-d117332e26de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b220025-9803-429e-9eb1-ef8faa2c7cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1084229a-e8dd-4089-8130-b090c92bd1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0169faf5-d0ee-4441-ae4d-faef1ce19971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cb6e1a-b042-43c1-ae55-7f666618abe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfa67fd-23fe-4703-8195-9541414dac75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e0c0e9-b7b6-4dee-921b-ff532775c7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcec5b9a-8f9a-4bed-99fa-d5b02b9b710c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a917087-c9b1-416f-8a09-99fc9a260de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf75dd4a-f0eb-4b80-a656-7039d69b4aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c285aed-e78e-4d35-91c5-24d1827d225b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892d76ed-6edf-48cb-ad90-a73a8c461002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c191d33-1a6e-41d9-8260-61349b96b728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c0eb23-e1a5-4812-ab75-7013078bcad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42a6d11d-3c91-46df-9f2f-85a4e1e477c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37cb8cb5-d93e-473d-9eff-720d360d4421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07897efb-1b38-4e44-b339-70acd55d5560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da407061-42a0-499b-85c8-e8c985c303ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efbf2ea5-d695-4a33-ad0c-4ad962ebd768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d04fa42-b05f-441d-83c5-d95cc6fe631e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f7ca14-093d-4617-9cb4-af38d4d29d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf744678-1eba-46ef-a403-d348c2029358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e17ee3dc-01d7-4180-9b8b-f4b80bf56a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2d774d-79d7-456b-bced-c151c3091b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89665e17-31e4-4ea5-ae41-92439bf08f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2b8375-b97a-4f06-ad74-8b07ddce0eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb20502-1a57-4c79-a540-c5cb905b7dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638f9179-35ad-4590-bd10-a350ae0d63a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b418d89a-2c14-4a78-b8f1-9d6a1e5d66e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6be5c28-fc67-496a-a30c-b5b8a3ce84a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66284808-ddb5-41fb-8eaa-5f18b26ea0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7381106a-fa9a-431a-aaf5-ca931b31cb1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c71ace-4735-4be8-ae2d-a9ec632c022a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca314c5-9b8d-4752-9d65-ede1f58b866a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a92eb4-aff1-43a5-9b60-2df9c1fb9f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76bfc183-d4ed-4fac-a78d-44e718f02291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3d064c-9ae0-42f2-8b59-2a32991f90bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff3ef51-7a65-440b-b18e-f42e38d9f8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59612ce-a8e0-47ae-b2e0-07c2809a22ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b027ea-2142-4d8c-a9b7-c898bebbddcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1db169-6d03-41a7-a864-e253b43ac4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9932ea4-49e8-4cb3-a0bd-bb27055782ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31f4c0b-f121-42ed-92bb-35a67b6a3184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99ce29b-1b8d-4595-ae33-e6b1acce7d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ccc9fa-5a1b-46ba-bf46-702090aaec0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced58707-1802-4f25-b391-969cb8d113b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b23dd4-ee96-4295-8f78-baa541af3688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598bc69e-0522-4d9b-9394-1ef5aa7b66ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89dcf96b-2461-4582-9148-a123ec575c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f20a22b-c595-4183-8a07-45bb42836cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd233cd-da3c-4a81-a657-98ef47b5e7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff132c7-db00-4c38-8d32-3e3f0c1268e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2cb63a-97b4-4220-9d53-32caedc75451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffdfda1-7e71-4a5b-a8e2-4aa6ec44b151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658a9037-167b-4e52-8068-28aaa7c06a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058590d6-0dab-47b6-a591-08f295dc16e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fb60969-99b2-45da-ba5d-f8bb30dc2099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8a7000-3a1f-4d93-b528-bf7cdedff474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3154c6-c9de-4198-b073-4ac83c7142a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3a8b32-535d-412d-b96b-0e7ba9c83ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95cb2822-f55f-4245-93ac-493e3603d5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554d2bca-bad2-4d53-b465-e327fb68e145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3ee722-0a8f-487e-a189-36bb5fcc6727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e494bb3b-b612-4472-a963-9e0e9b1a42d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5b3c33-f01b-4a06-9f53-5f948587c787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954f05f2-3ce3-4ee6-b4a9-16335b24d698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c542d55b-4337-491d-ba79-0ee681965f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d79dc10-7e8c-4507-ad9c-7e5fe7701300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fdc39f-fe4f-426c-8900-30a8a848a7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f10c13-bef4-4b37-ac5c-b00dbefa15bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8483b068-b49d-4dcf-8bea-fdaad5267711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b06e6f-a837-45d8-b9fd-a2f37b22af99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4fabfa-bfd8-4b32-8d87-c1c3a013edc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfa84d3-4d41-4bf9-b394-af65a5815d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b18f1a8-890b-4416-83aa-4c3023fd7748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d3771f-139e-4113-8d93-284ea04882c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6120a44c-e452-4152-b2ba-d3c1487f6698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f729975-0eef-46f2-aadf-f1389303743c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ffd1b44-d6bd-44ee-af44-dcf8f01cd695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9b1906-9858-475d-aa33-055559d620a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b88e00-ad3b-48f9-81a7-8870ee817298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e92d1c-2f18-4c64-8a55-562a748dbb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84eb3f48-9e9c-4181-bec8-5dc4c34c2561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22170af1-6204-4ca7-81b3-b1941e638f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38afb9b0-a59f-4a87-8058-e70d177b752b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1125ff-c7de-4f61-858e-a305b68216a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed5b586-b6b6-4ac0-a98b-5103eba019a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0f9340-dc3c-4c8c-b6ac-3f0d10c718e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8a998e-63f1-4fb8-9741-c97751d56553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4ff36eb-6455-445d-b8c2-25b812c15153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52df4f97-6491-482c-97c7-98dc6cdb83bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 464fec87-50bb-4d15-8719-c13f74fa9889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd55a8f6-daae-4753-b1ef-8da9bf0b9498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6497bd9-14e8-441e-8f95-f7e49bf6bd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7839959-3ae9-42f8-80bf-1e8d18671dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6d81c8-a1c5-4bc6-8cbf-218f713e42cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ff084f-d22a-47f3-9bbe-3c25dfca1335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce1c3e3-25d8-429a-b818-305db9f76184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e78d5a6-4ab7-4962-b90d-131279c0fa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3651e3f9-0a81-4821-bcbf-91e957763081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc35ffe-a3b9-4b03-b2cd-6ca601c7bb7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8bd3b02-5bb6-463f-80a4-7004537ccfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01cdc431-c67c-442c-a574-c299e1ac90f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce05182-01e6-42ab-ae2b-7805e0299ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa8c0df-5616-4a9c-8a48-f5870493d802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6325ab8-ec37-47fe-819d-a6d1ec9095ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff3dab4-7cf4-4dfb-8c6f-b7232a6a2f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e9765b5-2dba-4341-bd64-6bdce3905323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f787f081-7ffa-4a1a-ae52-78698949b4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca595f0-8b13-4ecd-bb25-b1c410b1ee16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe909034-9fe5-4098-9287-92e318ae7ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87243b3a-40dd-4bc8-9206-bbbc194fbf48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d465e678-645f-43d9-85ba-6b8ae1897074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4fa109e-f942-4e88-8ae9-f5980e830f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d4554d-c91f-40ed-8c37-a9a05ddd817f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e39f525-e1a4-4e72-be99-ace2486e55b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a424f1-f9a5-4539-91aa-fdfd54ea0fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4a2d61-359a-4c54-a0dc-6952f7c2ebfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97bc7472-7026-4a51-9e63-8dcff389f1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64101562-a1c4-485a-abae-dff46b6a7cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a6fa13-7885-4d8d-82f7-31ac0a220eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c46f905-1e17-4f6d-ade6-7a333ed140b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2b12b8-fb91-4ce3-bf7b-65a85517414a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf17cd2-f9da-4a63-a78a-22c48833a198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e257ab60-ba85-4270-8443-35ef190ae42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74311e17-dce1-4d74-93ea-89914cb9fcb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fb1cf5-6fa9-47f0-b397-d4646978a1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64218fe2-570c-46b0-90e9-4d3177d86580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b239daa-6e1c-414a-ac0b-f7d7a1e4aca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8dd5f7-c7b7-47fe-9b70-ce61fb9c08ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9436c53-0074-408d-b2c3-b8b04cb50027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38af7043-3c98-4559-aa73-5f930d15e742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4602d99-2f10-4763-b639-4a6f7f246e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0c2c60-8994-4f79-9819-f1bea24869c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aecff1ed-6f0e-4753-b3bb-b1fb9abdfff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0881a1b-98d3-4497-8150-ba2c4d1e8eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3441fd9-3519-4a37-8b11-d8c0e70a124e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42bdef4-c802-49ce-8a8b-6963717f3f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4922f288-06cf-4515-9ac9-eb81f445661d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b651d571-9186-4baa-b9cb-19d769a67bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ff638d-f8d6-4f6e-8bad-0d8a44329882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362af450-90fe-4ca8-952f-6fc0504e2b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90012dc-b987-4b2f-a11c-a44c31f9f1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b06f132-8612-49e7-a343-320c3db221dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0dbf795-8a57-4cd0-8a46-a4b51c9f47de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece86a44-3491-4d50-9a07-280b510e7af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2505e3-57aa-4715-ba9c-ee28f367138e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ee3d4b-435b-403a-8be5-d32f9a8f5574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae445296-8799-41cd-83dc-e24410a81116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a36ab38e-0cd9-485e-9463-96e691ba4e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce162307-946a-4a63-9c22-278669cdb5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e8dba3-e2ad-4490-9e62-79e9c5afaecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b199a33c-c323-4239-a907-3705bc79e41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423d7b51-cacb-4424-9fa4-ad6378c4422c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3e5c49b-d646-4c05-bc61-637f1eca41a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d7e012-503e-4f1e-94f5-5a74fb92058e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d0cbb40-d3f8-42fa-8155-6782fce51c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09e0750-db0c-4f06-b4a0-a454d6f04510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5f9d30-f7d3-4d3c-853b-dd4cd656d5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c242ef66-8693-45c0-9d0a-bfef1439952f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7d3540-d23e-4edb-859b-34558e7e6b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b8ab04-7021-4b53-afb5-807b0210e0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02707d6-8dfd-483d-9285-326ca4e6641d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5000bbff-3aff-42e6-917e-0ff501d12ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81f3057f-4fb8-47cf-b244-53c2425c45ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7abef8b-7b19-4bd4-9cb5-b65550da7b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e19c8f3-7d6b-46a9-b036-e121de5b5733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e874ed6-27d6-4f5a-b9bc-c3271249ed37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f9c664-3ec0-4725-9bb8-dc46338aa17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abae130-a119-4f56-9567-c5acfb08cb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957d8845-7307-47b3-9481-166e4d953f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83317831-d567-4f84-a045-68a7739838a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d60975-8acb-41ce-9654-93ed02cd7bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da216ae-ef4f-4364-bd37-1191f7387f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 499417c3-2c0f-42c7-9dc0-3121e4bbf089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 329c9181-c30f-45cf-96d3-4b9165ac614f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf3cbe9a-bcb1-4abe-96d4-779ca359f47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584aedb4-8da5-4ad6-a9f8-b387abd69474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac1e0b5-03cf-4cf4-87e3-4a4577a16af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efa0a9a-8dcf-4af9-95a3-41a9b2de1a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feab2de7-f59d-43b2-89d5-ab17ec90f8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690ae242-1377-4600-8528-893928083de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adadb46a-091e-43a9-b991-e48b200d9569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c1f8c2-a644-4486-a3fa-389d7609f467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdb9285-4910-4aad-95d0-c4f108f268b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab13baf8-40fa-412b-918f-6beded27715a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d9f45a-edea-4b38-882e-f19d5f73cd0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6475980d-0746-4a6f-af39-bd2a7e78a6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9c29e80-1c27-47d5-bdbd-ddbc1ce416b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c18342-1250-4c3f-9422-299efce57f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00003668-c43c-4c36-9ffd-ff7c57340fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb63b3d-d1bf-4469-a35a-2a065249632b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db4aaae-7855-4140-a96a-3f3fb51ddd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8775d934-a243-40f9-8a09-1bba6e190a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580cb39d-445f-432e-9af8-45b1c87adc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0b2bdd-9df3-400e-9f0b-a53286526ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a62772-b1bb-4d8f-91bf-8a571c337021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bfc7ce-9a99-4387-8458-fce7d0d4920f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9888d40d-55a4-41b9-a674-8eeca9a6c514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a70f0afc-89e6-409a-a3a0-c5360319addd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f8b460-c245-4226-b52b-e6b70b02077e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2452ad-da19-4bdc-a32c-1ebdf6022396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36179997-f516-4f99-8ac1-34c7ee217f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d79821-b255-4a8f-bdfe-542d583be579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075a7429-32d0-4e86-a5a9-3b31c96d3c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a4d7d57-c6f4-42ab-a461-caa8e40b6098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6308502e-492d-4d72-ad6b-24405eb6790c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220d6703-0cfa-497d-b65f-23381a941a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bd1485-bb22-4405-b58e-0947818a7bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655c7232-bad4-4e60-929c-04ed04f64347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5625ea16-afb0-4157-bb1d-ccc5cd4b6769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f0fe4f-e6ec-442c-805a-23a68f88a580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62552b79-0b66-494f-9186-b8b9f11f8e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e87e94ae-f7d1-4998-a366-9c74171b188a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0be81f4-a4dd-4ebe-a621-b7bcee6f222a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cdb6e6a-a55b-4485-8db6-0495307c5505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb12a2bf-754b-4280-95e8-59c16ac38960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed0cd73-7f71-4d5b-9f7a-05efb4e60b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d66ba57-fb3e-4d1f-b8fc-ece3fe8b44b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c302bb-0c6e-4825-8f2a-bd30b43104e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2cb285f-a734-4be3-a460-11a33ae34bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b3e9ff0-b83d-4c3e-84fd-6f7dca2a4f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b50d08b-ec80-490f-b5a5-aeeb54fe2736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796292c2-c8cd-4b05-980f-80b7785317a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d474f3-854c-4f7e-aed6-8651b8c8806c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8875a1e8-26d3-4ecc-ac41-1359bf5d7718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 345a95b5-c199-4b14-830e-1c183bc15c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61391b49-eed7-405c-a5bd-6443db15c537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07414168-c871-4a00-b4e0-16dc5fb2a489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af3c2a5-c54f-4de9-b9c6-7b203c58a7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16888ab5-ca33-42a6-a137-b3e6e00e9d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f89f6dc-c9c5-4a50-a4be-144580bf0480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d41b27e-ed48-4f08-9c6c-b3181ab45a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510a9ece-b215-46b7-8180-91e9dd3380b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe3ad6c-bd22-4a42-b3c7-f9d9f9572614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feeb8fe3-a0a5-46a7-8fb1-76665f709ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c04560fe-661a-4312-971a-dc94a921b884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8763a77c-5f64-4231-9c51-f41030851aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df41f8a2-adb6-45aa-a8ff-504529ce52b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db2c5dd-9a42-4b7c-a517-6af1876bc9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6ceb98-fdf1-49b2-8d6f-cd9ed0d6fbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 430414b4-5e42-498c-a07c-18835583ea65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b5769e-377d-4939-8595-31d5da96de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c655ec-9d92-4f14-a8cf-6da312e62ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b0b9073-31b1-44e6-8a38-c1f8161845a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd68b6f-4ae4-4c89-a220-276d7bc8883c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab5e9ed-038d-4fb1-b4c0-ea00c9aecc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dcddfc5-7c8f-43af-afe2-d781c7a01ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67dc263e-3d99-486d-8dad-4a73de0710ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ace558-d5b2-450f-81b3-bc39402d0994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14475ffa-7076-4db7-bb31-e307d79bcc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e167eb3b-4baf-4ba6-bb0e-8be0af201d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630de67e-a71b-41ef-977e-86d33c3f3f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ed74b7-a061-4a0f-92dc-d21238316195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5920b8d1-0efe-4a8c-b4e2-376fdab8c168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1cdc820-e23b-407f-ac1c-f697633e912d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cd19d3-aab5-4e79-a691-b1bcc1bddbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b1546a-8403-4f8e-9d04-624129b45141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e060bd6-0147-4c51-ba38-686b42815b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6df0b0c-e1cb-491e-a9dd-709eac66e963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ebcae3-a501-4717-9236-f01c665af5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 867d3dc4-2410-49ef-ba3a-b8ce100dd637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db8fc7a-8686-41ec-bb22-ac29e92194af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dacf1fd-1b73-4828-a2cf-b436680157ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02e24f1-96e1-4d90-968e-b748f47dd1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4afc875-ea3c-4512-a6a4-9a3259c496c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed4bf6d-d9af-466f-9bd7-7cdaf3da1694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d26683-91c7-40bf-9f5e-153260809768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823070d9-4e40-490f-8456-2a8d62ae386a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745042fb-2add-4038-8797-4712a3eade8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f62563-cc26-4f0f-aea0-4cf9ea470782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955b9d53-f2fd-4424-b1b9-1beeae31b415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163e3a26-79e7-462d-91ef-54fc07569de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be29e44e-197f-4787-8dfb-11156aaad82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5d3519-d65e-4e87-8219-4f06e7da61fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd39164e-fa15-48f4-9a5f-02576ec27f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7c34fa-29de-4195-9fca-86766197d0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a49b83-84d7-42b6-9e7f-12f2f28a2ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305cc7b0-e2c7-42e8-9835-7c4e66188ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e945c11f-41d7-4a4e-b9f9-1a2104452677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55782794-3027-4889-bd4d-53f589206d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8125f91-8865-4eb9-a726-d23f6f078e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790d9b22-0e75-46f5-863c-a7a74738c73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2cd5e1-5a6a-4390-9fd5-82616cc290e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79640a6-3145-41f5-8fab-82a6729f1625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afefcd37-bace-4d4f-af57-cce5e050b1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394e3533-7425-4772-9083-7e16c71fd86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f04d62-ba27-4caa-bc5e-14926956df2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa52250c-cfaf-4fb8-b620-1591476b56ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5778125-05f8-431f-9ebe-ba6539a6f07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c912c418-7a3b-4985-803b-18538dae38f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a32d3ee1-58b9-4117-9299-af51dece0b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 640bd4c0-17b8-4ceb-98da-9f1962284719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e3ac7b-1ff7-4211-9461-19899d8cba7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b8458c-71f2-4e7d-8f98-c3aa53f8f0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1d88d6-1746-4e07-924d-2382f8b3b2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e27c5e5-6658-428f-ab6e-129e61bf7931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd16649-2354-4259-b88a-683b3827ffa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dee5dc6-e6a7-451a-8223-6db7ec9d1977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4db9660-7fee-4742-b986-57c78938261b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b343a923-b4d4-4b8f-95d9-eedddc52f2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29412fab-170b-4086-8dc6-b0d5e867446f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e016bba6-2abd-42cb-a6b9-c20eadfe0f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99e917c-84d7-4b2a-89a0-aecb417e98cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d284ee-80bf-4d7c-a527-b727c5410ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89dc0aae-9653-49c7-8202-60984cabd821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f850c7b9-20e2-4bef-8933-5cf7e2b4619e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b461792c-5432-405a-be35-9160bff65b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8247cc06-6c83-42ab-9dde-133e1a147b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd5966d-b2f9-4ed3-81db-c3bcbf09253a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0805c83-e35e-40a6-a20e-5d5611edf413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3089dacc-1050-4149-826a-991f38803d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a58c95-05b4-463e-9a47-093fa4fb9db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae01c98-9376-49ee-9cd3-f999bd77bcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012e39e2-1ea9-468d-b087-5b04981822b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac693ce-8f6e-4462-95f5-f872e6297646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1df830-70f9-49be-93e8-923196169680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6320f389-ff75-401b-9bdc-fc4285d1ffe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e8a06d-493a-474d-9f5e-34845370ba57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be3a84c6-c891-49ea-a24a-dab33b0cd8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca00168-63e5-4f52-9782-0e02fe8a35b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c1c3cf-6a08-43cc-b350-3c2df1c174e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32ddfca-7c39-4a66-9251-5d051bafb6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee443d8b-5140-4257-b865-26f713bc98ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5944d02f-fa9f-417f-b31e-34b0baf14c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef134993-2699-46ea-baaa-906a9b4eb33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf2d33d-9993-46d3-bf81-b900ec8e3146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20965f33-4584-4669-a6b4-8a009e2b1f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2b23e2-3da5-44e8-b70e-9062c2e55bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 305f3183-a258-4402-92ce-a124d1883e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6112a072-2c10-4700-a0a3-4e0a9034069c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41fbfab-8ff2-4039-b2e1-d6a9aebd0208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65f0940-772f-412a-9e10-8fea643aa62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1181bf-936c-424f-b626-136d0463c23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f59bc6b2-cbd1-4c9c-8c9a-4319eeaeba93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0082b355-2a64-4754-907b-7aef670016d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd19262-ff99-4029-8c78-39f225c631e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94797ca-9b87-4a6f-974d-d2f7fe54aa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaab0321-ae53-42fc-a998-4e3f877776b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be10aafb-3f1d-4b1f-a642-91212da3591b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f3a29f-55a7-41be-969a-b16cda377f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ee56df-a565-4c8b-8083-616ab30bcff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bef728d-0d29-4a24-b9e9-ccff6c731610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec3589fc-6499-4aee-8ccd-260970309758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d8ea66-299f-424b-893f-03a89c938174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27b6a66-c939-46cc-9861-e0edd41a37c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef73c6c-2197-41d2-a918-948079508d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6aa340d-67f0-4fcd-97af-943d26831001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8146170-a899-4f4e-962a-3a80fb72902c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee7199f-4429-4ee5-ab0f-409088b227fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf8bd9e-e872-4643-a504-25d80baf657c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfcebfc4-1d1c-459b-85ef-20908f62fd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ecc8e9-3833-4e2b-bfd1-c11e6a816380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec3c8d4f-79f2-4a5c-9e03-2b0f50bed51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70710605-de95-442a-b899-7d59c686543d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d1416c-73b0-48c9-af74-ed0b8572c454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd6683f6-8773-4027-8443-35a2c142897b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c57185-0896-4309-8514-a9f11719bf8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d839869b-e162-463c-9683-669e089b8029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db25352e-5675-480c-b4d5-951219914e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd08c5fe-09a7-4f6e-955e-1d635fc415f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc8cb88-37f6-4585-940a-5d7b16e6f78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa428e8-9ee4-4728-8fed-1518d9603159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b064021-2117-452e-a8b1-d1adfdd35491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0416c99-43c2-4a01-bf4c-b89d0ccf2664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc7ae4f4-90b6-48d6-bd1b-119af25ac298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af32d9a3-0192-46ef-9fc6-8d2a69989cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfac101-d474-433f-a7a6-ae9725d97003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b02651d-bd4e-4c21-9e0a-1f6fd00e365f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec14a477-3de0-44d7-880c-391740759034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d91d146-190f-4c36-b85f-f6e32f1bd6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e44fb3-6e40-4533-99ab-5fa6ea95d013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7844fc0-bd28-475a-ac40-fad9e71f97f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1cccf8-91f3-4704-9a5b-3453ff7d8c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa73525-7fd8-49c0-a49b-5bbec7ab045b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d406f38b-bb9f-480a-9f6d-176d5b526bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fbce2e9-3c34-4bf3-88c0-30b7c729d532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4ce86e-d922-4874-97d0-87560556816e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018fd8b0-c008-4fb0-b7af-e44c5939a156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33715e3-0f17-41d2-8ebb-22b179539cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38d8ab7a-57c7-4263-9659-562b5251182d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b627ea-07e3-4953-ae2d-273b250a1597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b37ff83-3629-4fc0-b291-74bb68c08bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cde8ae0-9817-4eed-9d72-6319b9244dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fef6798-7907-4b1f-b9b1-0c1c0663dba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9bb7de6-9ed5-4375-af8c-5704071f4d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f28cdcd-8e18-42bc-af43-a0db90164db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd761a17-0c6d-4986-9a24-fe572048d4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9410afb8-9560-4518-9206-570996384281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a83231-57d7-4c5c-a6da-1d74ae961688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e42ae8-4a90-44c4-8527-163799050a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c007be-dbde-4ff9-9bc3-56cd15122ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f87fb82e-06ba-4e3e-8a42-5b1a5d2aba12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff54050-12c2-4439-b61f-70064315e115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a71835-9faf-4ebc-86e1-06f939034a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12d372a-6ddf-42a4-b0cd-875ca4125f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a96b87-7ffd-47d5-a8c3-c2bfbc1e5fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710cab1c-2893-4b3b-a87d-4edfbb6ac38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e47a164-4e96-4385-ba32-7c6b9e0da17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1357aab0-34a7-4c6e-ab12-0753d2a5d434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf49b96f-f8bd-4620-85d3-23b00a9f9997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899a0968-6bdb-4839-8b81-6f2a13f1ea36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b55438-ad31-481f-bf90-a72c9b0469c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9823321b-a450-4a25-b15b-aa4aef747939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af99785b-a163-47b3-b791-6362ff275b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 355f6ae6-18b4-4472-b07d-fdaef805ff9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d297a13-2eb3-436c-936f-dcd8d1a7cffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5495c20f-2a40-460c-93bb-91bb1368ba93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c3e38c-3823-46a1-86cd-f4e5e19a2e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86683d3f-b4d1-4ec2-bec0-5c477b9029e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afb9f4d7-b32b-4269-8718-c893ab9e3a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13547bb9-8db4-4e25-9750-57f7298820e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e35a036-a18d-4325-8b89-23d1e63958bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a07f70e-4925-40b7-a9dd-7afc9bbe3247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b58138-5b3d-4f7e-8499-5566680c3129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1101c5-f40f-4782-8565-fdc011cd1bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc540a3-cb9b-4c40-a676-41064b4f52ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390e7d2f-392e-4422-895b-1de2e918fcfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0c812b-da2c-4dc2-9ef8-88450f977fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca535f82-5408-474c-a8d2-91cf8ce21d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a052c4f1-8e99-4281-8c97-9b7c878a366b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f63c257-229e-4073-ae5e-6d8773974201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41160330-287f-437a-b1a5-eaba3420f73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5be0704-a351-488e-9827-9ae9daf0cb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea17961f-aae3-428f-a026-117015fb6b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a336f3ac-aec2-4502-b421-86dc9031b50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e44b08-ce80-4f8a-95fd-017b94b06acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa23aaf-9a9e-40fc-a01a-95148ab6a18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9511a59-01e3-46e8-b6a1-9b5952638aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63dc280a-2bd6-4053-a4ad-6c30a1006a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a72348e-6cdd-4ffa-a2ec-1ab3c6e64990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e882cb-1069-48df-879f-f24fc153cf4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c053165e-bd62-42b9-a88d-113c266cd608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaefe44a-ab51-4e76-a914-d420ff953fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37627ed-f813-4cf6-93b6-62934f3712d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 178831ff-a993-4ae1-b927-04f80e81952b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 298c0a93-14e8-4174-8f44-1d3627eb1f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204c59f1-a759-454a-a150-8343167327b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4466900-0790-41b4-8190-29cedc21c1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 867d5afb-9729-4753-ad90-4a531635ad87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78b8be79-053c-4868-80bb-8889e4398854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f389a2b2-b516-46a3-b470-c94360e13d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e51a10-c5d4-40bd-8e82-afcbc1c233ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5ffe12-2229-44c4-aef4-92fa02fac96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e062170d-462e-4c53-8fdb-64c6bf652750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3e3892-5a41-4f4f-a47e-23817897bfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0299f10-f2c3-4c87-82c6-5337b41f6661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6628d276-8b61-435e-b370-39db697ec7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f15d556-c12e-4ba9-a9f3-cae93c3a742a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66506a5b-51b2-48d7-a4fd-d90fcdbee9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd53eda-9535-4f28-94d2-f0ba5515f995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb9b4bca-d858-415f-b95c-57938ff1a761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0e1c01-f470-4c89-a3d7-1809443e5213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c17006f-0f3a-4068-aef8-ad49e2b4937c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f45719-9ad9-4a33-bb43-0b7058026e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5070d529-7b2d-4e76-890f-54678070e232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4870c556-b7d1-41c8-9289-d9d0a97b03a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92cfcc0-c21b-468e-9488-26a8a451fd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a18932-6499-4ac9-aef7-98751f6debdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d9ca5d-5925-4722-82d8-71dd745cb96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e72e40-453c-40f3-b968-499ab3c014bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e3593c-8392-407f-9fce-9049ece7aab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3724b8-7301-439f-a4ba-08868e9def98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5934e9a2-647e-4999-aa24-08e0c793c91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f67316-2f75-4989-97f1-5fd3d8bf7667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff243297-c9d6-477d-bae0-6aa01526901f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba013058-1afe-4ca0-a433-922c36fb9f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b233ac2-5ef9-4866-b220-ef822e9af72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0c49ed-384a-4d6a-b706-99d62abb2689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2216230-4b09-4165-94b2-707fe9d1a257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a452f4b4-7555-4b97-839e-46aac2a04921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f70d5684-b6df-4764-83e3-816f8b074345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38dd1333-5c40-45e1-b3d3-bad1d5a86580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbf1b1d-2fbd-4eea-b55f-f83aa4ef22c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2bcdf96-3307-4743-a09f-ec07a6a6b8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8afc1b6-dc33-4b26-a9bc-a7100a53cfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b34c854-c289-4d93-9304-7362ed8f6d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a77dbf-c759-47c7-a132-a1218ab22f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c027c46a-e120-4e40-9d9c-ab7037ddcc13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33621cf1-6db6-478b-8d98-8b2dc440d0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50440cef-1eea-4eb8-bfa1-730c8459b291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012bb6e7-3bd2-4ed7-bb1e-baa33aeedcec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c02693b-c5d3-4fa5-98e0-c6e1a338d995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bec59f75-8b0d-4b01-99e7-194c002e046e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f74c6d-8780-4c0b-ae59-b37f9e1f125f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ec1109-3a73-4a21-bdf0-92fb78f130ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39e86ae0-7b18-4c53-9063-7a8564194ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e63e1ee-50c3-4600-9c4f-ad498b7dd980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31049ea-df87-4dd1-a1d2-42ac3d8c9f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bbb0a56-4108-477c-94ea-93367dd9fd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c261d80-45df-4644-9524-7a369af5781d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc72711-953b-4dd3-a8ab-69fd09dceb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd6f625f-c273-4912-87f5-2a4cabcf83e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0c962b-2d15-400a-9962-b701427ab5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9b21cb-d89c-496b-8e0a-15ad92a6ba87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44caf12b-e020-4acb-97ec-dac2291bd0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7986f2b-4c6c-4afe-8854-02d11dd1a943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ccf241-1436-4167-920f-51cf88726333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb541c8-0368-473a-bf85-38dbb54794fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ec1f56-2374-457d-8573-850b34706674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3834eab-3f08-48d4-bf97-ffcfec87dd80
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(4164, 24), y=(4164,)
   Test:  X=(1042, 24), y=(1042,)

⚠️  Limiting training data: 4164 → 800 samples
⚠️  Limiting test data: 1042 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2451, R²: 0.0072

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2457, R²: 0.0016

📊 Round 0 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2450, R²: 0.0072

============================================================
🔄 Round 5 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0879 (↓), lr=0.001000
   • Epoch   2/100: train=0.0822, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0826, val=0.0875, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0811, val=0.0873 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0741, val=0.0789 (↓), lr=0.001000
   📉 Epoch 21: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0635, val=0.0760, patience=7/15, lr=0.000500
   📉 Epoch 29: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 5 Summary - Client client_17
   Epochs: 29/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0691, RMSE=0.2628, R²=0.1637
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.1514
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2448, R²: 0.0099

============================================================
🔄 Round 6 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0799 (↓), lr=0.000250
   • Epoch   2/100: train=0.0837, val=0.0800, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0835, val=0.0798, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0834, val=0.0798, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0824, val=0.0793, patience=3/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0817, val=0.0791, patience=13/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 6 Summary - Client client_17
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0295
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0173
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2443, R²: 0.0148

============================================================
🔄 Round 8 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0838, val=0.0787 (↓), lr=0.000031
   • Epoch   2/100: train=0.0837, val=0.0786, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0837, val=0.0786, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0836, val=0.0786, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0836, val=0.0786, patience=4/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0834, val=0.0785, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 8 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0206
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0203
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2443, R²: 0.0150

============================================================
🔄 Round 12 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0834, val=0.0807 (↓), lr=0.000008
   • Epoch   2/100: train=0.0834, val=0.0807, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0834, val=0.0807, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0834, val=0.0807, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0834, val=0.0806, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0833, val=0.0806, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 12 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0172
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0334
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0153

============================================================
🔄 Round 13 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0830, val=0.0816 (↓), lr=0.000002
   • Epoch   2/100: train=0.0830, val=0.0816, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0829, val=0.0816, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0829, val=0.0816, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0829, val=0.0816, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0829, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 13 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0193
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0178
============================================================


============================================================
🔄 Round 14 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 14 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0172
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0104
============================================================


============================================================
🔄 Round 16 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 16 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0213
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0099
============================================================


============================================================
🔄 Round 17 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 17 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0213
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0027
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2444, R²: 0.0147

============================================================
🔄 Round 22 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 22 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0222
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0060
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2444, R²: 0.0148

============================================================
🔄 Round 25 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 25 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0177
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0241
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2444, R²: 0.0149

============================================================
🔄 Round 27 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 27 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0198
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0021
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2444, R²: 0.0150

📊 Round 27 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2444, R²: 0.0150

============================================================
🔄 Round 31 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 31 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0169
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0201
============================================================


============================================================
🔄 Round 32 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 32 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0191
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0218
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2444, R²: 0.0150

============================================================
🔄 Round 34 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 34 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0233
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0083
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2444, R²: 0.0151

============================================================
🔄 Round 37 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 37 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0184
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0243
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2443, R²: 0.0151

============================================================
🔄 Round 39 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 39 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0185
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0214
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0151

============================================================
🔄 Round 41 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 41 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0236
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0148
============================================================


============================================================
🔄 Round 42 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 42 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0175
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0178
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0152

============================================================
🔄 Round 43 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 43 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0209
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0069
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0152

============================================================
🔄 Round 44 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 44 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0183
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0243
============================================================


============================================================
🔄 Round 46 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 46 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0180
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0224
============================================================


============================================================
🔄 Round 47 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 47 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0201
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0172
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0153

============================================================
🔄 Round 48 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 48 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0179
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0271
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0153

============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0191
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0161
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0153

📊 Round 49 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

============================================================
🔄 Round 52 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 52 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0220
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0106
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

============================================================
🔄 Round 53 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 53 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0163
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0337
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0154

📊 Round 53 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0155

============================================================
🔄 Round 65 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 65 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0186
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0236
============================================================


============================================================
🔄 Round 67 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 67 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0167
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0131
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0155

============================================================
🔄 Round 69 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 69 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0197
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0172
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

📊 Round 69 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

============================================================
🔄 Round 72 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 72 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0217
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0134
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

============================================================
🔄 Round 74 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 74 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0174
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0280
============================================================


============================================================
🔄 Round 78 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 78 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0180
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0231
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

============================================================
🔄 Round 79 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 79 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0224
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0092
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

============================================================
🔄 Round 80 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 80 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0216
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0112
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

📊 Round 80 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

============================================================
🔄 Round 82 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 82 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0199
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0200
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0156

============================================================
🔄 Round 84 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 84 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0189
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0223
============================================================


============================================================
🔄 Round 86 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 86 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0194
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0216
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

📊 Round 86 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

============================================================
🔄 Round 88 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 88 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0215
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0131
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

============================================================
🔄 Round 90 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 90 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0197
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0222
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

📊 Round 90 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

📊 Round 90 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

📊 Round 90 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

============================================================
🔄 Round 98 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 98 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0230
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0073
============================================================


============================================================
🔄 Round 99 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 99 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0150
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0378
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

📊 Round 99 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0157

============================================================
🔄 Round 101 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 101 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0204
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0174
============================================================


============================================================
🔄 Round 103 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 103 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0175
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0283
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

📊 Round 103 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 107 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 107 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0192
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0248
============================================================


============================================================
🔄 Round 109 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 109 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0212
   Val:   Loss=0.0690, RMSE=0.2628, R²=0.0003
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

📊 Round 109 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 111 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 111 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0208
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0157
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

📊 Round 111 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 115 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 115 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0213
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0161
============================================================


============================================================
🔄 Round 118 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 118 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0222
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0033
============================================================


============================================================
🔄 Round 119 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 119 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0208
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0183
============================================================


============================================================
🔄 Round 120 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 120 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0210
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0182
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 124 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 124 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0210
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0185
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 127 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 127 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0194
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0253
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 128 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 128 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0243
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0004
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

📊 Round 128 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

📊 Round 128 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 136 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 136 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0206
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0198
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 138 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 138 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0194
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0221
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 138 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 138 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 138 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 138 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 147 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 147 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0186
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0255
============================================================


============================================================
🔄 Round 151 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 151 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0205
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0171
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 152 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 152 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0209
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0169
============================================================


============================================================
🔄 Round 153 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 153 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0236
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0076
============================================================


============================================================
🔄 Round 154 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 154 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0210
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0005
============================================================


============================================================
🔄 Round 155 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 155 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0245
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0020
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 155 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 155 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 164 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 164 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0200
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0220
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 167 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 167 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0179
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0036
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 168 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 168 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0224
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0068
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

============================================================
🔄 Round 169 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 169 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0197
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0204
============================================================


============================================================
🔄 Round 170 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 170 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0246
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0130
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0158

📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

============================================================
🔄 Round 174 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 174 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0235
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0074
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 174 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0159

📊 Round 174 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0160

============================================================
🔄 Round 183 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 183 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0212
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0162
============================================================


============================================================
🔄 Round 184 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 184 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0174
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0322
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0160

============================================================
🔄 Round 185 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 185 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0222
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0057
============================================================


============================================================
🔄 Round 189 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 189 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0201
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0089
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 190 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 190 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0193
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0268
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 191 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 191 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0239
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0094
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 193 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 193 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0230
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0082
============================================================


============================================================
🔄 Round 196 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 196 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0230
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0010
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 197 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 197 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0212
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0175
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 201 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 201 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0186
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0093
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 201 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 201 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 201 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 209 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 209 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0197
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0223
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 209 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 213 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 213 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0206
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0064
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0160

============================================================
🔄 Round 218 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 218 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0238
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0004
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 218 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 218 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0160

============================================================
🔄 Round 222 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 222 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0215
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0057
============================================================


============================================================
🔄 Round 223 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 223 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0194
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0189
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0160

📊 Round 223 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 226 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 226 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0219
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0119
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 226 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 226 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 230 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 230 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0210
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0196
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 234 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 234 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0174
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0311
============================================================


============================================================
🔄 Round 235 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 235 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0232
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0073
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 236 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 236 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0239
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0074
============================================================


============================================================
🔄 Round 237 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 237 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0215
   Val:   Loss=0.0973, RMSE=0.3120, R²=0.0140
============================================================


============================================================
🔄 Round 239 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 239 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0203
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0107
============================================================


============================================================
🔄 Round 240 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 240 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0255
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0016
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 240 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 242 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 242 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0206
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0215
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 243 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 243 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0179
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0318
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 243 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 245 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 245 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0170
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0203
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 245 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 245 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 245 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 245 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 252 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 252 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0216
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0169
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 254 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 254 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0185
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0300
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 258 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 258 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0241
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0007
============================================================


============================================================
🔄 Round 259 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 259 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0203
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0172
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 259 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 261 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 261 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0216
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0177
============================================================


============================================================
🔄 Round 264 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 264 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0226
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0064
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 264 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0160

============================================================
🔄 Round 274 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 274 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0228
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0088
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 274 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 276 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 276 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0226
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0098
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 277 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 277 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0226
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0091
============================================================


============================================================
🔄 Round 279 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 279 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0198
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0245
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 280 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 280 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0209
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0203
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 281 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 281 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0213
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0168
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 281 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 283 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 283 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0227
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0128
============================================================


============================================================
🔄 Round 285 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 285 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0215
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0145
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 287 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 287 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0234
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0049
============================================================


============================================================
🔄 Round 288 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 288 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0180
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0072
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 288 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 294 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 294 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0225
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0125
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 294 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 296 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 296 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0210
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0192
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

📊 Round 296 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 313 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 313 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0209
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0193
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 313 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

📊 Round 313 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 321 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 321 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0209
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0077
============================================================


============================================================
🔄 Round 322 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 322 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0235
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0104
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 324 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 324 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0178
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0259
============================================================


============================================================
🔄 Round 325 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 325 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0194
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0129
============================================================


============================================================
🔄 Round 326 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 326 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0172
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0339
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 327 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 327 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0248
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0106
============================================================


============================================================
🔄 Round 329 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 329 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0215
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0185
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 330 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 330 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0197
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0249
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 330 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 330 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 330 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 338 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 338 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0224
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0050
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 341 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 341 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0188
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0223
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

📊 Round 341 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 345 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 345 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0227
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0032
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 347 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 347 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0208
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0101
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 349 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 349 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0251
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0031
============================================================


============================================================
🔄 Round 350 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 350 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0193
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0260
============================================================


============================================================
🔄 Round 351 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 351 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0240
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0011
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 351 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 351 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 360 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 360 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0220
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0157
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 360 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 360 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 365 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 365 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0241
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0028
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 366 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 366 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0205
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0023
============================================================


============================================================
🔄 Round 369 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 369 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0221
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0158
============================================================


============================================================
🔄 Round 370 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 370 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0183
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0118
============================================================


============================================================
🔄 Round 372 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 372 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0260
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0017
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 373 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 373 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0236
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0080
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 374 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 374 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0206
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0216
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 377 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 377 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0196
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0257
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 385 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 385 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0186
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0252
============================================================


============================================================
🔄 Round 386 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 386 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0181
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0317
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 386 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 389 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 389 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0177
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0318
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 389 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 392 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 392 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0188
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0283
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 395 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 395 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0236
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0127
============================================================


============================================================
🔄 Round 396 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 396 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0214
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0191
============================================================


============================================================
🔄 Round 398 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 398 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0212
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0202
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 403 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 403 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0210
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0196
============================================================


============================================================
🔄 Round 409 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 409 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0231
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0126
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 410 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 410 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0207
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0179
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

📊 Round 410 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0161

============================================================
🔄 Round 412 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 412 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0210
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0209
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 413 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 413 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0184
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0150
============================================================


============================================================
🔄 Round 414 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 414 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0229
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0006
============================================================


============================================================
🔄 Round 415 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 415 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0236
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0007
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 418 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 418 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0223
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0162
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 419 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 419 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0194
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0003
============================================================


============================================================
🔄 Round 421 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 421 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0178
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0273
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 430 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 430 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0205
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0193
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 431 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 431 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0220
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0170
============================================================


============================================================
🔄 Round 433 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 433 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0216
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0133
============================================================


============================================================
🔄 Round 435 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 435 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0209
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0179
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 435 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 438 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 438 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0195
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0276
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 440 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 440 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0226
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0141
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 442 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 442 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0226
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0077
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 442 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 446 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 446 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0194
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0271
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 449 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 449 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0220
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0044
============================================================


============================================================
🔄 Round 450 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 450 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0216
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0092
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 453 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 453 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0184
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0217
============================================================


============================================================
🔄 Round 454 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 454 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0197
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0185
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 454 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 459 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 459 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0201
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0192
============================================================


============================================================
🔄 Round 460 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 460 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0191
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0295
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 461 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 461 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0229
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0149
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 462 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 462 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0227
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0140
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 465 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 465 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0204
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0241
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 468 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 468 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0225
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0156
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 471 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 471 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0222
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0171
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 471 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 474 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 474 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0163
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0306
============================================================


============================================================
🔄 Round 476 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 476 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0193
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0272
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 477 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 477 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0199
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0209
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 477 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 480 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 480 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0208
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0180
============================================================


============================================================
🔄 Round 481 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 481 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0222
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0099
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 481 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 485 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 485 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0228
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0130
============================================================


============================================================
🔄 Round 486 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 486 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0204
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0245
============================================================


============================================================
🔄 Round 487 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 487 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0196
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0275
============================================================


============================================================
🔄 Round 488 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 488 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0196
   Val:   Loss=0.0988, RMSE=0.3143, R²=0.0158
============================================================


============================================================
🔄 Round 489 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 489 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0223
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0149
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 489 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 491 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 491 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0193
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0273
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 493 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 493 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0212
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0160
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 494 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 494 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0195
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0212
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 495 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 495 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0195
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0128
============================================================


============================================================
🔄 Round 498 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 498 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0189
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0300
============================================================


============================================================
🔄 Round 499 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 499 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0223
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0127
============================================================


============================================================
🔄 Round 500 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 500 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0238
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0069
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 501 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 501 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0213
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0198
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 503 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 503 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0227
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0055
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 503 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 507 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 507 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0252
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0138
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 507 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 510 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 510 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0190
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0177
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 510 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 514 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 514 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0195
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0265
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 514 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 517 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 517 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0203
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0189
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 518 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 518 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0208
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0173
============================================================


============================================================
🔄 Round 519 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 519 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0233
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0086
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 520 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 520 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0201
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0248
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 520 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 523 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 523 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0208
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0031
============================================================


============================================================
🔄 Round 524 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 524 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0198
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0250
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 531 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 531 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0216
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0131
============================================================


============================================================
🔄 Round 532 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 532 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0246
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0053
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 532 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 532 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 538 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 538 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0228
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0131
============================================================


============================================================
🔄 Round 539 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 539 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0222
   Val:   Loss=0.0709, RMSE=0.2664, R²=0.0130
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 542 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 542 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0215
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0128
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 542 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

============================================================
🔄 Round 550 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 550 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0185
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0189
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 553 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 553 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0227
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0145
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 554 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 554 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0246
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0033
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 554 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 556 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 556 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0203
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0225
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 558 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 558 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0199
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0197
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 558 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 560 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 560 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0236
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0101
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 560 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 564 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 564 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0193
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0003
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 564 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 564 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 567 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 567 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0223
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0160
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 569 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 569 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0224
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0132
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0162

📊 Round 569 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 571 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 571 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0194
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0279
============================================================


============================================================
🔄 Round 573 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 573 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0211
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0211
============================================================


============================================================
🔄 Round 577 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 577 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0161
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0111
============================================================


============================================================
🔄 Round 578 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 578 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0216
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0167
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 580 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 580 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0220
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0153
============================================================


============================================================
🔄 Round 583 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 583 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0208
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0108
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 585 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 585 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0236
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0009
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 587 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 587 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0197
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0048
============================================================


============================================================
🔄 Round 588 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 588 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0251
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0050
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 589 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 589 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0248
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0020
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 590 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 590 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0229
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0111
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 591 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 591 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0185
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0320
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 591 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 594 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 594 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0191
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0275
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 595 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 595 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0228
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0102
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 595 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 595 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 598 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 598 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0224
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0152
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 600 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 600 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0198
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0122
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 604 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 604 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0229
   Val:   Loss=0.0953, RMSE=0.3087, R²=0.0063
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 605 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 605 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0229
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0144
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 609 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 609 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0215
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0203
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 612 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 612 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0195
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0284
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 612 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 615 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 615 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0264
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0025
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 616 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 616 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0201
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0235
============================================================


============================================================
🔄 Round 617 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 617 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0206
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0168
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 621 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 621 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0227
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0148
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 622 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 622 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0230
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0146
============================================================


============================================================
🔄 Round 623 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 623 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0181
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0247
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 625 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 625 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0236
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0090
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 625 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 629 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 629 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0256
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0002
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 629 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 629 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 636 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 636 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0211
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0174
============================================================


============================================================
🔄 Round 637 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 637 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0228
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0138
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 638 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 638 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0218
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0171
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 640 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 640 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0211
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0271
============================================================


============================================================
🔄 Round 641 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 641 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0232
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0090
============================================================


============================================================
🔄 Round 643 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 643 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0225
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0140
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 644 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 644 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0213
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0334
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 644 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 650 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 650 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0199
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0137
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 651 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 651 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0198
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0213
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 653 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 653 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0210
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0229
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 655 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 655 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0197
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0266
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 657 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 657 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0195
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0282
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 658 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 658 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0192
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0275
============================================================


============================================================
🔄 Round 659 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 659 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0205
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0156
============================================================


============================================================
🔄 Round 660 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 660 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0200
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0195
============================================================


============================================================
🔄 Round 661 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 661 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0198
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0247
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 661 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 661 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 665 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 665 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0182
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0258
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 666 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 666 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0255
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0002
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 668 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 668 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0244
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0002
============================================================


============================================================
🔄 Round 669 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 669 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0195
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0276
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 670 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 670 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0228
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0118
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0163

============================================================
🔄 Round 671 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 671 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0219
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0173
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 671 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 671 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 676 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 676 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0209
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0197
============================================================


============================================================
🔄 Round 677 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 677 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0217
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0191
============================================================


============================================================
🔄 Round 678 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 678 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0184
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0244
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 680 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 680 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0169
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0391
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 680 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 682 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 682 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0227
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0062
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

📊 Round 682 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 687 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 687 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0217
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0198
============================================================


============================================================
🔄 Round 689 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 689 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0208
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0216
============================================================


============================================================
🔄 Round 690 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 690 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0197
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0143
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 691 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 691 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0207
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0225
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0163

============================================================
🔄 Round 692 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 692 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0215
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0207
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 693 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 693 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0214
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0137
============================================================


============================================================
🔄 Round 694 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 694 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0225
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0137
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 701 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 701 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0197
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0172
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 702 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 702 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0182
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0209
============================================================


============================================================
🔄 Round 703 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 703 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0164
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0411
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 704 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 704 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0236
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0051
============================================================


============================================================
🔄 Round 705 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 705 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0207
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0197
============================================================


============================================================
🔄 Round 708 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 708 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0221
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0156
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 708 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 708 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 711 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 711 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0218
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0193
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 713 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 713 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0233
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0130
============================================================


============================================================
🔄 Round 714 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 714 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0208
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0031
============================================================


============================================================
🔄 Round 715 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 715 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0222
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0170
============================================================


============================================================
🔄 Round 716 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 716 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0206
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0211
============================================================


============================================================
🔄 Round 717 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 717 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0251
   Val:   Loss=0.0998, RMSE=0.3159, R²=0.0075
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 719 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 719 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0221
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0318
============================================================


============================================================
🔄 Round 720 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 720 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0210
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0062
============================================================


============================================================
🔄 Round 724 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 724 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0204
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0254
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 725 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 725 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0187
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0185
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 726 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 726 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0224
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0168
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 726 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 728 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 728 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0174
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0368
============================================================


============================================================
🔄 Round 734 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 734 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0196
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0008
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 734 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 734 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 734 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 734 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 734 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 744 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 744 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0232
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0077
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 744 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 749 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 749 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0217
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0199
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 750 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 750 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0208
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0236
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 752 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 752 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0174
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0306
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 752 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 756 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 756 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0213
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0153
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 758 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 758 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0198
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0268
============================================================


============================================================
🔄 Round 760 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 760 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0174
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0177
============================================================


============================================================
🔄 Round 762 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 762 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0189
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0297
============================================================


============================================================
🔄 Round 763 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 763 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0222
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0182
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 769 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 769 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0201
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0260
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 773 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 773 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0221
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0184
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 776 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 776 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0187
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0036
============================================================


============================================================
🔄 Round 777 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 777 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0177
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0311
============================================================


============================================================
🔄 Round 784 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 784 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0236
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0036
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 784 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 790 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 790 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0212
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0101
============================================================


============================================================
🔄 Round 791 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 791 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0209
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0223
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 795 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 795 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0227
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0072
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 797 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 797 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0208
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0156
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 801 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 801 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0215
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0208
============================================================


============================================================
🔄 Round 802 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 802 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0178
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0299
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 803 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 803 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0195
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0090
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 803 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 809 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 809 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0225
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0162
============================================================


📊 Round 809 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 811 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 811 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0222
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0115
============================================================


📊 Round 811 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 811 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 811 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 811 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 811 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 818 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 818 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0225
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0021
============================================================


============================================================
🔄 Round 820 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 820 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0267
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0015
============================================================


📊 Round 820 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 820 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 820 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 826 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 826 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0237
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0115
============================================================


📊 Round 826 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 828 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 828 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0195
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0279
============================================================


============================================================
🔄 Round 829 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 829 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0194
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0124
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 829 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 832 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 832 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0221
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0153
============================================================


📊 Round 832 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 833 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 833 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0211
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0170
============================================================


============================================================
🔄 Round 834 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 834 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0216
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0203
============================================================


============================================================
🔄 Round 835 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 835 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0226
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0139
============================================================


============================================================
🔄 Round 836 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 836 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0190
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0277
============================================================


📊 Round 836 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 836 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

📊 Round 836 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 842 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 842 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0206
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0221
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 843 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 843 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0229
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0159
============================================================


============================================================
🔄 Round 844 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 844 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0217
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0180
============================================================


📊 Round 844 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 844 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 849 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 849 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0235
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0056
============================================================


📊 Round 849 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 852 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 852 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0213
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0225
============================================================


============================================================
🔄 Round 856 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 856 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0239
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0101
============================================================


📊 Round 856 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 857 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 857 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0218
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0125
============================================================


📊 Round 857 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 857 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 857 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0164

============================================================
🔄 Round 862 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 862 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0208
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0137
============================================================


============================================================
🔄 Round 863 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 863 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0244
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0054
============================================================


============================================================
🔄 Round 864 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 864 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0191
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0273
============================================================


📊 Round 864 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 866 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 866 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0210
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0238
============================================================


============================================================
🔄 Round 867 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 867 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0210
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0213
============================================================


============================================================
🔄 Round 868 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 868 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0229
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0150
============================================================


📊 Round 868 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 872 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 872 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0166
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0308
============================================================


📊 Round 872 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 873 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 873 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0197
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0264
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 873 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 878 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 878 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0203
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0051
============================================================


📊 Round 878 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 881 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 881 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0230
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0159
============================================================


📊 Round 881 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 881 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 884 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 884 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0197
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0286
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 884 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 886 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 886 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0212
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0232
============================================================


📊 Round 886 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 887 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 887 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0216
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0184
============================================================


📊 Round 887 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 889 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 889 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0201
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0254
============================================================


============================================================
🔄 Round 890 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 890 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0240
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0129
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 890 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 896 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 896 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0226
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0143
============================================================


============================================================
🔄 Round 897 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 897 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0164
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0340
============================================================


📊 Round 897 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 897 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 897 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 897 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 897 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 904 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 904 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0240
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0001
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 908 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 908 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0168
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0372
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 915 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 915 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0209
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0217
============================================================


📊 Round 915 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 916 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 916 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0214
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0191
============================================================


📊 Round 916 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 919 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 919 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0193
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0274
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 921 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 921 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0221
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0025
============================================================


📊 Round 921 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 921 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 923 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 923 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0227
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0007
============================================================


📊 Round 923 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 926 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 926 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0239
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0203
============================================================


============================================================
🔄 Round 927 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 927 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0251
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0057
============================================================


📊 Round 927 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 929 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 929 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0214
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0208
============================================================


📊 Round 929 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

📊 Round 929 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0165

============================================================
🔄 Round 932 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 932 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0220
   Val:   Loss=0.0937, RMSE=0.3062, R²=0.0203
============================================================


📊 Round 932 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 934 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 934 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0166
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0396
============================================================


============================================================
🔄 Round 935 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 935 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0207
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0241
============================================================


============================================================
🔄 Round 936 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 936 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0252
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0077
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 936 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 938 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 938 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0208
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0236
============================================================


📊 Round 938 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 940 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 940 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0214
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0064
============================================================


============================================================
🔄 Round 941 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 941 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0233
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0083
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

============================================================
🔄 Round 943 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 943 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0254
   Val:   Loss=0.0842, RMSE=0.2903, R²=0.0002
============================================================


============================================================
🔄 Round 944 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 944 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0229
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0068
============================================================


============================================================
🔄 Round 945 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 945 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0215
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0220
============================================================


📊 Round 945 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

📊 Round 945 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2441, R²: 0.0166

❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
