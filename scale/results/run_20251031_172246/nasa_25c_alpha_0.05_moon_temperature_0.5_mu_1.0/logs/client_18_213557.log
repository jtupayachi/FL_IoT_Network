[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a122275d-42d5-4a0e-809f-a8f6a2ec258d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05aa45e-d411-4624-8803-7592eca84fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afaef40e-a05b-49ad-a569-c9b92c4823ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7bf959-1d18-42f4-a10d-9e47e55f778c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd38cf72-a245-4a7f-966b-fe7929b41a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87cff9af-5e87-49ac-854c-7f35552e3968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26cd21a3-6801-49dc-bea5-337f88b5155a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa601325-29ea-4dc1-bb93-c12405a870b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01320e70-0b53-4670-99cd-b6286b3154cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8c4cab-ba69-4cc3-bc0e-bab2c350b3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218112ed-6b48-47b7-b1cb-6909f7a399a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c14067-04a1-4883-a427-116a9825d11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07178708-d818-48c2-a950-0daff0de0c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509402b6-b6b6-4ac0-96fc-97ba5b013c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b22312-25d6-46ee-835e-88d02eb98610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424d46e5-b988-44cf-a0bb-e194e5951d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8fa36e-5b20-43f9-9326-ee1ba70370e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04d0e65-fc61-4e8b-8a81-e2e984aacccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3649ce9e-5b7a-4ac1-9ef7-199cfebc958d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3cbf3f0-4642-4244-80af-2799f090eb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df2558c3-2782-47d6-b702-4ba4150b86f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603f82ae-7c6b-49fd-98a2-1fa11566e0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58a2d92-3edf-4ce3-9e94-3da6a2bf668e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18eba79f-8710-48ca-a387-14644f9541a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f959a7-5a6d-44e2-92a2-b7a0e6be89f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f2affb7-12e3-4784-b726-f589d05c66e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e14daa1-d70d-4eb2-92fb-ebf6952539ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3cd73d7-9f1f-4dc7-ade7-523296edfb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f755aeb2-f3a7-4741-b917-b8e1cbf68e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b2846bb-5bbe-4655-90d5-73631f274d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52bcd5e9-9d85-41d4-974e-fcb4bf0ae9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d66ff73-2afc-4eb2-b72f-fd2049b5a99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e9bb02-68a4-4e44-9d2f-d4c8ceab4896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34edb57-2dd3-4d13-a5b4-b784c74b078f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e09afd8-71cc-474a-9eb6-be9f71891f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3db439-f439-466f-b69c-0c5b89803dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1629bba3-4296-4f07-bdb7-6f655f1ad7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faeb7841-69ca-4e7b-8484-f1a6c1a8b294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed89dc2-f092-4940-93a9-2dfb4f5dd497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b02cda-4805-41c7-90b9-1a7d971369b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbe84969-a1f2-482c-bf00-4d51cc6e5bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3ca7f6-bacd-4762-a307-8c7d2bf80691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966e4af8-abef-45e8-8ce5-8c43402c4705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77e54a5-4cd8-49e4-b4af-0660eeda22da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b09178d-d831-409d-a29c-45e3c5e2ba13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e516f9a1-197b-40d1-a552-87f717b1afa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49147304-2621-44a0-856c-bf5d4ac212bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b0cef8-74c4-4eb2-8068-892e24227bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41cc0f32-6be4-4f6b-ae48-0bc8464ed7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b237dc46-992e-45d8-8748-91be9a97817d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21189a07-34d4-42e8-9313-11c8be0b7d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cad341c-e51b-49a4-ba80-215facf61f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d9b7b9-d051-47dd-a32c-6a3f3e3e7382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ad1839-bc7d-429f-8a5b-1ec633a99836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a82b6db-39f3-4a64-a79f-e0caab1f60fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437d3473-8b8c-4fbe-837b-e714aa6d70cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e65e3691-5bbc-4fde-9f79-355e053f68d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ed3d19-3822-439a-8980-deb769a74996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31dd3e65-d2a5-47f8-9711-567e8c06d235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efdfd822-f006-4de7-a941-4fe9ef13dd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7981e462-d43e-44b4-88a3-47e80e797ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df799355-8514-4a4d-8ca2-8222ae9ea916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd620e56-f39f-4b32-9504-673ee85c12f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b69f926-8da1-49e9-8c35-4fdcf5f22aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea4d324c-9bef-49d3-88f8-a9649d7a8403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32cfb248-c437-49c0-a452-3b6831ed4438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2334f276-ab29-4d0f-8647-eced35476381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4df1c92-9bfc-4382-8729-3ea246dbcad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27844ec1-63aa-4ea5-b6fb-480b2795c51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581a25c4-6942-47ee-a4ce-aaa843644239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7f8789-b1a9-436c-97f0-b0ae544c0b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b500911d-c45e-49a8-9b88-0a7aad35b1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf02ea3f-e37b-448e-9c07-69cf0e784229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0e045d-57a6-40fc-aa12-87258b30529a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6eb0e2-35c0-4029-8187-5d904ec93a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b3184f-b03e-4cd2-8969-530138ea6427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ea1448-699b-468a-ab88-966489e44b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 045c6423-14e2-42b0-8d52-917a4467c515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c51f851-aaf7-49dc-bf39-9cabca15ec85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9a91fa-1d92-4bd9-811e-e90705c98857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee926dec-1c03-4195-8602-7b716a1d7d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9455623b-af69-4b24-92ec-73568183e1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c983d29d-3f5a-4a0a-ac2b-e8bfb37c7a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3115ce77-b09a-4040-bd7c-933fcd5b1768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c572f7d0-ede3-4a66-a876-09817d8ae408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bdf02a7-7eaf-415e-ab00-69eac09d9246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f515062-2d28-4f13-89a2-67fee9066021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4fe6f5-b669-40f8-b94e-2b4d36c88052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f5e149-9b92-403b-88a1-5a718e14fd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a226423a-f1e1-41ed-83e0-a1ffaa4d5c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b2958f-940c-4711-a624-51f083fd947d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dfa3492-36d5-43dd-85d7-6e7fd3f743f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac5fbac-02bd-4e06-a0e6-c5ed53290af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99dd1f86-e68b-4b1d-85bd-88b6fb065bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc33e6c-75f8-418a-b5f2-d5e7a6d20c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8b3e3f-5d6c-4a8f-b0be-3b7339900817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1771c94-f45c-4ca7-8562-c8d864de1a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4473d8a7-5553-4c98-9c06-b9a86b15e7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064a0928-cc37-446e-928c-e62d9677b28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c57e73d-b8ad-4dc0-b384-c61900d0570a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec69362-ffee-40c7-9c5a-6889e645e961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da091209-c8ec-4fed-be44-06505bfd791e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d584646-2c59-4895-8539-74a8062295b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6284b1-3d03-47fe-9d24-c13fb4fe7d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac4b1a03-5121-47a4-a8ab-f68f902cb0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4084cb6b-5ce4-43e3-9f19-047bcfdd783b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1042ca5-673c-449b-9490-7fd6a28c38d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340c11b9-a370-41c8-9d4d-4b2f40d3ccae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3446ab8c-9d56-4674-8848-661a158b7a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b887f1b-8b40-4c18-a312-6e477ab4fe45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52085e57-d4d1-423f-a074-ac4e2d25861a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e01230-d631-4f5c-a466-dd8868df517f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beef36f1-a2d7-4fc6-991f-bee1151bd97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0232c39-0898-41ce-8881-fc4d3234ac09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1a7931-c4ae-477d-b91a-55141c2a271b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda2a600-cad0-4254-ae0e-1da9b7c47dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972d7f51-f2b9-4ece-984b-e8db9e9bb682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47928575-d2c8-4d6e-a285-4e53ffaed18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8179191-4d95-48bd-90c1-103ee3bd5557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453ca4cf-1939-4e2b-a0ad-b683c8533007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8233d192-769f-42d0-878a-1de1da22e282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b06fe1-f7db-496a-baf6-57cf116b5595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07495227-6b93-48f9-8f80-db27434ef9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05225b5e-c41f-4632-ab10-970a670c43e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23acc6a-487e-433a-8fe1-5f5815eabab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c6c671-a77e-4872-b9aa-f83d0c702a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a883195-dbbe-4f75-9a3c-abc01c1cd3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddfcd85-e3fa-41f9-a449-e454d5b6b947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c71d6f3e-b03a-4ce0-b6c1-e123043398a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3961bb75-a8ea-4d5b-ab10-d09d15fd93ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ec53b3-edbb-4a38-b7a2-077209ae8e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 089d4001-a49e-4e4b-a430-6afd186c6afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea63ab14-bca6-4456-9284-45f7f6f01c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a0ff3a-5beb-4f43-9a27-43410079e414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e82cf97-be7e-412c-9834-061c4e451af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202d75bd-8e01-4441-b98f-f7e8e625bd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8347bf2b-36b6-4594-bb08-89ee82da9678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21578fd-641b-4ec9-8574-2faeaf93a1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9751c73-8e4b-4464-9c1d-841fc893f811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6551e0af-587e-43f7-966b-017ccea6575c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d901fd-a8a0-4177-8138-08ea87db68a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a884a278-b376-402a-867c-ab1b8bef4435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c6ae0b-97bf-4857-bc85-aa607eb16f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca392978-87e2-48c5-810c-fe2798026c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458e841d-0fd7-421c-9b89-9d98b91d83d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1590158f-eeff-494e-8b19-d3df0bdd40ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9e0893-be0c-4ed0-a5b6-dd4aad20c3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9da4b1-af31-45da-b170-48653ba1e322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274ae258-0c04-41ac-9f63-9d87d8176a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b9b213c-0aa3-412c-86e1-c52f3d8cd3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d72580-e89b-42b4-b5ca-e6371d648a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552dbe80-e33e-4798-877d-7deced55dc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd86324-ce4e-45a6-9c4c-c6b8587d202b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8af9b08-fb3f-4433-85e8-238b6ce4aeb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20aa1eea-cab4-4d19-a8be-9e7ad777d128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e98949-495a-4887-9553-791ac0deb7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77ece795-649e-4daa-98de-be6c937d76b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 187a0301-65cd-4e4d-8530-deeb32d8c37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21ce15e6-68f9-42de-9960-d2d3d264df1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e9703a0-185c-4958-895c-d3271b2897ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91060695-120d-49ab-ad91-32af67cee3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb90c02-888a-47a2-8169-4fed0b9edb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52555856-8336-464a-9222-8ed54c8a530c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d2fbc6e-efe3-49fe-8db0-f45c9dcae8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27115f7-b161-48c6-84cd-d36447d9ecdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9dc01c-74df-456e-a6ec-a71857b335a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca9d3c07-2d64-4a6b-b981-899b7d8b8402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79121b91-9318-4f9c-835e-e3ec70493f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60a481fa-c4bd-4e0c-b91d-6480f0a27541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c4ca94f-9747-4001-b5d8-d68534d01349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438bd1a0-0567-4c8a-bac6-8a21c6043040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b9dcfb-2fe9-4aee-bee8-5db8ee86edf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18567f0-7bf4-483b-812a-4cbec2a52ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 172ddee7-bada-4a2c-9422-2e00d7064477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fe8590-0bfc-4c80-9030-fc7f58f52076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3138a9c-b1ab-4672-a0a9-0561eaed33a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50665271-2d69-416d-8789-26545c1f7f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62cd2a3-1523-4d35-b471-02f0b0f037e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c153b2c1-03f7-4aec-926c-0e8da96ebab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e12e696a-39ae-4a76-9153-6a989d2a70e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f541543-3615-4f7d-81d9-71af79f265e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5536abe1-6e62-45cb-a668-5c431427932a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853c2cfe-b269-4b57-ae41-f5ab873c41b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d611c26d-a4c4-45e8-aeb6-781fbaf0697b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef3c48f-3be2-421d-a74d-81aa307cfc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84aa90cf-1457-475b-b128-3faba2d5340b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7be3313-bd88-4af1-b2b6-c251d285dd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fd54b8-1cdd-44b4-acac-ad9679402287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c23cd7-143f-41a2-a450-0f8e5ae0a0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f28d6089-d0e1-40b6-8e0b-7503853f51c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56518ff2-0382-463b-b688-32526a7408e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d410f54b-c60e-44ca-af6e-cdb2b882a5e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f0cc6e-59cd-4815-9624-675cbd693ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c249ae34-263a-472a-9ed5-19d17088cf42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd2fad5-839e-4f7f-8e88-904c5db64908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e995f72-1f7f-40a2-be1e-c80546911386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddba0bde-9f0a-4d7a-895f-7d87cc65f80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855dd48c-55d1-45e2-8e10-397c40b21513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56eca3f7-6767-4fc2-b89f-4d8edcc0d69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21389eb-6e15-4c3e-9540-66bbed6c9422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7953a48-26ac-4c39-bb52-8b99d0ab882b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba70337-8c96-4461-826c-32055d77870c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91d6a2b-bccd-4b3f-a3ac-41c4c69760ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df8f29e-f159-470d-8f94-7b8b4e9b28f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31597460-e1f5-4421-a35f-6c9e56353333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b8552b0-dcde-4d2e-91fd-5810c498eb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19670ef8-62f8-40de-a6e5-775db7786d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f867e11-7b62-4b4c-a447-cb84e7abbcd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669df5d3-748f-4cc1-9ff0-b17fa10a2bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb71d260-2aba-4a78-97cb-f2b95b07f393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 976ab325-8e34-4b1f-ab39-4b8cc542e61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83dac5be-92b8-45de-a772-46694bb1dde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6bb62b-2695-4d17-b162-f1d3fe5ad598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd763005-d57f-492a-96c0-4f77cddbb6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e67822-8a30-4f4c-bbee-f2491539d156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0045d957-a2aa-4d24-9a09-f14e3dcc995f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99dd94c1-7f1f-4f7a-b4bf-dd8bd64bdab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f77a78b-4554-440f-83ff-51cf10b1648c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e2a629-5183-4670-91f0-25908451e77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9158cb44-c975-448b-9acc-5565d977fa5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b31da6-24c9-4a12-a477-539bf9075efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbae45a-1453-4191-936d-098f5b11e22b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef9bb1c-ba9d-4883-b1b6-19578a1ead38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71609668-e538-48f5-9d11-f8ba15077477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dddab193-e8c3-4142-8ced-6397296c3170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e241e67-6dce-4461-9243-b8548f36e0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cecabeb0-78a3-4c1d-b9fe-a7e52a2ca8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef22ced-5f93-49e2-b48a-6312a6d1202a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0e9964-a7a2-4d45-afeb-a9b94336ea9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5e1d90-8fb2-4980-a01d-ddd515af5aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1920b0c7-6e11-45e1-9532-a259cdf0e1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 060d4430-f51b-441a-b4c1-1ed8ddd4f9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b7de71-3285-4b0d-9032-9f81773f6fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8a769d-6981-4af7-b42d-42f7d79d98ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81305b24-6470-4a2c-8d8c-7d4c04abccbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e72efd4-4bc3-4f8f-b66d-1ebe33f16f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ad213c-c6f8-4dd3-91a7-94723eab9758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7cc9fd4-229a-4650-a912-e676048a1b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06480ff7-a9db-4a38-9d9e-ad52b5017635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f25bd5-9d52-4cb4-a1d9-63657506cdfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522ddc22-b559-48c0-a80e-a8a79a85e27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13979e1d-abe6-4040-bc27-e8ca197ebe67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4515a2-6770-4494-96ba-07912dd60a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19e26d8-8232-49d5-9fb0-545df334cbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 122d1d9a-9e27-419c-a9c0-9c0e88264e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 639c4a22-c0e5-494d-9b54-046ef2ffc91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816656c8-71de-412e-8e3f-c8d5a8b72675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae8a9f3-3e61-4016-99c0-5ab49c370e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21326036-5d4d-4e92-8691-166118169497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e88c50fc-236b-4766-bfe5-74e8e0b3be6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bd8952-a9b3-477b-aacd-8aa2d28d7b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f46d1a9-18d1-457c-ba93-349385315af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac87a139-3f76-41c9-9d2a-ccc921414b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111f38bb-2895-4a99-be7c-46f905a8ab59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11d7679f-787b-4b08-bc3c-68ddda6f791a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cda91dc-8c75-417e-86e5-ed0b72c849f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f33722-63a8-4245-b1f9-fd9365d4e512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e554d7-5ffb-47d4-9bfb-fa1efb7c6fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f1929cb-7af6-4260-9150-4a2fc0fc810b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4f74b3-a76d-437c-9f87-15a8dc660e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dd4c8e3-62e0-4f41-884f-f73f12885798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22fc7b7b-1b79-4ec7-b5ea-462667818e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a51952-0ce3-4f8b-aeb6-c2603afc0810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e13bc3-831d-4da8-8947-78c9da88011e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a1f330-556b-42a7-a16a-29339cadb845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2473c905-52f3-4d80-b361-9f280964049a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 659314af-d7c7-4071-a982-d8c39a11b752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c595111-38ad-43dc-940d-528db017c1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9bd90a-beaa-4fee-8f91-cf37b4daaf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4138cf76-fa52-40ca-81ec-ac762f79e4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3d63e0-88ce-42c0-9293-597e05798b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f81f41a-7f32-4a1c-abe0-d30ae42bdbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b6646a-f89b-4679-b415-e6fe13f50da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6fb7e4-c2e8-47f0-876a-34067d22dfc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb65c174-a360-4d97-86e3-3c049dc9c5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ecd02d-4dcb-4cf4-837d-17486217537a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859dd82d-45a6-4ef8-949a-827312e94863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b40c9a-c205-4dd0-8f21-10a2c54e8174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dfb4e1a-46fd-4b4b-9ca2-2961605f13ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7896ce4a-5e96-43a9-8cb3-11c97edc4380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c654614f-f883-47f9-90a3-3f889be7d6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a1de784-8594-47c5-9e0f-7992370a6d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b591a863-1725-4238-ba59-340352e77517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8110cb8d-cd22-41e9-89f2-c16ae4b41679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae9e40e-d0b6-42ad-906e-5f4754f8890f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf29182-6eec-41c5-bb90-ca662ac9d07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5bef846-3692-401c-a214-0180065c76e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0f5939-17eb-45da-ae4d-00925dbc19aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bb79f0-1b05-4c72-99a9-cb8d5164f3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c132a96-2ab5-4760-8a38-72380c5c12bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829ce764-d144-49c5-b280-29fcdda91ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec116d0-20ea-48ea-8a18-d15c0eb8edc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d629831e-d695-48d6-bee5-7ea826a1e322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a22d60-9b55-42d7-b1a3-d482fb5f8a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ef0305-6107-4d80-bd52-fe574405c422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43b0240-74fd-46a3-a6b6-8120ba3d7879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 139755ba-7d90-43f4-851d-6daac8ff6350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3495e5dc-1804-4a91-9a3d-88c551d10755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235f9880-6c24-412c-8327-6bb063aba74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c54d6e-c0cb-40fb-add8-0867b8f8dbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786f4f73-632c-471f-8c4b-ee562cd68433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383e8d25-144c-480d-a818-b05001497df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 670b5ed5-b18e-4d17-96d6-99fc958f3de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3dbaa01-a79d-4da3-af30-be0ae4c97523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb5a901-ec23-4b14-bc20-6eb0b4213f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb892b2b-abbd-4a93-992c-512dba663afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaea13ab-17b7-4a0e-88e3-7d6c7755ca5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3db777-9601-43bf-917f-cf4818cba992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0cd5a5d-5897-49b8-a917-c491a0fd95f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d93d53-8d28-4705-ba39-1978405dcf45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6422d390-9754-41b9-90b1-fb0c101d287c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47efa929-b4ce-4fbf-b458-d265a426d04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8192029-eeb1-4d9f-807e-ecc950f56aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b3a4a2a-1f19-42ee-a00b-3823b891e146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa94a10b-cfc9-4767-95d1-049d0551a30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e1e93d-5616-44d4-b4e0-b5a869495280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e982fdba-47c7-44a2-8cda-cba5a8e6ed87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb363ab-e0d9-45e8-8eb7-0011bea8444f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17bf087-1e0e-4d53-ab6d-9bc9f86040dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1956f75-84d1-4262-a6f3-a285ec851ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891f8937-fac6-4e8e-8788-000d8af8e1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376ce3df-10a6-4aa3-96a9-aac53b3c9f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 142bfac1-0b9c-46da-85b4-dd3d0783068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc14a06-8da2-4ff1-aa57-64222753369c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38b57de-32b5-4175-a8ca-ac45ad755fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0ef7ac-f88e-44e1-bec8-f23479e48e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a9a47a-b1f3-4b64-b1be-9a6e7921dc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3f6ff7-82ef-4fb4-b97a-9a1dfb4c3105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c800a0-994e-4439-9f87-c3d56592ba8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1621a171-b998-498e-af7e-49785c329b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04a7be7-b5f7-4097-99d1-d57688fcf810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdaffb76-3761-4270-a403-d937ad015c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee4af8d-f4f2-4c69-990d-e4374802c2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0578784a-95d2-46e3-bafe-4846ebad822e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595d938e-701b-4d76-8970-c00ed27700df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba37189-4899-41b6-aa79-ceb3b84a2656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9ef054-4aff-4b9b-8ac6-c344aac5eb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8442ea1-20c7-4c0b-ab0c-c82ecb3a2c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6b42f4-e578-42b2-ba11-f72f8776d972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9116a60-b931-4460-9d75-b9169440c44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65eceefb-fee4-42a1-a91f-4e07a56aba8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2afa34-aaad-4dc0-bca6-6de23c9d85dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d8ca10-fa66-412f-86b9-b277e4740746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acaac3f6-2b6e-46af-bca8-afcccb4902a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d1df1d-7549-4d05-819f-50c1a1b1f2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b17ada-f62e-4d1e-abd4-707c9ae97693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1abc084b-f535-493e-a7b3-58fc6d0026d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b00391d5-bd49-4756-ab4e-f95415ed8368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded9e906-911d-44c2-9c47-1fcacd2052e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06721c53-d478-4354-ac86-60c8caaf0105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b00114-e1ac-4a48-b0ec-5c5c82e34a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb43054b-32e5-4e39-a419-d212b45f3567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b76831e2-ba5a-49ba-8b50-8664983fac23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f9878f-2c94-4854-9de0-5e5c1bbe15b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78368501-356e-45e4-9b79-ebb34cbae1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50812551-39b0-40a8-aa25-f8e06324d802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5da89d7-36c7-4479-9119-a7833c9ab366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 596abe4b-1536-4827-ab35-b819b12248ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ec7a4e-7c8e-48b5-87d4-d68168214090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd10f0f3-bd5b-469d-8154-eeefdab67c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7242306b-c5fe-4eda-b007-b29a08c89ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12bcf6f1-cdfe-41a1-bf1d-f11447829bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8af055-4242-48c2-9c23-925fd382bd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7513294f-2c17-423f-a849-781b99e95930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae05d783-3a4e-4d71-8e74-37b3cfdcae80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85818cf7-7089-4109-bd98-bbd2129b261e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce6b697-4440-47b6-b16a-cf7a51c50bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff7b966-da3d-45d9-a840-ba535a2644ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 890b4823-6ed8-4b6f-9de4-fcd80ac9c589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28deb146-ab73-4c9f-a3cb-5da3bc5bba49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87c338f-a233-471e-8dfd-641b23426556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50278f91-ea34-4055-83a3-e909a222ca23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0b9bec-d529-4ffc-8091-96574d201e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31e51e9-7744-4d37-9c84-3ff0e1731558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd43c2ac-43ca-4a7a-bfb1-8b0de5238447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2000cf-7331-495c-aa34-fdba225d554c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18e349ba-95fc-49fa-b66a-e84a9dce966b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f3dec4-dc42-428e-9c88-bc6b8be592cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1df676-4cf2-4926-943e-e3b7689ef886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec79bbc-fb2e-4961-a7b5-1f518085b0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4806ff4-d74e-4ca2-93a0-b1c6131fa658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af17a5af-83cb-43b3-8dea-d2f2670ef7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b416325d-58b1-4ceb-82cd-a87fb1f97fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 763f2c35-22ee-48fe-83d7-00a54054b192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f969ea4-9953-4add-85b0-69ba7a368b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad634ad1-4897-42f1-a961-61b469d1a03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15868aa1-a17f-43b5-88fe-7a009e770a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f6bd0a1-f2ce-4d36-a21e-08ed085f2daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae4ea701-5ce2-42fb-8fe0-2f0cdb0e5509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af45e522-0084-4c4f-bf51-30e5d6994cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1020b3bf-6819-4363-a625-5fc643fe2765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539b82ed-47b5-4dfc-a924-485ce0648a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb88221-19c3-4526-ae54-b403aba156c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7e657d-3e62-46cc-8f8e-b92d0664b3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a83d54-4635-46c6-bb0f-10162886ae79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd0c20d-cbc9-4272-a572-0d0d9b8d79fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91557c40-fe98-4c4b-be9c-fa7f6bf9f619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48190d9b-1f91-4bf2-9716-75be8ee6bce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7207780f-f3c8-4265-b651-fcc03f17c05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31b51e5-a3c2-45ba-82c2-24a919a73327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b5f0eb7-f2a2-402c-8f4a-ea06d3c2d584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59240a72-b4bf-46ee-9635-32722de0db95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5b7706-c909-4fd7-b00b-d07a01d09c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f108ed-1b35-4777-94dc-ebf7f3b81b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e897e7-3ed5-4db0-b4b4-d2312cdee825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 907c9948-2f5d-449e-922c-73651f844d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06011616-522f-45d5-86b2-30fd2a72736f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4917c5ca-2af8-48e2-a0ed-39c8efc1ee63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737c7e1e-7228-4a94-b912-64e0629a301b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eae632a-dda1-4553-a877-ba4d0d9e403a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f01ca5ad-f30e-4c58-92e2-3c25ec148c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd63448-9cdd-4bc7-9b70-7ebd542475f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b4c59d-e1db-4ba2-beaf-70af4fd44f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a55d9e7d-52f9-48b3-8237-f6777f039ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f44b53-bc95-4e14-aa0d-6fe55528f543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de51d185-8394-4fbf-92bb-52ae77257026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ed5b5a-d787-4f50-a306-a7790001794f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c038f0-0c89-4212-b78a-153bd6784dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5b68f7-ce08-4e0b-b6d1-f41f1ca0c5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358f8571-47ca-4aff-b1a4-b85d92b71672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9472597-4c42-4b94-9821-99310e970b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f3c24e-6b2c-4c55-b8c7-9c8d5da07ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01e3dcc-7023-4349-8d94-e6fed76b5999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feba6f24-ea2f-4fde-990b-365f4cea9f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c780d9-01e7-4377-9214-867710ef41ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adcd5295-7c24-4bcc-a9fc-27a86ed66017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a19984-946f-4979-a767-e4293595592d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf0609c-fbea-47ec-98a2-14332e57a410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68aeb8e8-f832-487e-921e-7d2717e9e15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c86ccdca-3b25-4ff8-a227-ba2bd55f856c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a18dd75-43a5-4c50-bcfd-0965e234c97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba023135-3b6b-4fe4-a4c6-cb31dc767c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0208d80-b7f9-4e0b-b21b-521befee5151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ca0030-3616-4555-9c14-960c4c113324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee62b8fd-1600-4a32-b399-8932df193918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2045610-f83d-41a8-b18e-2e024a0bd1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622861b8-9d01-4751-9595-88c78a68fdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b1d10e-718d-4918-8959-e03564eb68ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f081545-ec74-4c18-a7f5-a6837d214d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a595ec-d96e-4278-96bb-b22cd1f6a787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3b119b-b5b5-45e9-8ce8-ee9e82251151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2cf2d43-4a6e-44f7-8fe3-9fd0ad3cfd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5800f93f-71cb-4c3a-9e51-7ab337a296e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a599de4-1180-422b-a2c8-b63545c11f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76209745-874d-4fd2-bd6f-48e293c01b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5645b48-2287-46ea-9edc-477f97189614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c4d555-1109-4a27-b303-291c96fcb628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552e5509-c4ae-4ec9-9720-dab0f8767c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e793a119-1a8f-4f92-bdf3-0e35c91c5825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5841acd6-d92e-42b2-a6e8-47b8646ff5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d425dcf5-8cf4-4fd1-ba8b-dabc64d06e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f03f3e76-1b77-482d-befc-2414350c65ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1278446a-97b0-4ba7-8035-b4df420e1986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e5f73b-240c-4cfd-8ac6-5072b42c152f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45875c5e-22a6-4752-93cb-db6177fb2fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562ca72f-9f17-4c71-ac07-20aa0af50128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00fa13c8-133e-43b3-91cc-dd47e19a46ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ee221a-2e24-490c-80cb-fad367cb7d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23992550-94c0-4e77-9d41-2f1c9ee7f54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93915708-0148-4859-a24e-66b42a9c40fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d8b972-fc02-4f1d-a803-dc5312120cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423b63b5-8edd-4548-a55a-c573f511b648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdfe6ab-015c-4ebd-b5c2-ffe66992aa66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49967a1-9729-4f73-a5a1-df774276dbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03e985f-1e3d-4e94-a0f1-4d2b555545cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb31c6f-7c00-4e42-9cf9-c2857e06b8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5733fa9a-1202-4927-b842-de4088af6cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4f36322-c5a7-4956-9448-507cef568ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31431e8-c4d4-42c5-8641-0cda64d37602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b431fd4-71da-4df1-b32b-a2ac4bd550e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6048b759-2d39-4dcb-a3dc-de46563fc242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547177ee-2e53-48b8-8212-a968a9b39c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdcb5655-51f6-4429-8d32-15190c9e0608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23624831-ff2c-4f3f-990c-50307d0e33fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee7d778e-4c82-4ea6-9c5b-1054b5eed42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bf2adb-b05e-4ee6-853a-07837829bc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823b31e9-24a2-4677-98e0-a4d35b250b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4112d5-8ed0-4a25-b6f0-5aff6b7c43dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d392acc-07b8-49f1-a4c5-ffa4453e2a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1bb32ce-d364-4dc7-bfb3-2b90bb56dba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009e7e86-c43f-4e64-9f8f-71a19e3e7807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b5c777-99d1-44f0-8ef3-dec09b99567d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714e56d4-09fb-4073-8bb3-34cca59e345b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb9b68a-141c-4a29-86a6-90efd2ae7bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c5e3cd-2124-4fe5-aae9-2948be4538a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b8d4a71-6cac-4fd4-88f5-3e2982430197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a425b1-18f4-4620-bb17-088cce86d3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 400f75ff-1399-48ab-a639-4152b38ac8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f228106-fcf4-40af-9b80-bd1262a5986a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc239e85-10fe-4233-9ab8-cfb365060697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d670ddb7-795f-42af-9093-5085d13ea4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab346a6-c5e1-49d3-9322-62582ea2ccb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 833f7ef3-2398-453b-ad75-bb5db1e33b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01efb073-31a8-4c58-b5cc-f60d39a9bb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be1ba4b-cae2-4997-873a-0cbe7e4457c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018b18c9-1888-425e-85a0-2c3d1f26b621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e2e1ce0-228f-48ba-ab51-01f1f0195c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74143fcb-427f-4cb9-b0bb-49abe0b95bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83cdc85-14e8-4601-b680-b516a6b61e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39c0b8ef-2c00-45bc-8bca-ecdba59c669b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c57e9d2-ca80-4152-bb8e-2e654b766e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f67ab3-668d-40ec-b902-b51997c87760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2003ef38-ab99-4fa1-8429-f95b9ba9de9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd928d25-b644-4224-af70-598002a7e661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09011167-b530-4080-bfab-c64b8acf7ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d29dad-8600-4c22-9b44-127a96719313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44dd3339-183a-443b-9bee-9a267f67cabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac0b09a-d745-44e7-a908-0d0b4e65cb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3214fd38-7bc2-4ccd-a51b-b527bd5693a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb7618d-4201-4d80-b178-a3d240c24a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085ca5f8-bf78-4665-8159-15e213b8f51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d958c9d7-ed89-45a8-8c7e-3d65ddfa9850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d75a52-fa80-4af3-bdb4-e0c6c22b0bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a4824d-1596-4fe6-a413-400228ed1ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fc3ffc-d0be-4018-bae9-8241a1b4a00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11880721-608a-4373-86b3-74a75fd95340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62686cd6-0c0a-4a82-8ae1-4700cd1d6181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97dc5c6e-038e-4c73-b6b0-aa404110b3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6816da68-3ea4-4b87-9399-dabd2996fd6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31108bd-420b-4cbd-85b1-26d92c9ae25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ff48060-e8df-44c4-ad41-80202ac93557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8504e421-1f49-495f-8a0c-32fb13f1e617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b920cf4-5110-4479-9be2-b51a81cf752f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa79737-ae3c-4f06-acf2-81c6c264ec55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0322e3de-1d42-4757-bc85-31160773be0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07be7853-3346-4287-91dd-9378188cac62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ac963d-3361-40a7-819e-a81c5166e721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594e9a4e-baa6-4205-8e6b-aa83f369823e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd8be3f-b24f-441f-a59f-4c1de5098c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee7bf5c8-b476-41dd-8b27-31b8e47c0da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c39fff-659f-4556-8170-668a0d0136fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7211d39-990a-4547-9589-30b14fa618f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6bda00-684a-4b0f-a76c-8cf5a01434d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb71454-456e-4d67-892d-7f385f9f5d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b623415d-3f98-44ae-a0fe-a267be5cdab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdedeadc-34f8-46b1-862d-dc97a64d2146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b64d55-34b5-41cc-8677-2b04d4bd5b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8368eea-a9a6-495b-b6b5-b30cbf46948b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3d596b-2781-4fa1-b147-08eb316cbab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21712e5d-0fed-45ee-adfa-cf2a82f5d395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cd30e7-de8d-47a0-90a7-c882e6bddb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83239e1d-a689-4298-8566-924500998e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04853382-0ab0-4c50-871a-90dfea090570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfb92dd-2045-4304-878c-d698e3b606c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d05adab-645b-4b4a-beab-91c46c12eda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da802be4-ae1f-4bb5-844b-c3f1220cf427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cc4d23e-3fc3-440d-9f74-126d0a78502a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c0ed49-855e-4f75-ba36-85c5b3cadd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 268ad424-d619-4a9a-b815-f85d1c36a282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9293c86f-a447-4d1b-8949-ebfcd463b850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b020948e-d56a-4741-b09d-fe726d19cab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acd4a3ab-ee06-43ef-bc15-3735d30fb458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d58543b-5d82-4eee-aff1-dfef934313a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78b5a985-b7a6-4f26-a846-fdcf5d0ad25e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8db40811-f87e-494c-bf37-635af6b417ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd480a9e-fa6d-4702-aca2-e008119af92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c98ad59-8fe1-435d-9ccc-2c209c1e3dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b50f9a-fb6e-4cb0-9d22-c21feca684ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4cef4f-9c7f-4e79-84ee-58368259ae21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07817439-1a91-4b9a-a669-0a94f6ec7555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0a6018-8078-4e8b-9a37-d95dc374c2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15ee8bc-25a3-48fc-9842-0bfb96b3b4f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80610084-6e07-421f-91e6-7f60c2c34c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03325b82-3a10-476c-b7f2-ae4da2a3b913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb523fd-fa86-4812-b144-bd39305968c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d338759a-46ea-4200-a90f-3cf6574c26d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79715063-ad1b-4dd8-b08d-eaa2abe15de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdaa234f-3361-4fc6-8b4c-2fd1043f7226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6797a6e-8d26-4067-8642-aaef0d9a68a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc224e1-d54c-4f79-97e8-3d510f9c857d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e855a4c4-ad8a-4c2e-b903-0a6d3a7cc38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5973af-23cf-45df-b49c-80a7edbb89f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1acca0b5-e00a-4b24-9047-c2709435c809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b24030-aef2-4ee8-b917-a70562750587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4952e6f9-ae3e-4261-894e-cfe2161e2b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01d3322-3db7-4a2a-b8af-aa25ef12c7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ec1006-72b9-4e74-9f4e-6a68b9129a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b64aa65-4082-401b-a3c4-efe62c5da7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc24339b-9a04-46fb-96f3-9d35bb0772e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247a5cad-2f2b-42a6-bb17-9b58b5c46eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ba19ea-4329-425f-8a19-25fc9e7cb18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0890ace0-2da4-457a-ad4f-487f1d943ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ffd4b77-f4df-48af-b385-8cb3584a9ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c247f123-7408-4d66-a926-b322d657181b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c44a4c2-fa72-4e3f-baa5-4b7fa8f0581c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f865def4-fb02-402a-b7c6-2b3ec10748ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3dd0a8-f25f-43b4-b60f-dbff70f93e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c46a66-52d4-4fac-aa0d-89cc86c0c491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5023f25d-4497-4b84-ba10-6116f5c3c94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bade6a9-9cc3-41c8-ae41-b8707e5cefce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234ce60a-f965-4609-acfb-820bb3b3962b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59595556-361f-4be0-8c1f-4b80ef76a3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fea127-44f6-4805-afae-a8f855dd850b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aed3bee-3443-4398-b7f7-df36f975f89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070f22c1-ad87-4d75-a9aa-3b695f7142d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd720159-2284-4c05-812a-e37b71916c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b152d0-68f3-42f5-af96-a247d2cc001c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0451adfe-75c4-4c77-b7e1-648c1bbb8e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5998745-bde2-49a7-8524-8af5839e867e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf31007-237a-4c79-a7d2-dd7b52a2c715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02838856-d329-4996-8f1a-8cc2f1d00bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13278ac4-2227-4cab-853a-0d7bb21f7ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57450292-d7bd-461c-b38e-2aabb3b4e72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a8faad-b604-4730-b983-ce799f7b6cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35859af0-ea7a-4c4a-9599-c1c86ac72dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b2b889-1dfb-4fc5-bb3c-92586250e2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8179fc1-79a4-419c-b05b-ad778043b550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a5f4f55-16e1-404c-9632-6c5bcbf06473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3107e0c1-d285-43fe-954d-804803714c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfba7906-eabe-4524-a179-14252d908048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852d00a6-9d96-4c84-adcc-88a457170c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d52f38-ab59-4d90-97fb-f40a468129a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68478fbc-6d33-4bdc-95e7-31f8d009d023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c69f7140-dc72-4b84-a0fd-9c57fc62dc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a594c2c4-9a56-49e1-8698-04a062ee6f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95730a91-ffe0-4b31-826e-ee225a3592d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78c4bb31-b100-4598-88d7-22f5d17cf4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de4e0e0-51ab-46ca-9a08-5bd0e4794d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33dcd51-934f-45cc-b137-c87797ff9538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75406df2-5324-4799-af1a-209630757e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1019fc96-97c8-44d4-abdd-befa1b91648f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af4eea2-66ab-4314-957d-7f61014a338e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 866e1f55-c048-4087-89be-8f7250b38f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9915e932-2751-4df0-a352-c4ec4629f857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e457276c-655d-493d-be3b-8799ef8bb745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0617bb0b-be10-43a1-bf2a-51ddd5b92e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb39611-c1df-4542-8458-592f0abf4f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fef0ff-a80f-4be3-a5e5-65c6ace59e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ef1eb5-3e37-4ce3-b3e0-889484a2077f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c18a31-4953-44a7-9d63-be1e6c16668f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cffc3bf2-9fe8-4c9e-aef3-ee0ded066d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080f61fc-0f79-4314-89bc-c2fe605ffc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab78090-809e-4405-aa28-088a121627cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80db323-a266-4c3e-b743-f5f24993e984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b736faf7-abea-43e5-85db-2405759c9706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087c3a02-89c4-4e4c-9196-bc93d5ae1e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c56f59-b371-4bf0-94dc-cd05a408f8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd670be-d934-4580-89ee-5c3650fff84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db2ef236-4043-4d7b-bf37-c67b1ee58970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18b9d3c-6928-461a-a104-cc7372682429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5058e8ea-2b20-4b08-a9a3-7272b005812f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353e1cc4-4ff9-4340-b5d2-5f77950f0c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcab46d9-30ee-4038-abf3-7e11b1644482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c089c51c-dd13-43a3-b6ff-d73d3757d8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa5b949-a2ff-4913-a42d-0a8fff99ccc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c420e748-c37c-456d-804c-22d54ea250f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a875e7-385b-42cb-9d23-9852ce2f6a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee5d1f3-218f-4431-9f09-4d2200983259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc4a3ab-caa8-4b25-8d0b-1f54a538a6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c73936d-309a-4711-b3a5-ab1a9d12b467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb6fade-1ca1-4af5-af12-3d911e93cc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e33481-289f-44aa-972b-5b823833fbeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a2618d4-1e86-4c85-ab9f-de78ded2756d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fdea46-d8db-423a-97a1-97c494d79f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5e6447-a36c-4708-927e-eddb4a170bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1973e318-9057-4ae0-9cae-3eb07c6a5d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7796e572-edfe-4943-9ad1-3ca63d2e695b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bd82ef-6e41-414d-8391-3f7c91bf18c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1ccc45-0ee8-4d97-93de-e8b0a5e7300e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d98bb9-1fb7-4d41-9939-00026376d17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8956bfd6-3c97-4c67-ad4c-42c9c7682636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb6ada2-9b2d-4537-954b-8c9a645b12fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 765742c5-2c0b-48b5-91fc-f804f8c43e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bc438c-a0d7-4197-8851-40b169f71a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8411d5b9-042d-45cc-b92a-2a9dc58c6d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78b1e18-aaa7-4ad2-bd95-245ceaf2b42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf573f28-2661-41f8-a80e-edfece1157fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d7828c-619f-46f3-a6b0-f7a1b627836e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453914a6-c215-4dd0-9b46-f3e4e3d4f9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d49d53-ae25-4f13-81f4-ad7b62b0b02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df807ea3-28d2-41e6-ae17-f771fed4c94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7428dacf-cb23-44a5-9873-76488c9408de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd15229f-e999-42ae-b9da-6ee8d940474e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1e3d6d-60e9-4fda-8d64-6da48eab8397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972a29e1-0ffa-4471-ac1f-d9e3df52da4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 398f7aa7-68f7-40bd-969a-19239a8b4eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599d0913-b1e5-4be3-90d9-ec68d57b493a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068b6040-aac5-491a-afbd-fbd2cdd9df13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1765d6c-9297-442b-8623-3325ff0af258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc78c1b-33a0-4554-9ecb-59fd47edd48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0126debe-60d1-44e7-9bcd-bbddb6d2408a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33ea2ae-7c9a-43ca-b468-3959807258f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7aaf00-2091-45f2-a2d4-6543217f8347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcea914b-16b2-4a33-9e81-3b6d6217d218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777d893c-cfee-4875-86db-54da910682cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4608e8fe-8ac4-486e-9988-34f0626c121a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb10c4f7-3be3-449f-8e2e-4b517082cf2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1765aeda-94b2-4745-b15b-809a6823ec0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e310bc5-51c1-445c-8c16-b6b60b656f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28298346-57e5-450d-9088-74eef1c6858b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a4ab91-6894-47db-8b8c-bfba25cb0c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a81d8f6-6f6c-4f75-8824-e2df30482bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858be8b0-34f2-4f64-8b3f-9fd61a5d5a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f74e10-abe5-44ac-a897-03d4e0996801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dacaa27f-e9fa-474f-a558-f99dfaf2ad69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e334cd-a661-46ea-af8a-6292f8a49b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0865fdab-9345-41cb-ba21-bcaead275ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcc82b8-7395-4af0-809a-1e2f7ad37908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e12cabcc-fb21-427c-a3dc-0e9cc7a7878c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d684b7-a4b7-4891-8f10-d47733a2f233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a81380-5a42-4f88-9d66-7c23fd010e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e193c8c-fde2-4bd4-b9d7-2f74dc154185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f2f672-093b-4e35-b0bd-206c584f4dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8477d9-a1c5-4c24-870c-1ea7bdde865e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 935363c0-b9d1-4831-b9f2-643f7eee25ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d1e280-1bad-4125-94a7-d3ef8ae00373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f213aea4-ec44-4c55-9ae6-920d0587ccf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c0cc785-0a51-4ea3-9387-5032e6c1ba89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10ff055-d294-41ce-bc44-de27c3d130c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e19b67-c9df-4a63-a5dc-7e81290c4ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61bb809-d476-4bbe-b611-43b3dee4c0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b06f31a-fa42-4eed-af17-af53cb5dc628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be628c2a-c422-4ee3-970f-28d36e68dee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7333aaef-3d55-4a43-b13b-93d2a645083d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3481791-8201-445f-b7c1-411a5ae0f72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf2b927-5023-4e3f-ac9f-65145d8992a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75b7f8f6-cd42-48c8-a906-d18c1f088206
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(3505, 24), y=(3505,)
   Test:  X=(877, 24), y=(877,)

⚠️  Limiting training data: 3505 → 800 samples
⚠️  Limiting test data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2384, R²: -0.0006

📊 Round 0 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2410, R²: -0.0131

============================================================
🔄 Round 3 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0885 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0804, val=0.0874 (↓), lr=0.001000
   • Epoch   3/100: train=0.0810, val=0.0888, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0794, val=0.0887, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0788, val=0.0884, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0775, val=0.0888, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 3 Summary - Client client_18
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0073
============================================================


============================================================
🔄 Round 4 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000250
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0800, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 4 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0061
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0019
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2401, R²: -0.0063

============================================================
🔄 Round 5 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0867 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   • Epoch   2/100: train=0.0795, val=0.0866, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0792, val=0.0866, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0791, val=0.0866, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0791, val=0.0866, patience=4/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0788, val=0.0867, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 5 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0034
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0017
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2393, R²: -0.0013

📊 Round 5 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2392, R²: -0.0009

📊 Round 5 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0005

============================================================
🔄 Round 10 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0793, val=0.0875, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0792, val=0.0874, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0791, val=0.0874, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0791, val=0.0874, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0789, val=0.0873, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 10 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0002
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0043
============================================================


============================================================
🔄 Round 12 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0816 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0812, val=0.0817, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0811, val=0.0818, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 12 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0043
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0133
============================================================


============================================================
🔄 Round 13 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0913 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0788, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 13 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0028
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0057
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2388, R²: 0.0008

============================================================
🔄 Round 19 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 19 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0021
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0087
============================================================


============================================================
🔄 Round 20 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 20 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0038
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0070
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2387, R²: 0.0019

============================================================
🔄 Round 23 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 23 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0014
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0042
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2387, R²: 0.0019

📊 Round 23 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2387, R²: 0.0019

📊 Round 23 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2387, R²: 0.0018

============================================================
🔄 Round 27 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 27 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0007
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0024
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2387, R²: 0.0017

============================================================
🔄 Round 32 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 32 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0023
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0054
============================================================


============================================================
🔄 Round 37 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 37 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0018
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0025
============================================================


============================================================
🔄 Round 38 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 38 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0004
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0080
============================================================


============================================================
🔄 Round 39 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 39 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0040
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0141
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2387, R²: 0.0015

============================================================
🔄 Round 43 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 43 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0004
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0047
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2388, R²: 0.0014

============================================================
🔄 Round 48 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 48 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0034
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0059
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2388, R²: 0.0012

📊 Round 48 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2388, R²: 0.0011

============================================================
🔄 Round 53 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 53 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0023
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0145
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2388, R²: 0.0011

============================================================
🔄 Round 54 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 54 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0028
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0026
============================================================


============================================================
🔄 Round 55 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 55 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0026
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0053
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2388, R²: 0.0010

============================================================
🔄 Round 57 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 57 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0037
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0025
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2388, R²: 0.0011

============================================================
🔄 Round 58 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 58 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0008
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0090
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2388, R²: 0.0011

============================================================
🔄 Round 59 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 59 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0010
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0016
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2388, R²: 0.0010

============================================================
🔄 Round 61 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 61 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0015
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0122
============================================================


============================================================
🔄 Round 66 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 66 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0015
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0005
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2388, R²: 0.0009

============================================================
🔄 Round 71 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 71 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0038
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0075
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

📊 Round 71 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

📊 Round 71 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

📊 Round 71 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

============================================================
🔄 Round 78 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 78 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0007
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0088
============================================================


============================================================
🔄 Round 80 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 80 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0031
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0068
============================================================


============================================================
🔄 Round 81 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 81 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0014
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0217
============================================================


============================================================
🔄 Round 82 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 82 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0009
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0068
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0008

📊 Round 82 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

============================================================
🔄 Round 84 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 84 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0004
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0034
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

============================================================
🔄 Round 85 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 85 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0022
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0045
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

============================================================
🔄 Round 87 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 87 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0016
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0023
============================================================


============================================================
🔄 Round 88 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 88 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0015
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0096
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0007

============================================================
🔄 Round 91 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 91 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0004
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0150
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0006

📊 Round 91 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0006

============================================================
🔄 Round 94 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 94 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0022
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0045
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0006

📊 Round 94 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0006

============================================================
🔄 Round 97 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 97 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0035
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0071
============================================================


============================================================
🔄 Round 98 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 98 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0030
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0227
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0006

============================================================
🔄 Round 99 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 99 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0007
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0162
============================================================


============================================================
🔄 Round 100 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 100 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0009
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0037
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0006

============================================================
🔄 Round 102 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 102 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0003
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0095
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0005

📊 Round 102 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0005

============================================================
🔄 Round 106 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 106 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0011
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0007
============================================================


============================================================
🔄 Round 107 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 107 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0009
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0021
============================================================


============================================================
🔄 Round 111 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 111 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0018
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0176
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0004

📊 Round 111 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0004

📊 Round 111 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2389, R²: 0.0004

📊 Round 111 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 118 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 118 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0007
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0021
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

📊 Round 118 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 122 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 122 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0025
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0058
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 125 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 125 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0005
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0123
============================================================


============================================================
🔄 Round 128 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 128 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0003
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0217
============================================================


============================================================
🔄 Round 129 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 129 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0026
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0458
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

📊 Round 129 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

📊 Round 129 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 133 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 133 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0023
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0042
============================================================


============================================================
🔄 Round 135 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 135 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0042
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0109
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 138 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 138 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0014
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0149
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 140 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 140 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0008
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0120
============================================================


============================================================
🔄 Round 141 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 141 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0040
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0104
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 143 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 143 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0013
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0003
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

============================================================
🔄 Round 146 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 146 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0029
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0062
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 148 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 148 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0024
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0293
============================================================


============================================================
🔄 Round 150 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 150 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0050
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0106
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 152 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 152 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0015
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0009
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 155 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 155 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0030
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0003
============================================================


============================================================
🔄 Round 156 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 156 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0027
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0120
============================================================


============================================================
🔄 Round 157 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 157 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0025
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0142
============================================================


============================================================
🔄 Round 158 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 158 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0016
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0122
============================================================


============================================================
🔄 Round 159 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 159 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0012
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0006
============================================================


============================================================
🔄 Round 160 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 160 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0024
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0044
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 161 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 161 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0006
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0017
============================================================


============================================================
🔄 Round 162 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 162 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0005
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0082
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 162 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

📊 Round 162 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

📊 Round 162 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

📊 Round 162 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2389, R²: 0.0004

============================================================
🔄 Round 174 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 174 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0017
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0031
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 176 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 176 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0041
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0128
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 179 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 179 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0012
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0783
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 179 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 185 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 185 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0003
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0098
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 186 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 186 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0012
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0254
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 186 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 188 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 188 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0042
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0189
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 188 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 192 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 192 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0025
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0047
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 192 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 197 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 197 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0004
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0080
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 199 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 199 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0032
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0058
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 199 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0001

============================================================
🔄 Round 202 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 202 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0012
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0013
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 202 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 206 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 206 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0009
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0267
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 206 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 206 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 206 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 210 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 210 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0051
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0160
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 213 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 213 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0027
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0047
============================================================


============================================================
🔄 Round 214 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 214 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0034
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0085
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 214 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 214 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 221 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 221 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0015
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0355
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 222 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 222 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0004
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0048
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 222 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 222 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 222 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 222 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 230 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 230 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0003
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0046
============================================================


============================================================
🔄 Round 231 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 231 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0013
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0040
============================================================


============================================================
🔄 Round 234 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 234 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0008
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0217
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 234 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 238 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 238 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0003
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0106
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 239 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 239 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0044
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0018
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 239 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 245 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 245 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0025
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0055
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 245 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 245 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 245 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 245 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 254 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 254 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0012
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0164
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 259 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 259 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0016
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0017
============================================================


============================================================
🔄 Round 260 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 260 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0048
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0021
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 260 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 267 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 267 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0027
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0014
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 267 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 269 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 269 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0082
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0189
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 270 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 270 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0017
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0056
============================================================


============================================================
🔄 Round 271 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 271 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0009
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0001
============================================================


============================================================
🔄 Round 272 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 272 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0026
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0056
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 272 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 272 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 277 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 277 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0022
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0023
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 277 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0001

============================================================
🔄 Round 281 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 281 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0032
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0077
============================================================


============================================================
🔄 Round 282 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 282 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0007
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0049
============================================================


============================================================
🔄 Round 285 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 285 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0009
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0068
============================================================


============================================================
🔄 Round 286 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 286 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0004
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0036
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 289 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 289 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0023
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0032
============================================================


============================================================
🔄 Round 290 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 290 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0001
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0506
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 291 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 291 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0033
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0081
============================================================


============================================================
🔄 Round 293 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 293 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0003
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0768
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 293 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 300 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 300 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0030
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0080
============================================================


============================================================
🔄 Round 301 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 301 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0067
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 304 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 304 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0023
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0136
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 308 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 308 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0013
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0089
============================================================


============================================================
🔄 Round 309 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 309 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0010
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0012
============================================================


============================================================
🔄 Round 310 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 310 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0023
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0024
============================================================


============================================================
🔄 Round 314 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 314 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0026
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0067
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0001

============================================================
🔄 Round 317 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 317 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0038
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0100
============================================================


============================================================
🔄 Round 318 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 318 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0018
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0108
============================================================


============================================================
🔄 Round 322 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 322 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0007
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0018
============================================================


============================================================
🔄 Round 323 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 323 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0006
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0020
============================================================


============================================================
🔄 Round 325 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 325 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0001
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0071
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 326 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 326 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0003
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0044
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

📊 Round 326 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 331 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 331 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0012
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0143
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0002

============================================================
🔄 Round 333 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 333 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0011
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0009
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0002

============================================================
🔄 Round 335 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 335 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0086
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0118
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 336 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 336 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0047
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0163
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 337 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 337 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0027
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0038
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0001

📊 Round 337 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 337 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 344 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 344 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0011
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0143
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 344 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 348 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 348 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0035
============================================================


============================================================
🔄 Round 350 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 350 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0023
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0121
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 350 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 350 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 354 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 354 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0008
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0126
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

📊 Round 354 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 356 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 356 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0001
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0047
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 357 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 357 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0002
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0057
============================================================


============================================================
🔄 Round 358 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 358 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0055
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0275
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 364 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 364 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0017
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0005
============================================================


============================================================
🔄 Round 365 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 365 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0026
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0260
============================================================


============================================================
🔄 Round 366 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 366 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0033
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0115
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 368 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 368 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0010
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0109
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

📊 Round 368 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 372 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 372 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0006
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0016
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 379 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 379 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0006
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0031
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

📊 Round 379 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 386 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 386 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0014
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0092
============================================================


============================================================
🔄 Round 387 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 387 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0016
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0008
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 389 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 389 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0135
============================================================


============================================================
🔄 Round 390 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 390 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0017
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0270
============================================================


============================================================
🔄 Round 391 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 391 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0014
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0248
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

📊 Round 391 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 393 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 393 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0003
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0022
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: -0.0000

============================================================
🔄 Round 395 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 395 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0017
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0196
============================================================


============================================================
🔄 Round 396 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 396 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0001
============================================================


============================================================
🔄 Round 397 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 397 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0161
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 397 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 399 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 399 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0049
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0007
============================================================


============================================================
🔄 Round 400 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 400 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0031
   Val:   Loss=0.0847, RMSE=0.2909, R²=0.0089
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 403 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 403 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0032
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0029
============================================================


============================================================
🔄 Round 404 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 404 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0011
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0014
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 404 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 408 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 408 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0046
============================================================


============================================================
🔄 Round 412 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 412 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0010
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0012
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 415 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 415 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0022
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0059
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 417 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 417 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0018
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0041
============================================================


============================================================
🔄 Round 419 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 419 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0003
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0051
============================================================


============================================================
🔄 Round 424 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 424 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0039
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0219
============================================================


============================================================
🔄 Round 425 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 425 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0014
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0246
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 429 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 429 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0003
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0020
============================================================


============================================================
🔄 Round 430 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 430 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0050
============================================================


============================================================
🔄 Round 431 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 431 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0005
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0008
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 433 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 433 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0029
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0200
============================================================


============================================================
🔄 Round 435 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 435 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0042
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0233
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 438 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 438 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0038
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0125
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 439 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 439 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0011
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0043
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 440 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 440 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0011
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0012
============================================================


============================================================
🔄 Round 441 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 441 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0004
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0153
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 444 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 444 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0009
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0028
============================================================


============================================================
🔄 Round 445 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 445 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0001
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0025
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

📊 Round 445 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 447 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 447 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0010
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0006
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 448 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 448 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0037
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0037
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 450 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 450 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0016
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0296
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 450 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 453 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 453 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0006
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0265
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 453 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 455 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 455 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0031
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0044
============================================================


============================================================
🔄 Round 456 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 456 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0007
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0000
============================================================


============================================================
🔄 Round 457 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 457 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0024
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0055
============================================================


============================================================
🔄 Round 459 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 459 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0001
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0136
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 459 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 462 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 462 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0022
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0293
============================================================


============================================================
🔄 Round 464 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 464 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0016
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0029
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 464 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 468 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 468 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0034
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0218
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 468 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 471 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 471 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0025
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0005
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

============================================================
🔄 Round 473 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 473 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0017
   Val:   Loss=0.0676, RMSE=0.2600, R²=-0.0361
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0000

📊 Round 473 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0000

📊 Round 473 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0000

📊 Round 473 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0000

============================================================
🔄 Round 480 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 480 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0001
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0030
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 488 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 488 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0016
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0098
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

📊 Round 488 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

📊 Round 488 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 496 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 496 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0022
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0328
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 497 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 497 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0003
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0134
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 500 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 500 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0004
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0018
============================================================


============================================================
🔄 Round 501 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 501 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0023
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0063
============================================================


============================================================
🔄 Round 502 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 502 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0010
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0077
============================================================


============================================================
🔄 Round 504 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 504 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0010
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0138
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 505 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 505 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0015
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0100
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

📊 Round 505 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 508 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 508 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0038
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0227
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0000

============================================================
🔄 Round 509 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 509 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0005
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0024
============================================================


============================================================
🔄 Round 510 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 510 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0000
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0032
============================================================


============================================================
🔄 Round 512 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 512 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0011
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0073
============================================================


============================================================
🔄 Round 513 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 513 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0052
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0084
============================================================


============================================================
🔄 Round 515 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 515 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0016
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0128
============================================================


============================================================
🔄 Round 516 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 516 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0024
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0072
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 516 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 516 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 520 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 520 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0006
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0201
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 520 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 520 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 524 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 524 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0021
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0098
============================================================


============================================================
🔄 Round 525 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 525 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0000
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0023
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 525 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 528 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 528 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0005
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0021
============================================================


============================================================
🔄 Round 531 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 531 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0013
============================================================


============================================================
🔄 Round 533 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 533 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0003
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0035
============================================================


============================================================
🔄 Round 534 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 534 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0002
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0150
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 541 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 541 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0014
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0142
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 543 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 543 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0015
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0027
============================================================


============================================================
🔄 Round 545 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 545 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0029
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0156
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 546 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 546 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0028
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0165
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 546 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 546 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 554 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 554 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0029
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0304
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 554 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 554 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 559 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 559 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0018
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0015
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 559 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 561 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 561 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0044
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0137
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 561 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 564 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 564 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0020
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0015
============================================================


============================================================
🔄 Round 566 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 566 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0009
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0065
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 566 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 573 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 573 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0014
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0085
============================================================


============================================================
🔄 Round 574 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 574 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0011
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0013
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 576 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 576 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0017
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0145
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 576 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0001

============================================================
🔄 Round 583 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 583 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0002
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0043
============================================================


============================================================
🔄 Round 584 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 584 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0022
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0094
============================================================


============================================================
🔄 Round 585 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 585 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0005
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0039
============================================================


============================================================
🔄 Round 587 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 587 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0014
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0024
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 588 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 588 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0023
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0112
============================================================


============================================================
🔄 Round 589 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 589 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0000
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0021
============================================================


============================================================
🔄 Round 590 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 590 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0002
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0046
============================================================


============================================================
🔄 Round 592 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 592 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0023
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0055
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0001

📊 Round 592 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0000

📊 Round 592 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0000

============================================================
🔄 Round 595 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 595 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0010
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0002
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: -0.0001

============================================================
🔄 Round 597 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 597 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0025
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0008
============================================================


============================================================
🔄 Round 598 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 598 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0003
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0054
============================================================


============================================================
🔄 Round 601 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 601 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0034
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0239
============================================================


============================================================
🔄 Round 603 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 603 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0011
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0151
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2391, R²: 0.0000

============================================================
🔄 Round 607 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 607 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0018
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0092
============================================================


============================================================
🔄 Round 608 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 608 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0018
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0091
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 608 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 608 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 612 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 612 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0003
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0023
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 615 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 615 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0019
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0006
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 616 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 616 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0030
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0029
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 619 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 619 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0016
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0076
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 619 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 625 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 625 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0021
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0309
============================================================


============================================================
🔄 Round 628 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 628 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0009
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0007
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 628 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 632 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 632 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0003
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0029
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 633 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 633 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0016
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0027
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 635 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 635 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0043
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 636 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 636 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0004
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0019
============================================================


============================================================
🔄 Round 638 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 638 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0045
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0028
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 638 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 638 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 638 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 645 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 645 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0032
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0177
============================================================


============================================================
🔄 Round 647 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 647 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0030
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0282
============================================================


============================================================
🔄 Round 648 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 648 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0156
============================================================


============================================================
🔄 Round 650 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 650 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0008
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0095
============================================================


============================================================
🔄 Round 651 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 651 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0009
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0416
============================================================


============================================================
🔄 Round 653 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 653 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0006
   Val:   Loss=0.0676, RMSE=0.2600, R²=-0.0294
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 653 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 656 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 656 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0027
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0136
============================================================


============================================================
🔄 Round 657 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 657 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0241
============================================================


============================================================
🔄 Round 660 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 660 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0005
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0034
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 664 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 664 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0015
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 666 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 666 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0007
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0168
============================================================


============================================================
🔄 Round 667 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 667 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0007
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0062
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 667 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 667 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 667 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 667 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 675 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 675 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0022
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0027
============================================================


============================================================
🔄 Round 677 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 677 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0032
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0072
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 677 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 677 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 677 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 677 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 677 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 687 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 687 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0004
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0003
============================================================


============================================================
🔄 Round 688 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 688 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0018
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0035
============================================================


============================================================
🔄 Round 689 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 689 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0016
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0078
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 695 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 695 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0031
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0037
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 697 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 697 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0007
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0014
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 703 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 703 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0004
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0003
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 703 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 709 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 709 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0020
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0220
============================================================


============================================================
🔄 Round 710 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 710 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0006
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0011
============================================================


============================================================
🔄 Round 713 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 713 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0003
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0000
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 715 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 715 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0031
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0018
============================================================


============================================================
🔄 Round 716 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 716 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0001
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0098
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 717 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 717 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0004
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0139
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 719 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 719 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0022
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0031
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 721 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 721 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0021
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0318
============================================================


============================================================
🔄 Round 723 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 723 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0016
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0075
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 725 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 725 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0012
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0027
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 727 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 727 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0000
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0030
============================================================


============================================================
🔄 Round 728 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 728 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0015
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0007
============================================================


============================================================
🔄 Round 729 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 729 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0026
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0104
============================================================


============================================================
🔄 Round 730 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 730 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0011
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 731 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 731 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0005
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0048
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 731 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

============================================================
🔄 Round 735 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 735 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0009
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0218
============================================================


============================================================
🔄 Round 738 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 738 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0045
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0238
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 739 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 739 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0021
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0058
============================================================


============================================================
🔄 Round 740 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 740 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0019
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0001

📊 Round 740 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 744 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 744 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0037
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0138
============================================================


============================================================
🔄 Round 745 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 745 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0020
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0063
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 746 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 746 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0019
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0072
============================================================


============================================================
🔄 Round 747 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 747 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0033
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0094
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 748 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 748 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0025
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0107
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 749 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 749 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0001
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0439
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 751 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 751 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0000
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0094
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 753 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 753 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0019
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0096
============================================================


============================================================
🔄 Round 754 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 754 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0003
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0024
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 754 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 754 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 754 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 754 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 762 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 762 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0027
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0069
============================================================


============================================================
🔄 Round 763 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 763 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0021
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0006
============================================================


============================================================
🔄 Round 766 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 766 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0003
   Val:   Loss=0.0697, RMSE=0.2639, R²=-0.0164
============================================================


============================================================
🔄 Round 767 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 767 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0027
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0174
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 768 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 768 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0015
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0183
============================================================


============================================================
🔄 Round 769 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 769 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0010
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0045
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 769 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 777 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 777 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0004
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0124
============================================================


============================================================
🔄 Round 778 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 778 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0001
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0012
============================================================


============================================================
🔄 Round 779 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 779 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0027
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0071
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 780 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 780 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0033
============================================================


============================================================
🔄 Round 783 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 783 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0011
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0076
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 783 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 788 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 788 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0032
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0671
============================================================


============================================================
🔄 Round 789 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 789 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0013
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0026
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 790 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 790 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0017
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0007
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 792 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 792 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0019
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0086
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 795 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 795 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0022
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0005
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 795 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 798 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 798 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0010
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0022
============================================================


============================================================
🔄 Round 799 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 799 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0020
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0031
============================================================


============================================================
🔄 Round 800 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 800 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0029
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0084
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 804 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 804 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0001
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0054
============================================================


============================================================
🔄 Round 805 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 805 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0035
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0112
============================================================


============================================================
🔄 Round 806 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 806 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0005
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0042
============================================================


============================================================
🔄 Round 808 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 808 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0024
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0060
============================================================


============================================================
🔄 Round 809 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 809 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0019
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0009
============================================================


📊 Round 809 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 811 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 811 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0001
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0049
============================================================


============================================================
🔄 Round 812 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 812 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0001
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0099
============================================================


============================================================
🔄 Round 813 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 813 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0005
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0047
============================================================


📊 Round 813 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 813 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 817 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 817 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0034
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0214
============================================================


============================================================
🔄 Round 819 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 819 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0015
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0018
============================================================


📊 Round 819 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 822 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 822 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0007
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0000
============================================================


📊 Round 822 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 822 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 824 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 824 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0013
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0024
============================================================


📊 Round 824 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 825 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 825 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0027
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0105
============================================================


📊 Round 825 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 827 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 827 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0005
   Val:   Loss=0.0688, RMSE=0.2624, R²=-0.0009
============================================================


============================================================
🔄 Round 828 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 828 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0039
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0142
============================================================


📊 Round 828 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 831 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 831 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0025
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0038
============================================================


============================================================
🔄 Round 832 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 832 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0029
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0089
============================================================


📊 Round 832 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 835 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 835 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0034
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0150
============================================================


📊 Round 835 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 836 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 836 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0001
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0024
============================================================


============================================================
🔄 Round 838 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 838 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0014
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0076
============================================================


📊 Round 838 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 840 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 840 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0009
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0040
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 840 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 840 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 849 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 849 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0005
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0015
============================================================


📊 Round 849 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 849 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 849 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 860 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 860 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0011
   Val:   Loss=0.0821, RMSE=0.2864, R²=0.0030
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

============================================================
🔄 Round 861 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 861 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0013
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0011
============================================================


📊 Round 861 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

============================================================
🔄 Round 863 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 863 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0006
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0013
============================================================


📊 Round 863 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

============================================================
🔄 Round 864 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 864 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0001
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0006
============================================================


📊 Round 864 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0004

============================================================
🔄 Round 865 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 865 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0014
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0080
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 865 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 865 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 865 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 865 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 875 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 875 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0032
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0084
============================================================


📊 Round 875 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 875 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 875 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 881 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 881 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0032
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0061
============================================================


📊 Round 881 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 883 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 883 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0014
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0017
============================================================


============================================================
🔄 Round 884 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 884 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0024
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0119
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 884 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 886 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 886 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0015
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0127
============================================================


📊 Round 886 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 888 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 888 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0004
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0164
============================================================


============================================================
🔄 Round 890 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 890 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0012
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0150
============================================================


============================================================
🔄 Round 891 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 891 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0022
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0075
============================================================


============================================================
🔄 Round 892 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 892 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0024
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0043
============================================================


📊 Round 892 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 892 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 897 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 897 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0002
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0037
============================================================


============================================================
🔄 Round 898 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 898 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0014
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0049
============================================================


============================================================
🔄 Round 899 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 899 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0019
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0066
============================================================


📊 Round 899 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 900 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 900 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0015
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0216
============================================================


📊 Round 900 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 901 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 901 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0007
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0070
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 901 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 903 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 903 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0008
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0042
============================================================


📊 Round 903 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 904 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 904 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0026
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0288
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 906 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 906 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0023
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0120
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

============================================================
🔄 Round 912 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 912 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0068
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0031
============================================================


============================================================
🔄 Round 913 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 913 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0011
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0049
============================================================


============================================================
🔄 Round 915 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 915 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0002
============================================================


============================================================
🔄 Round 916 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 916 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0023
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0076
============================================================


📊 Round 916 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 917 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 917 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0010
   Val:   Loss=0.0662, RMSE=0.2573, R²=-0.0219
============================================================


============================================================
🔄 Round 920 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 920 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0019
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0122
============================================================


📊 Round 920 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 925 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 925 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0001
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0117
============================================================


============================================================
🔄 Round 926 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 926 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0005
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0022
============================================================


📊 Round 926 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 926 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 926 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 930 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 930 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0001
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0030
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 930 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 933 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 933 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0001
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0008
============================================================


============================================================
🔄 Round 935 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 935 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0022
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0110
============================================================


📊 Round 935 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 937 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 937 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0019
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0043
============================================================


📊 Round 937 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 937 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

📊 Round 937 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0002

📊 Round 937 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 943 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 943 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0011
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0148
============================================================


📊 Round 943 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

============================================================
🔄 Round 945 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 945 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0015
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0137
============================================================


📊 Round 945 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2390, R²: 0.0003

❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
