[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57e0a767-b476-4f89-9300-a0565c2d4471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5a76d1-d0d1-4b93-ada7-027ceb782c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78435525-d437-4a5a-82ab-b85a1163c223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2682318d-5fc5-4952-a23b-950f39e352ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944b0dfc-84e5-4047-b696-488f8b833060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4ba061-732a-4602-8450-9e686d7ea847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a801fd-fbd6-40bd-970f-b052ff4aa066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5745982-a6b4-49f7-8908-f4df128ff3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b4c8b4-3ae6-4d5e-8ebe-4d63d3d77970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc052529-92a8-4683-a3ab-bd4b6b1c11b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6a5c3e-b459-430f-8bc2-928221a569b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e11225-f42a-4fd6-b5f5-8a74b80626cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be87b917-f3c2-4046-aab4-c11f6dd0dd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ff4d67-fdd8-4954-a76c-42ef010692e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2757ff-3f11-436a-bc03-0430c04dcc22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1cdcda-08da-469f-8f2a-6189fa1cffd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530aacba-4658-4bea-85d2-2eb1753df43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1dc981e-e775-4538-a2c0-a40c0cb054cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3fd48c3-ee2c-44c0-a407-e713ddf13dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea82365a-c37e-437b-b5f0-3d6370ce1e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630cd61d-fc38-4cfd-9814-9c2634a35eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349a8e3a-0139-4e02-b9a5-abbf683845dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48920cc1-b853-45b6-90d9-734f7d97b48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0438619-9c50-400f-9d92-80cc526faf83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076c78cb-cf99-44f1-828f-49aab571a7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f6e9074-2de1-404f-80e9-cc9858115ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae26b6e-0260-46fe-83dc-c9bc9f74ce80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8182234-63d1-4d6b-bfb5-78055fde22a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0644b9a5-4eb9-4399-b949-b940c333d55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39f8b6a-eb71-4445-8c99-13c63615eacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884dbef4-61a0-406b-a844-90feba4154ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c190ef-0c51-42dc-a9b0-e1afc5c5f9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6237356b-d787-4bed-8d77-2d7fce18aeb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136c9c39-2134-41d0-a1f8-d922eef4ed78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061dabdb-13b8-4977-a38c-d5f902d45336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f39411-0db3-4d5b-bca6-bb90d158fe3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19ea89d-7414-459c-bb93-27c16fe4eb6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2356cff7-7e5b-491b-8028-0cb2bc37aa45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa9c96d-dbc6-4507-9596-9f9460ecb40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08f620c-fcea-423d-826e-d40915ad2f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d59d83e6-f09a-4e22-a8ad-4b5be30819fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b0675b0-49a1-4f62-99af-dd7a39ba1b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd08948e-8259-43fe-bca0-4b0e6c25ac38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd63829c-7e2c-4caf-a436-12f69c076473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1512249b-b6fa-4a4a-9988-58c21be9d24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23dfdb0d-ef6b-4274-ad52-26fc259c01f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3627b8e7-8cd4-4283-944e-5d11dd72dccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ee8646-030d-45bf-a83c-25c7aa48d9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc5a9cb-94af-44a7-9ff7-6de4336055af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1c68af-9e80-44d9-92b9-8de7e52f7688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4a9902-369f-4330-81fe-f885ab8903ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e93583c-3dad-4c2e-98ce-bab42ee897f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8670795-11aa-42da-bb63-fd65c9245b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab01443-a17f-400d-8552-809e72bc4857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948f82bd-8805-4c69-b99e-2914b64a971f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5df71fe-6f16-4fc8-b0f3-255dd87fa826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19df634-f45a-4a70-aef6-203741b1c890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95fb8176-ad3d-48cd-9227-6844c7ce2136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13dc1b8a-1712-4b7f-902a-8e2cddc93c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb176999-dd60-484d-b1c8-bb10bc8e3956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f332aa-a3fb-4b0c-8837-3a313c972e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654c94e9-247f-49e7-8012-cf78b387210c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2ec5b3-bb43-400f-a63b-99ab7b0b7831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1664bda8-821a-4d0d-b5aa-32a51ac2d181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950ba1c9-cf27-49eb-a559-0c58435443a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85be8e16-dbc4-48b2-8603-c0c33030a854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d188dc6f-2ff4-40fc-966c-0c1c6c1ec436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1156ce9c-f893-44b7-9134-b5159e281bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de332dac-88fe-470b-a305-4d8473b50239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 957adc17-540a-4311-9267-c6a122163af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2dd865d-f342-4b1a-87a1-12d6ab9c3e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101f9256-d223-4de3-ba61-b90c38e1c5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 735a579e-6198-47d5-ab4c-4c56257a515f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd63eafa-8034-4924-9ed9-cbd3070e2c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a80fb37-a4c5-4dfd-b0b5-d0dc03bf6638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73de29e6-e0b3-45d3-adfa-e77b3e4fe7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d075e5e6-0e7f-4301-82b8-5be41ffc886d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10646013-236b-4797-b0b0-b108659760ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cb2d04-8df9-4bbf-bd34-b7bb1dfcd6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f97c225-683d-4c43-a1de-a07c335f4d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85e2f88-891d-4ce9-914e-b322c2297b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3e38a0-bd85-44ae-b4ca-9c8a41116a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 593d278e-76c5-4946-89ce-15cecc9a43e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d34da66-25ec-4f79-b898-228792156645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 398763a9-1db7-4cbd-939f-1ccfc6c96f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550e35b7-e7e8-4617-9c9e-adf4dc646726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38347cac-ec32-4fbe-b267-e9a677ae4521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3384eb9f-8b2b-4fdf-92b4-2c53edf794da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010ebfda-ab1e-421a-9672-20d68f74faa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a72a841-0327-45a2-b9f7-498faa475cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba392663-4448-4e40-82f1-3bc5a84ee537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81585147-7955-4861-b470-edc47fb5f0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72635662-9bd1-441d-a8c2-3116eb178646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60856907-d3f5-4409-bd51-7c252ab346ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68fcc74-2fd2-4a12-885c-4924b481856e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9c08fc-70b4-41da-80f4-38f03dc8a952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c05954-7888-4cb8-a964-ce846eb0f5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec3eab2-7d25-4876-8965-c25a79b4239b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d52f5ce-3b76-4134-aece-063ea95805d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ac1058-29dc-4c71-b8e5-8eb798b05a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c4ba1f-f863-4d94-91b2-c128b10d4a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e1b1d3-afa8-49cb-8a48-8353bfe3f0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db682292-4f4c-4a92-b48a-63d73f45aaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027d722b-58f2-4867-9cb3-74928cb9ed7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5086d2-195e-4340-9381-6528bc08fba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60c1e1c-8af6-451d-b4ba-3e6ac1ca959a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c0b33a7-e0f0-4819-abe7-969535d0a715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40ec364-d6d0-4763-bb2f-03ec1b8517bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 949ac92d-c9f9-41d3-b6a0-356c07c96b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a4a5ca-43cb-40a2-8a47-09bd14c140ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6d3113-6217-4cc5-a5ba-ed003ffc6fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f33792f-00b4-41b5-95ec-5ac7648929f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feda9b79-d9e0-4088-a78e-47b387d10470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1fb1cbd-2073-4d49-a118-b997d45e8366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b2a06d-7096-4991-83f1-b48290ee4527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8619d7ee-5083-4a63-945e-67b9b4efafd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52248768-948f-45f2-a619-aa54e31fbf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad958ea-8eef-4baf-8cf3-46ef720788ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d808da89-5cf1-4488-bfcd-0e82da5d878f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ad42ba-7c34-4662-993b-6e75dbf15639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message babb5552-1b2e-4a2e-bc99-43ed867923bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a873db59-8ddc-417d-ad2a-5ed954b22247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d474125c-d614-4b22-bc08-26c27340743c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6283de78-a9c2-4b61-bea3-cba55a6acbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46639c65-59f2-4c29-ab80-28116a02e6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d5aea6c-ad75-4944-a1d4-3d3171c0ed8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40f09f5-6260-4d19-8728-4712f13fe037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4679cc-9c2f-40b9-adc0-9d4100215cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a6d0085-8f2e-4fab-8cc2-7899502b60d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e701e071-2de2-4b12-be90-c71e8f3e66fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a897f13e-d563-4d9a-b235-384350d22214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364f707a-e3cd-4ce6-a742-9a2a2722b4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88766054-d8e4-4c71-90f0-9ec683ed3337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b845adc3-b075-47ea-960a-9a190f7e254f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43667eb0-3fa5-4dfb-951c-da1bd1a4716c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb8bf01-cd9f-4d27-b79c-9ff2791a1226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33db6448-6ab7-44f8-97a1-6f2220f333b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23587738-fcb1-4ae3-9dfd-d54d39bf85dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc52c6a7-91a2-46a2-8970-13b062ec52c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73bf964f-a33a-4ff3-a4ac-2f92e2d975a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456014c5-1def-49a2-9e80-5cb3a4b5d067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df3f4127-0a25-4acb-8b21-23cea39530ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246b58f2-2fd5-47e4-8dc7-21a4a4a60345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b37b06-5c2d-41b2-bab1-190a127e1792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003f48ce-a202-474c-8bfa-4d35c200dea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ada806-e610-4f9d-8757-69782aa75dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d20401f7-5e3b-4719-8370-26bc7aa360e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35af6afa-7690-442a-b5fd-3cea76556949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f57587-7e6a-48a4-a5e9-1a80ba599941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d92e913-c7ff-4c20-85a7-6fb9df62010c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9770bb2d-44e7-4ded-adc3-92614a15c2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976ab80b-8067-495c-9964-226580f1ebe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8b8217-f61b-4734-ac28-dff622896ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee06750-c583-416c-88dd-25a2cbb18e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1f51e5-1ec7-4d0d-bcb0-4e3fbdb80185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8386c0a3-503b-4d47-b153-0f8dbdab7b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b7f275-2b1d-466c-803f-46b4ee3c906e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e60509-03f8-4d0e-940b-8cdd6aad5ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffb5945-48fb-46c4-ac6b-885b0d1beb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e150998d-b5db-4b4f-a540-1edd17a7cb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc75c99-fff1-4d1c-b64b-80d6baab4684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 512db756-3c83-45f5-9eb7-329010509365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344317a5-3347-4fad-9673-2a78ec8ea8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1598844e-3d59-4427-be08-e214a48b8235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb85ae8-9a46-41dd-93f7-58e27ad54674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a383ed02-a6a7-4f96-9d2a-7f37abb45339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0803a01-9377-48dc-90d9-9d821b781b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8394d0c5-587f-4971-9fee-cd1fafb2e622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be65736b-47ce-44ce-bbfe-6e95f951dbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b0e5b8-fe0c-4a97-82da-38a02f7b6e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97621f94-8350-49da-86c1-581956a956e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961a0e07-3e3e-44ce-9f83-e83663065f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2505457a-b5af-4027-be23-0c5f4d6949b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c91da8-a724-43f4-8852-2821f20dfd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba71de3-85a1-42f0-9e1b-b85eafe7a080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddc7004-632d-43fe-882c-d0f80caa93b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 407e5df4-3f77-41ee-a9f1-38b1de89097c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1847cc-ccd9-444e-8ee5-480bef258f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb71cf0-970b-47eb-aef5-992199c966a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2044f0f0-024d-43ef-bfaa-e018d630ab6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e9cc5b-0c6e-4ef9-8284-68b696a0cb35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e163e22-cd59-4cb6-a1eb-f9b6fce96a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4acc4381-c2c0-4cec-a66d-b042beecb6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5c453d-51cd-47d8-886c-3bc613648072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6712a918-2f6f-4b2c-8009-86ba0b6669b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0795a729-e946-42dd-92e9-3c7156201471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a50416-2f1f-451b-9ac6-1c058b628ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e762dbb-a889-4189-863e-dd7343609938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f65aa79-1ac4-4ab4-b9e0-36bf2cf75c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc640bbb-dff3-4353-a6a1-a4c673b04bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a294ada7-5a87-4530-bf1b-d08831744700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fdd5c91-eebd-4550-bb70-64cb483a883a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d49e63-dd04-4529-ad12-cb5c229cd447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db73baff-ca4e-4d6b-b8dc-da9dfe88b60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759a19f0-283b-47a2-a9d0-78f002225ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0924fbb-4879-46f0-ab5d-a0ea9bfcbeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4029cbeb-475f-41e6-ad83-8bb67d7b9e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54db3286-c7b1-4179-a560-8f65df43430c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a59a358-6d78-46ed-b6fe-413101f5c788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a088fd-193b-4219-83f6-c1e554ba16f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67dc3b0-f089-4d1e-8af7-321ba6178db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49270f12-b99b-4535-99f0-833cc6d2268c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441f482d-d6b3-4fbc-b70e-fda3065e5f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5baef5-95ae-427f-8b34-203321d40991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a909636-b975-485a-9474-b23e49ec3c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 342ecd3c-736b-44ca-b925-6c56cc0b7ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d548b33c-bbb4-4a61-99af-c0a8b5333e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d1691f-6c88-45c1-b969-33f4be80d450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cca41a-86ba-49d8-892c-a5d10a255f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c4c28e-3714-4290-85e5-297c32461b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9500649e-9109-475b-9321-bfafb93d29a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2cd21f-6b24-4986-9ffc-242047ebf3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64615ec0-083e-453a-8a42-00fa67a729a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d1ed19-e07c-4cdf-a6db-3cc224f1b7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af3d64b-45be-4592-89c5-c5abfdd9665c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1176e06f-0c2b-4cff-80a4-ea805faf1e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2393c9a6-851c-4034-9287-886d19bec7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9024a639-2a3c-4645-9916-fc6f17dbd1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49116711-7f9f-46f5-bb3e-55d650e7c9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826cccb4-bdbc-413c-bd45-e7899d1c57f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed85dcf-06df-4e6a-bdb6-64d9382f1b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6e7db8-734e-4108-a305-12c649de8656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a7e55f2-ad76-498c-84e5-f86ea0047ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f6ce785-495b-4deb-86c6-42efb739c53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61c5687-d022-41d5-ac3e-64d72d177b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d2c841-009a-4d00-8101-9402662cb5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351c0dfe-1724-439c-beaa-59bd471ef3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6876f22-daf4-4b9a-96fd-453486101bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9dcdab0-17f5-498a-8114-af05f77b7c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d9ed7e-178f-4fc7-8e19-1b2d34a1eb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826575cc-232a-481a-8ff6-4cfc217cc191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c2eb9e-e664-4046-9a3a-3ed936919b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9aca830-dec3-4aa9-a87f-c832d78a18cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f66ce882-4b4e-47f0-babd-279b960f6f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b99217-4dda-46af-bac6-3caef3347b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da090f10-0f0b-4978-b3d1-6376fc08cd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fddff17-523e-4acd-a3aa-79fb17ceac44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca68125-9a70-4bbf-adf9-a9bb06be0a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2059f928-8b06-426d-b76c-01e62b599fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a7375f4-353a-463a-8d99-fc91e0279291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb7975a-5808-4747-baef-09b843efe2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb0e745-89ef-4184-8d89-42ef80acf660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5defc298-6527-44ac-926b-ad1fbdd1fe9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b62ab5c-0d50-4a2d-b685-9225d2cfcfea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18531cde-84f1-4ade-ae97-65b6fa594e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b641c969-57b4-4470-ad40-c66afd0837fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023253d7-ff29-4d54-9606-d43c968edd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 202338fa-10d0-47b7-b252-cab92d22830c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f9346f-d927-40fd-bb34-338e43716310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b43789-4737-4e89-85fd-21baf4be1af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac7f655-581f-4681-9225-3bf2ef9a4ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d578fb2-a51b-4ddf-974d-ee2b9475f123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3635b4-8c3e-4e03-8abc-f6b7ddcb5578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8612bd8c-4209-4bcb-80fe-374d3d4fbe6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5e4f8d-ec4c-47d8-bdbe-2b0396c15c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28c0d92-fd3c-49f1-be97-931c1dce6bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd0f151-3cf3-4aaa-87dd-325cafa14531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5866985f-e6c6-4ad4-889f-b93df902656a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a8e2aa-ffbd-4a44-8a0d-5d55c0b378f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa5ee64-8e00-421f-a08d-b180bbfd9005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70d0e76-47af-4524-9229-d8e6fd0a1c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c84b5d31-14ef-4b9c-b026-e4aa181c2cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bdf7cd8-4e99-47db-92c1-25e8b2cf2beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c38cbf6-907e-49eb-8642-428f47ad528c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad35f8e5-8671-434e-b9d9-18785affe73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ab6ac8-61f3-45d8-ad6e-d7de8e2b7f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c6c6c3-cea7-4106-aea8-5fc6dbd3794e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d0eded7-0dc7-4fb3-a965-342c7290252c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263f65ac-25e6-4d63-9064-5d1e3752879f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd295082-6873-4907-986b-ba1e6defb7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff46b80-42a1-4fd1-b2ef-d120400ac5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a857178-fe1e-431a-806e-1bc3651dd8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc9ddf0-b34f-4900-98e0-2b1695294e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0f1b1d-d011-495f-8967-e0f30ca2207e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b68e40-752f-4597-86e8-ce30b40c2abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2d9127-9205-47d6-904a-2802505be02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2beda3-ec47-4368-a12d-3e3b46314332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749e7292-4efa-4491-8cb9-6c24d29529b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a8171fe-b038-4f74-9682-fcb05b15901f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e12085-c1b7-4d75-91bf-e2e9082f1550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604cf219-1101-46cd-aab7-4ae900db54b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7283f7ff-fd34-4367-bf21-d0af5b974488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39cda102-4b48-4813-999e-2c35c2d1df69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7884fd0-542e-4a5b-9912-00143c81e2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41a11a4-690f-4233-a6ab-d5e38381f35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e4cdf78-95c4-41db-ae43-4feed1dc19df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2216f953-20ad-4c81-836e-4a17af0eb916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c392422c-e8a7-44e0-8996-cca92554aa8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b964f825-a70b-467d-a7cf-291ac56c7765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba17774f-bef4-449d-9f81-63650df13d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c22a13-c78d-4c18-bdfe-02d844a669bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311e843d-240c-4c6b-8ee7-1846b03b1060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af0107c7-6de9-4a90-a8d6-7bf30a7e0e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33df00c0-8f79-47b3-83a6-d0de01a93180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8011b3-7118-4c77-85d7-4514a8067882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b11bbe59-0f6b-4593-8e48-f61aecff7ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d818c97-1890-45ef-a6ff-8bc35063fa62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7880cf09-edee-403b-8d72-c1c304579bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19dcfe06-1a36-4966-82f7-b6618c995e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9fbe46-5b69-4a8f-a61b-af0c82009d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbf7ad9-e4c6-4302-a732-37cfa2c75548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aed1de6-f963-4228-a161-4301a7a2ec6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94f606b-9759-4c4f-a2fc-31c8929e2710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ba7d11-a159-4da5-beb3-038254d7d52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0471afb8-95cf-47c5-958e-4fb0fbb74e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f514e5-a440-4bfa-9e2d-8145c7f1527a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec18d9d2-5bdb-456c-826b-e6f257b8bf63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2621f6-fd5c-47b2-ad7b-3395961096d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6d7982-4905-4ea8-81c1-9a564343d2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d304b6-c2df-4d61-ad63-0c03af03aacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a8e3c1-3fad-4aa2-9bff-a8d4cc4c4fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba84296-4adf-49c9-a714-1a9756039d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b633106a-71ea-4cd0-9b63-3509867256ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a786f582-12e7-49dd-a26f-6854e72b52e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a664d889-afb1-42dc-99c6-9a714f0f855e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4c6566-98e5-4c95-98ce-48dce10ff474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e86129-436e-4547-8eba-d5e468d66da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad053b7-f06c-4ae5-8433-c6443d034df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46486571-0b16-43a3-8841-84b6b356ac1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7abef3c-5d58-4c52-8866-562a4250a399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2462464-9762-474c-9f39-7657008a2816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643b9b37-e602-4ca9-b664-1778616f5f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d9310f3-2a4d-4f29-b4bf-21d6935647be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d98031-77ed-4c1e-bad9-3a8bc4489f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed9a614-e9f2-4563-8a68-44e70541c4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51180a0e-60b2-45b7-b53b-0dfa971da678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3956136d-6c11-438a-9cf0-2e81b3bb600f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26d93a4-682d-4c17-8690-977adc234ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180b1258-7a11-4ed5-b7ee-c38563bac0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd631f7-0f75-4db0-a6bc-5238ad5922fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8968979-8149-4209-a843-790f91f8e685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c5179e-824e-4197-bfe8-f8db5db2f67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 794c6f1a-d8b9-41e8-b3ac-83b7e5078797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed3c287-028c-4afe-8cb8-a5006d0f2229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35002777-59d1-44d5-b3ca-ca6110c2743b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7cee79-56f0-4589-99de-b71f07dda0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d17d67b-dac8-4ce2-a726-b00ac752c4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08b9302-5e02-4688-8b2c-9b7005cd6276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641481cb-d371-4a37-8f73-e5350c69c18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a7bb053-b977-4536-b54b-412665a8bb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3271c87d-12f0-48fb-b58b-0c6b1abf6778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4feb9f0-f754-4c8d-a077-23bb0367d60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cedc38f2-930b-492d-aae8-33a1cef9e55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e1e5f7-d157-43e1-b43e-c1b3c36a74e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a82214-875a-4c26-9c5f-052bd0323cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a6b3041-44e9-43cb-a1f5-7e43a01428d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22318ba6-559b-42f3-92ca-752a7fff2714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4aeccb-d98e-49af-affb-21f7e9edb409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8f0fc2-e602-4772-8ba5-5f9b34bce964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69c7e3b-a051-408b-959b-b82ff2ee767f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a328293-2292-47d8-a57e-2f51c3158d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3b678f-8999-49ff-a204-9691dd525499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1885c82-4c7c-4dd9-91bf-098aea8559fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c66c93-6c63-420b-8e1f-06d0d8aa4468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b10e1d1-f90d-434b-adda-f3130f8c18b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a031e44-e8ad-4b28-9511-d00aded8a2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf1cf8b-fcfc-447c-a9f1-d01a89b68e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0776d500-1bf7-44b7-b799-32b6dc32ac6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77be074d-d6b6-47e3-8ec3-1c6d550e8f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8375ac8d-cfbc-4ece-afca-e7cbdb565c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be4b7c2-fbdc-41c2-9d7e-28a7506818de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37b95fa3-7f1e-453e-a96c-eabf9fcdb503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136a553e-d683-4309-8882-39a83057b5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aec3c52-d91f-4e9c-bd51-acb68d52e384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd054879-1184-4ab9-a588-9f6dfef2cfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a00d796-b45f-4601-80c9-571fd266f740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9ff85e9-532f-4bb8-853c-50b88bf9973e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd35aad-9e8b-4b25-b32c-14ade35a0810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90663a0f-5615-43b8-a87f-53bb360509f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44262bfc-e6e1-4eef-8f8b-11eb3bee4fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0afbc8a-71cc-4b88-b181-773389c44fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c25809a-c12e-459e-adc7-409666322cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfffe349-3801-4a63-ab93-6a24f96d8f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e41ece1-0f7a-43ee-ab9f-b7ffd348fba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fa7c5a-9dda-4fea-ad76-4c6740aa47f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdf24f8-eae3-4745-a74a-9984ed74d07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe636f57-5420-4765-a1b6-9550c3f2a5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63d9bfb-7a00-4c74-98b3-1891890599a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a965ff-8bbb-43a4-bfd6-ca617cd062bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3b4201-cb2b-4abf-803c-bfb874fb142d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf36d1e-38d8-4cca-a69c-fae14bd2d725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a934ba-4384-4e71-8a23-0b01afd71946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34a8e92-fd4e-450b-8cd5-a56edc906e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81557ef2-51bd-480b-b090-a872aae692c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4c79a5-fcd5-4f82-8ce6-1f5096711c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707deb80-78ff-41a5-aca5-d34f9c6ada53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e17113-2b71-45e4-b182-5f3a55bc4e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662bf336-2e46-491a-8945-4ee1b485f89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f7766af-56a8-4ba5-b0b0-3d520ce76651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580f9e97-61a2-46ad-8a2f-f39db94b8487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8ec740-d2b1-4074-bd30-1e168d4d8312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22767d74-8f3f-47de-a5f4-d39ed53006b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfc529a-380a-4e1c-b518-2dad91f6f96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78f24e76-8ebc-4536-a239-f07171458d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6507f40-b139-4bb6-8574-36aa92fb6640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db80d18d-c99d-4608-8718-e93d7e52cca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3253c61d-5a76-4dc3-bc06-393f50c7d487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ba9cc3-43b5-4b7f-9e29-c73a068bc220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6dadd3-5fbe-4ed4-9023-5f2067ca707f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac6e499-b468-41d2-bdfa-a54accc453fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86c5148a-86fa-4450-b408-8f9e9dc31dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32e4890-6352-45ca-87f5-18d16d61e6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d4f18c-82f9-48cd-88d8-8657fa6692a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dfd2415-d4d5-4450-b2e7-e7cec5b59fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa85b04f-d7ba-4fbb-a6bb-78644b8c613e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06755fc2-d7ee-4d41-975b-10461269b1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 511b0834-9e0b-447d-a325-dde6c66e6ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58f6983-c85c-4b2b-977d-d39d4abb115d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7be28fb-49c2-48af-a300-cd222aac4365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37294800-b613-4de0-8272-bd94cbe6c42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f5bbb2-575c-47d4-bd49-6ec4717bf31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1462af1-b3c0-4f2d-ad29-47d632d53092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce30ba4-15d8-4c93-85a5-21e4d54eb8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c0548d-fb3c-4b9a-8dd5-7694a754960c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c66952-aa63-42c0-8e44-64a3ea14c75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a5d7b5e-d376-4f48-a762-b0f15acb8d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d99c408-1e69-43a7-a369-5c239ea5b998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c68d4b83-fe4c-4c1d-a532-1e9444a09b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ebb4ef-bfa5-4aa1-ac6f-b61723fed764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e152d9-08f2-4bd9-8458-9d58232abb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a93a6cf-1269-428d-9526-d4dae37a6081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb54156-14d9-4669-81ca-f03cac0277d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06f8e83-2f32-48e3-abc5-17d9dfa3949f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90dbd768-3c4a-4023-baa8-1a52eb451258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ef1ed4-dd05-43e6-ae79-410ff9b0951a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05eff55-48ba-4a6d-bca8-6d981da6ac0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1286ec43-3ec4-4ae6-9677-8c4350db3e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1408c76-a62f-4334-b094-c63c4a714e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad071ee5-b3fc-4b54-86d3-84c1aaf530c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd784c5-39db-4f6f-bba9-68df2dbfcb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211280d6-7de9-4af0-a70f-ec636abde468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516ca3d1-2df8-469b-a921-732921ef661a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bf5563-1f07-4fdb-99ea-6cf394e43a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5753dc3-aff0-4a19-8f31-6caa314405d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5765ed-30d8-4bfe-bc30-e890db0679f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fffec35e-98d1-4e74-83ee-6c3731d67792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c745cb6-d986-4e39-a61f-642a928d0e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d8cd6e7-c08a-44ab-be81-60465a2e5a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193f0bf1-b6f7-4541-ab93-59391d05ec52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4611649-1e44-405c-b4ee-dc0223bea109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4c4f6b-e3b9-4058-946e-5937b7af5f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7afe4ddb-c423-4836-80f0-0cacfcd78f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01a1e30-0c9c-4c5c-ae91-6b1f34c361bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff817792-a646-479a-afe3-21f4e3d095b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea091e69-bb04-487c-bd0e-a6953cfc8634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f94378-d49c-4844-acd4-7a023c8bd0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1abd4b74-dcfc-4de5-8e35-a7a6e7bd1aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1696e72c-8825-4266-a765-b1221a934851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2296f5f5-8b2a-4494-bce2-a47861369954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b94af9e-6ffd-4733-bb3b-1b685112e54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3fa0a0-2070-4eb3-a6e5-bf10e878e992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649aa83e-f8ea-46e0-aac2-803bdd1f0c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9fdca4-5b2f-4e8e-9ae7-4ec5802eb40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637ec21a-1af4-4734-a0b6-0158bb77be1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b5944d-b5c3-41ea-a0fc-d3e0924ec98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4b00475-4e47-4b4c-9ba7-f9485addb764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae700b1-05e0-478a-ac68-96d65e734485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 355bb545-154e-4670-b19a-d9983f63b619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56dc26d-2d4f-4cbc-8b8e-80cbc50cacf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee46e82-9ed5-4c68-8ff8-f16de70583b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f441a6b-522f-49c5-ba06-1c2ee880502e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40678f9-15d0-4335-b6a7-58df0f2f99f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4a0199-af1b-4a17-8d35-54a7e708905f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b650f6-f055-4eb4-a9bb-5f6b835eae67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db6e205-6325-4293-810e-f73ad9da072c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d026a6a-a88a-4900-88c6-025dd0d9e2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be7cc88-334e-4336-aaea-b536491eca36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea4c6450-0f38-4939-902f-844f83fa4f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7faf5e7f-8596-4152-bf71-60a4019833a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354907a3-05f7-4c9e-b1fb-331c9e872db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa94beab-e864-4568-9fdc-b48062d53998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e6f846-9262-461c-88b0-0b887766582c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e656fab-008f-4c1b-bc11-0ef72d0d0b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ddb55d-3cce-491a-aad3-c8ed8ffc72f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f7f1e70-ffcf-4f03-abf3-3e3686fbe801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911795f7-c662-45cb-800f-1ea470760b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d49498-a3ba-4b07-9f3d-9dc338d9ca70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b44c9262-41db-40c7-8b43-06012a6c9c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27153b27-64be-49ad-959b-7eb5c513c257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5572676e-2e09-461a-8587-a67efe3ae701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 168f0adf-2795-4010-9cc0-c5b0e5eb5698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a3e479-007a-4ff4-819e-4ccb9402504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7e30db-8881-4fef-8b34-4df216a19cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 629da6d2-a98c-4846-a977-8caa7d5f8d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b7f0e41-1d11-4a60-ba60-b106a98594c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73328d2c-43d7-4455-8b3a-65f3b3768ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900355a9-cc90-483f-a46d-7a6576b4db22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd8e0f4-df86-49e6-afd2-791559cce5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e7a1a9-22eb-44d9-9313-a80c674f7aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afd5588-2365-4f31-a204-569f39cd562b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8a0739-11b3-4b97-8df8-1d99cd758383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e060a91-a189-45ed-a679-6412751f0731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c78c33-a77b-4ee7-9af8-45c139a33301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183948c2-d0aa-462c-b61b-a14c3cb19f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14af4120-8c47-4d7d-8a3c-a7d01be16f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ec135b-96d1-48aa-ab14-f319a37532e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50c3418b-2118-42bc-9dc3-dc45cd35d81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64248727-1845-4b7a-86bc-13b75dc69d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f747c50c-312d-49d6-91d0-114723d0db1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6753a098-89fa-452e-88ac-213f347bda02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef16b5bd-4fdd-47c0-a6b7-78152dc78d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fdada48-5254-4de5-a379-e3d9df1e5f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee785c5-91d4-4d6b-9104-9c2f90cecd28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e350a8b1-8d7f-4287-85d7-17819acb7b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f165ca2f-1bd2-47ef-b2a5-3608c1f73e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffacad57-19ab-40ae-be7b-698a46bf4a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42caa22-4e7d-42c1-a9d2-f14ea3a64ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96166510-8c7d-4dd3-aacb-53aae5d04d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a8e9cca-5131-4d12-9982-6c91eac9bf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a141ad-2232-47b2-90ef-ff4bdc54bf80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c5876b-b1c9-46ec-b3ba-c660f79907d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f452185-4909-4a08-917d-2351bdeb2229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da618809-b18c-4959-ab29-a4f443542ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a49e298-b4a9-4f1d-8ac2-a89995b28dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac162b4-369c-4eb2-9ff8-5b86f10a4df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0017dc5-4dd4-4d1f-888d-3d7074ada672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9e7839-ab80-4c84-afd8-004e760e6085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5a7c9e-4817-43a7-b18e-7b9a3ac9fe4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a78a53a-ded0-4e80-b0ca-55bd70c0a700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c49e1f-3a8c-4333-af4a-b5acedfcd374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee728b1-249e-4ad7-9cba-75564dd694d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ffdfa2-7d46-45ae-a2bd-477b46ba1f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2af76b8c-d07c-4506-ab3a-d1268c1a7761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21383599-e534-4551-ab03-5477023f4b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10447f1f-c162-4319-a55d-b23f1b0d9146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8aea430-910d-48ce-92f5-65044ea09816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f008b53-6825-4928-a0d3-26e130490f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925a1608-de34-4295-be1c-5f42bedfc431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33cce010-66b3-411a-9cea-18a8eb092152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f27956-90b1-4132-a734-62657e355120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ebac7a-cc37-4c9b-ab18-6f0b7aa7d5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c49d34-5ffb-40bb-9018-21e37352cc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5b622f-0f73-400d-b96d-195e30355ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a2c25f3-93e2-459e-8228-14c4659dadee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a44c1fc-8742-40e5-af60-caa7ebc9fc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3a36ce-3590-48db-a87e-8e17160a7747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c7918b-775e-48fb-8bbf-50d83b72defd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a97614-8fad-4f28-ae92-f08deca80bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d1ca09-fc1b-415c-8e21-7ceaa8252e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1dfd649-ede9-47ab-89b2-50db088c6bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb57e21-33e9-4213-8a7e-9d9fb8240811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6bb83d-b7a1-4696-952b-145f0ccc511f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f574e2f3-c358-47f1-a6fa-ca311e9d1d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5e9525-2608-49f5-8cf2-c6921fb9b5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a660b49c-9db7-4e33-ac03-bc4de4c75b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb9f7cf-912b-40bb-9901-283976ee0f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ffc1e08-d041-413b-83fb-23d7a4f42bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fb76e9-4d33-4b5f-b263-262d6e4295bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd835e9-2b73-49ae-8e07-f374b62f4ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e50e077-9d47-480f-958a-14d20af1c721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb81b56-bc78-4eb8-b1d3-3fb7d721ada0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56f2e3a-c091-462b-8525-616432546fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e8fe63-b8fd-44a5-ad2e-c6a0e07b4636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee392cef-7efc-4d76-bbc5-baecde9f8952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171978a7-9b1a-457a-b47c-8e1aae704744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9af820-78ac-4ecb-a2e7-def8f789463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc1c09a-b47b-4fa0-a78c-12dba31b1368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e16ea028-866c-4d4c-9631-d774d3c3042f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be78bc3f-3e9a-4f17-92c6-8eeda32c41bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615ea213-e0f7-4048-9979-06079b4d131f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fac71de-d3ac-4f9e-b35f-e3361cbfc283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38c5ed2-350f-4fa9-b600-ecd810b5e2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef30d06c-0179-44a4-a76b-119391ab91c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fc8956-249c-45b8-a6d5-64a64d49970c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594c7ac1-8097-4692-9f76-d9defc87a0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9dda8ca-b7b0-414e-9130-fd64eab9dc87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ec6b9f-8519-425f-a0e2-ff4dc550bbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0dc9bc4-7381-4673-aecd-55123a4aaa51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958a6370-9ee6-4865-879c-2ba5cbb368c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7730f8a-4dff-438c-883b-07bd7a3a6b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e352ae94-dc8c-4e85-89b0-11e6e36abc23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c7c65e-22f9-404d-9790-8a8017aad3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2cfbb1-e0f9-4e63-bd7e-c97ca0d261cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc14b0e-6081-4e48-b6d2-7dc76aea5555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4431fc5-656a-4872-bd9b-2e5f8c5b163d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6600e8-0639-4947-988d-4d1fc44ff9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a1b953-26ff-4c02-bf67-5996c992b764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c693b726-3ae2-4347-ba8a-3d57086f331c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0041edaf-993d-403e-8a82-8dd9286a5851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06976584-57ae-4a94-bc30-6c76508597d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a093fc-1acd-4082-b429-09836f37da6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4c1a59-0d58-47a0-85cb-8b8d67fa5b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ca4f29-d8ba-450e-a25f-c38c6eb31d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e6d6e0-cc8e-4cd0-b9a9-c096ed732f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e29f859-6e31-4812-8ce5-288bca0f7177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9788c4-c538-421f-9c20-573a09ee7d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8099ac-b497-47ff-ba9e-b596efff345c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73392e69-7b59-4767-ae96-a04888947ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4f9c11-48ce-49b4-9506-c5181184fe3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3754c8c5-ed7e-4094-aeaa-5b62f8990cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e22e01-6bae-4aef-afb7-0430549a9c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a115a009-1edc-4ea9-9e5b-b3ba48b2732c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b129869-df65-4927-af01-8738c73e8282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d11175d7-7d31-40ec-97b9-987d3525c2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18b619cc-acd8-4981-ad1a-4904628eff37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5b3347-224c-436d-a74c-7b8b09e6fc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b4d5563-e6e3-4b26-8283-90ec7073509c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a1699d4-5b34-4715-a02a-cf9bb4068b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea7a689-9ebf-4914-b8d0-76c9b669a2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cebf2adf-6e8f-48d7-b31b-1e5c312aa3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f293e019-cbfb-4b78-98d2-ea3cf12e1f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631f840a-4cc4-4de4-b6f9-2aa56756c5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83390084-d6f5-4b7e-a405-3452edbfac5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31179d7d-7339-4e49-9f57-cec876a0fa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf6902c-2e0d-42ae-ae13-319201b259d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6a3660-463e-4ced-9881-260c9fcce48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adfbbd62-6a61-4a5c-9fdc-c6783c60389d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf0d8da-a22b-4d67-8d5c-80ba25645969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbfa22fd-6144-4d71-9d00-a322b6d7b649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab52f5c-3a3f-444a-a887-9392c5122ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1001ee75-91cf-4a44-b162-8838885de520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3179da43-5e94-4aee-9111-1e9f6a2f32d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05d7e7d-44a3-496a-89b6-a0b21707067a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ec721f-94f7-4b3f-9bfe-8a08e1bfe2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ab63af-64e3-4b4b-a4f4-5cbf3f0d618f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ceafe12-9e8a-429e-991b-4a6a8483513c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee4c78c-c305-4225-afe5-66bcbfc7017c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a26cc54-381a-4845-908f-b2729645cdcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a5d67d-b48a-4269-8f02-a130e4ce06af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3345da-0058-4d79-8d0d-7458cd8f4d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388a73dc-0e8b-427d-b659-e6af6c62875e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46caec0a-bc51-4490-aef9-90a58bc45e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 749d3d9a-dd0b-4eef-8ff1-685d6db4f22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba32761-5973-49fc-ac3f-0f84a30f2382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b412afe2-b19c-4fd1-bc76-902cddf7e543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5386a716-6949-439f-b28e-d979c944f4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31522f3-5b6f-4407-a4a8-a5d80e83b60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c299361-5503-4c6b-99ab-263df27c1063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde91fd4-30b8-4860-93cf-0d6b109bec4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a0afc9-0948-4f1e-a682-c84992f29051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e21352-79be-476f-bae1-19a7ca8529ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad1fe8c-e427-4f61-ac40-24013d0b73e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf81762-8934-427c-ad84-e13fb437c71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14e5b9e-83e3-4c6f-9f89-7df2b5944f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1dc86b-7adc-4e41-820b-37e028b34613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95564313-8b61-4e0c-8c12-54506a5616e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1517d9a-9988-40af-bfcb-b14fa316aab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b5283c-aaac-444e-93f2-e1ccdfbe166d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359a1b55-b340-4854-84bb-45c174022b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d052d0-3fc6-4ad1-b148-127379d5a6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f91326-ad0f-4b61-a5ff-c98196db2e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e477d360-e32b-4c95-93b6-3f8c36882fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a512a5-3094-4f4a-856d-ad50533a281a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca7ff7d-9784-423e-bb21-ebf10659d7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee11c810-1195-40a4-95c8-cbabf2030749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a4d7ef-1389-425a-a0f5-4cbc5a47dc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7db3c4-29e9-49e6-b52f-9e5a214725d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1889b9e7-bbb7-4bbd-a013-96328394b6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 806e98ca-6f88-4581-86a6-eef1d201bcf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a0b929f-034e-4445-9b4e-d66376ce7b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa73bafc-91a3-4b08-9a4b-28789dacdae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147325a0-fe00-42e3-8d12-f83921a5c59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cfa285c-c6e3-4596-bebb-c2463c6c9ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299e636e-8e95-407a-b737-86902a69c03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd011a9-48d7-4637-8991-ea31f6dd66f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc631245-c12e-4459-b144-08880d4be1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b4513c-cbfd-4fb3-abe6-494efc09cfaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e96cc7c7-d95f-4364-89c5-26d6637a4eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf039af-42be-4a50-959f-28fd4a218517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 805dda91-542e-4769-9e5c-e0ecf6db58a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c82b8186-6bcf-4639-8f4b-5338874e6895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce1a6973-0c6b-4305-9d86-8da301fa8f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33fa74eb-be86-4222-adf8-94e2c3c7b6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea4fd20-fa66-493d-aae9-9621f5511904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5822d3-37ba-4761-ab53-5deedb8d4159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973178d3-8fac-4c93-9d05-063dee77fd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93559f8f-9895-4125-a200-2766e5599696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36af566b-6be2-4f61-ae61-73364ecf570a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ee5817-cb55-4f18-9e5c-7fab3c6ebb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce23b9d2-5206-4acb-a72a-4e1f39a29fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1a1367-eae8-463b-8235-610f211db07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9c5431-654b-42a6-bfa9-38aaaeb67c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e765aa1a-1c44-47ff-bcb4-e6bc2b0c03f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b023e93-bcd7-4e5a-aba5-bed43c254122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f93468-8c8b-40b9-9008-188b886d3927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69569089-f72f-481f-b024-f20704f14f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fccead1-e96d-4aa2-a5f4-34616949748e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07f6331-ccef-4319-b752-84ca80b5feac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a069bc17-e12a-4b6c-8bab-22d52842d323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9bc1df2-e562-418a-986c-c05563fcf0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbda66e-bd05-4370-ace0-dcadc12a6fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66dd12d2-9215-4b97-a6c2-682b85362dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c420c670-d4bc-4656-9717-a74a40432f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f73acb-1563-4f17-b16c-6acfc84bea53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02142e04-597b-499c-b25e-84cb6ad7a245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73aba90f-5d1b-40e9-8a80-6f132c4328d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9dbc71-bb04-42f7-82fe-284b75b76ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3ad0f4-7d4b-4b00-9500-e56f77aa2ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fde1795-d8c0-4eeb-a8d9-f7066748b611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd25d4db-e173-4d3a-a4de-32f5266f08ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c71c5d-a14c-4cdc-8ebb-063d510d01fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac8fc42-b90a-42f8-9fea-ca29a5211a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afcc67f2-e593-4092-bccc-8c8531adbaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d138ae0a-17ce-4983-8c77-ad14eff0edc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47bb7d45-d4db-4aaf-989b-1eaf152084c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9159253-2d38-498f-a995-da546aafaa0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37b37640-2333-486d-b964-0e356b326790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cacf631b-23db-4373-99b9-54268e3fb460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0958c318-94df-43b6-b51b-71ffbf568b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b895a1-4465-4736-8d29-f8531473e6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4db98a8-eccc-40da-8430-991ac0b0849c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42501e6a-4dcd-4763-8c32-6289aaee3633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d9ff73-20f8-4d69-9c05-71c03e4e82aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1737f7f-bcf7-454b-b67b-2ca26769be14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c0f160-3eba-4baa-92b1-5d57eb226d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4708c5f-b8da-45f2-8959-00a22772a62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80139a38-4b1f-4bb5-be29-3457f58c7f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0c2369-5043-4fa4-94e4-0838a4214242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c1e664f-e7a9-4f19-83b7-693162cebede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bf5f3c-ee6e-4a9e-993b-6c23149b199f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f160a42a-0760-42a6-9c0d-53f64cdde6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca99795f-ad80-415f-9369-c55bdb6ea125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6147c23-9399-4ba1-a1f9-77df69547e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b608be7-2f2b-4187-a8fc-4c14db48b4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91f4dcb-8532-49e5-b971-20a3b34a64bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f211200-cff5-4592-9980-a22ab96db120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e1cd8f-fe50-4bfd-bcdf-6765dabc6d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebfebc1f-be17-4604-bb22-e44635120905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9aa0a6d-f1bf-44bf-a20d-a36fecc60718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1880aede-0130-4d21-840b-b5be7d605c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b9d879a-d11a-4e72-91d8-93b67de924fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff2bcd2-ab9f-4753-bb1e-467d8e0150c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e19544-3056-4488-97dc-ffa619245fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abeb53dc-e0da-4b3b-b9a9-9002053fda19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc76fffb-8d9a-4ac4-bc05-d9041f1f9877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784346cc-562d-4d7d-908a-c9827f25c48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426f5d90-e2e9-4f59-8945-2707e3dbcb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3891dc8-1183-41aa-8d30-a23e6be6f15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0ba172-a616-4361-ac04-32dae13a1fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338252e3-356a-4619-8c7d-f6d44ac57a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42c6dbf-4d0b-433d-b914-a47662cc1e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32bc844a-7e47-44b8-9429-18354fbf233a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1366d8-af45-4134-9176-ead228448b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 499d7ad6-d2ad-4ea7-95e3-191fe04fc4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 984931a8-6de5-48f2-bb31-f92e5227cdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffff0373-0eb5-4400-a321-5ad73975a148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06fdbba-75dc-42e9-a36f-61f7941132ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793b1a4a-75b9-4bbf-bef0-e40f57a2b507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe71714-8946-4dcb-a531-d621112c37ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00088445-1b59-4be8-8735-ef6631f9a4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643836ed-77c4-425f-8466-1dcffc8f356d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc01b9dc-a536-41ae-a507-b632293dd114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43ce9749-2fa9-4719-a403-4b90a1880bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06d33d1-59f7-4902-8a3a-d6467c612376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3fff229-e813-4b44-9539-bc307f642b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e76311e-3271-482c-84cb-7e16013108e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65851350-c03e-4d0d-b631-06bd219a6923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f6c674-6f22-4141-a8f6-9c858c12ad19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af95cfd8-072b-44bc-9226-2e822e131d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed9b203-8e99-45f8-93b1-aa65f7c62c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1b499f-1983-40d9-b0e3-1e27ba92b516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc8ba79-c082-43cb-ac2a-d2633a7d5c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5524ead1-d1d7-4c81-8cc2-9cc66525cf5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c973c57-4dd4-4caf-9349-8e23c1dfe81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b4fd6a-7d37-4868-b431-6ee3757f4fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f1ceb36-14a9-4b4b-b434-0967b045ea67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdaedd0b-e690-4d3f-8655-1d5f91a7ba54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97090a37-e0a8-4a62-8302-91a975bc9aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f7239e-4fcd-422c-adf0-a86d27ab37e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1d8a0c-4aa4-46a7-bdfa-8af134eb1f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce9d7c65-e67a-48d0-9b63-bf1ba24ee9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6337d94d-8412-4f4d-b1ed-8d4e95e3278f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5307896b-479d-4e0c-acb1-4225de703918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99937fe7-ba62-4ff2-a5cd-2d62bf19df9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be94536-7030-47c8-915b-a784229026cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79926ccc-dfc8-4569-a509-e029dcb250f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 419c9aca-4342-4e34-85a3-9642bae78448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d92175-ec3e-44aa-bf11-34d7dfce32b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17bc4ba3-447a-44a6-887f-fb2f433d3e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b06664-d962-4102-83f6-207b0fd7a44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a1afdb-35f7-484f-a06c-ee435a3583c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f132c4-baa6-493d-bba3-6febb03e13a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9bbca18-947e-4b9e-9a0b-bf606fddb264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3d2463-05b6-4703-b35f-9ec8432adfc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c859594d-d2d8-416e-9c82-ed5af6fdb57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f72699-fb7f-4eda-a97d-c4958a79b6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6c644a-ceab-44fe-884c-42631986eb41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0b3702-ea99-47fa-86dd-6626928a57c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5efc2782-1eb4-4c53-b326-f6067c8ebdb5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(6065, 24), y=(6065,)
   Test:  X=(1517, 24), y=(1517,)

⚠️  Limiting training data: 6065 → 800 samples
⚠️  Limiting test data: 1517 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2447, R²: -0.0144

============================================================
🔄 Round 2 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0885 (↓), lr=0.001000
   • Epoch   2/100: train=0.0840, val=0.0887, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0838, val=0.0889, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0835, val=0.0889, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0889, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0816, val=0.0890, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 2 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0023
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0046
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2440, R²: -0.0029

============================================================
🔄 Round 4 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0880 (↓), lr=0.000250
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0836, val=0.0876, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0835, val=0.0876, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0834, val=0.0875, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0829, val=0.0874, patience=4/15, lr=0.000250
   • Epoch  21/100: train=0.0823, val=0.0873, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 4 Summary - Client client_1
   Epochs: 22/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0103
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0237
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2434, R²: 0.0008

============================================================
🔄 Round 7 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000250
   • Epoch   2/100: train=0.0859, val=0.0773, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0857, val=0.0771 (↓), lr=0.000250
   • Epoch   4/100: train=0.0855, val=0.0771, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0854, val=0.0771, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0848, val=0.0770, patience=8/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 7 Summary - Client client_1
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0121
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0031
============================================================


============================================================
🔄 Round 8 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000125
   • Epoch   2/100: train=0.0841, val=0.0846, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0837, val=0.0847, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0832, val=0.0849, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 8 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0046
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0116
============================================================


============================================================
🔄 Round 9 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0823 (↓), lr=0.000031
   • Epoch   2/100: train=0.0846, val=0.0823, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0844, val=0.0821, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 9 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0048
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0055
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: 0.0031

📊 Round 9 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2430, R²: 0.0042

============================================================
🔄 Round 11 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0899 (↓), lr=0.000008
   • Epoch   2/100: train=0.0831, val=0.0900, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0831, val=0.0900, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0831, val=0.0900, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 11 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0060
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0028
============================================================


============================================================
🔄 Round 14 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0773 (↓), lr=0.000002
   • Epoch   2/100: train=0.0860, val=0.0773, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0860, val=0.0773, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0860, val=0.0774, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0860, val=0.0774, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0860, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 14 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0059
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0055
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0031

📊 Round 14 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 16 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 16 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0040
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0180
============================================================


============================================================
🔄 Round 17 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 17 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0045
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0034
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2433, R²: 0.0022

============================================================
🔄 Round 18 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 18 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0056
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0025
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: 0.0023

📊 Round 18 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: 0.0023

📊 Round 18 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: 0.0023

📊 Round 18 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: 0.0023

📊 Round 18 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: 0.0024

============================================================
🔄 Round 28 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 28 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0035
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0154
============================================================


============================================================
🔄 Round 31 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 31 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0050
   Val:   Loss=0.0909, RMSE=0.3014, R²=0.0014
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 33 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 33 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0041
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0049
============================================================


============================================================
🔄 Round 34 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 34 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0061
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0051
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0026

📊 Round 34 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0027

📊 Round 34 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0027

📊 Round 34 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0027

============================================================
🔄 Round 38 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 38 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0032
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0063
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0027

============================================================
🔄 Round 40 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 40 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0049
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0020
============================================================


============================================================
🔄 Round 41 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 41 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0049
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0016
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0028

============================================================
🔄 Round 44 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 44 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0080
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0111
============================================================


============================================================
🔄 Round 45 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.1027 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.1027, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.1027, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.1027, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.1027, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.1027, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1027)

============================================================
📊 Round 45 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0034
   Val:   Loss=0.1027, RMSE=0.3205, R²=0.0070
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0028

============================================================
🔄 Round 46 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 46 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0051
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0004
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0029

📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0029

📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0029

============================================================
🔄 Round 50 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 50 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0024
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0109
============================================================


============================================================
🔄 Round 51 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 51 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0063
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0120
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0030

📊 Round 51 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0031

============================================================
🔄 Round 54 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 54 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0020
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0094
============================================================


============================================================
🔄 Round 55 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 55 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0050
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0011
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0031

📊 Round 55 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0031

============================================================
🔄 Round 58 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 58 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0001
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0205
============================================================


============================================================
🔄 Round 59 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 59 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0041
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0041
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0032

📊 Round 59 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2432, R²: 0.0032

📊 Round 59 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0033

📊 Round 59 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0033

📊 Round 59 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0033

============================================================
🔄 Round 68 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 68 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0042
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0042
============================================================


============================================================
🔄 Round 69 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 69 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0048
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0011
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0033

📊 Round 69 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 75 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 75 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0046
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0032
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 77 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 77 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0022
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0139
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0034

📊 Round 77 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 80 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 80 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0046
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0024
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 82 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 82 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0059
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0014
============================================================


============================================================
🔄 Round 83 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 83 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0044
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0013
============================================================


============================================================
🔄 Round 87 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 87 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0028
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0106
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 90 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 90 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0042
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0009
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0035

📊 Round 90 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0035

📊 Round 90 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0035

============================================================
🔄 Round 96 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 96 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0022
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0047
============================================================


============================================================
🔄 Round 99 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 99 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0051
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0009
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0035

📊 Round 99 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0036

============================================================
🔄 Round 104 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 104 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0056
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0072
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0036

============================================================
🔄 Round 105 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 105 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0024
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0128
============================================================


============================================================
🔄 Round 107 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 107 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0047
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0026
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 112 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 112 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0033
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0090
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 113 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 113 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0049
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0037
============================================================


============================================================
🔄 Round 114 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 114 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0053
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0013
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 115 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 115 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0019
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0053
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 117 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 117 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0054
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0009
============================================================


============================================================
🔄 Round 118 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 118 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0000
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0133
============================================================


============================================================
🔄 Round 119 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 119 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0035
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0010
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 119 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 121 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 121 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0014
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0026
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 121 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 121 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 121 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 125 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 125 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0070
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0082
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 126 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 126 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0046
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0053
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 127 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 127 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0013
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0142
============================================================


============================================================
🔄 Round 128 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 128 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0048
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0028
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 128 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 134 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 134 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0021
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0353
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 134 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 137 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 137 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0050
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0006
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 137 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 140 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 140 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0016
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0122
============================================================


============================================================
🔄 Round 141 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 141 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0048
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0031
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 144 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 144 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0055
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0204
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 144 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 144 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 144 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 144 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 155 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 155 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0049
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0007
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 157 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 157 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0063
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0054
============================================================


============================================================
🔄 Round 162 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 162 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0039
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0060
============================================================


============================================================
🔄 Round 164 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 164 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0025
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0117
============================================================


============================================================
🔄 Round 165 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 165 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0064
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0038
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 166 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 166 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0055
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0001
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 166 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 166 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

📊 Round 166 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 176 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 176 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0063
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0028
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0038

============================================================
🔄 Round 179 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 179 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0037
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0223
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0038

============================================================
🔄 Round 180 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 180 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0019
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0025
============================================================


============================================================
🔄 Round 181 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 181 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0037
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0075
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0038

📊 Round 181 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 184 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 184 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0021
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0062
============================================================


============================================================
🔄 Round 186 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 186 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0052
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0016
============================================================


============================================================
🔄 Round 189 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 189 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0041
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0054
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 189 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 191 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 191 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0052
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0004
============================================================


============================================================
🔄 Round 192 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 192 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0042
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0073
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 194 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 194 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0066
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0033
============================================================


============================================================
🔄 Round 195 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 195 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0035
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0072
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 196 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 196 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0032
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0084
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 197 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 197 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0057
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0021
============================================================


============================================================
🔄 Round 200 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 200 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0038
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0077
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 200 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 200 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 203 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 203 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0027
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0120
============================================================


============================================================
🔄 Round 204 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 204 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0051
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0006
============================================================


============================================================
🔄 Round 205 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 205 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0034
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0043
============================================================


============================================================
🔄 Round 206 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 206 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0061
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0024
============================================================


============================================================
🔄 Round 208 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 208 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0038
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0028
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 210 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 210 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0047
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0030
============================================================


============================================================
🔄 Round 211 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 211 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0032
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0048
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 212 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 212 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0016
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0030
============================================================


============================================================
🔄 Round 213 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 213 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0064
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0027
============================================================


============================================================
🔄 Round 215 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 215 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0036
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0008
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 215 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 219 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 219 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0043
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0175
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 221 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 221 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0036
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0029
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 225 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 225 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0057
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0012
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 228 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 228 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0046
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0125
============================================================


============================================================
🔄 Round 229 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 229 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0044
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0022
============================================================


============================================================
🔄 Round 230 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 230 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0044
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0044
============================================================


============================================================
🔄 Round 232 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 232 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0038
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0057
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 233 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 233 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0037
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0045
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 235 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 235 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0055
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0075
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 236 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 236 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0058
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0012
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 237 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 237 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0059
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0017
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 237 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 239 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 239 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0051
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0036
============================================================


============================================================
🔄 Round 241 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 241 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0046
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0013
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 243 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 243 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0052
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0007
============================================================


============================================================
🔄 Round 244 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 244 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0028
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0107
============================================================


============================================================
🔄 Round 246 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 246 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0032
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0083
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 246 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 246 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 249 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 249 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0008
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0099
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 250 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 250 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0049
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0030
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 251 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 251 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0028
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0112
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 253 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 253 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0056
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0021
============================================================


============================================================
🔄 Round 255 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 255 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0043
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0043
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 255 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 257 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 257 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0019
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0016
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 258 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 258 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0058
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0028
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 258 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 261 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 261 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0066
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0072
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 262 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 262 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0047
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0039
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 262 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 264 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 264 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0033
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0041
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 264 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 266 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 266 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0055
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0013
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 267 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 267 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0067
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 270 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 270 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0059
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0006
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 270 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 272 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 272 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0053
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0005
============================================================


============================================================
🔄 Round 273 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 273 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0037
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0188
============================================================


============================================================
🔄 Round 274 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 274 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0040
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0005
============================================================


============================================================
🔄 Round 275 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 275 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0020
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0137
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 275 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 277 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 277 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0027
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0103
============================================================


============================================================
🔄 Round 278 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 278 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0036
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0083
============================================================


============================================================
🔄 Round 279 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 279 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0045
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0034
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 280 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 280 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0034
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0053
============================================================


============================================================
🔄 Round 282 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 282 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0062
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0022
============================================================


============================================================
🔄 Round 284 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 284 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0047
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0018
============================================================


============================================================
🔄 Round 288 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 288 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0037
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0033
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 290 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 290 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0015
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0160
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 292 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 292 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0048
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0065
============================================================


============================================================
🔄 Round 295 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 295 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0052
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0008
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 296 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 296 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0063
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0255
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 296 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 296 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 296 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 301 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 301 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0054
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0014
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 301 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 305 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 305 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0049
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0014
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 307 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 307 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0032
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0028
============================================================


============================================================
🔄 Round 310 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 310 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0023
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0121
============================================================


============================================================
🔄 Round 313 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 313 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0019
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0129
============================================================


============================================================
🔄 Round 314 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 314 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0054
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0013
============================================================


============================================================
🔄 Round 315 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 315 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0039
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0019
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 315 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 315 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 318 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 318 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0053
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0073
============================================================


============================================================
🔄 Round 319 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 319 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0082
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0112
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 323 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 323 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0035
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0092
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 326 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 326 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0059
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0010
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 326 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 326 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 333 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 333 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0163
============================================================


============================================================
🔄 Round 334 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 334 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0050
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0013
============================================================


============================================================
🔄 Round 335 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 335 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0078
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0087
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 336 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 336 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0038
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0038
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 337 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 337 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0045
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0039
============================================================


============================================================
🔄 Round 339 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 339 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0040
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0156
============================================================


============================================================
🔄 Round 340 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 340 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0024
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0027
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 340 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 344 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 344 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0035
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0051
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 346 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 346 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0043
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0061
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 348 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 348 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0046
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0250
============================================================


============================================================
🔄 Round 351 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 351 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0054
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0158
============================================================


============================================================
🔄 Round 352 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 352 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0014
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0115
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 354 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 354 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0042
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0039
============================================================


============================================================
🔄 Round 356 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 356 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0082
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0089
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 357 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 357 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0052
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0009
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 359 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 359 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0062
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0095
============================================================


============================================================
🔄 Round 360 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 360 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0053
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0088
============================================================


============================================================
🔄 Round 361 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 361 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0008
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0389
============================================================


============================================================
🔄 Round 363 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 363 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0036
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0084
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 364 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 364 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0049
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0010
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 364 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 364 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 372 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 372 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0045
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0082
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 376 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 376 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0058
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0002
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 376 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 376 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 381 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 381 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0040
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0041
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 381 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 381 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 385 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 385 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=0.0041
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0048
============================================================


============================================================
🔄 Round 386 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 386 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0046
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0129
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 388 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 388 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0010
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0086
============================================================


============================================================
🔄 Round 391 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 391 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0072
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0070
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 393 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 393 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0034
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0097
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 393 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 395 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 395 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0034
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0103
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 397 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 397 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0062
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0081
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 397 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 399 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 399 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0052
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0030
============================================================


============================================================
🔄 Round 400 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 400 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0058
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0001
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 402 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 402 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0054
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0222
============================================================


============================================================
🔄 Round 403 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 403 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0014
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0171
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 403 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 405 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 405 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0032
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0102
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 405 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 405 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 405 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 413 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 413 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0072
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0147
============================================================


============================================================
🔄 Round 414 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 414 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0040
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0073
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 414 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 422 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 422 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0017
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0005
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 423 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 423 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0009
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0140
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 423 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 423 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 427 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 427 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0037
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0091
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 428 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 428 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0059
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0044
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 431 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 431 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0043
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0057
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 431 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 435 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 435 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0023
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0061
============================================================


============================================================
🔄 Round 436 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 436 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0047
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0039
============================================================


============================================================
🔄 Round 437 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 437 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0035
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0061
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 440 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 440 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0053
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0021
============================================================


============================================================
🔄 Round 441 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 441 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0068
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0139
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 443 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 443 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0056
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0110
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 444 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 444 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0057
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0026
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 445 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 445 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0057
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0120
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 445 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 445 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 445 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 445 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 455 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 455 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0041
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0052
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 455 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 457 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 457 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0028
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0014
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 460 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 460 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0061
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0114
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 463 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 463 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0038
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0076
============================================================


============================================================
🔄 Round 464 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 464 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0003
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0419
============================================================


============================================================
🔄 Round 466 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 466 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0036
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0004
============================================================


============================================================
🔄 Round 469 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 469 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0030
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0021
============================================================


============================================================
🔄 Round 470 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 470 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0044
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0046
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 472 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 472 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0060
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0034
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 474 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 474 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0042
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0067
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 474 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 479 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 479 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0020
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0068
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 479 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 479 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 483 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 483 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0059
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0014
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 484 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 484 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0005
   Val:   Loss=0.0964, RMSE=0.3104, R²=0.0186
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 486 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 486 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0006
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0039
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 487 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 487 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0034
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0096
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 487 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 489 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 489 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0041
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0066
============================================================


============================================================
🔄 Round 490 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 490 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0045
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0129
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 490 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 490 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 494 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 494 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0060
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0007
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 495 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 495 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0017
   Val:   Loss=0.0974, RMSE=0.3121, R²=0.0137
============================================================


============================================================
🔄 Round 497 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 497 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0011
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0480
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 498 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 498 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0032
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0059
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 500 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 500 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0022
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0065
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 500 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

📊 Round 500 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 507 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 507 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0056
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0169
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0041

============================================================
🔄 Round 508 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 508 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0028
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0116
============================================================


============================================================
🔄 Round 509 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 509 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0059
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0024
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 511 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 511 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0031
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0088
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 514 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 514 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0029
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0038
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 514 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 517 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 517 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0036
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0087
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 520 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 520 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0039
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0042
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 520 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 525 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 525 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0038
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0032
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 526 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 526 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0059
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0011
============================================================


============================================================
🔄 Round 527 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 527 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0049
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0032
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 529 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 529 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0024
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0040
============================================================


============================================================
🔄 Round 530 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 530 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0040
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0069
============================================================


============================================================
🔄 Round 533 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 533 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0032
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0057
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 533 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 536 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 536 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0031
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0037
============================================================


============================================================
🔄 Round 538 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 538 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0027
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0096
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 539 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 539 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0047
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0034
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 540 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 540 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0046
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0114
============================================================


============================================================
🔄 Round 542 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 542 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0024
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0069
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 544 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 544 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0039
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0057
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 545 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 545 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0027
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0022
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 548 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 548 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0037
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0126
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 548 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 551 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 551 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0061
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0101
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 552 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 552 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0040
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0051
============================================================


============================================================
🔄 Round 553 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 553 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0061
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0108
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 556 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 556 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0057
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0001
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 557 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 557 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0053
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0024
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 557 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 557 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 557 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 557 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 557 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 568 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 568 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0045
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0058
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 568 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 568 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 572 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 572 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0043
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0071
============================================================


============================================================
🔄 Round 573 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 573 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0029
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0028
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 575 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 575 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0044
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0001
============================================================


============================================================
🔄 Round 577 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 577 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0011
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0370
============================================================


============================================================
🔄 Round 578 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 578 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0054
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0012
============================================================


============================================================
🔄 Round 580 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 580 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0024
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0187
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 580 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 580 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 587 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 587 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0046
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0021
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 588 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 588 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0047
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0017
============================================================


============================================================
🔄 Round 589 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 589 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0049
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0028
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 589 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 593 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 593 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0050
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0006
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 593 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 593 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 593 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 600 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 600 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0036
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0218
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 600 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 604 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 604 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0067
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0088
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 604 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 604 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 608 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 608 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0055
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0005
============================================================


============================================================
🔄 Round 609 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 609 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0045
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0084
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 613 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 613 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0012
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0259
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 613 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 613 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 616 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 616 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0060
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0025
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 616 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 616 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 622 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 622 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0020
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0044
============================================================


============================================================
🔄 Round 623 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 623 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0044
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0009
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 625 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 625 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0031
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0045
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 626 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 626 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0044
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0217
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 628 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 628 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0015
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0153
============================================================


============================================================
🔄 Round 630 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 630 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0054
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0018
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 633 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 633 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0035
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0070
============================================================


============================================================
🔄 Round 634 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 634 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0029
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0119
============================================================


============================================================
🔄 Round 635 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 635 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0038
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0086
============================================================


============================================================
🔄 Round 641 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 641 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0046
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0054
============================================================


============================================================
🔄 Round 645 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 645 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0027
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0130
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 646 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 646 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0040
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0047
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 646 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 646 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 652 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 652 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0042
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0019
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 654 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 654 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0052
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0028
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 656 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 656 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0031
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0235
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 657 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 657 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0048
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0010
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 657 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 660 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 660 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0073
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0061
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 663 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 663 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0029
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0109
============================================================


============================================================
🔄 Round 664 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 664 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0056
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0001
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 666 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 666 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0050
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0038
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 668 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 668 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0067
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0136
============================================================


============================================================
🔄 Round 669 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 669 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0027
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0117
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 669 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 673 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 673 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0063
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0034
============================================================


============================================================
🔄 Round 674 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 674 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0041
   Val:   Loss=0.0706, RMSE=0.2656, R²=-0.0023
============================================================


============================================================
🔄 Round 675 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 675 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0049
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0011
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 678 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 678 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0064
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0028
============================================================


============================================================
🔄 Round 679 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 679 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0048
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0041
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 679 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 679 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 683 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 683 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0045
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0232
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 683 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 683 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0038

============================================================
🔄 Round 690 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 690 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0055
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0155
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0038

📊 Round 690 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 692 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 692 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0048
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0032
============================================================


============================================================
🔄 Round 693 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 693 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0073
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0067
============================================================


============================================================
🔄 Round 694 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 694 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0029
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0020
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 697 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 697 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0027
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0135
============================================================


============================================================
🔄 Round 699 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 699 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0019
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0462
============================================================


============================================================
🔄 Round 700 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 700 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0035
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0104
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 701 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 701 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0002
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0306
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 701 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 701 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 701 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 701 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 708 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 708 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0039
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0072
============================================================


============================================================
🔄 Round 709 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 709 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0011
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0161
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 711 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 711 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0039
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0012
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 714 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 714 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0052
   Val:   Loss=0.0960, RMSE=0.3098, R²=0.0002
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 715 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 715 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0066
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0030
============================================================


============================================================
🔄 Round 716 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 716 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0067
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0136
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 716 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 716 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 719 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 719 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0019
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0003
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 722 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 722 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0042
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0011
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 722 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 722 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 730 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 730 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0044
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0000
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 734 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 734 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0046
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0053
============================================================


============================================================
🔄 Round 737 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 737 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0039
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0047
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 737 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 742 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 742 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0028
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0129
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 743 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 743 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0026
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0038
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 743 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 743 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 749 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 749 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0035
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0073
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 750 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 750 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0029
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0013
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 750 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 750 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 753 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 753 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0046
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0037
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 756 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 756 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0037
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0074
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0038

============================================================
🔄 Round 760 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 760 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0061
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0174
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

📊 Round 760 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 764 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 764 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0037
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0074
============================================================


============================================================
🔄 Round 766 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 766 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0039
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0034
============================================================


============================================================
🔄 Round 767 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 767 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0057
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0128
============================================================


============================================================
🔄 Round 769 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 769 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0056
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0017
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 772 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 772 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0050
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0025
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 772 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 774 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 774 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0063
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0034
============================================================


============================================================
🔄 Round 775 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 775 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0051
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0024
============================================================


============================================================
🔄 Round 776 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 776 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0048
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0028
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 779 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 779 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0048
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0051
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 782 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 782 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0073
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0207
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 783 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 783 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0033
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0100
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 788 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 788 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0063
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0051
============================================================


============================================================
🔄 Round 789 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 789 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0056
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0016
============================================================


============================================================
🔄 Round 791 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 791 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0048
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0042
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 793 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 793 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0035
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0092
============================================================


============================================================
🔄 Round 794 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 794 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0039
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0035
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 796 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 796 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0050
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0073
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 798 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 798 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0058
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0094
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 799 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 799 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0048
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0018
============================================================


============================================================
🔄 Round 801 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 801 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0048
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0001
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 801 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 801 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 804 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 804 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0061
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0099
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 806 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 806 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0030
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0062
============================================================


============================================================
🔄 Round 807 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 807 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0053
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0072
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 810 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 810 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0080
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0070
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0039

📊 Round 810 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 815 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 815 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0027
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0066
============================================================


============================================================
🔄 Round 817 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 817 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0059
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0013
============================================================


============================================================
🔄 Round 818 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 818 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0068
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0041
============================================================


📊 Round 818 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 818 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 823 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 823 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0035
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0029
============================================================


📊 Round 823 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 826 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 826 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0033
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0090
============================================================


📊 Round 826 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 827 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 827 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0063
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0051
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 832 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 832 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0052
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0005
============================================================


============================================================
🔄 Round 835 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 835 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0028
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0126
============================================================


============================================================
🔄 Round 836 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 836 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0056
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0144
============================================================


📊 Round 836 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 836 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 840 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 840 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0045
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0007
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 840 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 842 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 842 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0022
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0119
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 843 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 843 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0030
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0034
============================================================


📊 Round 843 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 845 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 845 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0048
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0047
============================================================


============================================================
🔄 Round 850 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 850 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0024
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0115
============================================================


📊 Round 850 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 853 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 853 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0019
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0057
============================================================


📊 Round 853 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 853 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 853 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 858 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 858 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0036
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0072
============================================================


📊 Round 858 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 859 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 859 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0045
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0022
============================================================


📊 Round 859 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 859 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0038

============================================================
🔄 Round 861 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 861 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0047
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0047
============================================================


============================================================
🔄 Round 862 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 862 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0013
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0185
============================================================


============================================================
🔄 Round 863 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 863 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0028
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0069
============================================================


📊 Round 863 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0038

============================================================
🔄 Round 864 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 864 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0061
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0036
============================================================


============================================================
🔄 Round 865 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 865 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0042
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0057
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 865 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 865 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 870 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 870 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0051
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0102
============================================================


============================================================
🔄 Round 872 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 872 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0064
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0020
============================================================


📊 Round 872 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 874 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 874 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0037
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0003
============================================================


📊 Round 874 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 874 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 874 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 879 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 879 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0053
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0034
============================================================


📊 Round 879 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0040

============================================================
🔄 Round 886 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 886 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0055
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0011
============================================================


============================================================
🔄 Round 887 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 887 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0032
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0007
============================================================


📊 Round 887 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 893 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 893 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0041
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0046
============================================================


📊 Round 893 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 893 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 895 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 895 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0051
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0037
============================================================


📊 Round 895 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 900 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 900 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0058
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0065
============================================================


📊 Round 900 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 901 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 901 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0065
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0021
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 903 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 903 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0039
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0070
============================================================


📊 Round 903 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

📊 Round 903 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 907 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 907 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0053
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0031
============================================================


📊 Round 907 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0040

============================================================
🔄 Round 910 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 910 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0046
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0045
============================================================


📊 Round 910 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 911 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 911 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0023
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0322
============================================================


============================================================
🔄 Round 917 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 917 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0056
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0154
============================================================


============================================================
🔄 Round 920 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 920 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0049
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0007
============================================================


============================================================
🔄 Round 921 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 921 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0075
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0204
============================================================


📊 Round 921 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 923 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 923 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0045
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0009
============================================================


📊 Round 923 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

📊 Round 923 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 930 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 930 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0049
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0066
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 938 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 938 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0040
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0062
============================================================


============================================================
🔄 Round 939 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 939 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0028
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0051
============================================================


============================================================
🔄 Round 941 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 941 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0074
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0075
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: 0.0039

============================================================
🔄 Round 942 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 942 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0021
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0098
============================================================


============================================================
🔄 Round 943 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 943 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0042
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0075
============================================================


============================================================
🔄 Round 944 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 944 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0042
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0047
============================================================


============================================================
🔄 Round 945 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 945 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0031
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0084
============================================================


============================================================
🔄 Round 946 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 946 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0055
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0050
============================================================


❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
