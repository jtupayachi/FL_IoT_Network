[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4495b6af-ebe0-4719-964d-8aa2a62aa09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 710b1c27-1526-41f2-aeef-23011abe09a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49acf868-1fd6-4f65-a2ed-7c541afc88c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42824fd-8694-4c10-84dd-699345d051c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76003414-b9a5-4455-9a32-1388a9b884dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b016480c-d3c3-4468-ad91-6646fa456077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2199b3-6360-4644-8d5d-dcd7e5ffaef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a757ff9-5d8d-469b-af41-b7e388bd19d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa1451e9-4d38-463b-9e8a-82b9c24947d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afefe3a8-5187-4384-97da-b0dfc683b481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e17cb898-fbc9-4ba5-9652-916acfea1459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bfd4435-ca7d-4477-b217-ad88ab73a342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b20d1c-78e5-4903-aec1-7c9d1a60ab3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8301ddd-2f1e-4093-ae99-469a7cbfdb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71eedf4-4bef-4ca7-9aa7-d726e6d91c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc63cf8c-7f1f-43f8-bfa4-5669a3457071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c584b01-d3bf-40b5-a3e0-0e0325498881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26083274-5144-4a7b-9cb8-392336a3f39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1780aa7-9e1f-40c7-86ab-cef643391c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e0385cd-db00-43b9-807b-1270c526349b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2099e4c-6c51-4b52-b6f5-e6025ce56344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 329461b5-52d6-4899-a25c-412be08a4917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40f2331-89b1-48f5-ad64-92b0b24fe987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17937e2-0c32-43f1-8f58-43aada462928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d3e9520-bcd0-4e97-8db5-6f2816f94749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ab887c-a1e9-4cca-8847-913c8657670d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daea14b9-0b73-480b-a720-a2d0803fb310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485db0ed-dc82-4a3b-8dea-3e86f8ca5f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4271215a-61a1-407d-b25d-5177fdf098c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a4a23d-8dde-4d22-b4ce-a741df1b9b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3500b8f-0213-42f2-b1d0-69e8a1b83b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3884a79-d694-40f8-baeb-d8bfb280f783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e946c17e-4aec-4057-9f4d-b07b1b0ec139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb8cb4c-64d9-489a-86e6-5f3dcd464da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f4629d-0e95-494e-a10d-7d92ee85c092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7415c8-ae11-4c2e-9b59-5ccbdc92779e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5435629-3bae-45f4-a93a-1b6627d2afb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136a1f5a-461d-4502-a7d1-e353318ef09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 406f39ef-f13c-4660-a3c3-5d1f6154ce30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c4ed321-999f-4920-852e-83594daa46e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2774fc38-e37b-406c-9368-ac3222089a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339fd278-8c41-4aba-a673-a4e53d4c637a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa7c42f5-e68e-413b-b378-3fb95bb26f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10e6349c-93ef-4705-908e-4656f40b50bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 534abd15-4a7c-47d7-8d3e-56d56a905afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef3456e-d9a6-4017-99aa-931ab792fb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee07b5df-d73c-4a98-9e35-e018cf928abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb65ed7-6368-40f3-baab-4b3315bea66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adda8186-a634-4bf1-ae3b-364414dcb17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961f28dc-5126-4533-b4e6-023cb8edfc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56330550-6984-4bf4-9d51-72e7b8574b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51fd0b47-ef54-4207-b05a-83e492cb488f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd906d8-be4d-4542-8baa-669d78f48668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a15de0f7-e21f-47ca-99cc-8a636ef6bf31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2451c782-45e9-4303-a859-83c5a67236b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01d33de4-9705-4613-9dc4-31a75fa0fc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22672c42-1a13-4d1a-ba6f-9323ef3082cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a8d2bc-f5a0-4073-8446-57dba63ff3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ad4dfac-9d8b-4122-a003-1714553189da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e029804-5dac-4572-b7e2-47e147cfa13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b86a2bd0-eba1-465b-b7fc-fcd1173eebf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95531566-2f1d-4c96-ae4b-28fbaaee601e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c4147a-89f2-4227-8173-4210e22cf237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 499e37e8-5599-418a-8d97-960d5325554b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc27343-4f50-4da1-bc75-f136991bc8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b840be6b-2699-4cf4-8e65-4d2a370d7aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644a6930-c7d4-4283-8b65-5b397b5253a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74843edd-aa70-4f9c-ac71-26e5328ffc79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fe3109-4746-41b1-9a03-65654bcd90cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5857d12-4a06-4a84-b589-0c9cfce8b016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26645859-9040-415d-a130-4af4870d65b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a40d45-2152-4b31-9ff2-f36b8c747de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390dfb0e-5898-405f-b66c-576c289f32e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c99950e0-502e-49b9-8d8a-574a4ee17415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bbcba4e-e480-4695-9bfe-ee7ca977bb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44dcbd7a-ce05-4157-8fb4-806e5f4a6a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad6e7a55-d2c1-4f04-a92d-e7a262d503a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82e0dde-b4ab-422a-8fce-f4120c940c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd668f9-a6bc-4a06-8e48-6de4b3ccaa51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bda12c-a985-4287-acec-863f5f06c552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33136260-98d0-4a66-96dd-90a14c8ede75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa8639a-ca70-4a86-ae20-64ce19bb3806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3bc55bb-78ac-48d1-b994-1c755d58736c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1e68af-8293-41b2-be1f-d0a8fcc467e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59867a40-d8ae-4a55-bbf1-4e3df28d3849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a4f4651-d69d-419b-87d8-f21af425454e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91899c81-91a1-41e7-886f-014f1d0ccecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c63fe3d-c0b8-4a7f-b53e-a8560a54e72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8250a096-663c-4c70-b41e-4110bafed2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fffd833b-1486-4876-a1de-7ce2d1fdb3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde4c376-6715-4d71-a645-f3e044dd6495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf9255df-a3f0-4ef8-9d0f-0112cccfda15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b518723b-6d08-4aa0-a755-4ccb52795bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212d179d-d7f9-477a-8c59-1964f5a3a3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44e60f1-19f9-420c-a2d3-257244e5c298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11cc2f9f-4dca-4617-93df-0723fd959d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1343e0e0-b53a-4550-a487-ddfa87f2504d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe90f45-7d8f-482a-80c4-481134a7173f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e46cca-2e5e-4010-a74a-1ef54afe50da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01c0715-a944-48c8-8406-69219c5a99d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd2ca039-04f6-409e-b2a9-19bfe4dc270d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378526d9-1e88-4db3-8c17-299d8da2c093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41cf3552-1279-4a2c-95a6-8f013dada2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02428853-17c7-4921-b1fc-2ac062e3f88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c3314e-be21-4b62-8c89-b8a57aaee99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ae9efd-57d9-4d4f-a85e-fed77f1ed5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc90f76d-607e-433a-be12-78d8bb99adbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e12e3f48-a1c3-4376-ad6b-7be9a6642db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d43e19-9f19-41a0-ad22-bb5fdbdc68a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917690e2-db6f-4683-b954-ebee482c8ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a5088a-5189-4df9-b2bf-3ae5f0c3c764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d248d3b-47ac-4ce2-be70-f5b5d8c79464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc059619-72c1-4326-9333-8e0b5db9e2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe931b9-ff7c-4f13-9167-a5ae8ca40b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4a7435-403d-4be3-9ed1-1f4e1f5ee988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e07584-1913-4323-932d-99bb75f8765c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a6c940-a1bc-4bbb-8c82-6d651bf21842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b676da72-8d74-4235-b598-39691dbc3e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7caa8d73-fd1e-42fc-b5a3-536133a6d3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01b06d0b-d46b-493e-a203-6f9eb755bad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b736b9de-b5e2-40bd-b296-bf3c648fca04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444166e3-e48a-4a21-9b9c-4bd74c68dd2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0187e7ce-05ee-41ae-9439-d91cafe20c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1abc22e9-df88-413b-a41e-7c7be30320cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a2304f-d43a-4678-b1f1-30760bd9eec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee7e6546-f0f1-46a5-9fcf-a95cfacd0065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4baaa7db-73de-4ffd-a48e-fdf017992bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663765cb-8a3f-47bb-9b6e-f5d0c51d771e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 758064de-bf3c-4421-ac7e-4ade99b9d0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c949e9b-cc24-429c-9ac1-b2d917f03d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8d3cd5-a1bf-49e8-9fc1-7c0fd417a85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a7d611-64d0-4568-9840-b35215ad97f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e439a5a-a8d8-4db1-8fbb-db0f0225d103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de30edf5-30de-4cca-9b27-6dc4d81caac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e9325b-3f71-4a00-8815-ec2800f34f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ac535a-b7f7-4e7a-b93b-5a2ae3307435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ef9682-0d68-4b6d-bdb0-a3235a301ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae531451-90a4-444d-898c-9c48e7ea610e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58edc351-8910-4d1b-af4f-1e82a1e380e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c78b23-c696-4c34-95a0-c19a4adbc25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9076dd-d386-4143-9bd5-c9cf1737ccd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b21bf9-14b6-4cd2-b4d7-27cba8558a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb3fb0b-1d11-4249-a76b-9b0e161cc7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d45924-5aaf-4f21-9bfc-d9c4d2ecb06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bae54a8-b41a-4291-8642-247c8e4acc29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3841582d-9446-43e7-9357-925101b94e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e00f8de-1703-48c0-84ae-2856b94606cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8150d2-167c-45d1-81a1-71d7648cfe12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a11a1e-7c91-49b8-9235-aac4d256e7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86b1680b-5b23-441f-8c71-7638031bbcd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd8a3b7-a91b-4c36-bdff-39526d4c973e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df1fc0f6-69c5-44d3-b620-99c062aa1ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988ebf48-b046-4568-a372-2df36add22a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c056f6f-ef47-40aa-8529-593d172e4151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8c049c-4e3c-44ea-957e-4e8e13f1c151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af1693b-eac7-43b6-8827-4aa72328f878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc2e2ec4-232d-462f-a6c3-8e24b9a5c3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57e9a7c-44ea-4f8e-a223-91839decbe03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a7aa979-257c-408f-83fe-03e4a00307de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23318b9d-c807-42a4-92c6-cdb72702c776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b43024a-9b91-432f-b078-387fcc41b390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01401c95-33f8-44c6-ae2c-44ce001a8120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c48d35c-12a7-4c08-8ab8-1abed25f753b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1027820-ae88-4955-ae49-f820579a87c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4456052a-8b62-4c44-9bfa-caafbb2fb3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e1bbb4-da64-4015-a0e0-1508d1fe2ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539428ee-4050-4087-9c64-413637c2e194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff419ce-7ccf-4305-99cc-45605d3353d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37cf8569-09fc-4b49-87e8-2ce601445ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d55f7b-2273-4d58-87ae-49c27402a934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebcb0e1b-4f4b-4d79-a998-8f62db372e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e955d00-4f81-4280-8853-b0db7ecbebe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84635a7c-efa9-4a8d-aecc-be55d09bb0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfca822e-41e0-4999-a96f-0cd568b61a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e79c6d-18a5-4ff6-ba83-0391d47be303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be05cfc-265c-4bda-8e0c-1121ae308f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39f7d30a-c1bb-4420-901c-39767c01c71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28806026-205d-4193-a650-f5ff000dcc19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ec8e995-edaf-4b09-bec8-6792e57af38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7468cb41-d4b5-421b-8e33-f53ccd55fc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72df9fd8-506d-4081-9a04-378327074c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 832a8059-ccb9-4187-ad40-76c9d0287af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8feafecf-4136-4674-954e-453150c80bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0caed664-2340-47b9-a46c-3af93bb77c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f43f59a-c84b-4984-b583-219d84e2de4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ceab98-4dc6-419b-a6e8-3797aced724d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce602a48-9685-4281-a872-169905d3c21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c10f28c8-1ace-47f0-bee0-cece4f35fffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cae4a6-57dc-4739-88f8-66f3718abfbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1d4acb-fbe8-42e7-98d8-a07ed21eb06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4ba19d-2fa9-4ba7-a1fd-b8e0ed39a4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fedc7d-dfdf-4b17-9b99-f12ce40aec2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf3bdd3-8743-4fcd-be42-677e48802cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede42db6-22d1-492f-a71a-93ea6f2d2207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00edf158-c5b8-4621-b2e7-e573dbb4465f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc2cffb0-d241-45bd-ad57-68f1ff5eda50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b91e02-9fac-4049-8bc2-6affef2b5615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ac0b7a-bd53-492c-ad7a-c6638a56e435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b1e881-c4ab-4939-bb0e-6ccfd6099852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee054d81-a545-4c49-a678-6dcc505e89fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b204bd-4238-4cbd-8d40-86e9b1d3c50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1646f67b-4c4b-43a4-91cb-8b1e0bc60eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d248fd-93ca-428f-888e-5141d1421353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b53f663-5c58-4683-8cd3-07a7ef8231ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78baaa9-8908-4547-b5fa-bb30c37d808d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f9e2b9-2381-4938-bd25-0ee0bce62c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c4d926-d255-45e3-98d7-2fc584d2f41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da119b02-7162-495b-afaf-8812c7775b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a3ae77-f0e5-4a43-9b21-44b909047f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45581587-4ce1-4587-b930-15f6ba3a0930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351d4691-85c8-47ee-abfe-55995bd268c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e540fd91-8689-465e-aa21-361f72187d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91958340-2893-45cd-8c7e-76d7bde84fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1c880b-5bbc-4675-bf6e-448f79f9da27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833d462b-8438-4f4c-9254-cc423c0484b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5943b949-e730-4b48-bb2d-44b6101ab4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7ff685-541c-4508-96ab-b6bc9d7212e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27a8563-79c5-4546-bfb9-e3016d9d020b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0216ac03-d0bb-4c89-826e-b40495032d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1211392-287e-416a-b05f-95cc6ec72af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1540bf90-d336-4a52-80a8-5b3b6f2e85e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d0a258-892d-4e19-bca6-0d1ccbac3182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79edae4-a673-4b9a-bfbb-ef15f7bcc362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216aef4d-bfa1-4e22-8424-4e3b70260460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb788e3-e902-4dd6-a062-87480e4ce56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4fb1e6-5923-4dfd-982a-06e62bcbe9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd725db7-5b72-4bbb-8fdb-3545f857c381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82386d6-1761-4aa4-a911-6300e2e078dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d48c84-6127-45c6-b7b7-8d25f3e61d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8e5a89-1f6a-4b61-b380-da0dd29c3a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb007abb-cc18-4eca-bd13-7a6a62608e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5df389-2af3-4ade-bcbb-98f6285023bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdcd409c-a7e4-4c23-937c-1b249a2c7a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9600d766-9f6d-4a78-848f-709c4ae75cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338d0a1a-b50b-4d8b-87cc-25a0f26a7391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0756eda3-55f3-4dc8-a409-e55c6a25f7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3ebb76-9465-4c2e-96eb-f82d60ee978b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0cdd64-9619-443f-b46e-c8bf880949e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2500e7d-b9ae-4c10-bfe3-0a0bf23ba735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16e08066-c148-432e-b266-c94487c2efea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e7674e-7682-43e0-83b6-f35023213b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda8e222-ce15-40aa-b673-d24d7c729385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94ef91c-c0d5-4ec8-a038-ce27f2b3623f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ca8d7e-4820-4266-bcc4-0d4d587bf226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e49e791-af77-4ff9-b805-6d3fe37ec0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b43d64-53d8-4fca-8603-20d8d3dee79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67b800f9-fd2e-41c5-95fb-445cb2ba8530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e54541-e961-468a-8b00-2dc7eabb6550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 106ef0b1-9627-40bd-b323-89ac9291b944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca149d9-15ff-42dd-96a4-eec37bad0f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7eb1e8a-e376-426d-a169-837693c13a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d358c4c-bacd-41a0-a12c-c03150585135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb7b89f-bb41-4b09-b0ef-c06026d5bec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26867e6f-e2ea-4848-8889-6fb16fdf86cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d3514a-3f7b-4b35-b4b2-01771a6e9771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00094938-cbba-41b2-9497-e1c81f84ef34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29dc6658-6366-4588-83fd-b8be5cbec3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7478f248-e5b8-4427-a454-7690dba14966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56036e34-8ff8-447f-9613-b541cce787ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8acc2bc6-dd2e-4400-a879-ced64c7563b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e0264f3-f211-4ea2-8879-1593cded41d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e00aaa-ed47-4b5d-aff7-a02e1b88f574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be35ed4-9f20-4214-9edb-49928bff8189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31e8523-020e-4097-be17-4178351ec556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafa4dd9-79eb-492f-b2f2-6bf38faf22dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd3d737-6360-4833-865c-562035272e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c0322a-2fc2-443d-a442-4a4dba3837fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb74c64c-01d2-49f1-8773-de10cf2329e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5137196-b864-416e-aaa3-6c50955a261e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5960d5af-63b6-4f04-bd31-ba545c01dfc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca36da4-d5fe-4f96-bf9b-84255be68072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4498cd-829a-465f-84f4-fdbfc8f7bbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b18b57f-a556-4de2-b06c-c016fe0814d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60847c7-a5fb-4284-9326-93acc7675577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be7f7f8-9a81-49c6-aa43-3dada914e357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854bcb2e-6450-4638-ad2d-83101c03e03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19b4957-b7af-418f-89b8-3db2059a4778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571bef4f-8e00-4f05-953c-304dbaed97d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3409fb8-d60f-44fc-8902-4684357a574f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9297544-2475-40c8-982f-6fbb4b0b7aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8768a436-db25-4553-be27-3fc21188ec18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b288b19c-d858-4904-851d-ac4095a1df22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfaf044c-8303-4b83-a876-b27200c477e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70688e07-98bb-40b6-91e8-3a87637c63e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20e7952f-bf06-4dd1-b4b0-af9c5b0f5138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbfc84ac-cbd2-4f5e-86cd-1e2dfd6cf084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23bbd8ba-0ba7-425d-9299-8e9cb522d049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fbcc449-3205-4f90-acef-3254c2ee5ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e8a37a0-2878-46c0-8a35-c42ac7214680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76281ee4-a2d6-4191-a27f-321f95c29426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b518c4c-f3df-4cf2-9783-7d667e4eded2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b2fc138-d118-4fff-ab29-2812f4c32838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c4364a-07b2-46a0-8a54-2b824e7130d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b9972e-ea4d-47d2-8c28-e09ae3d8e962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2da7ea4-5cd7-4bae-83bf-414841f66c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9d0019-739c-421c-a1f8-63051400a6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9459d3f-71ed-4bc1-84fa-ee35333d43a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe6b1a7-2777-42e4-82c5-e9d7abb6ecd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac2e1a0-64f8-4215-965e-c56aad75c522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6473b0-bab6-438c-8f99-3d23887ab50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4e6086-06d7-4c73-9e74-340b987e0cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6532cf6d-4aa3-486f-9e3e-58233b657623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f773e0-740d-433e-9ac5-39283e3a6964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603e5243-9701-4bdd-a211-94c01ee9c927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2cb6c47-f3c8-4247-af3c-e657d721f7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34ae33f-11b9-4368-8273-42193d4f2d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4473c6e0-4fce-4c06-be61-92c0eb965623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaea4a7e-daab-44d1-b33d-671c294347e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 756183ab-8367-43d4-84b1-ed78b7458c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877a738b-d3ac-4bae-ac9b-d7164e90a98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce04f71e-ecc8-4c4b-95f6-4f06412f5e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33df0479-58a9-4fb4-b261-3a2dfcff048f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4ab36bd-8192-49f1-9394-e42d9d49f09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c6e278-d72c-439f-8e32-275772973aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0ecf5c-e6d0-40cc-818c-d34fd04eb5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a3dee7-6a11-4ca0-a7a7-0da9d3790763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90cfefa2-9aa3-481a-b20d-2779a5d08ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d5f3e7-8f8e-431d-91ea-ae72629209a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc554b2-d69f-4678-bcab-075ecf8aed35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ff89e7-d437-432b-85dc-2b28815e53d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2d786d-2439-4870-9b98-a66a9ec5d163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ec7195-bb15-4454-84fd-fd7ffc6272be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86eefc86-dce6-4bd8-b54e-a1334593ef81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9061d2b-c70e-472f-b0ca-41bdf0db2c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a094691e-2bf8-4b74-9f04-89b0535e72a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af92aa4-3055-4da0-9511-9bf0839bd32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc9d1f7-ff67-44f4-bac3-b866422cc647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2c19b3-65a6-4247-a61f-535de5c0e015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f48845f-efbf-4887-90c4-62b3054a8f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c7be9e0-2acf-45d2-9d17-ff85c492a10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7968143-9a4b-4805-bb3b-e6e25711ebc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf858360-911a-451f-92b3-3268ca9a92b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c817df-2571-40cc-a5eb-57f954276a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c47e865-044a-4e65-a08b-808985b39974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f005cdbd-2ae1-4003-98ec-9276444e2ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2613db-ed24-4982-a303-33ae17526700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1bad94-f98f-4423-8a94-29f40c624b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4aaeb30-82f1-4c52-8af9-f1c031bd0614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89f8495-207d-40b2-b21f-d44e715d1316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a30661-b2fd-4785-9f14-dc52fd4c4b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a36b15d-4ecf-4457-85b6-f5cb778730b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4014b2fc-50e3-4393-9630-9d722aaea72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a15f564-4be2-4230-bfeb-aab910960d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b658e3-18c3-4a80-8e3d-866c35e0bb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ef3ac2-7dc7-4300-909b-e5a4e1920c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1ba6e0-f320-4fd7-a32a-c02ec72bed1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f2f20e-0a97-4a4d-96f5-6a2605bfd900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53736bfd-05f2-4ab6-af98-e95dad721ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7639b8-951e-4739-a3f7-cb98314c52b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c15113e-6930-4129-8918-575651c06578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b65aa8-d269-4e81-816d-6e9481579555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba1fa27f-59de-411e-9756-133b0ac1415b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 845f50aa-b729-4c98-8b67-90b377804c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec0d1689-cbdb-4874-8baf-076e9141eb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457cdfec-0337-4635-9db5-911ecd0e4484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf26cb7a-efb1-49ae-a522-ddb06b04f06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7136dbfb-b738-4150-a320-8d78a1aac773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81268027-7959-452f-9a3c-4cde6f2c0945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f3cd8d-c50c-4d80-9f9e-cc56c01121b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88fd4d88-f966-4208-b223-7df4b5a33ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374d6b63-96d4-4bd3-ad14-c3c436c0b664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7eb85e-6839-495e-956b-d890009849e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8075cf-31d7-4ad7-b39f-92ceb2320f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a2bf0ff-b0ed-4175-94af-e94750c45162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6a84cc4-a014-4bda-b7c4-a27dc842c04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0545c63c-7375-4a38-b384-3f9ac5f2a1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee820bfd-4f90-4fee-94d4-804c83fc10d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05aff684-1d59-470b-b9b1-24dae2d17d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b28b02d-3c88-4654-8c6e-badcb84d1e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f197c8-dd40-4280-8996-00c9995a561f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8384f8c7-35cb-4d3a-89eb-32255e93c87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d89d5e7-4e16-4443-8e2d-b22a1a870320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 382fbbdc-2113-48d5-8a0e-5744a8ba14b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07380ab-705c-49ce-91b8-2ae421926b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeaaf685-82a4-4b88-938e-c38b3ba9eae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e99175de-cf48-400f-9ccd-e6c3fbc8128f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300806a5-3bc0-4d20-a303-8ad432552dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d0cba1-92da-4a70-bdd4-10b6259a66fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31057275-91f7-474f-9a57-746f0c4ba48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83a69c6-2be8-4a27-a4cc-02299ad253a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d6f3504-58d9-42eb-a570-75c8b9c549ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d0fbc9-a023-4e06-a0c6-8e95ab4217ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6370445-e8fe-4bf0-a4f6-892573fc0bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050289ba-af4e-43ba-b8ab-f007fc8ff866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811988e9-c6b7-412f-b2e7-c525cb79b7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e292c5d2-7879-408b-99ed-6cd3c7952087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b324cd1-2904-4a0f-bc79-0cff080cd5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586048da-4056-459c-a6b1-306631e5a319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b32395-b996-48b0-a9ba-7c8a324644df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd862139-47e0-45a1-a0a8-0c656c7f93b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f299e23d-f01b-4bcf-932b-7d803c2871d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 564932b1-bdc5-4a33-9e4f-796514a5e377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 766e0df8-8282-443d-a42e-76b98ee32679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fcb3038-5c39-42a6-b53e-9e64df94848c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8876440-727a-4e06-98c9-201b68c0afe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad4fb82-c4e6-4e29-ba4b-174cc108818e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dad6fb3-15ae-4b9c-b24f-9ef14afe8476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6561d550-3e57-4e61-9c95-f0b43d2d1c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dbf6317-fef8-4d94-8d0a-6c1dba12d43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c604ea0-ccc5-434b-b708-4562eeb44721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d96f693-9720-4764-a942-e9df1be310b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a72224-6bf3-413f-8b0c-d745845c0c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6748373c-9a10-4e56-9485-de0caefde083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a24eec9-0f0e-43d8-8f78-a8788dfa069d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743f80c4-724e-46b3-afc5-77eab7d09bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2080811-8ed0-4d95-b0fd-0e2e59f919fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de248e4-69c4-4cd0-b859-8ef86136df1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f23c6c0e-0966-42b1-b3ac-54d9639c1a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0e15d1-21c3-4249-b727-0f8eed2e0ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8775e3d5-1b81-4c87-9e37-406d0c0d7f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27d743e-f4d1-463d-bda2-16a8fadff506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53216910-a484-496c-bec2-760c9fc48817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b83f5e-6728-4e0c-9e35-ce28114835a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f35b22-1edb-4512-a104-a342a5ac0b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fdbb98e-15eb-42ab-91fb-d79435d5e5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e047c2e4-99c6-419b-919c-f614cc3faac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1183c582-e17e-4a27-8238-e287744890d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d15f10-f5bd-4162-9718-f13e8be32c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18829aa-ed27-4842-8e9e-6b8b72b92d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16141454-075a-4d1a-8f55-915b54c0b195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17544c1f-3644-48e5-8d10-43381b4feefd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4150ce15-fc82-4b5c-95f7-4ee03d2c0cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95693b1-9f52-4fe7-9db9-21cdeca61c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94df98b4-f893-4041-9f58-ce093b43c018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecf69073-31b2-4436-b9a4-a9674804c3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f019c6-37fd-4afd-b4f1-c86c1b3c7c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708b396e-497f-4255-be9c-66e6596ec7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e7ca62-2dad-4d3f-b79a-605912b7b1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8323ad-49ac-4b37-b29e-a9ff7de56698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4643829-a625-45e7-ac49-6588d9aa09b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b98ac407-3680-4567-bc4c-ab6dd89a4dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc83c5d-5962-4aa6-880b-1bb60fa69d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c207d3ab-f492-4560-b9bd-fcbfea80fe4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4414ecd8-05b3-4438-a187-be1ca2bc74b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c1e5ad-6421-47d0-8c5c-324cc9c2d6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7903e4-56e6-4ca9-a295-07f3f96cc33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c53370-3f2b-46c8-9202-1a479815c6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16a7b4d8-25ec-431d-9eb2-112c934a625c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df78b765-2104-4004-8005-93292906fc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f873ed85-b081-40d5-9e29-4288eaa1cf09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd5ca3dc-dd5b-49c5-8053-2a98605a4bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0d02a2-450c-47e9-999c-dbb7b9b60984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3537483f-b976-49e6-ae2e-bcf6de5c1e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43292d4e-f7b3-4549-b540-b6dc46905a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6ce07a-b3c2-4874-b65f-dfd28e8b7f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d992288f-e37e-453b-b9c9-31d83b293409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b9c34d-357b-4595-a4b9-f74b1429c1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f58d47-14cd-409c-a847-872e09bf704d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afee5ec3-d731-4e10-96db-72b64e82fea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f44daf4-c8bd-4fa6-8a5e-40ececf60908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4aa7d96-c301-4854-bce3-1c22f4d4d621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e332df6-0308-4c09-9a36-fdec07cffc79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90d879f-b173-4128-889b-ddd30c9754c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178b4c4f-9d77-4f72-a1e1-651d851ba124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea24bdc-c6e4-4724-986b-b5e5135d5e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccc9cd6a-5dce-4b51-a930-1936dc13f870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca0e165-bfb5-4e61-a1f5-0c2551098da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8503e7ea-0928-47a0-9cf6-b0f7291e9a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 168c5e90-2ca9-4e0c-90aa-9e208a7cae2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0964f2ff-eca4-4c0c-8508-6aba4d112dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6aa86b-846b-4e0b-a3e9-f36dac48f4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760abba5-3426-41c3-8bdc-9fb688f04ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8248898-2f20-4ad0-a143-9cc9793b467c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9286f84c-72e3-430f-8e50-19b4da0acac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae940c3-79d7-4623-b140-420f5a01b0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d878342-1d65-40ca-8f21-83112dcc64b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f89bd4f1-e302-4139-b1a2-36b78f4a91cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae047c2-933f-4a48-a48e-6669992cb33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c73e288-5f77-4e19-bac1-8b7d9216c26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3218e04b-11a1-484d-a2b8-391c709e0026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11724571-c94f-45a6-a8a7-58e07a27e005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a3f0ea6-178b-41d6-8868-a9609d9dc93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d11136-c2d4-4983-8fff-0f8fb3f593d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749c9dd4-1e0d-49c1-ad3a-a08435699e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0934f338-6c1f-4bb3-9561-225018e91fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121f9ac9-391d-4e68-9e5c-d7614ecc5ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c006f518-003b-4c5a-b668-42b3baa383ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b63c810-27ae-46f3-b6c1-6edab5d19346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ff31de-2ff5-4b00-9b5f-ed358a4f31c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0647133d-6694-4049-9f58-0d80bae07ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e60ebab-1312-4828-b59f-c524ce3ae1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9557105-6877-455b-8635-87e5740ca6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0dc5d55-c531-4d0c-8f31-d3b3cbc8f971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b977aeb-5bb1-4d11-b187-97deddc9298b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3cfbf8-2433-4da6-9629-e9e7de9c359c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde9cff6-a87e-4720-b028-d3ebc43410f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9596be35-5ab2-41cc-959e-d97100753b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f42e44-3cb0-4152-9bb6-9b7d362d2353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1f4e19-fdf9-489e-8091-1eef734d07d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc53bdb0-2000-49fc-906b-e869861ea1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e858192-882f-442f-868e-6f1ab5a88322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40758eae-84d8-4539-ad52-a4f344d9048d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be473838-edb9-4dab-a8da-178755479ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccefb42-e434-443a-a26b-5a14fc4b5c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33820399-f292-444d-a338-d46b9085ccb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e4d089-66d6-465c-85f1-0adf13896e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42e39b6-46aa-4546-8b24-fbff24aa9427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce9998c-6cc4-4e78-8960-2969db40d66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5298cc48-0536-49be-874d-a3df6e3d03ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771b867b-2261-45e6-93bf-53362ef1e356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135c65b1-2df7-44c6-8f74-3644c60d56ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35419409-3f75-4d3b-b541-d89dffeb502a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92fb69c-8d71-4d05-becd-ec1c93ee78d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdbdab05-d372-43ee-858e-3ef53627ff50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df76417a-86cd-4b73-9974-0ca50b0db01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95bd201-419b-426c-99a0-4c6ec10b6627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5768e38d-00d5-4038-9a65-3c51bc0ccb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a681a5-b80e-4db5-9bc2-f31b745da405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff3a1fb5-5f4c-43f8-a163-b84d0d25a2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58aedc94-20dd-4c46-9192-d3af7553df3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b59331-f023-4cf6-992f-a19433dbb30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eaf5e6-60cc-4f6c-af1a-ebd9277afc68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff63ebe-5491-4df2-8531-4cdf3089f157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71d50a4-017a-4e97-898b-651eceb72904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7010f7fc-eee2-4766-b2ce-04d53fa9a055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbf7a95-8d0e-40ba-9341-10624446624e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d595dc-46fd-4165-94f5-cef8e5e07e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44a86d8-4b13-4bff-8d80-a4e025bf1be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e735cb9f-5a63-4b22-b6af-e0ead8461bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44833557-a971-4d4d-b36b-503b04f7d351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be6365e-3bb2-42a0-8903-26c80e74b80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c19084-9e00-4d36-bd35-612014133358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c35622f-dd55-4079-be33-da6dacecf6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d86649bc-6a61-47d6-8b9b-ac113c837660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6fa6b6e-9845-402d-b1f9-e221781df126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf56d701-cd0f-4dbb-b9f8-374a518fa4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5610c790-8b22-41af-af4c-80411eab9d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2c4c19-9e77-46b3-a415-e69c02623079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0541a9d4-d295-4020-b7c2-b8bb3bd8537b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d443a53c-10be-484b-b623-051cce262f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59eb7078-1677-4472-a07d-cd761f14fc46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af3f02e-8d30-4cf9-9758-06e4e0ff90e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a85d98f-2dcf-49da-901f-108620f96374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ed13fb-ed6c-445d-829d-eb3866515830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495f3fb9-8e4a-42f4-beb6-5e1775132e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e0f6e9-287e-42f4-b588-b5ccefdfceba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1719f696-cca3-4e17-a57f-77d6cf0d5a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc53c0ff-5d5a-483a-ab34-adbd5e8326b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 429bb652-041e-40fe-9626-c85fa080f8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21158007-6e81-4219-951b-bb3fb2a08308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cee7c9e-6da9-4ef6-bb76-54239438223c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e15c5b9-7967-4bbf-90d9-b00f7f80afdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bb1dcc4-80d7-47be-aba6-ccbf34748814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97da0db8-03ea-4f13-a585-d654b568d93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c95960-ea31-4053-8a72-c2b2a34237d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2b4f15-ad8a-4c06-86dc-53fc82e3cc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0153caaa-cb5f-4934-b1ea-5e1325ee8cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8822c239-4975-4200-865a-ea3a38a96912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 667ba800-009d-48a5-9073-b283a99fa2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35270540-45b8-45d4-9fc7-655ec8d99745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15bfbfd3-faac-45cb-968f-11bb725587ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfeb55f0-6d75-49e0-9a13-ba9b524ec910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02157be-b4af-4790-9b41-11c91bc56866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f63e31d-d1ef-42a3-ae4d-d6cebdcce98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c63d24-e1c0-46fc-bdfc-8bd38b9de87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555f05da-589b-4b3e-a988-52b8ed37b97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf9d6cb9-a295-43b9-af86-d2e4f5e1dddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ad830a-0309-4d64-8a8d-6bc62202c462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd75fc8f-9923-4b4c-9bd9-254ba83e6a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d9b43f0-4eaf-457f-991a-b684e28fdc48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3857f4aa-dab4-4b51-b128-7b5ca5ca1121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330a6ac2-d71a-4420-a909-2772aac9975d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c8166ab-230a-492e-b66e-18448d52d712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f55e89-2224-40b6-a07e-44261d215901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0aeb08-daea-42a7-89ab-420f07c9c301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30e4cc4-a129-47df-af7d-f2ec6f515978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73504e72-09b2-418a-bb5d-f02a0ce60c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d8d3d0-0c28-44f6-aef8-02712278a321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6958e10b-d794-4888-8553-7f7603f171e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10706fe-c3dc-4abc-9ec8-b718df1b2a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f730cae3-7dc2-4b80-bd17-9d0aab41cdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09357d77-9689-4709-98c7-bc703d913453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972803ac-83a0-45f3-a74b-d8e1a179504d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04bf65fb-8169-4107-9bb4-9c2e3822726f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1dafb5-1511-43d9-a4ca-36cda54c715c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59085fcc-24a5-402e-8f24-96eb7e3492dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d6b2af-dcc6-44f9-8024-d14abd6184b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe16dea3-d712-4d53-a0c8-6f489f91f4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9687171-6ef2-4460-84fe-30ea06d47c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3822fe3c-dff1-459b-aa12-1c39418c7ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8800148-e028-4d16-911f-f42b9f5791c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79035f1b-3850-4bce-b51f-4f7573ef53f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd26bdf1-66ae-4421-a3ea-9d42fac3dd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636bdb8c-9111-4d07-a569-222a4905132e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651ded24-b879-413e-ab5e-55030d25a936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2819c494-3a85-49df-b2f2-4593fe8c25c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c20a20-5c67-47f4-85a0-a987aa9ef4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 259cb51a-c973-4c8c-ab20-948dc755b2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1ab4e5-fae5-45eb-9fe1-632714a14e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930ea028-a76d-4b24-be5e-582300d840ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfdc8e08-0362-4f95-8681-991d8bd96079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46dd8d8-b540-4c80-ba0c-4aaf8008827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377acef2-8040-46fb-8aa1-5839763c3a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269066af-de1c-4dc0-b676-65daf96917c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3580db0-3a4f-4356-aabd-eb14c7baa7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9695787b-02ed-4f8b-acea-94e7fc63d808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 147f0c63-a8f7-4e0f-a9e0-191d6da8c126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef82f57-a6dd-4b84-839c-11e3d841e82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853b8ee9-5271-4cab-9da6-bc678852db55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0966d714-9789-4603-a874-937ccc76e724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619e8ade-49ea-4f62-81ce-d9d11457bdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e74fc0-fefa-4e05-9336-e5ea8580364f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33ffac0-86e1-40e3-bb03-884db0a716f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f58d6f-3f5c-4374-b365-2123f5ec7cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87c7a181-a91b-434e-b88d-a9c1f9ec8aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340fe9e1-be83-446c-a228-bdcde57e2aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026b0555-5895-4970-b0e0-d589fdcb8998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef99541-cfa1-41de-93bc-b6a7efe470ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 567bb495-ac62-49d9-b905-465e228ef899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a93af62-a68c-4cb3-8285-6bf650d6dbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907b944b-bf83-499a-bdb8-d9a648591419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45cff9f-7095-4d64-9bb7-409b6592f99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79c03df-fe80-4188-89cd-7e7a0c8bc4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6dc981-1124-4742-86d2-24c58897bc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca8d936-f8c0-4312-87eb-c37cc778ed11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f05ae633-a5bd-40fd-9fac-510de83b6816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9387c380-ea40-496a-b3fa-e83a1d5b7256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e68e38-1304-46cf-a364-6679640d33bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca403e7-682b-4c3d-a18d-8407591a99ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3934306-ede2-4a3f-b4a0-9ccad89c2cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91770f23-9d85-4f66-9290-9e16be25fbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40eb9c16-673a-43da-a92b-6ce34c610f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee6efbd-b924-4174-a3bc-5daa4c5c585b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32206d8d-cbc8-449c-84b3-7c6e3feb12c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c836895-31d0-4a94-bd0d-b907bad03d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d2dcf0-5abc-4ea8-98d5-84e895390c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6f12559-578e-4696-ba0a-a401a084d6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c31fa99-c5ec-42d8-955a-23983f21a25e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8802a3-1de4-4357-bea9-92849b6bac6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a22665-d216-42e6-acba-92c7135991a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca015e9c-72b0-4954-b097-65ea3f55ed76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd49ce1-a1b7-4983-ad7d-c0581a1c4bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a93a5ab3-25f0-451a-9efe-817f3242823c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e6293a4-04ec-4610-bf79-194197d74a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6ee44c-c0a3-4421-a4b7-61b843122cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8663bcc3-9460-4093-b111-4d1c6fc6e069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f53738eb-3006-4bcd-b6a2-06f8bd27aa9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c699534c-d908-484d-af10-7fc10f4b2a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b943c7a0-3a82-44a4-9a92-c6d8fb564dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f815b91-2e08-4bf4-90aa-6e70069f1201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ccc4ad4-5a2f-4ae1-b1cc-f81156552fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991cef78-b4fe-4419-a620-7a469f609b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc355a3-7fa7-4603-84ab-3f8d013a0528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc323071-58cc-4a70-a8c6-53d8771cb7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2174934-6db7-431d-bdff-eb2974d69bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92120383-1878-4e8e-b518-cf05a73dc03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced0c17f-9073-4f59-acc3-6a6396f92152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d44414-c0bf-43a2-9197-e7a575a12fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133b264f-1d19-4cc3-a73f-28423c1666d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d762c82-47ee-46af-a4b5-a2eae34e5ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f188e54f-4332-4cef-888a-692573d2e0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5b1250-51cd-4aa6-bb57-007647cc238b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a194b0e-4eae-4bf4-84da-ebc0463ea1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9248b3f0-e5f5-4cb9-bea1-0be7566592af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675dabb7-8b7a-4895-bf53-b9cf2e226ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5da88e8-f3f2-4298-8bc0-7aa840bceea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b51ce87-cd0e-4eae-a421-e4ce5321e623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1c8096-ecd6-4aae-a660-3d0f8d040191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c836d9-4f0a-49b2-8064-d44c219928fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3005285f-c0ea-4643-8209-94e9c360c2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8535886d-056a-4de8-a9d2-5ca91d2be0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017a0330-fa2d-4e23-a121-c120cb5c7662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27968b09-2eaf-4540-b339-88680cce4173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e662e63-fe74-4d7d-ac27-d8389bc72514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95a6212-cef2-4e85-a75d-e2501d438da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a04fd17-3ba8-42c6-85b0-adb3f36b2d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc2a103-a23c-4ede-bba6-7271696bb99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58521ab-d9bc-42ab-9f84-5f57280d4150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f5da5d-4243-4db5-9fd2-59c4bf90cf5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c705f7-f56a-42af-88b1-fdcb421d80e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dfdafa2-640f-472c-bc99-a20e22fdc16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd67a6e-3167-4505-b6eb-41dbf9bc0884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5a9907-cd7b-4c56-bd5c-17f0a395a381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4992be7-ea6e-4846-a6f7-3e150cde57ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1f0517-823f-4c53-9c76-144ec571c0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a77e7b5-554c-49d9-a68a-1105cf527f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc885b8d-fd0d-447f-b9ea-7a79ebdf6f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4982b9ac-0226-44e3-9233-1e76875b351c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b454373f-10e5-438e-bb9b-34079e0649b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43591201-91a8-44b7-a0ff-b0e496b66815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec30d056-16d5-4bf7-a21d-ea5ea5d8bdec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6907372-dfcf-4f7c-b874-230395e87916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abfa292-0bca-4fac-af8b-9c14e845e76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f930778-57ee-4acd-a68b-cf2ba1eab938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ae3417-fe01-4fe3-bd12-a8cb8f6cf9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52cd2847-476f-4768-bd44-aae95ed93c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0e92f5-315e-4a6b-9fd6-51099e587984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f15acc-3472-48c5-95c7-06482055263f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54c975f-72bc-4531-af84-b97cfa03e43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b16e5b-c89f-432c-9bd2-2e2670685416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c62787-63c7-4c1f-89d9-0954f13ce7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dab1bfb-dd37-444f-a572-b4704e4aa6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c89b963-d39b-4250-99d8-396a3a91294c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b194d642-39cd-4b68-8ddc-91fa891c5e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40eb233f-9b96-4176-b453-036ae76976cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdc9847-11ea-41dc-bf41-63675fbd2e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896c89ea-9552-4cc6-8574-0f5155e168e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d930305-0ea7-4ea3-a6d6-7c8dc9adb066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb00193a-d5b9-4175-8a03-a227e367c809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814edf93-fcbd-41b6-930b-459b3a4a27d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ce5846-fe51-4396-8677-1efbe48a3c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d4b3ac-bfa6-407a-8035-9022caa8278b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3fa893e-32c1-402f-ad7e-61bc29bfef89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27559f06-4c44-43e0-aadd-7ff60218790f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb241bbf-1920-4b5d-994c-d8883ace8b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0e61f9-1a8a-438c-8c7e-23f9311144c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf81869d-6fb7-408e-b1ca-43eda410f5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d9c1662-2b55-4efd-967b-4cba5fed93ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7586826e-9f3e-4999-b921-5b642ff707d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1dd3824-0e77-4340-bf44-d2eba9ce6c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eb5a88-6fde-46b9-961f-b050a94b136d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d051116-309f-479f-a005-1fec7261df7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce680eb8-9970-4588-b587-4cacb25e64c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e300abc-d8f0-45ef-8b83-7d7322eba458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414acd58-e737-4f52-80b9-3889589fd6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5aec2e-fc84-4f3f-bec0-167d23bbcfb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22e35d9-0915-43e9-93e7-878ac30c1b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde1c1a3-03c0-416b-bc27-7f127dc5021f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e456eed-df24-4e4b-ae12-dabf40594078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf6ff0d7-0d1e-4e9e-864b-4c0db641e7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8c7834-05a1-47cd-b096-11bc612286dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae6d0a3-1c32-4fd4-b5e4-2addb2eea2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebe916f3-6609-4a74-96be-f5d428afa347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5d50d1-d97e-494e-87ec-4c100cd6152f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c4e50a-840c-47aa-bf5c-05e796f263bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42a14071-311e-42fc-b54e-dc5b990e691f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0d6fe7-53fb-4ad1-a28e-73ae9e879991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c27c39-7f30-4af1-8893-79fad61481a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d40343a-04c2-4a50-9bb0-af4657eabf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bbe6e50-ae44-4789-9103-d4ced87889e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526b280e-f82c-4e62-bc41-12ef8eb6ce5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce6ed2a-8f63-487d-b6a5-3b1c89e87ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f72b42-8e97-46dd-a630-6e29feca9edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e70d8d-8a20-45a2-997e-a683679ecf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133e20fa-10df-4bb7-898d-a5b6e1572541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 134a573e-739d-40b6-9e59-8ef963d2c74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e898bc6-a2a8-49c4-84e5-a7e66924c289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135b1478-b7dc-419e-9a38-2c4318a29263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b0f31a-d672-4d6f-8190-d26e344f5dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e628eb8-91d4-44dc-91d8-b07f0d5f10aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e397ac-f451-44e6-993e-f409d7816174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b722b3e9-1560-47dd-ab78-94a8f8bce8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30b5d0c-2810-4078-a65a-5e38da99b014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfa21f6-7024-4eb8-a7da-5109e5bb1bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ecd9fa-188a-4223-bc49-e2a515289a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c9678fc-3f8e-41d5-8e4e-7d7bc7721fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b0cd78-8032-4054-81ff-e94d91fe8ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae8c6f1-b65a-43c8-9c8b-66e2d44dbaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 282fa5ae-e8b3-43bb-8d53-6bbe9c33d807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7885e8a2-cf49-4a05-b27e-3b4364e46f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5becee-e686-403c-9398-8953c5415129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8128a7be-8f92-4cfd-914e-fe8b8181d97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222e940b-25e4-45d6-a801-701cab006dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7cddc7-dc5c-4d88-bfb4-e141445a5525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e1142c-7378-4559-8241-f543979193b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d4a09a-36f9-47e6-8de1-1df2e6dd9068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54b9e6a8-1d3d-4d73-a032-dbf9254daa93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715c91f1-224f-4c50-b17f-174e41768e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02789bab-fdfa-4f50-a7e1-cc78d072846c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49fefdc-be7c-4ca0-95fd-a81440b236f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c88442e-1a63-4355-99e2-6393b258b15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68acf2f2-43d2-491c-8b96-39b8ed76d96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43685f64-e72d-4d77-979b-cfbd0a6b1ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f2d5642-de0b-4d4c-88b9-a12baad36f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1efa53-2026-41e3-ba95-03e25eb91462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 779246d0-60ca-4aea-871f-1040bd006db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cba66ff3-bfcd-4e08-8163-12175702d0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26a2a8c-1918-4dbb-b708-518912a5a223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf1386f-79e3-42e1-b180-376499dce453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51a9462-907e-44eb-b8b2-396a17f4cf2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74885464-9664-4a56-a43a-a1874ffa2611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4794f2d1-a6cd-4aa0-af98-29f4818a1406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0b2324-febe-4065-a082-7d55526a7f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec899dc-7c2c-41fc-b6ab-3b90d932679a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e83ccb-c564-4877-b91f-e6b3c71b7dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1bc9d3-9d1b-49f2-be5d-5696a2537fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c31716b-8475-4cde-a9de-b547c98d829e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5fc4995-a55f-4b7e-93c0-84608127a270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25655fca-fd96-431d-bc5d-52a2c049fed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c70d5d0e-4a16-4798-9251-57dd99824188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e326c8-459c-4345-9bf2-3858d51d3159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fb44d4-5209-476f-85e3-1b3933e2691d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9b4a5f-68de-4cdb-a83d-c2a6707ec1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fe23b7-61f9-4570-88d4-d459a780b461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f24eda4e-c71f-42bc-baea-9c35fc5f33b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca419391-a9e9-42e0-8580-f87cb13b74d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3980c5cd-3fad-4e6f-97be-c62bc5c29cd7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(6680, 24), y=(6680,)
   Test:  X=(1670, 24), y=(1670,)

⚠️  Limiting training data: 6680 → 800 samples
⚠️  Limiting test data: 1670 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0876 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0896, val=0.0847 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0890, val=0.0841 (↓), lr=0.001000
   • Epoch   4/100: train=0.0881, val=0.0843, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0879, val=0.0846, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0868, val=0.0850, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 2 Summary - Client client_20
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0060
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0114
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2487, R²: -0.0021

============================================================
🔄 Round 5 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0871 (↓), lr=0.000250
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0859, val=0.0880, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0858, val=0.0881, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0855, val=0.0885, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 5 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0045
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0103
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2488, R²: -0.0007

============================================================
🔄 Round 7 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0892 (↓), lr=0.000063
   • Epoch   2/100: train=0.0855, val=0.0891, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0854, val=0.0891, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0854, val=0.0891, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0853, val=0.0891, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0852, val=0.0890, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 7 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0012
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0125
============================================================


============================================================
🔄 Round 8 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0841 (↓), lr=0.000016
   • Epoch   2/100: train=0.0871, val=0.0842, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0871, val=0.0843, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0870, val=0.0845, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0869, val=0.0847, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 8 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0006
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0005
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

📊 Round 8 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

============================================================
🔄 Round 14 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0773 (↓), lr=0.000004
   • Epoch   2/100: train=0.0887, val=0.0773, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0886, val=0.0774, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0886, val=0.0774, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0886, val=0.0774, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0885, val=0.0775, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 14 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0027
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0079
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

============================================================
🔄 Round 15 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 15 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0005
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0021
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0003

============================================================
🔄 Round 21 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 21 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0042
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0117
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0003

============================================================
🔄 Round 22 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 22 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0017
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0018
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 22 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 22 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 22 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

============================================================
🔄 Round 34 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 34 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0007
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0003
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

============================================================
🔄 Round 37 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 37 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0038
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0076
============================================================


============================================================
🔄 Round 38 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 38 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0013
   Val:   Loss=0.0976, RMSE=0.3123, R²=0.0022
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

📊 Round 38 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0002

============================================================
🔄 Round 49 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 49 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0015
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0130
============================================================


============================================================
🔄 Round 50 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 50 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0015
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0104
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0001

============================================================
🔄 Round 55 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 55 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0030
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0034
============================================================


============================================================
🔄 Round 56 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 56 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0008
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0110
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0001

📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0001

📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0001

============================================================
🔄 Round 62 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 62 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0006
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0065
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: 0.0001

📊 Round 62 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: 0.0001

============================================================
🔄 Round 65 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 65 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0021
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0044
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: 0.0001

============================================================
🔄 Round 67 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 67 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0107
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0001

📊 Round 67 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0001

📊 Round 67 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

============================================================
🔄 Round 74 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 74 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0010
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0170
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

============================================================
🔄 Round 84 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 84 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0025
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0008
============================================================


============================================================
🔄 Round 86 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 86 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0017
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0043
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

============================================================
🔄 Round 88 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 88 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0000
   Val:   Loss=0.0972, RMSE=0.3118, R²=0.0075
============================================================


============================================================
🔄 Round 89 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 89 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0027
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0004
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 89 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

============================================================
🔄 Round 92 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 92 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0019
   Val:   Loss=0.0879, RMSE=0.2966, R²=0.0027
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

============================================================
🔄 Round 98 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 98 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0043
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0067
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0000

📊 Round 98 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 101 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 101 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0007
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0273
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 103 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 103 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0019
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0016
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 107 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 107 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0018
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0022
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 111 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 111 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0046
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0113
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 116 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 116 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0019
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0001
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 117 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 117 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0020
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0002
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 118 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 118 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0051
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0114
============================================================


============================================================
🔄 Round 120 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 120 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0002
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0039
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 121 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 121 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0000
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0025
============================================================


============================================================
🔄 Round 122 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 122 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0014
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0407
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 124 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 124 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0029
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0051
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 126 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 126 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0005
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0142
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 132 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 132 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0010
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0057
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 135 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 135 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0015
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0054
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 135 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 139 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 139 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0032
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0032
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 142 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 142 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0017
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0011
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 146 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 146 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0024
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0135
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 146 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 150 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 150 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0005
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0055
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 152 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 152 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0029
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0030
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 153 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 153 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0022
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0124
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 154 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 154 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0019
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0010
============================================================


============================================================
🔄 Round 157 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 157 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0030
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0009
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 160 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 160 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0034
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0049
============================================================


============================================================
🔄 Round 162 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 162 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0019
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0009
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 162 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0066
   Val:   Loss=0.0993, RMSE=0.3151, R²=-0.0197
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

============================================================
🔄 Round 168 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 168 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0012
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0090
============================================================


============================================================
🔄 Round 169 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 169 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0001
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0098
============================================================


============================================================
🔄 Round 170 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 170 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0006
   Val:   Loss=0.0956, RMSE=0.3093, R²=0.0080
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 170 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0000

📊 Round 170 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 176 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 176 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0023
   Val:   Loss=0.0957, RMSE=0.3094, R²=0.0019
============================================================


============================================================
🔄 Round 177 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 177 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0026
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0007
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 178 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 178 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0042
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0054
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 178 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 178 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 178 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 186 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 186 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0010
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0096
============================================================


============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0008
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0011
============================================================


============================================================
🔄 Round 189 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 189 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0035
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0021
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 192 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 192 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0015
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0051
============================================================


============================================================
🔄 Round 193 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 193 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0015
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0048
============================================================


============================================================
🔄 Round 194 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 194 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0026
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0067
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 195 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 195 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0050
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0091
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 196 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 196 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0029
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0004
============================================================


============================================================
🔄 Round 197 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 197 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0001
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0001
============================================================


============================================================
🔄 Round 198 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 198 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0020
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0046
============================================================


============================================================
🔄 Round 199 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 199 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0013
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0052
============================================================


============================================================
🔄 Round 200 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 200 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0031
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0030
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 201 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 201 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0043
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0051
============================================================


============================================================
🔄 Round 202 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 202 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0001
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0001
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 206 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 206 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0040
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0063
============================================================


============================================================
🔄 Round 207 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 207 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0034
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0045
============================================================


============================================================
🔄 Round 208 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 208 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0032
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0039
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 213 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 213 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0025
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0905
============================================================


============================================================
🔄 Round 214 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 214 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0021
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0020
============================================================


============================================================
🔄 Round 215 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 215 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0025
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0014
============================================================


============================================================
🔄 Round 217 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 217 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0010
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0101
============================================================


============================================================
🔄 Round 219 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 219 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0019
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0039
============================================================


============================================================
🔄 Round 220 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 220 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0028
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 220 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 228 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 228 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0038
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0084
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 228 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 230 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 230 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0041
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0070
============================================================


============================================================
🔄 Round 231 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 231 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0007
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0049
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 231 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 231 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 234 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 234 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0020
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0128
============================================================


============================================================
🔄 Round 236 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 236 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0052
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0093
============================================================


============================================================
🔄 Round 237 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 237 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0026
   Val:   Loss=0.0979, RMSE=0.3130, R²=0.0014
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 242 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 242 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0006
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0096
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 242 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 242 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 247 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 247 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0023
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0079
============================================================


============================================================
🔄 Round 248 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 248 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0015
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0004
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 249 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 249 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0021
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0052
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 251 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 251 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0022
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0107
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 256 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 256 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0055
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0173
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 257 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 257 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0048
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0210
============================================================


============================================================
🔄 Round 259 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 259 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0016
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0175
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 262 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 262 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0114
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 262 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 264 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 264 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0007
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0264
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 267 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 267 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0024
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0072
============================================================


============================================================
🔄 Round 268 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 268 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0027
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0016
============================================================


============================================================
🔄 Round 269 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 269 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0035
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0014
============================================================


============================================================
🔄 Round 271 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 271 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0022
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0107
============================================================


============================================================
🔄 Round 272 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 272 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0028
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0065
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 274 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 274 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0006
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0062
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 275 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 275 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0001
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0082
============================================================


============================================================
🔄 Round 276 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 276 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0001
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0053
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 276 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 276 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 276 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 276 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 283 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 283 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0017
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0045
============================================================


============================================================
🔄 Round 285 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 285 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=0.0023
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0054
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 285 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 285 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 289 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 289 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0031
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0034
============================================================


============================================================
🔄 Round 291 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 291 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=0.0057
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0167
============================================================


============================================================
🔄 Round 292 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 292 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0050
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0187
============================================================


============================================================
🔄 Round 294 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 294 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0000
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0094
============================================================


============================================================
🔄 Round 295 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 295 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0039
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0079
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 295 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 298 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 298 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0039
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0081
============================================================


============================================================
🔄 Round 299 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 299 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0050
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0119
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 300 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 300 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0068
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0129
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 301 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 301 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0009
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0072
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 301 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 301 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 306 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 306 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0030
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0013
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 306 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 310 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 310 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0002
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0129
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 312 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 312 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0039
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0045
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 314 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 314 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0038
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0032
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 317 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 317 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0016
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0067
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 320 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 320 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0026
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0030
============================================================


============================================================
🔄 Round 321 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 321 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0006
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0083
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 322 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 322 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0010
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0060
============================================================


============================================================
🔄 Round 323 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 323 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0048
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0079
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 324 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 324 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0009
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0016
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 325 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 325 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0028
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0017
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 327 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 327 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0035
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0114
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0002

============================================================
🔄 Round 328 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 328 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0061
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0209
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0002

============================================================
🔄 Round 329 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 329 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0029
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0046
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0002

============================================================
🔄 Round 330 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 330 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0033
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0125
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0002

============================================================
🔄 Round 332 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 332 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0009
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0095
============================================================


============================================================
🔄 Round 336 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 336 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0041
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0055
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0002

📊 Round 336 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 336 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 344 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 344 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0044
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0060
============================================================


============================================================
🔄 Round 345 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 345 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0036
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0069
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 346 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.1001, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 346 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0017
   Val:   Loss=0.1002, RMSE=0.3165, R²=0.0052
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 347 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 347 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0047
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0222
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 347 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 351 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 351 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0008
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0104
============================================================


============================================================
🔄 Round 352 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 352 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0038
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0113
============================================================


============================================================
🔄 Round 353 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 353 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0016
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0387
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 355 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 355 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0023
   Val:   Loss=0.0945, RMSE=0.3073, R²=-0.0058
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 355 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 358 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 358 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0018
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0055
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 358 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 358 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 366 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 366 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0029
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0016
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 369 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 369 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0016
   Val:   Loss=0.0971, RMSE=0.3116, R²=0.0065
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 371 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 371 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0017
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0010
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 371 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 375 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 375 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0030
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0080
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 377 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 377 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0017
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0077
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 378 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 378 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0051
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0084
============================================================


============================================================
🔄 Round 379 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 379 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0036
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0008
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 379 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 381 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 381 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0018
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0054
============================================================


============================================================
🔄 Round 382 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 382 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0024
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0031
============================================================


============================================================
🔄 Round 384 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 384 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0008
   Val:   Loss=0.0984, RMSE=0.3137, R²=0.0089
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 384 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 387 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 387 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0026
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0009
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 391 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 391 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0000
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0128
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 391 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 399 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 399 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0038
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0182
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 400 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 400 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0022
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0047
============================================================


============================================================
🔄 Round 402 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 402 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0035
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0120
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 402 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 404 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 404 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0004
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0085
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 406 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 406 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0034
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0007
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 407 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 407 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0028
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0018
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 407 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 407 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 410 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 410 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0031
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0015
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 421 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 421 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0036
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0006
============================================================


============================================================
🔄 Round 423 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 423 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0027
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0024
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 424 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 424 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0021
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0032
============================================================


============================================================
🔄 Round 425 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 425 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0029
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0010
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 426 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 426 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0033
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0074
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 431 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 431 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0032
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0123
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 432 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 432 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0052
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0089
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 435 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 435 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0041
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0050
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 435 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 437 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 437 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0038
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0013
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 440 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 440 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0029
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0020
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 443 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 443 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0016
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0072
============================================================


============================================================
🔄 Round 444 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 444 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0010
   Val:   Loss=0.0956, RMSE=0.3092, R²=0.0034
============================================================


============================================================
🔄 Round 445 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 445 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0027
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0039
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 446 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 446 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0005
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0099
============================================================


============================================================
🔄 Round 448 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 448 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0025
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0167
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 449 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 449 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2950, R²=0.0031
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0012
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 449 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 453 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 453 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0032
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0012
============================================================


============================================================
🔄 Round 454 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 454 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0008
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0101
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 458 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 458 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0043
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0059
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 462 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 462 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0000
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0027
============================================================


============================================================
🔄 Round 463 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 463 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0021
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0054
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 463 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 463 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 468 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 468 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0050
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0065
============================================================


============================================================
🔄 Round 469 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 469 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0040
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0027
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 470 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 470 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0034
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0072
============================================================


============================================================
🔄 Round 471 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 471 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0031
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0023
============================================================


============================================================
🔄 Round 472 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 472 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0041
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0048
============================================================


============================================================
🔄 Round 473 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 473 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0025
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0026
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 473 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 477 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 477 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0000
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0062
============================================================


============================================================
🔄 Round 478 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 478 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0059
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0154
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 480 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 480 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0017
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0022
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 481 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 481 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0029
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0028
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 481 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 481 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 487 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 487 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0020
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0050
============================================================


============================================================
🔄 Round 488 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 488 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0046
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0152
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 488 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 493 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 493 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0019
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0033
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 494 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 494 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0054
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0268
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 494 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 499 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 499 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0029
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0009
============================================================


============================================================
🔄 Round 500 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 500 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0034
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0064
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 503 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 503 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0035
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0002
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 504 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 504 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0014
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0196
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 509 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 509 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0021
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0055
============================================================


============================================================
🔄 Round 511 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 511 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0013
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0044
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 512 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 512 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0037
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0031
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 514 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 514 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0018
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0152
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 516 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 516 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0025
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0019
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 518 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 518 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0056
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0105
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 519 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 519 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0013
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0079
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 522 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 522 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0015
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0083
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 524 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 524 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0040
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0077
============================================================


============================================================
🔄 Round 525 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 525 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0013
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0089
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 525 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 527 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 527 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0029
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0008
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 527 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 527 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 527 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 534 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 534 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0026
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0020
============================================================


============================================================
🔄 Round 536 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 536 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0023
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0038
============================================================


============================================================
🔄 Round 537 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 537 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0017
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0296
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 538 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 538 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0047
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0278
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 538 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 541 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 541 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0011
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0068
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 542 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 542 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0030
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0016
============================================================


============================================================
🔄 Round 545 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 545 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0142
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 545 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 547 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 547 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0001
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0111
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 548 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 548 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0019
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0056
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 548 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 553 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 553 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0033
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0001
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 554 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 554 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0049
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0074
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 554 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 558 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 558 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0021
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0059
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 558 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 562 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 562 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0045
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0100
============================================================


============================================================
🔄 Round 563 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 563 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0035
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0002
============================================================


============================================================
🔄 Round 565 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 565 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0040
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0017
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 565 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 568 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 568 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0046
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0283
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 571 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 571 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0033
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0001
============================================================


============================================================
🔄 Round 572 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1024 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.1024, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.1024, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.1024, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.1024, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1024, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1024)

============================================================
📊 Round 572 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0020
   Val:   Loss=0.1024, RMSE=0.3199, R²=0.0024
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 572 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 576 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 576 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0040
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0055
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 579 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 579 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0013
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0045
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 579 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 579 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 582 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 582 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0025
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0020
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 583 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 583 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0028
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0017
============================================================


============================================================
🔄 Round 585 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 585 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0012
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0101
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 586 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 586 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0011
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0088
============================================================


============================================================
🔄 Round 588 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 588 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0008
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0081
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 590 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 590 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0030
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0024
============================================================


============================================================
🔄 Round 593 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 593 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0058
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 593 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 596 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 596 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0034
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0009
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 597 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 597 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0023
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0073
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 597 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 599 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 599 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0010
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0024
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 602 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 602 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0004
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0167
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 604 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 604 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0031
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0021
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 604 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 606 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 606 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0047
   Val:   Loss=0.0998, RMSE=0.3159, R²=-0.0053
============================================================


============================================================
🔄 Round 607 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 607 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0032
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0003
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 608 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 608 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0029
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0029
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 610 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 610 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0045
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0050
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

📊 Round 610 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 610 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0001

============================================================
🔄 Round 615 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 615 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0029
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0031
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 616 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 616 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0041
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0046
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 616 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 621 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 621 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0047
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0045
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 624 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 624 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0022
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0028
============================================================


============================================================
🔄 Round 627 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 627 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0038
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0104
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 629 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 629 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0035
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0005
============================================================


============================================================
🔄 Round 630 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 630 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=0.0014
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0028
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 631 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 631 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0025
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0042
============================================================


============================================================
🔄 Round 632 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 632 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0055
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0149
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 634 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 634 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0055
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0080
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 640 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 640 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0018
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0076
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 642 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 642 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0029
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0018
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 644 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 644 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0049
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0167
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 645 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 645 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0022
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0059
============================================================


============================================================
🔄 Round 649 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 649 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0012
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0019
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 651 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.1011, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 651 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0063
   Val:   Loss=0.1010, RMSE=0.3177, R²=-0.0029
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 651 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 651 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 656 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 656 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0003
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0146
============================================================


============================================================
🔄 Round 657 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 657 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0016
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0040
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 659 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 659 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0031
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0007
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 663 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 663 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0027
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0309
============================================================


============================================================
🔄 Round 665 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 665 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0042
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0025
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 667 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 667 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0018
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0073
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 667 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 667 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 667 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 678 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 678 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0000
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0065
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 681 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 681 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0013
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0068
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 684 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 684 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0020
   Val:   Loss=0.0887, RMSE=0.2977, R²=0.0057
============================================================


============================================================
🔄 Round 686 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 686 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0015
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0076
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 687 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 687 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0009
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0390
============================================================


============================================================
🔄 Round 688 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 688 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0061
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0099
============================================================


============================================================
🔄 Round 689 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 689 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0010
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0094
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 689 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 694 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 694 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0031
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0026
============================================================


============================================================
🔄 Round 695 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 695 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0043
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0027
============================================================


============================================================
🔄 Round 696 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 696 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0029
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0001
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 698 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 698 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0017
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0079
============================================================


============================================================
🔄 Round 699 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 699 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0009
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0009
============================================================


============================================================
🔄 Round 700 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 700 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0022
   Val:   Loss=0.0960, RMSE=0.3098, R²=0.0053
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 700 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 700 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 705 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 705 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0012
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0090
============================================================


============================================================
🔄 Round 706 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 706 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0016
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0045
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 707 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 707 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0023
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0048
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 708 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 708 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0015
   Val:   Loss=0.0987, RMSE=0.3141, R²=0.0155
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 710 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 710 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0034
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0007
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 714 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 714 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0041
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0034
============================================================


============================================================
🔄 Round 715 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 715 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0006
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0058
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 715 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 717 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 717 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0041
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0033
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 717 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 721 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 721 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0036
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0007
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 721 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 721 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 721 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 726 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 726 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0021
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0039
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 727 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 727 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0042
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0044
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 731 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 731 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0018
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0082
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 733 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 733 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0056
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0074
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 733 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 737 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 737 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0025
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0055
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 739 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 739 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=0.0039
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0052
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 740 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 740 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0029
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0023
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 740 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 740 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 743 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 743 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0052
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0083
============================================================


============================================================
🔄 Round 745 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 745 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0039
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0120
============================================================


============================================================
🔄 Round 746 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 746 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0021
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0035
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 747 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 747 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0033
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0095
============================================================


============================================================
🔄 Round 748 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 748 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0002
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0085
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 748 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 751 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 751 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0067
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0150
============================================================


============================================================
🔄 Round 753 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 753 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0023
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0042
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 756 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 756 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0039
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0014
============================================================


============================================================
🔄 Round 757 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 757 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0020
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0129
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 757 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 761 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 761 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0046
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0032
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 763 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 763 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0136
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 763 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 765 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 765 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0015
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0064
============================================================


============================================================
🔄 Round 767 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 767 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0022
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0013
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 767 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 769 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 769 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0022
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0063
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 770 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 770 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0014
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0068
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 772 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 772 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0023
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0057
============================================================


============================================================
🔄 Round 775 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 775 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0006
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0044
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 778 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 778 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0006
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0106
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 780 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 780 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0024
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0010
============================================================


============================================================
🔄 Round 781 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 781 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0026
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0029
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 787 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 787 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0036
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0066
============================================================


============================================================
🔄 Round 788 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 788 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0018
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0036
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 791 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 791 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0036
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0057
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 792 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 792 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0038
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0001
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 792 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 792 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 798 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 798 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0026
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0041
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 801 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 801 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0031
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0023
============================================================


============================================================
🔄 Round 803 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 803 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0027
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0047
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 804 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 804 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0037
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0039
============================================================


============================================================
🔄 Round 805 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 805 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0035
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0095
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 805 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 808 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 808 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0028
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0040
============================================================


============================================================
🔄 Round 809 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 809 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0008
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0024
============================================================


📊 Round 809 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 810 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 810 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0017
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0023
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 810 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 810 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 813 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 813 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0037
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0043
============================================================


============================================================
🔄 Round 814 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 814 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0034
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0021
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 814 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 814 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 817 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 817 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0029
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0040
============================================================


============================================================
🔄 Round 818 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 818 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0060
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0160
============================================================


📊 Round 818 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 818 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 821 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 821 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0031
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0031
============================================================


📊 Round 821 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 823 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 823 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0045
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0175
============================================================


============================================================
🔄 Round 824 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 824 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0019
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0046
============================================================


📊 Round 824 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 824 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 824 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 829 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 829 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0035
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0015
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 831 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 831 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0036
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0073
============================================================


📊 Round 831 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 834 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 834 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0044
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0022
============================================================


📊 Round 834 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 837 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 837 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0111
============================================================


============================================================
🔄 Round 838 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 838 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0026
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0026
============================================================


============================================================
🔄 Round 842 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 842 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0034
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0066
============================================================


============================================================
🔄 Round 844 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 844 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0002
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0112
============================================================


📊 Round 844 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 846 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 846 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0040
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0113
============================================================


============================================================
🔄 Round 847 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 847 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0031
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0008
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 848 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 848 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0054
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0134
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 849 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 849 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0011
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0061
============================================================


============================================================
🔄 Round 850 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 850 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0022
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0024
============================================================


📊 Round 850 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 851 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 851 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0049
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0050
============================================================


📊 Round 851 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 851 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 851 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 851 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 858 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 858 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0030
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0019
============================================================


📊 Round 858 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 858 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: 0.0000

============================================================
🔄 Round 861 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 861 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0036
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0010
============================================================


📊 Round 861 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: 0.0000

============================================================
🔄 Round 866 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 866 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0031
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0023
============================================================


📊 Round 866 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 866 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 866 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 866 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 871 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 871 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0026
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0016
============================================================


📊 Round 871 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 876 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 876 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0045
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0303
============================================================


============================================================
🔄 Round 877 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 877 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0019
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0074
============================================================


============================================================
🔄 Round 882 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 882 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0049
   Val:   Loss=0.0998, RMSE=0.3159, R²=-0.0037
============================================================


📊 Round 882 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 886 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 886 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0023
   Val:   Loss=0.0976, RMSE=0.3125, R²=-0.0074
============================================================


📊 Round 886 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 892 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 892 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0011
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0051
============================================================


============================================================
🔄 Round 893 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 893 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0025
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0056
============================================================


============================================================
🔄 Round 895 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 895 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0042
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0254
============================================================


📊 Round 895 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 896 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 896 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0026
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0058
============================================================


📊 Round 896 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 898 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 898 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0025
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0059
============================================================


============================================================
🔄 Round 899 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 899 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0033
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0029
============================================================


📊 Round 899 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 899 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 902 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 902 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0032
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0026
============================================================


============================================================
🔄 Round 903 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 903 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0049
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0042
============================================================


============================================================
🔄 Round 904 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 904 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0029
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0017
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 904 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 904 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 908 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 908 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0060
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0152
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 909 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 909 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0054
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0111
============================================================


============================================================
🔄 Round 910 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 910 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0005
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0004
============================================================


📊 Round 910 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 910 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 912 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 912 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0052
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0055
============================================================


📊 Round 912 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 912 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 912 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 912 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 920 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 920 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0042
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0022
============================================================


📊 Round 920 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 920 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 924 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 924 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0035
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0008
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 924 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 926 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 926 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0045
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0086
============================================================


📊 Round 926 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 927 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 927 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0030
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0083
============================================================


============================================================
🔄 Round 928 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 928 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0011
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0086
============================================================


📊 Round 928 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 928 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 930 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 930 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0018
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0066
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 931 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 931 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0022
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0032
============================================================


📊 Round 931 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 932 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 932 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0012
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0060
============================================================


============================================================
🔄 Round 935 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 935 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0039
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0138
============================================================


============================================================
🔄 Round 937 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 937 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0030
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0039
============================================================


📊 Round 937 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 940 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 940 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0006
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0035
============================================================


📊 Round 940 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 940 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 944 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 944 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0003
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0167
============================================================


============================================================
🔄 Round 947 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 947 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0000
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0110
============================================================


============================================================
🔄 Round 948 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 948 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0051
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0116
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
