[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6995b71c-10f9-4a76-a43b-3b11104b3971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88a194b-57d9-496d-8b50-44e12bf4e2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596321d1-0f13-43d6-9b79-00d9d6e5da22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0c6c58-f733-4faa-94e8-d12faef5bc93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc4b70d-d219-479b-8618-715c4af227ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52aa4c8f-ab7b-422f-8e99-2b86f1f90ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d38dc49-8c14-44e0-926a-797c8244e92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e2c0d3-2c71-4944-a2b4-540dd41ffb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d6f045-e6d2-403b-8be5-a3eb946ef56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94afc146-b033-41ad-8dd8-eafb7dee9b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec4befd-3edf-4e74-9287-6a104b294b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c6dd9d-cd4f-498d-8c17-c1098e74dff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4382cff-2dfe-45b6-831c-2caf3c608b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4cd7ba3-4bf1-484b-8763-60fe96932f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20cc28fe-925f-4760-aceb-187fe18b4ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab85dd5d-7bea-43ca-bedb-368f7aefdc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0835a489-8d00-4fa5-a2ea-8b34223d1404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d8a1c72-86e6-422f-a68b-73893ec718b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c84a04-ccb8-49e4-aca2-f9b5f792b435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15cf97b-2d91-4b15-8acc-dde95f0a4856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0206b6c2-58fa-4e8e-a0fa-0c7886018c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb5dd6d-4e08-44da-b04c-69e560c09a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4c304d-dc60-4860-84b4-43099a6fa6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466e5001-298c-4f2b-8945-c217d7c20c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa5b491-8bbb-4f30-b5e3-f6feb3a3b31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ac6d4f-0c26-4b04-a9e7-b3653146a95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dbd9844-37d3-4a6b-a6d2-3d0ca971da0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a26807d-33cb-4057-ab10-9d582325ebfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf46bde-3438-4681-8bf3-2465b5854efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3714c8ab-0cdc-45a3-aeee-6409020ad2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91b5e29e-7ab6-4997-8d07-ced24b436a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a270b80-231b-4b28-9854-c466d1878f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f991052-325d-47a7-aec4-42da0de38a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd09e2f-e2da-4e85-a947-c2d338fe6382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768b8156-4284-49cd-8ba7-5ac59bc30b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db9502a-c3fc-49e1-bdcb-89a34fafda1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53bcd8af-7554-4337-a5d7-4eefe7bc461f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d73bfa-c82d-4e1a-aa4b-c12ce9918ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d6fe02-772f-483b-9013-b580d2cc6ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a29dce87-364c-4f7f-ab12-542b3079129f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7b0cdc-c8f0-4fc9-8534-a69efb2af51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088a4e46-f0b1-434d-b8ac-23bab1933e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1908f701-0f27-4b36-b1d2-f8e71e1e7ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4410354a-bba9-4fb3-8274-82e52a5c550c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba960034-4499-493e-bbaa-24fe691aa53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be094b21-3cbb-481b-8160-759fa7d56b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dac1ce5-e071-428b-a5dc-41952495139b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e98b4e9-429e-44c9-9c06-191112f140fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5af0fe-f716-45d1-87b5-bc4352dfa00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32886c09-59b9-4dff-bda0-c07de582318f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3a2ed2-0954-436a-87ce-67baa709cf29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2349c369-96d4-4597-94b5-3896e60f9433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 037eb9c3-3d2b-40c2-8def-8e06b667c70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3d0926-a3b3-44e4-abb0-2807d94e57f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5498ab-ec82-450b-92ce-a547540e57bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14cfe76-03a3-4f3f-8eff-71d3affc497c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b89886-d285-45dc-87aa-e1eb442b9f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d7fa3a-d326-446d-acb8-30b0a2a556e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a48498-afee-4293-8a53-17f40d07dbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409b7ac9-b58a-423e-a4c0-8f923c6e1163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c34863-9c8d-4422-8bbd-0d7cf02a9bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f825993-ba83-4e61-896c-3c3547134b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d40336-78f7-428d-8d98-ba9ab91f8881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fce607a-5e0a-4759-a6fc-407c7ad9e0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d03b31-899d-4387-8562-fe368b451856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae0a42e-dba5-41e8-abe3-276440615c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4028da87-feee-4070-9fac-3b4500ad3c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054c71d3-8178-4f01-b997-d145b7b1cdc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ae717c2-6b67-4d09-b46a-868377719630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a3fa5c-9e5a-431a-93d4-4748a63fc913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4d46a7-ab60-4902-a7d6-889afa2e4af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924da58b-dd5c-4f97-8436-87be2b8cd616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97383680-021b-428b-ad89-793dc9a18e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736b8420-5b36-4b28-bca9-11b7bf640116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772f7d0b-174d-4eac-9219-f49e632aa2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a01ab85-7b40-4a63-8df8-8714cfa36c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198a14f6-3f67-47f0-b30c-5684115ac9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c37de67-bd15-4839-811c-4cc08cea0d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a48ad8-de09-44e8-a4a9-770f48ee0203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793a086b-e0f9-4b42-a890-e0cee4e92d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773b5b0f-0ba7-4cf1-b33c-745e3e1fab1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6904f9-1929-4fdd-8ced-e2b39b286353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44c26b1-d62a-42eb-9922-b5eb6be0b7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cbd968e-718c-4460-a1f6-79f32dc2435c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3777dbb8-ca01-4c97-ba1f-a706d3a4f7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d87bd7-82a0-4b17-adfa-cd0cd6233e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb113f2d-5b2b-4219-9634-a6191b1338d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251b68b7-9228-41ee-b2da-b3d5e68215f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77b43f2-3302-40e1-af74-22eeff2731c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6d4fb4-9ad7-4f1d-9f57-a0e0dcf736ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a28f47-6a51-42c5-bb4e-f2680f5df8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a2890a-c48b-496f-84d4-ba055dfe069a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8813c62-618e-4198-9da9-ec0452a4c07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac0bbd4-2a69-4f0a-8c4c-2929a302ad44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 928a4199-bd77-48d6-892c-923bb7adbb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a00330-2d2c-49f1-bbf4-8c64da225edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74748e4-023a-40ca-bfe9-cb774b2feb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9952c91-b57b-450d-87ce-0263d33c6bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e94747-fe55-4601-909c-0fcaa3855a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d0ccab-b90f-48d6-9627-e24514f2758a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e359a3-cc76-40e2-afef-2bf60d381d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448859e8-c7cf-4c7c-b967-d9471df3e20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb5befb-46f5-4fe5-84b0-8bf9e3ece478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc63f66-cb9e-4bf1-9410-21463bbc4ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dedd12c-88ee-494c-bb66-ae685d3a325e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6935076b-7fa0-4603-be85-271579e0f0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a03749d7-a2b3-44de-ba9f-b84725cffebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 500535f8-dd5f-427b-a5ca-ce042f1f772b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a93655a-a73a-4618-afbe-45bb8fd2ae33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09167e8e-c2ec-4606-b052-4b129dc209fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31e8824-e0ce-47aa-8d94-3c578a483733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc83a4e1-77d7-489a-bed8-298bbcc68797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd89d45d-05c5-4b4f-8c2b-ad398e339bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e93a04-021a-4ff7-bf57-7a7fb7ceb7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d559d50-db87-449e-95d7-d1c213cdc570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4e1d77-e3de-48cc-a754-600d92249802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e1a9a0-3cb3-418c-920b-7028569ea9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51f04bb3-ebb5-426a-92bb-eb55851003b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e751242-5abf-4b7b-8174-30e5c3015bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6289f5-e714-4867-9b26-95b18f184d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8cf326-5b8a-4515-99a8-aac4003a3f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd76eff5-8397-4a4b-baac-28ebb1e25200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d43f8a-a002-4bc0-bd8a-4c8cdcbe5e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654e772b-f10e-436a-a9bb-9a6d9eb1f639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c58bc71-d236-4e5d-8dfe-635d7fe48c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea43dd6-0c9e-4317-8885-553eff10e5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91246cf9-5d0f-4000-9743-fa0c46451ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f25caa-cac3-4307-bffb-3ccec9051c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae067e45-ebf3-4ea3-a98e-6a647d548958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97eb2728-cbb3-4b2f-9fb7-a18253aee5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd50faa4-4728-4fb1-a223-e06901e993ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf5b0de-8dff-437e-8ad1-0bc59d2356d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51f294a-7f00-4058-bf82-70008dc808f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95f1b6f-dda6-495c-8ad4-3e4cd29d8172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3521911-2271-48aa-a9ab-e28e35e5560a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a53cfc4-c82b-4136-8367-8dce732ff0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8d1483-f9b3-4734-9c80-6daf3683544d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01897208-80ce-40db-8ce9-11e9aabcbb23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9edee5bb-2015-4e0f-ba21-55fc8079789d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07b5977-0910-490c-af96-d0dbc2571477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0d3a71-22e8-4a1c-b532-33dc8234bbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae054b8d-f567-4dd0-8fe4-92a867236994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d8ea1d-005c-47e7-863f-d8f076f8f0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71759b57-d983-410e-8788-f1753f902aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9eff2b-18b1-4599-8496-804c13a9b46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20eaa70f-36eb-4dea-8bb7-483d9e5bc5b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07a4608-f81d-454b-a31b-3da729056a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683e0bde-58f9-46cd-9a29-779d9da444a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16a705a9-0a0f-472f-88e7-fd49cbc7515a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ad5d83-a56b-4424-9af0-bc0877f03dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc78b9c4-a39e-4bb9-8369-a75ada982c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ab8ee0-c5de-4b0f-ab9b-7a7d3ce4096e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01512f5-d1b8-4c88-a376-9f840bd6db15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b551d9d0-2c70-4fb1-adeb-57da3a3c14d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f0f52fb-e190-41f4-8839-694d7ff1db26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d50894c-0fb8-478f-8191-41776dd6c1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8969052c-86ab-4f82-80b9-2fb374aa5c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09063be-274f-41e9-bcf3-bb335673379f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8edbadce-efbe-4f21-b62a-12a72a6f3be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9143e83-1898-4bc2-849e-c7d8626e6560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 967fd594-0dfd-4d29-97d0-5dac1428f8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9de4e9f-d788-4669-8fd6-7321146875dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72deb210-2147-42cf-abf9-a7ffbf1ded08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a92f0d-cf1a-4358-89cd-8924bbf109ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7324a1-0d7d-4bb9-9298-6fd74b0ee7a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf486ee2-8ea8-4caf-ab48-058c4554a02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9722bb-1aaf-4e77-93b3-d75a104e341e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31ac5fd-a7fe-4af9-b13d-6cd342f96fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a3d50b-e44f-44b9-958f-c5b4755d6648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1865ed5b-cc12-4765-9d1b-944efcc996c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dfff3a4-1e25-4fbf-83d5-2c0161df8a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ae49dc-93b3-4a8a-8139-5fc0e9f24edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 092e4ce6-58ee-4c90-92e4-929420521ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f5143c2-bc7a-4cf6-90e9-c31ee87d341c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08c5018-6b37-4458-a9bd-6619c9548441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad4fce9-a8e9-4b50-b054-ace90e5942ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec9654e-26f3-48b9-8e99-65c4fa29b2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c43f33-8b67-4c3f-bf12-bce12961edcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448a35f9-46d8-4188-8cf1-b384ee96ae60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d6d191-8e98-4d57-92fb-c5b911877d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603019b9-b711-4d3b-aaab-f197d1599798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd48fbc-7d8e-4be7-95d2-94e85eb6b51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cc83579-fb70-44f6-95f9-5d57f54a9204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 972085db-32bc-4338-8bd2-26f1aa7f4894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d23d9ac-12e4-48ad-a214-7148f4c0c6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 523ce753-94a9-468f-9e5f-8b4a8c19ce3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b525bdae-2abc-4304-b03a-358f819e9dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e89fb8-e65a-4018-a49b-3a62c528862a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9898ec52-1c32-4c7e-a840-4432ad410255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fef9945-8cdd-4643-8c5e-d6820c24c634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d4f434d-9211-4d27-8e6c-bc9c96a34e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d9053c-e94e-4cb6-aa25-3bcbd559f56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8451d1-dd46-4512-9394-4f8de151dab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423513d9-9fda-4bbc-ba4a-9bfba7d36df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90223e8e-50b6-4e57-9c68-fbb517ca43ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07fdf41-2cb7-4989-a011-5b9f81096123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48bcccf-a750-424f-b87e-cd1038e2d57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3537ef5e-be0b-416f-b0a0-142372d24880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa5ea74-3e62-4ba9-b7c7-de6e553e2a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36480582-07da-4bf2-9ddd-bea591bb37ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611252a0-c05b-409a-8902-8374b7a318b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b5bdfa-d4fd-4f3d-9268-eeb56c0440d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326b11c9-1a30-43e5-a9de-f253e717f334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d09c0c9-7658-42b7-9f51-2582631a8568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f5806b-fcb9-4734-9043-b9de04fe88c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27d1cf9-bb89-4776-bbfd-3366ea34b0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e6be13-3558-4e0b-875d-64193e032112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce7973c-ad87-47c1-aae1-8de117334225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54932c46-fb0a-46e6-ad0a-428e0be522a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed8ed9d-fcfd-4387-b281-eee6ea9347b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f583438d-50fc-4f2a-a340-f439b7ec6cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3592db2a-b65f-4869-8565-8a5ca5cadb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0704cb59-ebcd-48c9-8a32-3e8356c8ce39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a32bfc-00e8-4f94-8578-600d7d5529c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3842996-635a-4376-af5e-2eb4b57cede3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72fa23cb-c98f-44fc-a26d-da2d664b01fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3996a30-fc99-48b0-aa78-b5ca1adbbd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2264088-a26b-42ef-ac65-a1ec107299f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528fd4d7-0eb3-4b1b-9a0c-cbcf24f58aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58fd2b36-b157-48ab-9432-684792fd792c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9120290a-5521-431a-b9e6-2227fbdd939c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135edd5a-80d8-46fe-91ac-b862171a3e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5214bf55-2e26-4831-bfe2-99dbf9610a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13093c4c-623a-4327-a62a-a325156a3ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d949894b-0fd8-46d9-a430-45852d485de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4cb0c39-348c-42f1-acde-6575734fac2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70121dc5-8ff2-400a-bed8-5a0938e66c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be785d56-1337-4229-8f2a-71b48ec8133d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42430b33-e324-4966-9495-9e5d75c6ed21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd263b0-821c-4d38-b011-63c3c82dbc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b67495-1d58-473b-a941-62d7feb8dd93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c5e132-ae78-40f7-a3e2-0fbc24797bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddd1d4c-2851-407a-9f0a-d5da6140e91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4478fffb-e33e-46bd-aa1d-80885b32e26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a375e2-02ca-451f-b165-0cfcffd359c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3efc4e5-80bb-43ce-aa50-ffbf28af640d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8bc532-5a34-4c68-85fb-ba32ef0af3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e64f6d0-29ee-4b67-b2ff-821c68de16f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa80c89-2d6e-49eb-a38d-f23ccf7c8caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69449fa9-08ab-4370-9079-83f5347edcec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ca1564-d3d0-4363-85fa-8bfacc9f9a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd675e26-d52c-407e-a68d-e261a0ab9ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15db7cee-738c-4f3e-8a57-f6373ee48c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5402954-6b8a-49b1-a597-7685cd849afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7617d8e6-227f-4d67-92db-2d1d47c60633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2913a99-47b0-4326-80f8-f7ab1a9b1455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceaed964-a63b-4b65-98d1-023dc1b2e568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35720e7-c291-4edb-ac3e-6d1069aebcb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f1b18b-4a6e-4a60-bff7-e8b47fbdbf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529e2a69-e45c-45c6-8a55-cacb8c1ed933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460f4f97-a22c-410f-b211-8fa46619a034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c251d635-9c8b-4c9e-979a-50a509a3727a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ab5e58-3831-4086-8a96-90e5eff94d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fd79ac3-86c0-44f6-8776-4a383ec213fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01aa2a4b-9ae7-456a-bebb-67d83126f198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da677243-a87f-4605-ad77-e4cf6a8a8f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02a0892-a61e-4553-a7e7-7c4f6a5b2afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ba0e97-a7af-4b92-a805-58ce2808c718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3edf15e-c6da-44d3-996f-665b7e724a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 807dcea7-abd1-417b-8c45-f3ffbbaecfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7550cddf-2691-4af5-ac7c-b16800193b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3edec1a-641a-4162-bc40-6a8581756126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4983ab1-8c2a-41bf-8b20-49599fb740fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff9d0280-3e79-402a-bfca-0d236bd10798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6f6803-4eae-4d2b-b54e-64d191d7d2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea26672-a2fd-4c6b-8349-8e99eea1fe11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e23646d-b391-42ef-ae8a-e293321501f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bde8b9e-ce97-4703-88f0-6b2ec3bceb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8005225-cd76-4e4b-87d8-d1ba4ae1c385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8608c04-d6ba-41d8-ba84-2d40edd5b9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64df1a43-00d3-439c-95a3-6e57114d25e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0576ff2c-7c37-4d50-a56b-1a9e93baee15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1354b40-c89d-44d3-98d9-8d8bbf8446e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b63d87-b3cc-4efc-b996-94be23eee2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c7fbb52-0e3c-4095-9a8d-34238af531fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddddf13-3459-41df-ab92-9c999abcb132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5354899-b61f-4573-ab75-8afbb134ba48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d4fb44-90a0-479a-8986-93131346865f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d70f22-8287-45f7-90cf-d2e72cc6d0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2085ab08-94ec-48aa-990d-4b8a53b54f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb232bee-070c-494e-8233-14f3e5e9b4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033cbfb5-ca43-4a74-b156-21e6a04cf11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7f1124-a1ff-4c7c-8560-f1e22bc5bbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bfe7bbe-0af8-4181-8191-43ce52786208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e43ad5-c7fc-42b3-a612-a46c5662ec0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3898c452-6640-42e1-b092-40ace70be1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca511a9-6db0-4f0e-889b-1f2aa62ea3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa74746-122d-402a-925e-470e520086c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b341df28-2db4-410e-864d-be990f1b1c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7529c901-15c7-40eb-95b6-33852b2766d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94dd29c5-e598-4556-b0fb-0b82176ce987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f52041c1-31e8-4481-b74f-5b7573d08727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937eda13-578c-4a50-a7cb-6de8117ab2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfe9b3e-4e1e-4dd3-aa23-b1734d6884dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebcb30c-6e16-44a1-b1ed-fd4e83b60984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f205417d-ba34-4228-b9b5-c1a203d8385d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39aaad30-00ba-4e44-ad22-b335d7bd36c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be6393e-3030-4a77-b8e2-456eec16a5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a616d3-6413-494a-b7fa-38925da32b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4cab52c-7f3b-49df-852a-ca5a859df0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec075cf4-b5e1-4546-87d1-cce4302f58ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5268d38b-1b1a-4e06-a417-64b3c0eb1719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf6c303d-32a8-434d-a225-1e3a73e84e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a76571-efe8-4151-be10-88f90d5abf33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f635d9-b123-40d3-87c8-a31e0ac96225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8173a60d-2245-4cb4-b0da-277c7bd897aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8ad034-f4fd-4232-bf75-9271c3825f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1a16932-d49a-4fe4-ae88-33001355f5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e1cff77-a712-4775-9d89-97341baf84bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d63706c-bf1a-41f2-a6be-88d4a21b3cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996887f0-b95b-448a-b4a6-970d27f67860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd3bab7-7f87-41f2-9edd-efc7b4eb612c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef6665b-f5d0-43f8-9365-e5ef08284d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34653160-5cab-4ac5-8c50-05aec80291ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d82f57-2c86-49e2-9f8a-448d9972563b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f318865-65c9-4f47-9c72-bb44d5517d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf9b94f-2b66-46db-8524-f829656082b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd9de4e2-6c97-4b4b-890f-24086b465bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3e9a38-a199-4ef7-a51e-bc3423aa865f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4217322d-9144-41f9-8a92-f3776d9db60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f64d58d-ed55-4ffd-9cf6-cb52820d9a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 872b6b1f-36c9-4e9e-871c-53f691a087a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94bfd0d-db81-466f-9d53-7d05217fbdb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0046d956-5b30-40a4-86f1-e7b840811431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 738308ca-a37f-4238-bda9-6d2b4d94dab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b75337ce-10a8-43b0-b3c7-3c5de0156071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b3f0f43-2081-4cb3-83de-db1bbab2942e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ed09e0-f8a1-47bb-87ef-dfc0dd7993de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f585a2-36b2-4141-91df-1cc6c9dfad6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff1f2c5-5132-412d-9762-280a30c36963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7ed37e-801a-4954-9278-35d7764a7aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c49e8f-a4f4-4707-9436-7d08a01759b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71df4d8-b0f0-489b-a9e8-97ae05809f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7bde20b-674c-47e1-99d3-a82623701801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae2dbb4e-22de-46ec-8405-3f59377daf51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24d5cbe6-473b-4fa9-aad9-2d6917d7c43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8b97ea-a28c-4735-ba1f-389093774d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32261eee-f085-4847-9c6e-ea850416a087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8aad52-276d-4078-921c-530306ba2fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093afd72-4c10-4a3c-ab92-07ae16cb4243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94488c8b-a765-4543-9e9c-c258dce94240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cab7cc-c5e7-471a-b3ff-4f4791a8481c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498462ee-fa15-4215-af0a-01dd26951b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6acf77a-189e-43d7-a588-a5ba11190b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cb93ae-4b06-46d3-a040-90eaaadaab5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69dd5c1f-2feb-46f8-905a-19d01875afa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb6e0be-1f19-4e5b-abb8-23dd33b73a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c1ce05-a7bf-4fb6-9ac0-089117368dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7953f9c-415f-4c85-8ec6-df06b1a7a5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8075c0d4-115e-4e4c-ac0b-e73620390ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d459c0e-3546-47f7-8c08-7315cc59305a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287d03a4-d5e4-48e0-b886-158ec6167748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff90fe4-4fa2-4c50-a0df-d0a5cfd0bde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78a8135-4d6c-4bdf-8784-0b589da50dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a60328b-e8bc-4932-a769-9138975b79b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f4211f-184f-4a41-9683-f2b4b905baf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1a3551-4831-433c-87da-7b8e5e6be9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb9f354-fe89-4d85-b420-33bcdf3ccc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7675a3c-5270-4847-af72-0bcf844b681f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bed1e9b-b9ce-4910-a3dc-f069908884d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fac01b4-845f-4b0f-9abf-084914f450a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf03ad68-3060-4079-bdf4-013e8090084e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7553690f-1580-4a99-8e54-c8cd81560b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b26a0e-85d4-40bb-ac8e-063bb5da8123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7bb8dc-4f87-4987-be39-4241fec0c4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ceff4a0-9e1a-43cd-bcf8-5e774f0bd84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f963511f-f744-4ae9-a50b-d1f276732a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3efe4a1c-0b25-4f79-b8dd-e02a0aea3b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d46032-1b73-4c05-8db1-cf8788e11962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2bb0cc-1ebc-47a5-8e8d-b7b246d04b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8bf254-be14-42f2-a8a5-6e6859aa0dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa10089b-b362-470e-88e1-8891ea38a552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43ce84c-96cb-40e9-b70c-711cbcab1d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636571fd-34c0-462c-b045-ad45164c2a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df17670-7b5b-4e01-84c6-815e0f7637c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02433f2d-1444-49bc-bbec-70c59cdb6d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d9c9a45-7216-487d-9538-c6f7fb07ec16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8700b175-86a0-4bac-903c-681b25c5b126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1924f39-40e8-43db-b722-111e7a284f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b86419a-af13-423b-b3b0-affeae1bbda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 075d6016-ffff-4e2d-b34b-f01446281f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ccb02f-aad3-4ad4-a928-ad269a281330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de13f7dd-832e-492a-8570-c25a6bf2d21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ab5a7e-a175-4805-8c38-4da2d0e24ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942bb6f9-e85e-408a-abef-bc2ed08acf08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b3ee76-bdef-4fe5-8641-485ced730a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd68f84c-8fb7-47be-97f7-9af1b8a4c778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac43ef8-dd1f-4474-8644-fa0468b9e2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09075227-c63b-4dfd-a599-68249b6b77b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8202aaa2-e2af-4e0e-9bde-f3a508d387d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf533f1-c846-4034-84ed-1c072ba28285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9ffa68-294a-44a2-971f-57408440dd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a871f73-aa14-4019-9d33-91de2c41748f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5c7050-f603-4ab6-80ee-b98e6826ac84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d154162-d416-4ce4-b4db-b70ea7b0a961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a8646da-9f98-4803-90b9-78bc83fe4d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 745def8e-b9aa-4294-812e-c991faa5db08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa4dbb4-1c34-4400-a276-ad7da917f854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19aa0e7-f40d-4406-8047-4570180b692b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e43042-9c7b-4d9c-bc1b-d82f4ea43cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aaf1ab9-570d-4cc0-a2f6-128aac427d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb53154-b1ed-4f44-a0f3-48d297137074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf44c8d-4798-4035-800e-d56e06dfea5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a147b283-4de1-4a14-8026-d673cdf504c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b2ece1e-778d-424f-9f25-d57b5d138b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0168a49e-ef29-4063-9985-dd7990422470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30fdc96c-1af5-451d-85c9-16399e6f9099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebab32f-74e6-4ce3-829d-614317600447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b96f42a-781d-45f6-a37b-26975cc4581c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615e3d42-b947-4a85-a359-74906427f604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4771f694-06b8-4054-b379-ad6e244f0532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5ab7f2-e5c2-4638-89f0-e0909826fd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e83869b-af5d-4ce9-bfea-19fc537bc1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f6d7777-cd3f-4e0b-89a1-cd052e663383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7033f8d7-be87-4afa-9ace-de0da2d81f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926b6e12-c650-48d1-9190-adaef120f84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ac0f53-56c9-4c50-b446-4b49a5121c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bc7f71-f3eb-415e-b223-3b3e4a01b4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c5862e-73ed-4263-b318-9507ec830fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc0297e4-5784-4fe6-8992-124ece6437d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c474ba77-e9be-41b8-8820-baaba0c8dff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 836f04d9-048c-4a33-93b6-24a8624113ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0006cda-529e-4ea6-bc6a-2312d28d282b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed05251f-2de0-466d-88e7-850ab5e13fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9768df5-4a41-4444-8cb2-db8ad916152c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6dd098b-983e-4e59-a737-54021202f2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b339e2e7-d814-422e-b85e-dce9bc69cb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4f28ad-54ab-4a64-80d9-09dce97cd9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68170ecc-9dae-4933-8019-204f68ff5e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74271169-069f-42ba-8e4c-51e64b08fdac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a52672d-2d66-493d-b05e-61d980fc5e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 842a90c9-d7d0-4e09-917c-5faf36b05699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273935f3-0a06-4b3d-82d3-402dfc0bdffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7f29a5-3192-4d89-8dba-e94a4d11cfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aaa711a-dc3b-4a22-a153-a7e52fa5ada0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3999902c-cf68-4946-a89e-3356bcbbd22b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd3574c-8771-4cb1-950f-e1e423e2c80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7922495f-39e4-4901-b97b-a5f247545744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d841e4ad-d943-497d-969f-f8ab6dda2afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b433452b-9b7a-4890-8429-1e7043021fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c131c4a9-d04b-4015-b8cf-ecde9e47e67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3d1780-a54c-4729-950c-6bfd5e3a8dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdf6712-3c85-49e7-a9f2-d30ff484568a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5c47a9-f735-4984-8d26-d7ff7f308f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95023675-4ef5-486a-9232-2698ba6e7806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9544f190-38af-43dc-a939-73c9cd931b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b2ebdd3-1740-42f0-9467-23c69ab2e382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674b9263-70fa-4d42-8bb5-26330a77e6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee3714b-4c38-4b7b-8b0b-c27e3758faa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51133a4f-4f41-4961-a2cb-2135a7ab0fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321b220f-88ee-4561-a558-f4607e4248b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a61482b-6157-4316-88a2-1d72688f14dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4b02f1d-ed31-414f-8c37-041f3ddbdf6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5c9533-4752-48d6-af99-49254c09a867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faac2ed1-8f68-40cd-9ae3-990341749a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee1cd89-77c4-4ab3-9f70-d0cd9c96c33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b2b460b-f2bc-4037-9250-fcb14d11dab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52efe6d0-24d8-451d-b934-10a39c900896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32c03f1-a4e2-4cff-9e6c-000d8a597c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a28617-4230-4654-870d-a84251863294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f56a15a-b711-4f55-a17e-712f950308d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5dda6e-ff1b-4460-8e20-f4a5c653deb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad57e2e-dee6-4e37-b4cc-1601958853b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d372af-2d98-42d1-a53b-8de9e305e498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6eea0c9-25de-4279-8df5-9f417df37e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03515997-f64b-4360-97fb-bf11078e128b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5662245c-1c72-403d-8a95-7e3e3a431a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc87a9e-68f8-4f8e-8b23-724a4e653c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20062910-c39c-40e2-a50c-2db4be59e918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457d8052-26ac-428a-9ead-9790b1b5829b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44663bf6-f842-4aea-80a3-77dfd7ce32ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d785072-8dd4-48d2-a249-dba4098492f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac1fef9-c7a6-44c1-81da-858c07ae464b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21fe887-a549-41fa-a521-ffb1679ce600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b118719d-a6d2-45fd-80cc-28c0c3ba66a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01523913-b39d-4a63-83fa-e254880fc440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b0c6b8-d3b5-44af-8444-178d9a677c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab0e3681-5cba-4793-af2a-7df976354608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c7c3ce-40be-489e-a4e5-4a13ca18b591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145c253f-7e1b-41ea-9c27-838cfc8958fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a483e7-4cf6-4b68-9e1b-3b329fa94a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a8494e-0388-43b7-beec-5e1eeb8a8042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ce2838-7663-4b12-b1ea-75d30e65299f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8efb08c8-f231-4f86-857e-be78dc553460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa36ba4-3c9a-4d62-8b40-34dd3b5e9145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5581bb83-1a3a-4945-8eb1-fa6dc4fc174e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be5323c-45e4-4ac3-8873-c5536f396643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b25d4f0c-70d5-4482-bb44-0f825afa0091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa6ed386-e0a3-4e9e-94b6-0e40c6411d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611d368c-4b24-491a-9ee0-8e19766b7b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec3b6c0-b19a-4e3f-8813-039b583dfe20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 997ef0e3-9753-4a44-bf24-95c70e41e289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a49d417-b73e-4ffe-8e9e-3146a50b351e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39aca4f7-d14c-4990-a8a2-64ea54a31721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7faa4635-7f27-476e-a604-0e25b3d71c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3485e770-ba40-4431-9f6a-387dbc4fc3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f344f2e1-31b4-4546-bce3-1a0d4e8941a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641ddc99-efe5-4394-852c-ce58e2315a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e720e0-3c16-4f95-9a06-eb49b642bf89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802fb183-23f1-4f58-bf86-1f88cc3f05ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 821ddd8c-0368-484b-b989-b21b0b3a4567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86eef1b-e701-4cf2-a4e6-9870ae56ffb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e9b111b-3103-4390-a253-bc4964ad5571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0b359d-c6da-47f6-89cf-222a845d77ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43174b2e-563c-4ff6-9098-a4c57ff2756e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ef29cb1-59fe-4a23-a285-44e683f86570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 724433a1-5460-4c1e-b887-3d78f2cfc509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbd6e84-95e5-4ceb-ac95-ee8c3d0910e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9044773-2897-471d-9ec6-1dd2f9366831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19bf216e-c4a8-4271-8504-82cfe9f53a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82bd6715-1d22-49ab-9938-58926be42a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caff6fdc-3d88-472f-8cbd-b456ecb1189d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455f72de-3203-4886-be6b-b5c8a623e4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa97099-26fa-4380-a624-2febb8801d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5e2cf2-4a25-4041-acec-1d3f75df97e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d629f0-57c7-4d4f-8706-451191c768cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c33919-5b3e-401e-acd2-944851ebb66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d35a1a9f-24c5-4bf4-8162-4429ca2f2e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073319e6-849d-452e-8e99-7474699d158c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc85446e-4f41-4dd8-910e-6043e45ee06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a6a7e23-3798-448d-a0c6-a962f26b7ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa123067-deab-474c-82b9-135b6aaa901c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d38e8a-84c4-4873-8dff-1230342ef7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 476465b1-4c78-4aa9-a0dc-c2e4af843e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff62a8b-6c07-4d9f-b4f4-ed4a8e68156b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014b9897-f971-46d7-9b00-e010ac2cb259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f6f2de-10fa-4eac-8f92-67a75539d5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7a4b9f-5c62-42ea-9b99-1884da5d2e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b8cbf4-3d59-4874-b829-ed4e41cdb9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ce4065-4fe6-4e2d-a5ad-8ba1b1a912a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6169b8f-95e1-4d28-99fa-2864e55a63ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb2cbffe-dca4-4632-be64-7d82b19ae172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3d0ff7-d78e-479c-bf46-33d8fa21aa89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e3c826-2c91-40a9-bf29-ae16851a3899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2997ea4-eda7-481c-abda-20fb6be110be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3248f80-2853-4551-9f5f-36d1c5d1ae73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 259a17af-117a-4279-93ed-708156c5ab75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899279b6-6f8c-4198-b957-ec6600a8a311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288fde4f-8152-4f3a-95a1-92e92864b97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5baf266b-6b34-43ec-94f1-1c985c6fd7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d98253d-7e47-4b62-b2f3-9685e4e32cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1420b69c-9df9-4736-9ce4-94895f6f4865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3deb0e9-fad6-4494-b83b-1f7433518e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304ead80-bb12-46b7-8a7b-8365378cb74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7acfe0-79c0-4f88-a94a-ecbd111efa1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 652cb353-a385-43c1-91c1-7d1a6633cebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47e882c8-067f-4e2f-ad1f-cc61d4ee624d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab74d242-c889-469b-ae7c-588e2183c4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a143f91b-cb5d-4b03-8314-c1b9c6d8a121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b77088d-1fd6-419a-b097-4f70b448de3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 066daf1d-0912-44b2-9f3e-b33332548d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ef8f5d-37f2-4c68-a73b-36a8424077d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0b7c5fb-8aa7-43f6-a1e2-6a69548d86a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ea7977-9b59-4b3e-bbaf-d6837f96efc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c8aaca-879c-48f8-8971-98c81eef6732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f687be4-0b78-45d4-80fd-c7b0dc2fa834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d195d3b-2b93-4ad3-a0e7-1e510841a692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed88ffb-655e-47b5-a0a2-ffa980e86e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248c4d80-b3c4-45b1-8b59-16417827e1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ae498d-d137-4787-8ae9-232fadc56445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94c2219-3111-49ad-9d4b-27b4e70b7f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f423d01a-da3e-471b-8c47-388cdd535c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6697b64d-9e4f-4b6a-b909-23639e1f6a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb4bafd-46c3-4460-8392-211b307ad42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41278d8-054e-41c0-9733-ee8911d9935a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 117ac5d7-c63e-44f7-b1ad-29231887b975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720e430e-4653-4fbf-9bd6-135da2653e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595db0ec-5590-4d39-9582-1876a624ba26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc7898f3-3afc-4f60-a573-967e0dfa3428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0492e409-2424-45a7-9de3-dabbc202638d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6e77d9-4a6d-496c-bc19-2ef4d33e153c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 534f9c54-1d1f-4baf-ae8d-de36f9263c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf2e9ab-f110-4839-a94b-7f84739be8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f12cb84b-96ec-444d-84bb-2617464015f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a3d413-6ddf-483d-992a-1b924a680dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbaf2972-4477-4221-a884-2f4c5ff21405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce83f5d-7c5d-41f0-8243-4f7232b6b21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748aed91-8223-4b45-b513-8546e4bdc257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce8a1cf-7d25-4bd2-94fa-52f8348202fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33592d2d-5bac-4227-8d17-6c70b8faa682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4e9ce2-bf92-4f5c-a4f5-dfc061d2c58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e951f8f-2233-470d-8465-cd2af5388920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5adae709-03d5-42f5-9650-e3af6309387e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ca234d-e397-4192-b0bc-0abcd1c298ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde1d73a-3f5f-44e9-a320-237c72ed9a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9959293-e5cb-468c-a279-e2fcde45a0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec0ad6f-f729-4088-ad62-c01f223d06b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870d2505-74e0-47f4-9c67-00df28a4ee25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f5e102-bdc9-43a7-9d9c-0e72dd5c3f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc71b57-7e1b-4a97-9f14-21384ddec7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc23d8f0-c122-49aa-b7ff-ddba2c9373e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b468222f-f0b6-4612-9f41-500a1d42e8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ba09d4-1804-42fc-ae5a-d9860dc9488b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5aa88da-6644-4ecc-b6b6-6ce5b337443a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be4ec89e-fff6-4ba6-8ef6-b439dfc58ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b972a52-0d73-4c53-9c37-fe82acdf049c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392efb76-f112-40fc-b8a7-d089905775e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136abd13-53c5-408e-9b9b-4674266b283a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 473ae9fb-937f-4e10-8559-c50f7ae06373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0a60e6-66ab-4ba8-8154-5be67eee125c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc9da77-b23a-434f-9fa2-19833920182f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b009f8-e79e-47ca-9fcd-7e72bdb577d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8099a51-a18a-482c-9777-412266a1e20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7afd2d-2df2-401d-b3a1-529019e8ead3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c237c888-3223-45cf-b3d6-d43029b3cae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f34513-e716-49f0-b076-e1eefb0f5380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd8bb20-b2ae-43f6-bb75-a641f89936e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9d638b-7277-4de3-b4a3-cf712fc464c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4478eb82-8c39-4f7b-88f3-f8c701cbea93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf10275-4db8-48d7-adaf-951d7f218585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196edbe3-5073-4426-b089-cb801f0dfec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a539455-9c3f-4cbb-92ae-c9620bba94e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188358c2-d489-495d-b614-cf2769ae735b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9522214-89ee-4cef-b356-342755822753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4d805a3-511c-4145-8d53-2b4dc015f8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5cf8d8-40c7-47bf-b1ed-052925bc378d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d4cd1a-9903-4035-91b1-132255efe4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e617dd6-6820-4d3e-968c-4d7ba90f5921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f0aa18-137d-4c5a-97e3-dda2da61cb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 500af329-3649-4a2f-bf3a-aeffd7912331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def54309-f3d6-43dd-8c29-65070874f6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2dbe1db-3dc9-41aa-910f-24beb2e2b74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2251ff2a-83df-4a09-8e60-dfc97d2cb32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e818cda-dfcc-478d-ab6c-5fb27c3a091f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eba53f9-5e27-4e31-8399-541cd3800f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7074bf5f-a57e-4445-8dbb-7808fdd97143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f48047c-c232-4754-8b78-bbd854407173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ddb1fc8-a2d3-4bfa-b779-690bf84b1b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b815e66-e35c-49f8-85e7-fa1530c6d158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee60f7ea-28d2-4b75-bbb2-b52d7d28fff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ddec38-164f-459b-bfa8-380ad93f18ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d19bd0-756c-4278-a742-18db617c6d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c77ede4-3eb5-47ae-a293-68fbd967b9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eadddeb-3e95-4dda-a32a-e55541203c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d1f3d21-903f-449c-b36c-151d9469a399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e90baf4-ad95-4f55-a84c-abe8c79c4cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea698e0-fded-4f16-b9b6-2495d47008b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed572a7-e8f8-4ce0-96da-dfeba897ddf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b85fad-4171-4a8a-a3c2-1414f22e6628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561b82b5-9877-4324-9646-58995731f0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9926106-6740-4733-ba76-e541b42f8b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d75a0cdd-ff17-40ee-92f3-6a86b1e1f288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec09024-eb96-45ad-a533-fe4d0d8ee26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3de13b10-2776-4617-9c8c-033fde78ddbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d517b7-be54-4792-845b-18cfbc8149fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2456884-e080-4c8d-8aba-64843008da63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6115b7df-53da-4393-ac86-51cbc0a94210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14fff0c0-2f6c-43d0-a171-6a601a8e7fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5890da17-db00-4bb0-a3a4-7229e9dee38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e64a67e-db13-4adb-abf6-b5a6f67b6662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b389bff-89ba-4227-a9b7-6d9195c4c4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1ab5ad-c2c3-4c20-87ad-cb85698bc5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ef70c4d-7eaa-4c53-996a-1300a791ce07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bcc1c7f-c716-4fcf-ae8c-30521b40d3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1066ff-6eba-405e-9a6c-172b012096da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad19114-645e-49fb-9406-598b73408f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca096fb-cb46-4c6a-a9e3-a71403824de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6241cd7-f46b-498b-bea1-5ddcade01e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ad8650-ef90-422b-9102-1b5c9488807d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274d199a-6d5f-4e79-b1a9-591d51cd9fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c052630-3c5e-48cf-8de2-8fcde0d8c0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b0e21a-59cb-4d47-b02e-302b4482e0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927acbfd-957f-4c36-ba52-fd1a5bcbb055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6392c72-05b2-478a-92e3-ded2b31db7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c19fbc-d487-4f22-b957-160c50f2f83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72ad2d7-bd70-4b5b-a944-6e7b123799c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30eaf4c3-bd01-4828-91c5-c07b6aeae3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22fda0f9-f53f-48f8-9991-0d9743f16d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ffe484-68f2-41af-8ee7-f9ebd5172dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c562781d-2041-4669-8840-2e231017c109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe19f81-ce5c-4f92-8d2d-d8d62301df20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04893a4a-a4ab-4667-b859-cdfd067df929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69552cd2-c83b-4405-816b-a8726f6b6ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57ed4e7-6b17-4b67-93d9-fe428d01f4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47703c36-14e7-430c-ac37-ba52d15cd426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188abecc-27f5-4c09-b9a0-d8de8ddec803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2f21b1-800a-4e6d-930b-4b00f4514b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c290c67-3ebe-40e2-84c7-96249d5d4ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a5027a-7481-4e10-a60d-539be5f4fbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19484aad-9532-4525-a397-2dd6b67c27be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa20fd5c-ffb6-4bd8-8a07-35ccf85d3245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62baf504-a169-4ff6-bc32-5c599e8207b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f26c3af-786e-4b02-912e-a570b107dbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837a379b-185b-47be-8cb3-702443547655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20173e54-b13c-47a7-a58c-4380fc339b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a52bc9a8-1c8f-42de-996a-ac29771671b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b511c555-9f88-4fda-8760-2ac2ea0ccb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a05d993c-f71e-46d2-b4d8-00718df1741c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a3fd72-1cbf-428a-a60a-eb63537f003c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6bc851-c6fe-45b6-b286-070d8dcd4e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11359a77-2383-40c9-9aed-6d692e020648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08fc0c3e-1c76-4fbe-aa99-fdcaccff3a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1371179d-7c0f-46cc-ac75-294184c7fce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9641a09f-c0aa-4745-8254-b2e9d8ad90f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2c4846-1400-4f8b-bb74-5657f62e860f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75db1ec-2ac0-40f0-a58c-be8421ac647b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b8f6b7-1d03-4c54-8535-4a9110a02a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19717ef5-392d-4d4e-a8f1-dbce9be253d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf82f07a-5315-42bc-8d04-2953b311dcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f34c58-224c-4e7c-97e7-7a71fa6ef2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d7e8c1-df88-43e0-98cf-09bbf9db892a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1281c9bc-2ade-4de5-b601-4ed86784081d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a543dd-a465-4ca4-85e9-13619bcae61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a937acf1-2743-4d05-819a-33dd72e920fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e71760b-be68-463f-a7a0-b72ac2af2ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7505b7-9d95-467a-861d-84537799617f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f3d0a1-3ab9-43ad-8690-f8b6e9ffc1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ca9fcf-4593-473c-8cab-a751371eab73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200d18f9-7c98-427c-bae5-3b870f153934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0683025-f9d5-46e5-a915-b0d0590ae8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44c791b-3ed5-42e6-b6a0-b1160ef32581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ffe564-88a1-4d6f-9beb-672b3d602332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c52c295-8b1d-494e-b582-7e7846e35f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf52a32-b1ae-46ea-b7e1-2b0153b54c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad49c179-360a-4116-b8f0-d2841c60b74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48009ddd-9cc2-4f46-b5a3-446f4590ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141c638d-2b97-4928-9ff8-3e9046b5b560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89bb784d-f557-4999-9e11-197cab4b9717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e0877e-9ec1-4835-94b6-7caf9dbb61cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff236fc2-b83c-4efb-8559-f5869ae78b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5afb2760-f42c-46a7-aa05-5a8cf67a27b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95cd2428-5f6c-4fce-a04d-6d1df869f2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717ecbe3-ebfc-4fc1-b965-389c7dd9593c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6f4d86-9054-4152-900b-c47381a16f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22aee89-611c-48e6-a31f-625eb645ac67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84068ab-0ad9-4da5-a6fd-dd21a8b11950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message effb605f-68e0-4a09-bd65-9cf6e532bb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff320410-04df-427f-af3b-8b952f4312dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d099a9d6-717d-4e5f-90c8-8fa63d1462df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1229362-2beb-4b6f-b416-efe08f866293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2575f59f-48d2-4416-858b-d93bd337c07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4053f3a9-dc55-45ee-9cae-8b71d97c961b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b62586-dace-4dd0-a6d3-21963f117972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195298b8-b7c9-4a71-a7c5-51cf445d956c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f1a9b15-2f23-4204-b509-6586bd455444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed78349e-c491-4b07-949e-d6034548b388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1201ac-21dc-4acb-9c06-c9d7a04c791c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e78e627-3f6f-47f7-925d-614c614346f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b8074d-7ed4-4595-b21b-74cac7ef674f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5386aa50-c6b5-4d31-84e4-89e44440aa43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe66a8d-61d8-462f-8300-50ed0a6b63ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc4b4376-7c1d-4aa4-ae6e-cee1a431516e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca8eabc-6a71-43b2-bbcb-5a2982af0b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8c4ab1-78b6-43f7-bdbd-fff22e40b3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7f83ff-d58d-4f9b-91d6-3e9a3ef30d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca5976e-f6c5-4674-8e29-592d20e82860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f06bc9-370b-4828-90ea-1b0d066877cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49344d8a-c1c3-4f69-83c0-2f455947b300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd917141-f4b0-4e59-863e-2a8edacc27fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b69ce42-0658-4b80-9122-eeaece812069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c470ac-f34a-48bd-8ee4-9293aa1bd711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297c2382-dfbf-488b-8580-0766dff251a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292f8c85-162a-4c66-a011-2e4f29b07d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e3bb49-cab0-4970-ad78-e4fd6fb3ee1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5acf3ca0-d15d-472f-b5c6-fd1d40566999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c7adb75-ca4a-45bc-baf7-8743eb5b4027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f511a7-6427-4119-91ff-1fed7b7f8221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3859a1a-4060-4b9d-af78-f1fadfee4bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b9193c-f2a7-45c4-a19e-59c53527badf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6ef6e2-3470-4dd1-a74d-cc42ae651a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690c58ef-a4cd-423e-b49f-cd880d1dbe2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1cb3a79-e7da-4e2d-98d5-f645cc33108f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059f1769-096f-40fe-8fd7-4467d55d004a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7610b1b-fb5b-4076-a8a0-b6c1266e5f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 070677b7-64bd-49a9-a20a-ab381d97767f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7bc9352-4afa-43f5-9b42-c5a8b9d45211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2b26c8-ed5a-4e5d-8bc4-0642f7f86b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 534412a1-9d39-4f17-8c45-92ce128228b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7298d9b-44f9-4edb-853a-451972da15d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69722cf-f157-41b0-9c04-7e54f745ee08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bee8de5-9ac9-40a1-989c-11f46cc88f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47a1e47-2697-4446-b340-30185027c8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1179f69-0680-4251-8c92-4e64ab121fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ce79bb-e539-4d7b-9d07-988fcf61ebc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084bdf6a-7f85-4d11-83aa-882d66db94f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ccdb5fd-fa45-42ae-8c31-c3ae17a9ce24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06dba36-0901-4c6c-988f-b923ca598f51
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(4800, 24), y=(4800,)
   Test:  X=(1200, 24), y=(1200,)

⚠️  Limiting training data: 4800 → 800 samples
⚠️  Limiting test data: 1200 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 3 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0789 (↓), lr=0.001000
   • Epoch   2/100: train=0.0761, val=0.0791, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0763, val=0.0794, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0762, val=0.0792, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0760, val=0.0790, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0744, val=0.0778, patience=2/15, lr=0.001000
   • Epoch  21/100: train=0.0717, val=0.0773, patience=6/15, lr=0.001000
   📉 Epoch 23: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 3 Summary - Client client_21
   Epochs: 30/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.0494
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0250
============================================================


============================================================
🔄 Round 6 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0766, val=0.0790 (↓), lr=0.000250
   • Epoch   2/100: train=0.0761, val=0.0791, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0760, val=0.0792, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0759, val=0.0793, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0759, val=0.0793, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0755, val=0.0794, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 6 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0086
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0029
============================================================


============================================================
🔄 Round 7 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0746, val=0.0829 (↓), lr=0.000063
   • Epoch   2/100: train=0.0745, val=0.0830, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0744, val=0.0830, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0744, val=0.0830, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0743, val=0.0831, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0741, val=0.0833, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 7 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0117
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0110
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0025

📊 Round 7 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 13 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0738, val=0.0868 (↓), lr=0.000016
   • Epoch   2/100: train=0.0737, val=0.0868, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0737, val=0.0867, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0737, val=0.0867, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0737, val=0.0867, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0736, val=0.0867, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 13 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0118
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0010
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 16 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0761 (↓), lr=0.000008
   • Epoch   2/100: train=0.0762, val=0.0761, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0762, val=0.0761, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0762, val=0.0762, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0762, val=0.0762, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0761, val=0.0763, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 16 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0062
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0140
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 16 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 16 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 20 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0707 (↓), lr=0.000002
   • Epoch   2/100: train=0.0777, val=0.0707, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0777, val=0.0707, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0777, val=0.0707, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0777, val=0.0707, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0777, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 20 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0078
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0129
============================================================


============================================================
🔄 Round 22 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 22 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0071
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0153
============================================================


============================================================
🔄 Round 23 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 23 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0093
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0051
============================================================


============================================================
🔄 Round 25 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 25 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0114
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0021
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 26 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 26 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0090
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0078
============================================================


============================================================
🔄 Round 28 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 28 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0099
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0006
============================================================


============================================================
🔄 Round 29 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 29 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0073
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0092
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 31 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 31 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0110
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0005
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 33 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 33 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0099
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0043
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 33 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 33 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 33 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 33 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 42 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 42 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0077
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0077
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 43 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 43 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0100
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0005
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 49 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 49 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0115
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0069
============================================================


============================================================
🔄 Round 52 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 52 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0086
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0094
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 52 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0072
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0155
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 56 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 56 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0092
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0071
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 56 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 60 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 60 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0082
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0054
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 60 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

📊 Round 60 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

📊 Round 60 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 65 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 65 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0095
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0057
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

📊 Round 65 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 67 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 67 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0087
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0021
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 68 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 68 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0076
   Val:   Loss=0.0685, RMSE=0.2617, R²=-0.0129
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 70 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 70 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0072
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0131
============================================================


============================================================
🔄 Round 71 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 71 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0054
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0223
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 72 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 72 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0092
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0030
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 73 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 73 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0094
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0016
============================================================


============================================================
🔄 Round 74 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 74 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0085
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0066
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 74 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 77 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 77 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0080
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0083
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 79 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 79 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0128
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0230
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 84 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 84 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0094
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0019
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

📊 Round 84 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

📊 Round 84 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0099
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0046
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 90 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 90 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0075
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0035
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 91 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 91 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0110
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0047
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 91 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 91 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 91 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 99 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 99 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0078
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0076
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 102 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 102 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0099
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0096
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 104 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 104 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0082
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0016
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 106 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 106 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0076
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0134
============================================================


============================================================
🔄 Round 108 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 108 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0072
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0161
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 110 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 110 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0094
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0034
============================================================


============================================================
🔄 Round 114 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 114 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0059
   Val:   Loss=0.0664, RMSE=0.2577, R²=0.0161
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 117 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 117 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0104
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0010
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 119 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 119 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0079
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0120
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 122 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 122 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0096
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0061
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 122 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 122 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 130 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 130 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.0089
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0070
============================================================


============================================================
🔄 Round 131 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 131 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0077
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0081
============================================================


============================================================
🔄 Round 132 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 132 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0103
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0054
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 132 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 138 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0620 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0620, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0620, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0620, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0620, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0620, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0620)

============================================================
📊 Round 138 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0076
   Val:   Loss=0.0620, RMSE=0.2490, R²=0.0152
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 140 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 140 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0096
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0061
============================================================


============================================================
🔄 Round 141 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 141 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0081
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0122
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 141 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 146 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 146 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0100
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0040
============================================================


============================================================
🔄 Round 148 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 148 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0082
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0077
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 149 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 149 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0085
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0056
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 149 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 149 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 155 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 155 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0103
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0012
============================================================


============================================================
🔄 Round 157 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 157 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0098
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0041
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 157 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 157 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 157 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0050
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0179
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 166 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0079
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0103
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 172 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 172 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2719, R²=0.0069
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0138
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 172 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 174 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 174 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0063
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0207
============================================================


============================================================
🔄 Round 175 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 175 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0078
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0257
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 178 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 178 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0063
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0172
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 178 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 181 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 181 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0069
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0143
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 182 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 182 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0082
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0114
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 182 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 184 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 184 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0057
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0134
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 194 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 194 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0056
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0027
============================================================


============================================================
🔄 Round 195 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 195 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0093
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0057
============================================================


============================================================
🔄 Round 196 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 196 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0073
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0042
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 196 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 196 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 201 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 201 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0080
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0123
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 202 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 202 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0123
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0063
============================================================


============================================================
🔄 Round 203 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 203 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0118
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0035
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 204 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 204 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0062
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0120
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 206 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 206 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0099
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0015
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 209 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 209 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.0062
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0010
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 210 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 210 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0081
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0030
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 210 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 215 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 215 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0095
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0056
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 217 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 217 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0093
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0014
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 218 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 218 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0100
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0088
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 220 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 220 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0080
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0120
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 221 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0667 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0667)

============================================================
📊 Round 221 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0103
   Val:   Loss=0.0667, RMSE=0.2582, R²=0.0014
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 225 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 225 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0084
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0108
============================================================


============================================================
🔄 Round 226 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 226 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0111
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0024
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 227 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 227 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0087
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0096
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 227 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 227 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 227 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 231 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 231 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0088
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0013
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 231 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 231 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 231 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 242 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 242 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0100
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0013
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 242 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 242 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 245 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 245 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0078
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0128
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 245 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 247 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 247 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0083
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0102
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 247 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 250 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 250 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0084
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0104
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 252 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 252 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0114
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0182
============================================================


============================================================
🔄 Round 253 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 253 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0090
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0081
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 253 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 256 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 256 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0088
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0039
============================================================


============================================================
🔄 Round 257 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 257 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0076
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0133
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 257 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 260 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 260 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0080
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0099
============================================================


============================================================
🔄 Round 262 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 262 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0093
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0015
============================================================


============================================================
🔄 Round 263 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 263 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0104
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0010
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 265 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 265 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0083
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0102
============================================================


============================================================
🔄 Round 266 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 266 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0097
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0053
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 266 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 266 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 271 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 271 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0113
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0034
============================================================


============================================================
🔄 Round 272 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 272 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0080
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0124
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 274 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 274 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0095
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0034
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 274 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 274 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 274 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 283 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 283 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0099
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0016
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 283 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 286 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 286 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0106
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0015
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 288 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 288 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0073
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0116
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 288 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 293 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 293 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0067
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0172
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 293 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 296 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 296 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0065
   Val:   Loss=0.0684, RMSE=0.2616, R²=0.0193
============================================================


============================================================
🔄 Round 297 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 297 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.0099
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0046
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 299 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 299 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0077
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0042
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 301 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 301 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0102
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0016
============================================================


============================================================
🔄 Round 302 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 302 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0084
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0090
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 303 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 303 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0109
   Val:   Loss=0.0689, RMSE=0.2626, R²=-0.0040
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 305 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 305 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0093
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0066
============================================================


============================================================
🔄 Round 306 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 306 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0096
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0056
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 306 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 306 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 306 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 311 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 311 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0083
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0023
============================================================


============================================================
🔄 Round 312 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0607 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0607, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0607, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0607, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0607, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0607, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0607)

============================================================
📊 Round 312 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0101
   Val:   Loss=0.0607, RMSE=0.2464, R²=-0.0003
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 314 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 314 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0115
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0031
============================================================


============================================================
🔄 Round 315 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 315 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0058
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0107
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 316 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 316 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0096
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0019
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 317 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 317 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0075
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0118
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 317 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 317 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 324 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 324 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0084
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0079
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 324 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 324 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 324 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 324 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

📊 Round 324 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0029

============================================================
🔄 Round 333 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 333 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0071
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0164
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 333 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2415, R²: 0.0030

📊 Round 333 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 338 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 338 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0089
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0058
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 339 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 339 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0083
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0228
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 339 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 339 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 345 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 345 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0112
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0018
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 345 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 345 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 348 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 348 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0097
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0032
============================================================


============================================================
🔄 Round 355 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 355 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0071
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0048
============================================================


============================================================
🔄 Round 356 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 356 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0050
   Val:   Loss=0.0679, RMSE=0.2607, R²=0.0045
============================================================


============================================================
🔄 Round 358 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 358 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0085
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0102
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 361 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 361 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0092
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0077
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 362 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 362 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0092
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0122
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 363 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 363 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0089
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0058
============================================================


============================================================
🔄 Round 365 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 365 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0091
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0077
============================================================


============================================================
🔄 Round 366 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 366 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0096
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0026
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 366 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 366 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 370 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 370 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0080
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0082
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 374 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 374 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0095
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0014
============================================================


============================================================
🔄 Round 375 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 375 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0107
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0002
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 376 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 376 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0070
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0144
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 376 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 379 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 379 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0081
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0119
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 380 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 380 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0087
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0096
============================================================


============================================================
🔄 Round 382 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 382 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0096
   Val:   Loss=0.0685, RMSE=0.2616, R²=0.0001
============================================================


============================================================
🔄 Round 383 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 383 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0069
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0098
============================================================


============================================================
🔄 Round 384 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 384 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0098
   Val:   Loss=0.0672, RMSE=0.2593, R²=-0.0062
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 384 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 384 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 387 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 387 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0073
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0145
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 387 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 390 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 390 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0083
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0085
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

📊 Round 390 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 395 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 395 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0112
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0005
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0030

============================================================
🔄 Round 396 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 396 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0069
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0167
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2415, R²: 0.0031

============================================================
🔄 Round 397 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 397 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0101
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0045
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 397 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 402 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 402 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0102
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0007
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 404 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 404 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0087
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0092
============================================================


============================================================
🔄 Round 405 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 405 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0066
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0179
============================================================


============================================================
🔄 Round 407 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 407 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0081
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0065
============================================================


============================================================
🔄 Round 408 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 408 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0091
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0064
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 411 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 411 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0081
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0118
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 414 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 414 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0104
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0016
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 419 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 419 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0070
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0199
============================================================


============================================================
🔄 Round 421 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 421 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0085
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0062
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 422 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 422 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0102
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0011
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 423 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 423 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0084
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0108
============================================================


============================================================
🔄 Round 427 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 427 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0082
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0100
============================================================


============================================================
🔄 Round 429 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 429 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0081
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0099
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 429 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 434 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 434 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0059
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0166
============================================================


============================================================
🔄 Round 435 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 435 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.0072
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0133
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 437 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 437 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0088
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0001
============================================================


============================================================
🔄 Round 440 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 440 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0088
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0028
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 441 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 441 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0079
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0096
============================================================


============================================================
🔄 Round 442 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 442 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0104
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0031
============================================================


============================================================
🔄 Round 443 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 443 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0087
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0056
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 443 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 447 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 447 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0087
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0088
============================================================


============================================================
🔄 Round 449 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 449 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0078
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0086
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 449 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 449 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 449 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 449 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 459 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 459 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0077
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0067
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 459 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 462 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 462 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0099
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0026
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 464 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 464 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0085
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0006
============================================================


============================================================
🔄 Round 465 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 465 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0076
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0092
============================================================


============================================================
🔄 Round 466 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 466 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0046
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0232
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 467 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0643 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0643, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0643, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0643, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0643)

============================================================
📊 Round 467 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0068
   Val:   Loss=0.0643, RMSE=0.2535, R²=0.0189
============================================================


============================================================
🔄 Round 468 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 468 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0095
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0006
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 470 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 470 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0085
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0083
============================================================


============================================================
🔄 Round 472 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 472 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0105
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0017
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 474 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 474 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0076
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0139
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 475 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 475 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0103
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0020
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 477 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 477 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0085
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0045
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 477 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 481 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 481 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0082
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0106
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 484 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 484 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0092
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0061
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 485 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 485 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0091
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.0080
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 486 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 486 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0084
   Val:   Loss=0.0645, RMSE=0.2539, R²=-0.0060
============================================================


============================================================
🔄 Round 487 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 487 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0102
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0033
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 491 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 491 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0055
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0199
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 496 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 496 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0065
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0064
============================================================


============================================================
🔄 Round 497 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 497 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0069
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0166
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 498 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 498 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0082
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0116
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 498 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

📊 Round 498 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 503 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 503 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0083
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0095
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0031

============================================================
🔄 Round 506 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 506 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0073
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0141
============================================================


============================================================
🔄 Round 509 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 509 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0065
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0104
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 512 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 512 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0065
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0141
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 512 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 512 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 517 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 517 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0097
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0035
============================================================


============================================================
🔄 Round 518 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 518 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0088
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0091
============================================================


============================================================
🔄 Round 519 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 519 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0092
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0054
============================================================


============================================================
🔄 Round 520 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 520 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0077
   Val:   Loss=0.0678, RMSE=0.2605, R²=-0.0212
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 522 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 522 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0086
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0060
============================================================


============================================================
🔄 Round 526 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 526 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0068
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0087
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 527 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 527 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0088
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0052
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 528 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 528 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0100
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0028
============================================================


============================================================
🔄 Round 529 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 529 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0074
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0074
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 531 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 531 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0076
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0024
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 532 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 532 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0058
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0258
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 533 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 533 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0107
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0067
============================================================


============================================================
🔄 Round 534 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 534 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0069
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0174
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 535 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 535 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0092
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0098
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 535 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 535 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 539 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 539 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0087
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0034
============================================================


============================================================
🔄 Round 541 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 541 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0071
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0159
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 543 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 543 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0114
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0018
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 544 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 544 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0094
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0168
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 547 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 547 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0125
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0165
============================================================


============================================================
🔄 Round 548 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 548 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0088
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0088
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 550 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 550 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0084
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0099
============================================================


============================================================
🔄 Round 551 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 551 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0094
   Val:   Loss=0.0708, RMSE=0.2662, R²=-0.0012
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 552 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 552 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0090
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0009
============================================================


============================================================
🔄 Round 553 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 553 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.0100
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0004
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 555 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 555 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0077
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0138
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 557 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 557 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0084
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0021
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 559 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 559 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0081
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0121
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 563 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 563 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0091
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0027
============================================================


============================================================
🔄 Round 565 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 565 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0080
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0107
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 566 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 566 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0087
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0043
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 572 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 572 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0064
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0007
============================================================


============================================================
🔄 Round 576 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 576 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0112
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0030
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 576 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 576 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 584 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 584 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0096
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0025
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 585 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 585 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0088
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0085
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 586 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 586 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0099
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0105
============================================================


============================================================
🔄 Round 587 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 587 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0075
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0093
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 590 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 590 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0087
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0092
============================================================


============================================================
🔄 Round 591 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 591 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0093
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0068
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 592 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 592 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0079
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0079
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 592 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 592 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 599 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 599 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0074
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0093
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 599 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

📊 Round 599 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 606 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 606 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0097
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0016
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0032

============================================================
🔄 Round 608 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 608 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0076
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0134
============================================================


============================================================
🔄 Round 609 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 609 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0080
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0105
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 609 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 614 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 614 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0098
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0042
============================================================


============================================================
🔄 Round 615 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 615 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0067
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0134
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 615 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 615 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 619 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 619 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0096
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0123
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 620 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 620 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0106
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0213
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 622 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 622 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0080
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0111
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 625 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 625 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0092
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0027
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 627 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 627 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0061
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0151
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 629 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 629 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0094
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0053
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 631 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 631 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0077
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0004
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 631 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 634 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 634 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0090
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0284
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 635 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 635 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0114
   Val:   Loss=0.0678, RMSE=0.2604, R²=-0.0085
============================================================


============================================================
🔄 Round 637 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 637 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.0064
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0169
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 638 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 638 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0096
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0019
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 645 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 645 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0075
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0090
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 646 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 646 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0108
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0042
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 647 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 647 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0076
   Val:   Loss=0.0686, RMSE=0.2620, R²=-0.0180
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 647 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 651 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 651 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0094
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0058
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 655 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 655 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0086
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0074
============================================================


============================================================
🔄 Round 662 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 662 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0097
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0054
============================================================


============================================================
🔄 Round 664 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 664 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0081
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0107
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 666 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 666 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0087
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0068
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 669 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 669 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0069
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0070
============================================================


============================================================
🔄 Round 672 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 672 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0111
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0000
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 672 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 674 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 674 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0084
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0106
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 674 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 678 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 678 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0062
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0143
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 679 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 679 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0081
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0111
============================================================


============================================================
🔄 Round 681 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 681 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0111
   Val:   Loss=0.0675, RMSE=0.2599, R²=-0.0039
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 681 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 687 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 687 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0103
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0028
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 692 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 692 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0107
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0019
============================================================


============================================================
🔄 Round 693 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 693 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0064
   Val:   Loss=0.0675, RMSE=0.2599, R²=-0.0133
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 693 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 697 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 697 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0090
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0054
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 698 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 698 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0111
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0008
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 703 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 703 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0060
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0036
============================================================


============================================================
🔄 Round 704 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 704 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0074
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0093
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 704 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 704 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 708 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 708 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0090
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0053
============================================================


============================================================
🔄 Round 709 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 709 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0076
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0125
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 709 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 711 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 711 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0094
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0068
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 711 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 711 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

📊 Round 711 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 711 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 718 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 718 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0089
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0043
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 721 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 721 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0111
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0001
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 722 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 722 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0086
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0209
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 723 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 723 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0094
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0043
============================================================


============================================================
🔄 Round 727 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 727 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0095
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0058
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 731 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 731 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0087
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0063
============================================================


============================================================
🔄 Round 733 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 733 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0093
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0065
============================================================


============================================================
🔄 Round 736 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 736 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0073
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0275
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 737 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 737 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0098
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0103
============================================================


============================================================
🔄 Round 739 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 739 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0059
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0160
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0033

============================================================
🔄 Round 743 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 743 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0066
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0080
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 743 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 746 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 746 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0061
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0138
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 747 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 747 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0083
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0001
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 748 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 748 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0101
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0040
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 748 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 751 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 751 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0089
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0070
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 751 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 755 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 755 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0075
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0041
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 757 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 757 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0088
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0061
============================================================


============================================================
🔄 Round 759 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 759 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0094
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0103
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 759 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 759 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 766 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 766 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0089
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0006
============================================================


============================================================
🔄 Round 767 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 767 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0072
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0089
============================================================


============================================================
🔄 Round 771 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 771 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0082
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0073
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 771 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 775 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 775 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0088
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0068
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 782 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 782 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0083
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.0096
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 782 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 782 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 788 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 788 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0085
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0050
============================================================


============================================================
🔄 Round 789 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 789 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0086
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0115
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 790 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 790 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0092
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0015
============================================================


============================================================
🔄 Round 791 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 791 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0080
   Val:   Loss=0.0666, RMSE=0.2580, R²=0.0127
============================================================


============================================================
🔄 Round 793 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 793 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0068
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0051
============================================================


============================================================
🔄 Round 794 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 794 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0093
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0064
============================================================


============================================================
🔄 Round 796 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0656, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0656, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0656, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0656, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0656, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 796 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0087
   Val:   Loss=0.0656, RMSE=0.2561, R²=0.0091
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 796 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 796 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 800 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 800 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0079
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0003
============================================================


📊 Round 800 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 802 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 802 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0107
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0032
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 806 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 806 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0073
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0137
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 806 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 813 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 813 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0088
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0078
============================================================


============================================================
🔄 Round 816 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 816 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0093
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0059
============================================================


📊 Round 816 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 816 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 820 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 820 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0076
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0084
============================================================


📊 Round 820 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 822 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 822 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0069
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0289
============================================================


📊 Round 822 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 823 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 823 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0092
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0059
============================================================


📊 Round 823 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 823 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 826 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 826 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0103
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0018
============================================================


📊 Round 826 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 828 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 828 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0110
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0077
============================================================


============================================================
🔄 Round 831 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 831 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0085
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0247
============================================================


============================================================
🔄 Round 832 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 832 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0081
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0100
============================================================


📊 Round 832 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 834 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 834 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0117
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0037
============================================================


============================================================
🔄 Round 836 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 836 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0074
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0128
============================================================


============================================================
🔄 Round 837 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 837 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0108
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0003
============================================================


📊 Round 837 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 839 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 839 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0081
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0083
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 840 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 840 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0072
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0062
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 843 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 843 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0081
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0087
============================================================


📊 Round 843 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 846 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 846 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0087
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0063
============================================================


============================================================
🔄 Round 847 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 847 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0072
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0101
============================================================


📊 Round 847 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 848 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 848 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0057
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0214
============================================================


📊 Round 848 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 849 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 849 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0073
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0140
============================================================


📊 Round 849 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 849 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 849 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 849 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 855 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 855 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0134
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0107
============================================================


============================================================
🔄 Round 857 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 857 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0104
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0023
============================================================


============================================================
🔄 Round 858 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 858 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0063
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0062
============================================================


============================================================
🔄 Round 859 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 859 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=0.0088
   Val:   Loss=0.0660, RMSE=0.2569, R²=0.0078
============================================================


📊 Round 859 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 861 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 861 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0064
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0156
============================================================


📊 Round 861 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 861 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 861 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 861 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 861 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 861 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 869 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 869 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0091
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0047
============================================================


📊 Round 869 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 870 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 870 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0073
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0148
============================================================


📊 Round 870 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 870 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 874 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 874 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0088
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0069
============================================================


============================================================
🔄 Round 875 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 875 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0107
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0036
============================================================


📊 Round 875 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 877 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 877 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0088
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0064
============================================================


📊 Round 877 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

📊 Round 877 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 880 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 880 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0096
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0048
============================================================


📊 Round 880 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 880 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 882 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 882 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0055
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0055
============================================================


📊 Round 882 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 884 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 884 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0088
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0277
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0034

============================================================
🔄 Round 889 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 889 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0066
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0084
============================================================


============================================================
🔄 Round 890 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 890 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0143
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0111
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 891 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 891 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2708, R²=0.0071
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0063
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 891 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 894 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 894 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0099
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0011
============================================================


============================================================
🔄 Round 895 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 895 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0099
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0003
============================================================


============================================================
🔄 Round 896 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 896 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0090
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0046
============================================================


============================================================
🔄 Round 897 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 897 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0081
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0082
============================================================


📊 Round 897 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 898 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 898 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0104
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0072
============================================================


📊 Round 898 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 899 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 899 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0098
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0049
============================================================


📊 Round 899 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 900 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 900 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0099
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0085
============================================================


============================================================
🔄 Round 902 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 902 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0095
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0032
============================================================


📊 Round 902 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 905 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 905 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0093
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0058
============================================================


📊 Round 905 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 906 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 906 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0097
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0073
============================================================


============================================================
🔄 Round 907 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 907 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0074
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0016
============================================================


============================================================
🔄 Round 909 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 909 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0087
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0094
============================================================


============================================================
🔄 Round 910 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 910 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0106
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0016
============================================================


📊 Round 910 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 911 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 911 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0086
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0070
============================================================


============================================================
🔄 Round 912 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 912 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0049
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0135
============================================================


📊 Round 912 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 912 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 915 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 915 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0072
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0148
============================================================


📊 Round 915 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 917 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 917 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2727, R²=0.0050
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0220
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 919 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 919 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0070
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0030
============================================================


📊 Round 919 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 920 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 920 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0085
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0087
============================================================


📊 Round 920 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 921 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 921 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0062
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0203
============================================================


📊 Round 921 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 921 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 921 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 924 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 924 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0095
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0036
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 928 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 928 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0087
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0059
============================================================


📊 Round 928 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 929 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 929 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0073
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0044
============================================================


📊 Round 929 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 929 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 931 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 931 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0090
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0068
============================================================


============================================================
🔄 Round 932 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 932 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0082
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0095
============================================================


📊 Round 932 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 932 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 940 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 940 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0075
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0128
============================================================


============================================================
🔄 Round 941 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 941 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0094
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.0008
============================================================


📊 Round 941 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 941 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

📊 Round 941 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 945 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 945 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0072
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0057
============================================================


📊 Round 945 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

============================================================
🔄 Round 947 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 947 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0095
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0054
============================================================


📊 Round 947 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2414, R²: 0.0035

❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
