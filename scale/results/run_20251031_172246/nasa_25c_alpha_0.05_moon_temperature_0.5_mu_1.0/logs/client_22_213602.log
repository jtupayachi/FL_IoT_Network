[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae49afc-6a7e-486c-beff-5068ccae3f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74bf479e-13cb-4152-b112-e226442f04ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b369daf-b58e-45a9-aa0c-5d451a600059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67b0d356-5e73-4f50-b64b-b2be3e08137d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440e21dc-8467-4597-87d5-52f3925fea60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f2c217-9f69-476d-a1d4-052b2df4ebb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd97863a-f830-4d8b-8b58-1ef48792eda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88129507-1925-484c-b676-36f9ad642569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ca0f78-3eec-41d2-91d8-ec1c1b481bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a9a665-eae3-47e4-bd1f-be8eae1a2464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f342debf-ca74-4aa3-a5de-01a29ce568d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee4fa42-376d-4bfd-9292-0d1fa650593b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0969def7-1a16-46a1-8114-3e4c14abe670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8b6406-a3cb-4fcd-82d1-5a6e4f6f4519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba48b8d5-20ad-45c4-9ebd-f04525fd028e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc94c1d-b008-49e9-968c-61ed129eb214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4209daa-8db1-43d2-93cc-a012ca97edab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea2e71f-6127-4fc4-b8fd-ede14bf6393d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c0780a-aa9d-4cb1-9f88-3a66baf96104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0516d894-e72e-4ae5-9ed5-aa1330ce611b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a19aeea-0d1b-481b-8aac-c4f21ac7c3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57fd6c4-7bb8-4906-b2d8-6f8991795c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6adf2b5f-a968-4ee8-b6c7-41358576d62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc255f39-9750-4c16-8c0d-e5d2dc2c1cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894d1bc6-79f1-418b-96ad-edfa34ab7c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd456900-61e2-462f-9239-f48a06c57ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1ded33-4aad-46c9-91b7-0f5f44bc4a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac0e9b63-e9a6-4351-961e-d255b8a8ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8e6ad1-12f4-4208-afae-52ca73874fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5323dd-b1c7-4b96-a6da-df2fd1454284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b3e1a9-baad-4d92-a8d3-53f91bb58528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a635674f-94ce-460e-ac42-6933690fe7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab798d05-939a-4caf-a66e-a7c47ca46703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27ef4b8-6052-4c8b-a431-535c378352b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b35cb1c3-28f5-47d7-a83d-3d4032c38a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59940bb3-4f38-4787-ba8c-da1ce62e4e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 267e9656-32e8-44e3-b5c7-43fc107a9f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c25a9b32-25b3-42da-9893-227ed1394128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7075e00a-ed2c-4abe-ab4a-bee27d3d9247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df168b4-9bf2-4919-ac2f-9cb343fb236f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a14f89-83ec-474c-99e6-d8b5ebd8b667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ae82f9-dcc6-4f27-a45c-de384306f843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b326ec2c-7f11-40e0-8d5d-a8d2fd2b69a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e10ace0d-13f1-4fb7-8c2a-cf2be416b93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ea7982-7251-4d5e-a06c-d69c578f79e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93446d7a-4e06-4282-aa55-4b3d1ca25adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad779e1-a3d8-4c14-b42a-9460637c75c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09632e03-ab7c-4e30-904a-dea4a1601cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55d63923-0c76-4a21-af34-729868479ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d19a669-6c8a-4c76-9688-184af9569779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68b40119-c706-432a-95f4-91bce6ba9682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 781f2c6e-baf5-421a-b41b-40653f616029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a228c50d-1088-4106-8576-644fc6936e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a890b5ba-ceb1-4d0e-8451-5637f79b886b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c596b17-dd07-4527-a46c-549026061069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca99f24-54e2-4bca-89a8-efc83abd4e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dff73ef4-fe12-449b-89a6-41f682bb5d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09333598-1d69-4483-96a6-a1883f398cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e05e376-1173-4d58-985c-59708cdf0346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d22412-97a3-4e23-a329-a52460cc540a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5cb6997-5f5e-4caa-b87f-5c75efd8b61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdce3bf6-ac90-4ac0-a962-2a3893ce3fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8e920ff-a160-4336-8e64-66896af1fafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3291a693-db5c-4eb0-81f5-f8c11600dc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32bb7751-b140-4250-afa6-1b6f48477603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d92ae9-68f7-4385-855b-e5a83f428d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397b95b1-a293-428e-9b0c-e543d41e066e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c251ab63-a7f7-4638-8542-314489b22fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad462536-c256-47b3-9bf5-fe403b2ffb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04ab7ae-0ef5-4d38-a01c-fc6f4bb7c33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68bfd625-c86d-4786-98e8-de82dc7c3436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a52a71-513d-4da1-b10e-2d0a800e2f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed70855-a115-40d5-9445-59de1442c228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fb4916-4ab1-4791-9974-be001fd555dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76ec3e7-ccc4-44b3-8396-ceeb9713c17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581d57d8-7f12-4d91-8cfa-8390ea0cb071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c085b03-00c2-494b-b57a-3baa8e78c978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb47a79f-9a1c-4280-a2ef-bf5de5875111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d6538a-3a3a-4792-9eba-dc48f077cbae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3031a0fb-93d3-4bd0-91a2-aa74da0c8c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71c3656-684d-40dc-baa8-28515e54d7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def0ead5-1f19-4ece-8058-5c754b1047c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e0c74e-6634-4b78-80fd-9307142d3ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae689ecd-dc8e-4f6c-a3fd-bac4e85104d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2259bf-f64c-40ae-9d5c-766c98b5e463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a447d4-3de9-4c6b-b6bc-2e0c19b3c2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07cc5ec5-6e20-45a6-b345-1d41f5891da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215ac075-47b5-4cb8-a6b3-98452f3fcae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0f02b1-4188-4380-bd4b-6915a5fa0e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f986b01-01a7-4675-887b-ed6dd947f06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b186afe7-84a1-4d10-b936-17875fd7659d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a244b2-0cd7-452b-8087-b196e854d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bce27842-26bc-4451-99a7-85f5ece3d032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a634763-62c1-4c01-bc30-2ddcc0bab06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63055a0-e871-4c98-85be-e7642dd8cb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064b9133-8f96-430a-8444-a56650fe064b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66bcca54-c030-466f-af81-dfcc2ec84269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde89fe9-3ee5-4aaf-9999-0069e5af9c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c29c360-bf62-4d51-a945-ae4ef8bd5d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f66acd-a117-430d-8746-fb09b3a9b958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f13b69-46c9-4860-b7ac-034557679241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e192ae26-dd1d-4376-9abb-613b37e5216f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f5fd58-81da-4c12-ba00-40d4eee24658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad9c9a6-736c-487d-8245-d342f18b7745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0bca493-a44f-4b85-8be6-bff924b5918c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70443e92-430a-41d1-a492-4ace59fc32d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19734546-e06e-4bbc-93ff-7c7b25b195d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90d2117-fe07-4e2d-8998-de74a716bb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb11f15-4e4a-4e17-8134-5ae65afec821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f68be2-7fe8-499e-b72c-7beadf5d6c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06ddb21-d32e-44d8-8bc5-23009085484a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986b3335-1dea-43a8-af4c-cf51c166ef3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b74de8-5a93-4e25-bb98-1e7393bb146d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121ab44c-f2d4-4795-8880-aa90bc0d1194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5d59eb-9807-473e-ae82-ef3004f04b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a052f317-38e7-469e-a914-cfb4d33ac8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6396b0e4-a21b-49f4-a9c2-0e567d9dc4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a5881f-94dc-476f-93cb-266292e7c21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61fcb9e-1566-4354-9a8b-057260bf8a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a0d0304-24e7-43df-b5dd-fbd10ec3177e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a8758b-ccdd-4de1-8ddb-5237eabaa6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af676a1c-83c4-498e-8712-4a0929857f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2348338a-aa2f-44cc-8aa4-fe3cf31c4315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd25a5d-163c-4aad-9b73-e533fb98aee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c99827-727b-47e8-9eec-b61ff52a6edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41341a27-8f94-431b-8814-12ff14dcca71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec363f4-c5ee-4d1a-8e25-91e77c49f1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b41390-98d9-4361-b9f2-c78d6d1f5eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a0caad-48ab-4dd2-b1df-568412912527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc7ff2e-263e-43e4-b412-b60651568402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e279d4a4-a5f7-4c81-887d-9d9cc6c21da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b888cc7-70df-4e39-bedb-316642f1c1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ba4779-4915-4d0a-97e5-e3900cd1bd32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd9970a8-6b99-4959-9468-d9b143d664d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6217eec2-5db7-4ccb-a753-c742b1a9443c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482b5486-cb92-4667-aef1-8bc2e6f980cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144c55bc-d89a-4cc5-9ed6-6dab9d7c10c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77abe9ca-cd99-48d1-9c89-fc11ca7de864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7456d41d-ff62-4bdd-875c-b9b55c13827d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d53cd1-04a9-41cf-929f-3a63a5110627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536ec26d-b0fe-431d-94ec-04a946ceca27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 646ccddd-0470-4aaf-b292-dc58a09506f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76d34c1-e105-40ed-9904-abcef9f310d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171ac2bb-0d00-4dfb-9b30-eb70d99f1a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35d6f1f-6f05-4539-a31f-c4a79953ff36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e531e8-ba0a-40c9-9702-f7432e7499e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dfc86dd-28a0-4f53-a89e-abccfb3ad171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cae750da-de06-476a-94b8-83e087712d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eebf53d0-25a6-4388-9863-c4dc71fd5e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0be7b94-1918-408b-8fae-aff4175b03f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72bbc21e-194d-4fbe-9947-158535a19a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bfdd3e0-999f-493d-a782-832143813407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d9e311-8f16-468b-9225-a73e94ab82df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08c26bd-3853-41ba-94fa-8db6b77940eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cdc4077-7a83-40d0-b2f1-739037c77707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1aec36-544a-4bf7-9c7d-d40e4e3986ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb18cfe-027f-4392-b365-edf3f6fbc818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aec9654-8c5f-4760-b21e-3f77c01eed82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef9f5c8-10a9-4d05-a50b-af97790ce38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e624bc-e948-42eb-acc4-a17c7c3d1ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5917d42-0a7c-4e0c-811a-ab209de1fc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410528a6-2812-4654-9b16-f13c19ba8b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06adbabc-f512-4d82-b398-5b9c963236d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a79036-5812-4775-8fb9-2d49da7aaca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21fe270b-36cf-4a1d-8999-c45638460a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeca581b-1160-4951-b84b-b0c7bf1fea7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61242db-556b-4777-9138-70cfe80e25ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88caf28-125e-40c5-9875-5135f1ca1c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cafa3f87-0798-4c5d-b41b-1b222345211d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7609c098-4d29-4c0b-804a-fcb71e01a5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ff2308-3702-4a8e-8593-ac578b260e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e575b3-6456-4655-a516-00d044145cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d5b960-9da8-4af5-be83-6e5fdc5ebcdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3da960c-1cf6-4820-8249-8724dc53d171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72dd2d40-5503-46d4-8a82-1b445d337e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0447a2fe-b8c4-4912-8a80-78a7b3563490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8187e89a-0305-4fc6-9539-29dcf2519f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45c9c6f-384f-4bff-b6f7-b1cd6930f5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d77d4d-0298-4233-86e6-edcc9972a1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2007f11c-7cf5-4006-87a3-c7683f3ace43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70d69cc-553b-4937-ac5c-9a3c19a37172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ccd8288-f3c9-44cc-a7d4-b7b80923ddc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b24ef5a-eaeb-46c6-bcd5-1eb120f3fe02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c88d2b-1917-44c1-acd1-14f3b1cb981d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf56f34-2c33-4273-9b5e-43d1b67bfeef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a9e6c1-a6d7-4ba4-81ec-57a34673c1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9816719-0a77-46cc-baa6-ab0a95bf55ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62f47b44-ea98-4d7b-b474-d76d60554ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821b90c8-e055-41cf-831a-4bf930990695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d69470-60d0-4d4a-9f88-dcda25bf590b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2fd0f60-3bb1-40a6-bdda-12b2731d6a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9108456-1b2c-4cb5-bfa9-65007c98f061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98b60d3-7de7-4447-ae82-fa8beef89a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bd47ea-39a8-4afc-ab73-5a22f6d17d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d506a667-bb64-4988-9b4d-4fb7a7b31dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b2fd3fc-0550-48ff-98e3-b97704dae61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6e6724-73e6-44c3-b9f3-7b49e71fee16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11cb5b44-ad31-49ef-b171-27ebad6ea7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ffff8c6-4f27-4111-9a57-0c5a1b7f8cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff542cbd-35a2-4945-99c8-46e7125041ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b020e51-2293-446e-ac38-756541b9dd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dc288ef-99ab-4c0b-8aa9-a78a8d9821d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f1b6d4-2ac5-49dc-b97e-fab096ff3b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be66e35-4f45-493a-9971-db5a649b33e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868186fe-b9b6-4d3a-aeca-a7cfd01ce94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ee2f74-356f-407a-bf1b-3fa99233a61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a67640-549d-4575-8f8d-8580d08f18d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b846b558-401d-4ded-9073-72e16f98892e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a86ad76-b727-47d5-ab21-4ce06000c4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3b8be5-23fa-41b9-b3db-45ad902e2aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8dff721-5003-4683-a3c5-bd4c52c06bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75eb860f-2545-44c5-b08e-b898f25aa17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b64bdd9-fb8e-41d9-b0bf-feb36d265efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618afb69-5d47-4ac3-93c9-74f0f7ecd2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48df113c-208c-4850-8a6d-246f8b228261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 033287bb-e240-4917-9dfd-9e4ae4dd3557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d0609a-56b1-448b-8aea-bab0ee116d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef9aa25-d7e1-4efc-82b5-e80177a36df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c525e8-a0e7-4464-a25e-f1c8341bd230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a465d4c-6f3d-4e79-8208-0f7ceb4ac52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b52182-fea0-4f38-ae0d-8b4e4039ab4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a4be11-c46d-40c9-9c12-2b4990d2b4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e09b98-d3cb-4ad6-ae89-9ab69bd2ab53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f001e31-c402-41da-9d03-11af245745a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0afe430f-005b-4eda-8eb7-8d708f206d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d5bbf7b-b6ba-4bf8-97e4-83b66af9c389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1dde4c-0310-4d14-a511-2a04ae81cbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cda8af0-02c5-47b4-96a9-90ff399d1550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de40ee94-e5e8-40fb-9e88-7c639d9b770f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1b3fd8-d7ff-4dad-b68a-5725bfc456cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d75803d-afa8-4647-9a9c-8c15415c51fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498ad047-a3aa-4b61-82e9-20906eb7ea4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb61e4b3-ee9f-40b2-b3bb-a1190a8c4850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e0b1ef-a8a1-4015-8223-0abb47075b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c89ad4-06af-4195-a3d0-489960c7d51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f147558-6a08-402a-b866-be74e6aef89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff06fae-a89f-4722-b2b3-0e59f4fc17e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401d4f75-32ce-4645-a6a9-a0e3f9ac7aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ddff2f-fdb2-4762-b2f2-cdd9ef16d98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01db484f-a1bc-48ac-badc-e0e7aab81c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13095f0b-69b6-4fcd-9ec6-778819e1b013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0cd2f0-1054-4812-96f2-b813290e520f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4691af-3d34-4f61-9674-bbbf3cb1fc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f304946f-bc0f-4ef2-ae38-d045f6f26ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2863fb12-483f-40c2-953a-445faa5586b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065c20eb-6ffe-4d28-8de8-b71aced0a281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 807e8445-7c21-4822-bb8a-173780edfe17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 790fb344-fd9d-41ec-9724-4b1ea4381f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6da95b-987a-4e36-8bb4-164ae6fad545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f65ee3-acbe-4c4c-88bf-8cbf7fb36db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd116a9-badc-43e4-87c5-6001b3288a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a6995d-c397-473e-be5a-531c912d8565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6530719-7a8d-4101-9a9e-3a4225590701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c42325f-965f-446c-bb61-295143b14c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99502e37-e0a1-4b6c-a23a-a3dbaaf58868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5c8ab3-027f-4a1d-9041-dc4dd3852a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2c9aaa9-c413-48dc-89d0-9c135a26e27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0798af62-a59e-4411-8642-0ac0c8997052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7a9a66-8555-4834-bc03-0ca4ad6267ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3000527e-6ad7-4fd1-b229-d6677c8b2ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba9ff83-7605-4023-8885-98b1d757f686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fde64f-811e-44a8-a0a2-ef3ab1d8e103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73aaff9-28f5-43fc-a547-036346dce8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a87a03e-d106-4779-82e6-b38397ea1ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbb51db-0922-46f9-89e2-6350581d9290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5aa729c-a632-41d1-94f5-3dea6cb8bbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd19322b-016c-415b-831e-ce104e779abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8cb51a-cb28-4a83-8050-573a604cbc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1827eddb-63e9-421b-a1cb-06e8fd006eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a86718-6148-458a-a80d-e8774fb4025b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b600b9-e518-4577-aaf2-263292d4aacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00a2d94-45fd-421b-8909-6cf627da9136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ca9f21-5bc7-458b-bf22-7096995c1085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d5f8a2-40b7-4ba3-88f2-68e99a4d3f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f501e4e5-73b4-41f5-b7ec-69c86ee7e306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303ad00a-72c7-49a2-a72c-130302e283c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec9f032-8c22-4571-ac51-30933753a230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d421a08-abae-4728-94c1-e6f727a797d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7599d861-e4c7-4f13-92f3-3d0bdeb2d6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8755e670-b411-4111-9ad0-6be655db324e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590db061-a948-4f50-a770-4380dcba5d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0e48e1-4589-4815-ab7a-7eb7583a1e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46800c57-cafb-4065-aae0-ae1485f4172c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a50b6fc-3ee4-4f09-a3ea-e3c0d1da8550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e26fc562-87b6-440e-864f-5789f6f3fbb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9705531f-a216-4e88-b5d5-6fe5d10f949a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86036b23-0ab3-4901-8a39-c4920e15ccfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c99498-34d0-4496-aa2c-fa1919e6040c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f38cd918-e1d1-4849-a9f1-bd41162e2947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee258fa5-40b3-4785-a406-9cdaa296ff8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d593ee84-3492-4998-8f71-80d68aa538cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c213a8e4-fc8a-4e0c-b0ca-f512ebaec182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c79b7de-8b38-44ac-9e7b-4169430b1aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309d66ae-154d-4e24-9792-9bf06fe450fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 002193c8-8777-4a21-a1d5-a8cb559f7680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfbc9e9-9790-4785-a26c-aea4fea95b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82915f65-7b5a-42d8-ad72-016372c9bbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16370ce0-f06f-4ebe-8835-a81d010576b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655e99c7-e033-4c2b-b540-e80822ba0f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b6bf90-a573-4afc-a7bc-1d50112c9def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6993f9-3d7b-4176-89ea-7c4b8efd78d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da9fff6-98bb-4e99-9c2e-fb41e88acb45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446d929d-b116-4aae-ae34-68df49b79140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2001e4a-8f81-40b7-804e-7771c1f7509e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c967d8a2-24ca-45c8-8a4c-3f6d7b100c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9caf7f9c-e29f-4708-88c0-9ca6df7bbe86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d58cd3-db6f-4637-8ded-ace1c337addc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f7b74f-a5b8-4c55-9869-e100da952d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e271e4-635f-48e8-b60a-f130029663ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427b901a-be2d-4a41-9c4a-38cd854efa95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2710978c-461a-41f5-9ac0-81d67abf235c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d30f193-b07c-4c5b-bb6c-fb6313126af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90adea41-b93d-4832-8570-c76af0ada77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc348bc8-aedc-475b-ad5a-327e1539f649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0d84c9-aac9-4532-9243-c4e83a18c345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e751d09-19ed-4641-aed9-415e3609d8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21aaf027-dcf0-4852-8cc7-54a80b527910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e21555-2897-4bd2-ae77-fbfe3050db07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2f8b3d-a008-440c-ab87-59597d1b3709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bdc154f-6691-4313-a11a-0a6440eff5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d237eb5a-f22b-4852-b44e-ee61267768f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4800ba7b-461f-45b2-bb12-58a52a1c711c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1b4bff-3e14-47ae-980f-54cb5991ec87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ec735c-a70c-407b-b610-ccaa3decb87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77095e45-fe23-45b0-96f4-69af101aa7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f80b5c53-5294-4896-a906-54cdf961036b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bc660c-8b07-4bf3-af00-d778926ea4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d94313-1a29-4870-8774-1fd342509425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec4192fa-9fcd-4ab6-892d-779487776f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee06945-3d00-4e53-99e5-948d99e53827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42ef4c7-2e89-4253-b297-918b620efcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cc0087c-efef-424f-8e84-2452b37ec3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d41fe088-a29a-48d6-aef8-3f0bb22a4e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c426df9c-17a3-4f77-beb6-e84397d0be5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9313445-9535-441c-bb84-b7e791a04367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbe74c0f-18a1-4f97-86e1-3663f6f8e876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad1108d-8f09-48c6-b210-43c1f8fe0c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e846d76-f6af-4135-b395-46a0bf045d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04705037-8840-40db-8841-7b669dc1cc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe2e681-8f12-405b-b0fc-20fd96082d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287ea6ae-b594-4b1f-9b45-1fdda93f3b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f63dd8-a553-4586-a8a3-7fd5d25de2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7594ce42-822e-43ea-a37f-45339f10e3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23bd14e-09c5-4358-8ebd-34d3732739cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a2a8808-7f30-4392-9542-e15342c13148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb9c2ef-74d4-4992-b37d-8bd7fc9f2ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c2ca96d-983f-4e31-b8b1-067e4f5db7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dab835a-400e-466e-86a1-2db7a878a10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74237a33-b23b-4611-9221-8b4b52bdce4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb2c331-1f19-44ba-9f7e-3083777b1239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62fa6bb2-f68b-44e3-8aa1-2684c97976b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e868cd1-d4ea-4a60-adf0-6726d3f0a007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c973a4-b081-4e2d-acfe-9858144db663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b38e6cf-a489-4db6-b3ef-28bbcd4dd680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f67ab2-6a53-4f30-9b4e-c92342f05f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3eedbf0-43ea-444a-81fe-a5f894cbde7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20418894-9e85-483e-8f65-d17a3c9090da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8ccb43-3261-421c-9281-a097ebbc576f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6709cf49-c4d4-4fbe-887d-8137be3ad856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f72168-2c0a-4d35-86ea-e9909a82393a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5bea008-8d12-4eac-a1b9-f066b69794e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cf40ab2-1661-4ad8-9fd8-4a2c06b02871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b11ee517-31ee-459d-abec-8b4a02f8f8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c13425-7470-4120-8bf2-9fdd41b24ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4864387-e7f5-4fe6-ad2d-858a6da0155b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e0d111-1746-4a00-adbb-aab920628b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e20def-ace2-4c2f-bc23-9625999f2c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da600c4-c7dd-4530-87fb-e2087697dbac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e62823-acaf-43a6-9be8-0f452033e3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e209e84-849e-4952-914e-cd0cfeb94662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9942432-7c34-46a3-bde7-4f6d3a3788b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3770d8d0-2566-4a29-84fb-58ad2ffb47ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702c4b12-2d0b-48b5-8324-42e5e227903c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79977fa7-6a5c-4ddb-8dd6-c07f17cfaf40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e64064a-fa89-40d5-83fd-50e264b84b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388d148d-fa00-4f9e-87bb-14b86ba49b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be769f5-6757-4609-93aa-779833fe4dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcaeb4e-accb-4af4-8614-9039b1290c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c6fce3-774a-436e-9d4e-8aee41ffe503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa478916-0a2c-4fd8-8fd1-81d55c6f43ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8724f894-29e2-4662-83cc-480d7b83ae90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca1170c3-c148-4391-9dee-fc46d9fac121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb8f70c-a26c-4986-b188-9a3e6b9d906b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f00ddff-d0c8-4b08-b799-bbe686ea2696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177c73cd-8322-4844-90c7-ee36b33be7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56ad024a-f55c-4f27-938b-bbc8bfbdb922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd783b0-0027-4a05-903c-34a45aee2ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c35580-e8e7-4349-b586-d884523cd808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f815a830-191b-47af-906f-500a7c59c8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53987a8c-72ec-47d3-afd9-93252cfbfc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191323a7-4516-41d4-9cec-5cbcddb6e5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf28727-e1f6-4864-afc6-3aa0e4c1a344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ec5f14-a2d7-4042-93cd-aad9ffa99551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1ad4f1-9084-4f63-a1f6-c1421dbc1192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ba9dda-c2f9-4390-9f0a-6d07bbde9eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f52ff1-716f-4191-b661-6b23de81600c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a575c0-4bd1-4e1d-a2bf-1593479a386b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b441a8f-138c-40e3-bc2f-3cef97ca3fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a3de51-aed0-43e4-b39e-a1e7f905e097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890cae59-e786-446d-b1ed-f7405469efe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411f799f-95f0-464c-bb7a-3630240e16c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd33f51-7776-4923-865e-a347331bb5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c11e07-207a-418e-982b-5889891631b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb7fe06-dbaa-411e-b673-365c07414967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa752769-c481-4076-b04a-3c4fb5a1b4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80964e42-e4b0-4d83-b26a-c31bfabbf963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aae0bb04-9e4e-46e0-a6b5-393cf8b7bf14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b3f7f7-af99-4cb9-b03a-bb1f2d44a763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b85a7c-0879-42f7-8c0e-019aa2bdb997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2a0d54-7eec-4c37-944a-61e6c22fe295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469e3d13-1337-4898-99e6-23535501e246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d75aeec1-d1c6-4858-a010-ab7a5c9f0013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90746822-eb2e-4823-bbd5-b5b05086ea96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b05b56-6c42-41c4-8cf2-df25bff49148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d99b7bef-618b-4fcc-abfe-0917b27e99ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4886b93-c78e-4fa5-b0f4-cd8856004034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73497ff-89ac-4efc-877b-c2727a59d95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83eb0cee-fcdd-4b98-910d-b708bd99f26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492ea209-5ca7-4170-91a5-a1490595c493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58818428-bd29-4014-990b-4acc355535bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcb64317-05e8-435c-a57e-21563047a0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5355e7dd-754d-4566-8201-03bd02eda893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b57a6d1-c63e-4df7-9986-74782a48d06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd8f9e9-9bf5-4ddf-a796-2783892e3be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a346ec-1770-4f45-b719-33c6d2bdcbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb993376-4260-4334-b838-19aed134b911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ce8af3-b693-4f49-84c4-ee61298b8491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2621d8e-bb99-48cf-a131-7136e59a347c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf87c79f-5941-4cc8-938a-5a23ed0d9671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45dd7139-df6c-4431-bea6-ba752623adf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a1c7b4-e13e-4c52-b100-7dc5f0ab1d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a301b323-cdd5-49f8-afc7-d952cbccb580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7cbc1b3-1d0c-4f80-928b-bb5c56ce7acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8560dd10-240c-4868-a576-e4d7d94c5da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c93ee30-602b-4b8c-9ef1-b61356d17ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0f66300-82c7-41dc-baa2-571d7ecc27a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8163fb4b-9f53-4a75-b452-0a25a647af16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8616b9-3c1c-48c0-948c-147d6b10d775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f57c4c-9a92-49b1-8c69-9ca1c8a11b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933198c4-e2c0-406c-ad68-dc6b3d263aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20c2d64e-9ddc-4228-bd84-b67ed36a5135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfa32696-1d98-4de9-a372-b1ef446c6a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97112de-4f2c-495f-abcc-494469c18592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89060ec4-6dcf-4e47-ae96-115c0fa6098d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e42dbec-9597-46aa-ab24-0063ea9ac447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0e046a-f3bc-4ce5-beba-94d7e3b52388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ab2b08-2d0e-4b35-a29f-546119818941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d055fec-fb22-4ba6-8702-1514f38f66b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39be2ce-9443-43a6-8934-d213bd8309a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a4ffb93-fc2e-4eb8-9b38-f0614afd57a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f74e37ae-fc62-4bf8-8088-e85647a8a1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65d4405-2749-442c-bd9d-cb3dd938b0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de4f852b-2cd7-4a37-9491-83859fa8a89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8710f9e0-b6e9-4511-8be0-6011444fa563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362385bd-48d7-4b07-88ae-dd5b350d97c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039c5742-9bef-40a8-9a68-b85a8c6dc4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67beea7f-0fe9-409e-bc13-a74c6773657d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1429747-6941-4550-b7d3-3847bc0d8367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3aa31e3-2b2d-4539-94c0-96bf8f61e1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330e8e53-587a-4340-b89f-42f60783b8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb4237bb-f3bc-402e-8a74-00f3f0606aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7e4e7c-bbeb-48f1-a6e5-338a313db392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4a8fcb-2d02-4da0-8854-16d9c249f37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d474200-387d-4efd-a981-66d9efa37d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdecb7b-735e-44cb-9785-bc4b618aec25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e9797f-1240-42a1-b7bc-788910129b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a61b4fb-aa34-45b2-83fc-69b1b488db17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeafb4ab-a3f1-4ef4-a5d2-0f47196c5df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b998e74-8237-4cdc-af93-ea5f7e399146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc0cb9e-580e-419c-83da-bf9bf86a11f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087bf7ae-41d0-45e3-ba46-d07dc5d26cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1315c7d0-fa15-4940-a057-ce0d4864d3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8215cbdd-27c8-46d7-8bc3-b3386182ad3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb9e94e7-553c-404d-b69d-5a6c803c6ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111457dc-bb60-4d5b-bbd4-06ea30008244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3e9dbe-9f62-4b56-ad90-cfe7943bbd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896c7baf-ac58-43db-8426-bfff39d0d93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d49f4d6-1e65-4565-82dd-5692b0e8c418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2bac0d-c317-4a62-9f59-cc0f431e84ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376347f9-a052-49f8-a25b-08390e718b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c93212-7b7a-41ae-9613-8c252248e453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4b19dd-74bf-4575-8e91-ecb29ef892e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21172f48-997c-4a87-ac76-56b6629dee6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac96a78-9ee0-47ba-a52a-2121e6bd10b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5817bbb-15be-4a07-91aa-35633fac5604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26cc0287-4b21-4d3a-9060-57a175993ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a2d618-e0a1-4423-a626-f0c21e05c161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5930e17-e736-40c5-93db-c80fc2994792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b640fc4f-3988-4774-bf05-5d07f0b7ca57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ae5c79-dc7f-4e63-919d-d000cbf812a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ed42ee-3fc2-4ec6-abbe-872030394f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1679c769-2abb-4762-9822-8bafaffdc153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440327b9-46b0-4027-8600-03e2c5476e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9692a9a7-a3f9-4900-82c1-d8f03dc903d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 743108e1-c4b2-491e-882d-4b25787e2651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eaa1b42-1584-425f-a134-6e6c22f900d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed358a1a-2060-440b-9175-3b6048130786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d96660-6afd-4519-9ee8-6906f83b7652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 560c9db3-52e4-495c-9db4-abbaee255241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3a3ae4-308f-4e51-97ce-c1a33c3768ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 479f66aa-8bf1-4f01-b2b0-e15550feb7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec95006-aa8b-41c8-a408-7fd34a2328e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1803833-46dd-48bc-bf18-f373ccfd1901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d032d83e-10d9-4236-9f8f-7c4fae774386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5ed5c4-9308-4708-b7b8-e867357cd9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ae240d-37e7-4347-9470-6ffa5df699ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da055a5-685b-42c5-9601-33b40012b704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84029a4d-b643-4f63-860c-e15aa0127a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230fe394-e406-4a5e-808d-402ea8cac634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8441d5-282b-4b3d-9e84-87fbaee49386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73447804-de00-42d7-a900-79fbd3c8a830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee6140d-e604-4c58-85af-8327e144ded1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb24631-2bd5-404e-8dee-e680c6a311e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e46c1f-69ee-4970-83a9-7e924d208e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab375aa-4793-4224-87b3-492029e3f443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca1d277-6e63-4ceb-8456-5627ec37a7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5805a3-0812-4b85-bf1e-84d1bb7d31be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f0ffe5-3907-4a44-bbfe-d96b89ae2ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a01e4435-5eae-4e92-9f19-e477eae2637c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1eb7a83-0f5b-465a-8d70-612ca8f1928e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43212241-0b45-4761-be1e-5c4e6b0bbeb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65e44fd-22fe-4ab8-8a4e-eb4001ce1299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d87eca48-0b6d-418b-ac0a-98f60e2b10cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676f2fde-6de5-42c7-9d1e-d2c4316d2eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325eb96f-d045-4d5d-8443-1256e293caa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991b3aed-a362-4940-a761-72cdba99ebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0bfb70-1ee7-4d64-a213-e12b4ff843e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e002a41-b116-4ce1-a101-c6b1ab4c0800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e2daff-bafa-45e1-988f-ca44ab796956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47ab1fb-bde1-45b2-9f8e-d9bc9581cd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2602d029-4ad2-4c27-b55c-2fc406244c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31d9fc0-041c-4143-9a5e-ebf4438484ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae21cad-bee7-4192-948c-c3315bde8845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8cbcbd3-f7ea-4b6d-80d8-7600a25bd944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2740ee37-edeb-4472-8ab6-07a664325157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df55fe5-d159-47d3-9b88-99501d63938e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223b97b3-a279-42ee-a3e9-3e84b04379ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3413ca01-0580-4741-aac6-19d4a4437325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fde0621-3d65-4931-a1a7-105eebb8c540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63422acd-d9b1-4bf6-a09a-730bedf4b0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d25afd-4bb6-493e-9d2c-5f9669101772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a622aec-7cad-4020-82ce-34a6ed0e1ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada825d2-1b06-4650-a2ad-50faebaf17ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bdceb58-5fff-4031-8950-1a9649854f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 576f71a3-69c2-48dd-a3f5-fd9822662623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763eba20-d649-4723-989b-940dc32e0797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe011e62-52c0-4e8a-b117-213e55d2d72c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d94de3e-cc1d-462f-9c61-cd8c1eb9d973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6457856b-a254-4eda-85f9-f3c9f5b2d6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb46037c-241f-4d28-b1a0-7d1c623f9056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50673d3b-ee1d-4ade-bafb-12a821b9ec8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed649cc-cdf9-43a4-8303-05f05347490f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72054012-e6ea-4ce8-b3d3-b6b08288a979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfe3216-6f85-4f8e-b2c4-a9b5981ac719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0631b983-4245-4cb1-8b1e-5818db58daf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1dc0391-6796-41a0-a81f-4df388e4416d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b78309d1-2571-4f20-bfd2-8e5e130ebf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ccb832-1eae-4b49-9aec-6fd84b6165be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86a8b4e2-6e18-47e1-bab2-837592f0325e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d749dad-7522-43eb-b6f5-053756858e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65b1bb83-be59-4e75-8c60-d6f8a785b8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b04239b-96f5-46e4-a419-280bade166ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5534df9-b906-4359-af5f-f19ae7f692d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a067c21c-9242-4766-8e7a-b4e690ed65e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133ea4c9-3249-4cc9-b9e0-ddd8e74f4020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1caca2b4-6f91-4c33-8b83-cdca783aa222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cebb481-f6b0-47bd-8001-151272d34a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012df58d-03d7-4d12-96f6-47608337593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ed78c1-e265-41e2-b8d5-36367a2a8e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859ab5ef-ffa8-478e-a85f-60b1dd9e4751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b48da444-e395-40b3-a151-0f3c0af966a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff15341-a0f1-4d75-96b1-cb9832d2db82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d9da27-0e98-49d1-9231-dedc906f6175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70c6969-020e-467c-b0d7-beebd032ef09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca01b00d-6816-4ee8-b7a9-9854bf03a6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbabfa4a-cb27-4e39-8125-0ccdd006744c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a421c475-4b28-4c74-8fca-56b7672e6152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f275bbff-aecb-4f7d-9058-919ca5265c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6fcf4d-e810-4b88-ab6f-def91659ebfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3323a65b-f761-4327-9a9d-7d8609dafe42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a005a6a1-b58d-4166-90ab-6b00e702812c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e512627-eebd-4e3e-b425-0ae039ede73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0996a681-5410-4e3a-b93d-cf086347c40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea768cba-5f58-462d-80ac-0c180f298366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e09cf7-3ad7-49bf-aad1-480d29114cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e008d3-cbe0-40ef-8b93-7daf4d636354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8b7d50-6a2e-44ff-ad1e-fef56adf1fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0158e8be-0a0f-462f-8be3-9a1f621547e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e441920-07bc-40fd-8261-5535b24dbd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c27a236-7bb6-4a5c-9740-58724957a5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a392c229-c092-4b85-b77b-5d7480affba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b56585-1505-4d77-8149-6725446a84b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f85e798-fd39-4769-9e62-96585a5cdfa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 854a75ed-c22d-4b75-b2cc-74b22f6a2aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e38f97-bec3-4f85-a468-853682b965a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0835df42-07c8-48ae-b051-2cbd7c457569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6692e4-70f2-472a-8bce-cf3bd6281cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7968d794-c831-457e-a4c6-c817d18828c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89093022-4d2b-45d5-82c7-1b1ba17345bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d39c24b-77e3-4d61-a6c4-f2c6c4a8d46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f00db67-198f-4410-906b-0fdd1613899d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505af5d7-2ca1-47c0-b597-362914105440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1305a10-fccd-49cf-bb73-96ff5b3d3b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5009db60-81a3-403b-815d-a4fce87fb5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62477004-8147-4126-9871-f6fa20d43cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a2b880-64f9-4f2e-b28e-1c4ae613c8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280c96df-00db-499e-9fac-248f22e8ebde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef87e3c-d514-4cfd-bc77-52a369eeae66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c411903b-8e0a-4a8a-8129-63d3b6107dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ee8523-15b1-44f9-859d-2b32eacb78a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c12221-d143-4238-a3e3-34dd8c4c55eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f085e123-4238-4cca-b1fa-cf581ed1cab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d039e99b-593a-475c-8d0d-d849a85f616b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0acdcdc8-9f92-432f-90d5-b78960ab4c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ab91e2-c0cf-4b93-8f64-12e51b63c542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cb340e-a114-4b68-b493-430d95b38bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f592289d-12cf-4e1b-94b4-b226ae6f454e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c0b525-3a2a-47d1-ad4c-edce59f63599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef6dfbd1-9234-4982-ab2d-6b9946d68607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bc80bf-5645-4d5a-9a3a-183f36517a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602d76bb-5b87-4564-8391-842d3495e4d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4181dd79-2c2a-48b1-b0ea-4a89ba470b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3491c124-444b-4ee5-96db-c63854095cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770637d3-3d8c-4d40-9810-dcd6bb8992af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9269dd34-9420-4913-bfa5-3eee7dd981a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9449c8-d6d2-4d3a-a4c3-5966343fadf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b41458-259f-4dff-a5b1-8626ced45d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3cb2024-aee1-426c-97fc-3b577cd99d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397c7567-e223-46bc-b915-65b298b30940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94506569-97d3-49b9-a2bf-28efb99ab433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ed55d11-7961-43e5-bfaf-5ee390d62cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11489cd3-45e5-4ff8-b2f5-9af8247e81aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d22242-5d73-46d6-89c1-79bb9f36af5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeae8cc2-2019-4117-a838-fb31c43c25c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa2f28c-4dd6-4b2d-8247-a088c0f4d1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594a664c-2f78-4166-8db4-f5c22e0dde9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01278ed0-d0e2-4388-b665-58575aeea2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1298ec-4401-4dec-bc7d-28b8206d08d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b608590-7050-4ea8-b1b3-605b02e70801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f385a1-2ec6-4d9a-bd79-21d8604e21c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a896cc-a7dc-4131-9332-793c12909fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38903bd2-c14f-4444-a609-3f9ae1dc67de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8549fcd5-889e-45dd-8756-09160cd1c4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa100ad-a72c-41e4-bd77-cae55b56a037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6bb1ef-98d3-4001-943d-31d425270c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d53a6371-e3f2-47bb-8a4b-72f348951772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d2764d-8b6b-4953-8e6c-59592315301d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84db4d9c-2fb3-476c-aa80-fa1085f54a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438d2df7-7007-4200-a0c1-f53894f49291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e330f3e4-9323-4308-a165-a5f9c3d1e108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d9ad2a6-651e-44bc-b189-017fb5d2dfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3742c01e-0a02-4abb-8739-12517902ab3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4960ccd7-627e-4ed9-b853-d9cba2db03a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b53136-1db4-4b85-81ba-128c1e163a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc48abb-c849-4493-b9e6-5a56cfbe552a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddae6798-ab9f-4d8b-80a9-6bc5e941ebc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da56a5f9-8fd5-4e44-a2e3-4658589c6146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d402cd-30f2-49fd-88d4-1efc5e2c7248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde78d4a-d79d-4e9d-82dd-3f1476879aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9781760e-a409-4e88-b07f-a4d8b6f032b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d3da46-0aa0-41f5-9403-371f2d4f7e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5730471d-bb86-4ce6-aded-aedd7aa2caf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3079e98-1a49-415c-91c4-0da63ef42b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360fbde5-8f77-4418-b3f3-ef37704af134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91239260-77a1-4213-969a-ca7d797a5d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeed0f51-57a6-441b-9569-9aec575c033c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ead44a5-915b-4709-b72d-7b6921c9fd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a873ef5c-1ead-471f-8eff-e6cf5289cddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e557090-a7dd-4bc4-9936-c325ea6e9cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be971dfa-1b91-4634-8f77-e86c88dab551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5796de-3ea2-4c5c-8140-a1afdee659c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f06fc48-4957-4485-9855-439f71eaac20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef152e4f-d564-4421-acd3-886e2ce61c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca5fdeb-9f2e-42aa-af05-749a9aecf723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1279f80a-5a32-4ede-b088-cb539434b19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60555a44-842d-4f73-bc5a-7db4bc6b8965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975363cf-74a9-4a1e-ba73-d5853e106081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4f4eb2-eed6-44cf-a825-fdd66786878e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825834eb-1208-463f-ac09-b5e8a94273c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473252d6-bf96-45fd-a3d6-daaace0beef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 815dd99c-fa0f-446c-8306-336e9accd982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d583d6e6-558b-4216-a902-76697e0bd920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00256dd-c43b-4b06-ad58-92142d0f33b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c937043-6221-4ae2-91c0-c412ee8974b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1abe95e-f7db-404e-819b-e91d15c64cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf14d191-1655-48b1-bac6-b97fb2cb52cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7863bd-c5a1-4c23-82bb-a0c22e0f534a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f63ed0-5e01-4f0c-8811-c6660c3d399a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b247c1-4319-41ee-b05e-37a344dba5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b79c7f-054e-4ae4-89e0-96d713ad2710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4583f416-3bd9-4b0d-aefa-d364e816a2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d548c016-1e33-46d7-986c-c3f0bfccebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de22ba0-6d2c-4e78-9c7e-9f7289645373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd21ca2-e63b-4775-a7b5-817807b78353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dea1c40-e7cd-461d-b072-2278e339096d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87eac218-6835-453e-a4aa-bbdb1096c11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523b03a8-09eb-4bb1-b904-3714f4710c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7314cfbb-0e48-4380-ba56-bb6cbedf91bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef803ec4-5b2c-4b12-8c6f-a42d284831a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f96620-c20c-4ce6-ae49-6201aea99738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2981c4dd-a0b6-48c9-b2e4-a853cbad52c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f06018-5cf7-4e58-b7b5-1a5154f0b516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b17904bb-250a-4426-926b-a77bff381a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c454b3b-b089-4f65-838c-9f0d379a32d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec0f079-e88b-4ecf-a506-9076836f1bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4ca8fe-2362-49a5-b75f-fc3e4cf0476b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185022b1-fdce-42a1-888a-9b4d955dddf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da55496a-fa6e-470f-b158-31c0b557213b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bd0aa1-74a6-420a-bdd4-f551b98efed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7699f00c-fb7e-4d11-92f7-319a8826d2e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69df3be-676e-45c9-adbd-3953d419b6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f249d91-3f06-45e6-8528-0e0deafa99da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05083674-0809-4703-82d4-2b9ba8d8830d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239187b2-1d96-4e99-bdc5-1338dd90ec4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a232f284-a482-495f-a993-ce5d92eb557b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d211b7-c31e-41f2-bb08-dc18d43713f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe01ad7-956e-4008-9604-4ea8d05ff293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc570209-93f3-4046-ae2c-11c7510bf27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f4e9fa8-c8de-470f-9599-3d05ee2ea935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50a2c0a-c344-4eaa-a3c7-edaa1d8ff5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6541237-8b09-46af-a554-d4ee4a073409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd67d92-686f-4f94-9553-aedb32fb8aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844d1ab1-750d-4775-9599-2a55234fb0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea6fc520-198c-445a-ac99-92c7eaf02bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1037fa2-b2ef-484a-be36-26ea36eb6608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f82f499b-2abd-4f9a-8794-94b2c6e2e0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 627b75e2-908f-4dd2-a911-9075f7a86678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5095f9f-9a17-470d-9d62-5a52fa321108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25c64f9-042f-4c2d-a4ac-26223ad6de27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7b22f4-1178-4d7d-9ef7-c61ae30e76e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f237a348-3f59-4fe9-b8b0-bf0f0bbd0e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7220a4-fca4-4280-8e23-c2b7b8aa26de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4640e3df-728d-4ba1-a266-725304a83385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 503a839f-2345-49bc-98f4-e8249d3f810a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f293451-d41e-43d0-97dd-e444ca8bf6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9096ec56-4ffc-4e60-9ec4-b96ad06523a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d2311f-4cb0-40c5-9d0e-b7536e3da0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20db2e0d-5695-4c2e-afe0-e1e3ba5611b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e4fcce-bb14-4299-9394-c1e00f2a6c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3877cf2d-0a95-4490-8d38-774f9ea13ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e325f8e7-c7af-47c3-8cbb-2af039089e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a606106b-0000-457a-86ff-8b52679cef59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b93be8-6f88-4302-b300-7ae3edcdf35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce275ccf-9f7c-4cad-b21d-1f70d3cfa7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f80df0c-f59f-4cfa-a381-143c37bb05bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051f54f5-74eb-4837-a852-3d67343891f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f316d9c1-d98e-4e05-a48a-3471fecd0052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8adf3b-5d28-4c33-ac4e-0a80444bb75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04cf8088-e1cd-4b57-a076-095912cca333
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(3694, 24), y=(3694,)
   Test:  X=(924, 24), y=(924,)

⚠️  Limiting training data: 3694 → 800 samples
⚠️  Limiting test data: 924 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0750 (↓), lr=0.001000
   • Epoch   2/100: train=0.0839, val=0.0771, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0845, val=0.0767, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0841, val=0.0756, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0835, val=0.0753, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0819, val=0.0741, patience=3/15, lr=0.000500
   • Epoch  21/100: train=0.0803, val=0.0735, patience=5/15, lr=0.000500
   • Epoch  31/100: train=0.0780, val=0.0735, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 3 Summary - Client client_22
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0304
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0013
============================================================


============================================================
🔄 Round 4 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0754 (↓), lr=0.000500
   • Epoch   2/100: train=0.0826, val=0.0760, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0824, val=0.0764, patience=2/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0822, val=0.0767, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 4 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0021
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0016
============================================================


============================================================
🔄 Round 5 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0815 (↓), lr=0.000125
   • Epoch   2/100: train=0.0809, val=0.0818, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 5 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0027
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0184
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2415, R²: 0.0045

============================================================
🔄 Round 8 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0630 (↓), lr=0.000031
   • Epoch   2/100: train=0.0858, val=0.0630, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0857, val=0.0630, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0857, val=0.0630, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0856, val=0.0630, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0855, val=0.0630, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0630)

============================================================
📊 Round 8 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0007
   Val:   Loss=0.0630, RMSE=0.2511, R²=-0.0046
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2414, R²: 0.0052

📊 Round 8 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0033

📊 Round 8 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

============================================================
🔄 Round 14 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0795 (↓), lr=0.000031
   • Epoch   2/100: train=0.0816, val=0.0798, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0815, val=0.0799, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0815, val=0.0800, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 14 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0031
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0040
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0033

============================================================
🔄 Round 17 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000008
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 17 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0004
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0084
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0024

============================================================
🔄 Round 18 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000002
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 18 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0002
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0057
============================================================


============================================================
🔄 Round 19 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 19 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0002
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0060
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0025

📊 Round 19 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0025

============================================================
🔄 Round 22 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 22 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0002
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0081
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0026

============================================================
🔄 Round 23 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 23 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0002
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0057
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0025

📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0026

📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0026

📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0027

📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0027

============================================================
🔄 Round 31 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 31 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0028
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0025
============================================================


============================================================
🔄 Round 32 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 32 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0018
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0125
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: 0.0028

============================================================
🔄 Round 33 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 33 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0007
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0043
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2418, R²: 0.0029

📊 Round 33 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2418, R²: 0.0029

============================================================
🔄 Round 38 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 38 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0017
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0011
============================================================


============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0002
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0040
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2418, R²: 0.0029

📊 Round 39 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2417, R²: 0.0030

============================================================
🔄 Round 43 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 43 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0019
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0090
============================================================


============================================================
🔄 Round 44 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 44 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0008
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0083
============================================================


============================================================
🔄 Round 46 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 46 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0023
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0145
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0032

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0033

============================================================
🔄 Round 55 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 55 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0000
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0635
============================================================


============================================================
🔄 Round 56 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 56 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0033
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0034

📊 Round 56 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0034

📊 Round 56 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

============================================================
🔄 Round 62 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 62 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0026
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0162
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

📊 Round 62 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

📊 Round 62 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

============================================================
🔄 Round 66 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 66 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0006
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0041
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

📊 Round 66 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

============================================================
🔄 Round 68 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 68 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0019
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0014
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0035

============================================================
🔄 Round 69 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 69 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0002
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0162
============================================================


============================================================
🔄 Round 70 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 70 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0043
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0113
============================================================


============================================================
🔄 Round 71 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 71 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0015
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0008
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0036

============================================================
🔄 Round 72 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 72 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0032
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0194
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

📊 Round 72 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

📊 Round 72 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

============================================================
🔄 Round 81 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 81 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0015
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0007
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

============================================================
🔄 Round 83 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 83 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0009
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0022
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

============================================================
🔄 Round 86 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 86 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0047
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0088
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

📊 Round 86 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: 0.0037

============================================================
🔄 Round 91 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 91 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0041
   Val:   Loss=0.0696, RMSE=0.2637, R²=0.0121
============================================================


============================================================
🔄 Round 93 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 93 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0075
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0038

📊 Round 93 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0038

============================================================
🔄 Round 95 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 95 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0014
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0038

============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0014
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0127
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0038

============================================================
🔄 Round 98 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 98 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0030
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0068
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0038

============================================================
🔄 Round 101 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 101 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0006
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0084
============================================================


============================================================
🔄 Round 102 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 102 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0026
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0018
============================================================


============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0042
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0054
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0039

📊 Round 105 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0039

📊 Round 105 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0039

============================================================
🔄 Round 109 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 109 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0033
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0067
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0039

📊 Round 109 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0039

============================================================
🔄 Round 112 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 112 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0000
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0049
============================================================


============================================================
🔄 Round 113 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 113 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0001
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0335
============================================================


============================================================
🔄 Round 115 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 115 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0007
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0155
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 117 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 117 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0008
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0017
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 118 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 118 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0031
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0348
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0039

============================================================
🔄 Round 119 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 119 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0036
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0026
============================================================


============================================================
🔄 Round 120 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 120 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0006
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0051
============================================================


============================================================
🔄 Round 121 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 121 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0005
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0143
============================================================


============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0015
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0028
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 127 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 127 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0002
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0330
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 127 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 127 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 132 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 132 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0026
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0056
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 134 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 134 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0104
============================================================


============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0002
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0045
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 139 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 139 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0003
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0121
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 139 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 142 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 142 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0012
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0259
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 142 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 144 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 144 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0040
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0086
============================================================


============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0025
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0042
============================================================


============================================================
🔄 Round 146 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 146 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0015
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0105
============================================================


============================================================
🔄 Round 147 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 147 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0029
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0363
============================================================


============================================================
🔄 Round 149 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 149 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0025
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 150 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 150 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0008
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0076
============================================================


============================================================
🔄 Round 151 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 151 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0002
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0059
============================================================


============================================================
🔄 Round 152 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 152 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0006
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0097
============================================================


============================================================
🔄 Round 153 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 153 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0004
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0072
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 154 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 154 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0021
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0092
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 156 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 156 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0008
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0101
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0007
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0024
============================================================


============================================================
🔄 Round 159 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 159 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0009
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0081
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 160 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 160 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0019
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0045
============================================================


============================================================
🔄 Round 163 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 163 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0026
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0030
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 165 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 165 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0008
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0017
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 165 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 168 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 168 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0012
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0139
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 168 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

📊 Round 168 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2416, R²: 0.0040

============================================================
🔄 Round 174 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 174 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0027
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0044
============================================================


============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0006
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0054
============================================================


============================================================
🔄 Round 177 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 177 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0028
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0062
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0041

📊 Round 177 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0041

📊 Round 177 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0041

============================================================
🔄 Round 182 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 182 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0010
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0102
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 182 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 182 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 188 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 188 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0016
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0226
============================================================


============================================================
🔄 Round 191 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 191 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0014
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0186
============================================================


============================================================
🔄 Round 192 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 192 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0053
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0120
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 193 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 193 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0015
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0099
============================================================


============================================================
🔄 Round 196 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 196 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0043
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0117
============================================================


============================================================
🔄 Round 200 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 200 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0038
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0059
============================================================


============================================================
🔄 Round 202 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 202 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0017
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0014
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 202 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 204 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 204 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0051
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0090
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 205 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 205 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0020
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0126
============================================================


============================================================
🔄 Round 208 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 208 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0029
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0163
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 212 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 212 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0013
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0358
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 212 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 214 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 214 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0017
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0014
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 215 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 215 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0040
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0085
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 215 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 217 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 217 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0010
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0001
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 217 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 219 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 219 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0007
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0072
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 221 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 221 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0032
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0090
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 222 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 222 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0026
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0150
============================================================


============================================================
🔄 Round 223 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 223 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0009
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0101
============================================================


============================================================
🔄 Round 227 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 227 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0007
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0076
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 231 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 231 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0032
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0048
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 232 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 232 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0073
============================================================


============================================================
🔄 Round 233 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 233 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0143
============================================================


============================================================
🔄 Round 234 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 234 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0007
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0165
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 236 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 236 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0001
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0132
============================================================


============================================================
🔄 Round 238 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 238 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0037
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0104
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 240 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 240 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0023
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0095
============================================================


============================================================
🔄 Round 241 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 241 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0001
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0033
============================================================


============================================================
🔄 Round 242 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 242 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0011
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0227
============================================================


============================================================
🔄 Round 243 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 243 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0033
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0081
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 245 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 245 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0023
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0045
============================================================


============================================================
🔄 Round 246 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 246 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0002
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0073
============================================================


============================================================
🔄 Round 247 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 247 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0022
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0139
============================================================


============================================================
🔄 Round 248 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 248 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0043
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0080
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 248 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 252 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 252 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0033
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0000
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 253 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 253 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0006
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0085
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 254 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 254 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0033
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0161
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 256 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 256 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0011
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0225
============================================================


============================================================
🔄 Round 257 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 257 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0006
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0073
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 259 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 259 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0003
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0045
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 260 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 260 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0001
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0065
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 263 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 263 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0034
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0078
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 268 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 268 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0034
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0064
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 268 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 274 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 274 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0011
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0017
============================================================


============================================================
🔄 Round 276 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 276 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0014
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0009
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 278 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 278 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0001
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0078
============================================================


============================================================
🔄 Round 279 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 279 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0000
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0038
============================================================


============================================================
🔄 Round 281 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 281 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0002
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0323
============================================================


============================================================
🔄 Round 282 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 282 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0016
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0113
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 284 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 284 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0036
============================================================


============================================================
🔄 Round 291 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 291 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0039
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0138
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 292 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 292 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0317
============================================================


============================================================
🔄 Round 293 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 293 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0028
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0170
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 296 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 296 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0035
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0048
============================================================


============================================================
🔄 Round 297 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 297 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0015
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0029
============================================================


============================================================
🔄 Round 299 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 299 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0002
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0102
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 300 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 300 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0014
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0021
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 302 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 302 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0003
   Val:   Loss=0.0688, RMSE=0.2622, R²=-0.0092
============================================================


============================================================
🔄 Round 304 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 304 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0019
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0008
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 304 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 306 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 306 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0005
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0064
============================================================


============================================================
🔄 Round 307 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 307 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0008
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 307 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 310 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 310 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0007
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0037
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 312 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 312 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0012
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0005
============================================================


============================================================
🔄 Round 315 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 315 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0005
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0078
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 315 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 319 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 319 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0025
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0016
============================================================


============================================================
🔄 Round 320 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 320 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0018
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0016
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 320 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 332 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 332 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0005
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0016
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2415, R²: 0.0045

============================================================
🔄 Round 334 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 334 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0048
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0156
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 338 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 338 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0019
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0036
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 340 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 340 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0034
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0124
============================================================


============================================================
🔄 Round 341 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 341 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0011
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0072
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 341 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 345 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 345 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0006
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0074
============================================================


============================================================
🔄 Round 346 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 346 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0028
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0157
============================================================


============================================================
🔄 Round 347 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 347 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0014
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0080
============================================================


============================================================
🔄 Round 348 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 348 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0017
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0036
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 349 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 349 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0047
============================================================


============================================================
🔄 Round 352 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 352 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0027
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0208
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 353 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 353 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0013
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0088
============================================================


============================================================
🔄 Round 357 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 357 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0045
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0112
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 359 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 359 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0012
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0048
============================================================


============================================================
🔄 Round 361 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 361 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0024
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 361 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 363 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 363 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0012
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0077
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 365 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 365 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0013
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0182
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 368 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 368 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0028
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0070
============================================================


============================================================
🔄 Round 370 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 370 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0029
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0065
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 373 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 373 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0005
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0024
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 374 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 374 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0008
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0111
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 375 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 375 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0009
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0118
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 375 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 375 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 381 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 381 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0018
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0014
============================================================


============================================================
🔄 Round 383 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 383 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0006
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0013
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 385 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 385 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0011
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0158
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 387 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 387 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0016
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0023
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 388 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 388 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0019
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0001
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 389 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 389 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0023
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0155
============================================================


============================================================
🔄 Round 390 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 390 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0010
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0051
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 391 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 391 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0001
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0049
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 391 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 391 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

============================================================
🔄 Round 394 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 394 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0016
============================================================


============================================================
🔄 Round 396 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 396 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0036
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0085
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 396 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0044

📊 Round 396 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 396 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 396 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 402 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 402 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0030
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0046
============================================================


============================================================
🔄 Round 403 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 403 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0016
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0049
============================================================


============================================================
🔄 Round 405 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 405 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0011
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0017
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 405 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 408 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 408 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0032
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0081
============================================================


============================================================
🔄 Round 410 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 410 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0018
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0128
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 410 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 412 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 412 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0009
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 412 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 417 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 417 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0025
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0117
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 418 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 418 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0024
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0037
============================================================


============================================================
🔄 Round 419 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 419 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0026
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0030
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 421 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 421 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0019
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0105
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 421 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 428 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 428 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0007
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0073
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 430 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 430 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0020
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0021
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 430 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 433 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 433 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0009
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0028
============================================================


============================================================
🔄 Round 434 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 434 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0019
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0098
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 434 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 434 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 434 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 434 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 442 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 442 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0052
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 446 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 446 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0022
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0023
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 448 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 448 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0005
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0072
============================================================


============================================================
🔄 Round 450 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 450 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0005
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0006
============================================================


============================================================
🔄 Round 453 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 453 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0003
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0050
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 453 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 458 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 458 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0004
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0129
============================================================


============================================================
🔄 Round 459 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 459 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0034
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0022
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 459 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 461 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 461 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0002
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0015
============================================================


============================================================
🔄 Round 462 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 462 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0028
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0067
============================================================


============================================================
🔄 Round 463 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 463 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0032
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0100
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 465 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 465 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0016
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0012
============================================================


============================================================
🔄 Round 467 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 467 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0002
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0087
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 468 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 468 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0025
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0103
============================================================


============================================================
🔄 Round 470 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 470 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0012
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0028
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 473 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 473 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0010
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0188
============================================================


============================================================
🔄 Round 474 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 474 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0006
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0051
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 475 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 475 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0003
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0118
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 476 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 476 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0029
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0038
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 476 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 476 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 476 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 486 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 486 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0000
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0028
============================================================


============================================================
🔄 Round 487 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 487 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0001
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0039
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 491 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 491 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0012
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0016
============================================================


============================================================
🔄 Round 494 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 494 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0025
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0080
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2415, R²: 0.0044

📊 Round 494 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 499 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 499 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0011
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0147
============================================================


============================================================
🔄 Round 500 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 500 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0012
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0028
============================================================


============================================================
🔄 Round 502 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 502 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0005
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0065
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 503 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 503 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0028
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0047
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 503 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 505 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 505 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0004
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0043
============================================================


============================================================
🔄 Round 506 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 506 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0001
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0017
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 510 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 510 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0025
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0080
============================================================


============================================================
🔄 Round 512 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 512 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0014
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0002
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 512 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 512 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 512 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 516 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 516 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0032
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0064
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 516 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 521 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 521 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0015
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0032
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 522 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 522 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0000
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0036
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 528 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 528 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0012
   Val:   Loss=0.0663, RMSE=0.2575, R²=-0.0164
============================================================


============================================================
🔄 Round 529 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 529 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0012
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0005
============================================================


============================================================
🔄 Round 530 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 530 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0024
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0008
============================================================


============================================================
🔄 Round 532 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 532 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0021
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0006
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 532 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 535 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 535 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0014
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0078
============================================================


============================================================
🔄 Round 536 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 536 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0024
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0115
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 538 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 538 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0016
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0085
============================================================


============================================================
🔄 Round 540 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 540 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0008
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0005
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 545 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 545 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0023
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0207
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 547 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 547 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0045
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0078
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 550 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 550 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0006
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0035
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 555 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 555 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0033
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0031
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 557 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 557 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0003
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0060
============================================================


============================================================
🔄 Round 558 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 558 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0033
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0050
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 558 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 561 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 561 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0012
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0072
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 563 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 563 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0005
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0039
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 563 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 563 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 568 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 568 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0010
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0079
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 568 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 568 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 568 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 575 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 575 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0018
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0061
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 578 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 578 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0006
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0002
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 578 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 578 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 578 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 591 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 591 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0017
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0001
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 591 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 594 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 594 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0020
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0217
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 596 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 596 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0017
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0007
============================================================


============================================================
🔄 Round 597 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 597 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0037
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0053
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 597 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 603 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 603 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0019
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0039
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 604 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 604 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0007
   Val:   Loss=0.0686, RMSE=0.2620, R²=0.0006
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 607 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 607 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0032
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0002
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 608 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 608 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0024
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0061
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 611 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 611 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0013
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0036
============================================================


============================================================
🔄 Round 613 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 613 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0016
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0020
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 614 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 614 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0010
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0002
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 617 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 617 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0037
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0123
============================================================


============================================================
🔄 Round 618 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 618 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0020
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0109
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 618 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 618 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 622 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 622 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0018
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0145
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 625 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 625 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0014
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0097
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 626 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 626 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0040
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0093
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 632 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 632 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0015
   Val:   Loss=0.0968, RMSE=0.3111, R²=0.0016
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 636 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 636 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0002
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0063
============================================================


============================================================
🔄 Round 637 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 637 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0044
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0147
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 639 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 639 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0016
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0014
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 639 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 641 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 641 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0043
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0252
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 642 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 642 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0019
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0015
============================================================


============================================================
🔄 Round 643 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 643 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0033
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0111
============================================================


============================================================
🔄 Round 646 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 646 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0006
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0369
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 646 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 646 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 646 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 656 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 656 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0011
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0023
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 656 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 659 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 659 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0007
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0011
============================================================


============================================================
🔄 Round 660 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 660 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0046
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0137
============================================================


============================================================
🔄 Round 662 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 662 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0026
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0088
============================================================


============================================================
🔄 Round 663 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 663 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0012
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0029
============================================================


============================================================
🔄 Round 664 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 664 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0000
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0102
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 664 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 664 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 669 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 669 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0005
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0110
============================================================


============================================================
🔄 Round 672 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 672 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0019
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0113
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 672 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 672 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 672 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 678 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 678 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0007
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0231
============================================================


============================================================
🔄 Round 679 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 679 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0000
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0126
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 680 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 680 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0005
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0003
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 683 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 683 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0005
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0034
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 684 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 684 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0037
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 687 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 687 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0013
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0068
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 687 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 691 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 691 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0024
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0088
============================================================


============================================================
🔄 Round 692 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 692 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0015
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0077
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 697 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 697 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0013
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0061
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 700 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 700 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0017
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0001
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 700 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 702 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 702 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0029
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0016
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 702 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 712 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 712 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0015
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0075
============================================================


============================================================
🔄 Round 714 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 714 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0041
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0043
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 718 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 718 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0015
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0008
============================================================


============================================================
🔄 Round 719 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 719 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0032
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0147
============================================================


============================================================
🔄 Round 720 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 720 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0025
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0129
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 720 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 723 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 723 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0029
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0008
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 725 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 725 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0000
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0091
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 727 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 727 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0088
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 732 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 732 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0002
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 732 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 734 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 734 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0017
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0095
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 736 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 736 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0021
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0105
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 738 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 738 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0008
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0079
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 738 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 743 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 743 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0003
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0149
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 743 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 746 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 746 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0023
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0131
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 746 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 748 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 748 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0070
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 748 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 752 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 752 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0015
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0046
============================================================


============================================================
🔄 Round 753 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 753 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0012
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0034
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 755 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 755 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0014
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0234
============================================================


============================================================
🔄 Round 756 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 756 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0030
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 757 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 757 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0003
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0255
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 757 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 761 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 761 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0109
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 761 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 761 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 761 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 768 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 768 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0001
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0020
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 770 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 770 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0007
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0053
============================================================


============================================================
🔄 Round 772 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 772 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0002
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0026
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 774 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 774 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0032
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0246
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 776 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 776 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0016
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0073
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 776 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 776 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 779 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 779 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0041
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 780 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 780 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0071
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 780 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 780 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 785 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 785 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0022
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0141
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 786 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 786 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0003
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0231
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 786 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 788 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 788 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0008
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0024
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 789 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 789 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0009
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0054
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 789 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 791 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 791 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0027
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 791 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 791 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 795 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 795 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0003
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0019
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 796 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 796 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0016
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0044
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 796 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 800 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 800 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0017
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0064
============================================================


============================================================
🔄 Round 801 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 801 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0005
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0002
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 807 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 807 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0027
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0010
============================================================


============================================================
🔄 Round 811 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 811 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0012
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0029
============================================================


============================================================
🔄 Round 812 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 812 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0062
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0040
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 818 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 818 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0004
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0001
============================================================


📊 Round 818 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 818 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 821 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 821 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0004
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0017
============================================================


============================================================
🔄 Round 827 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 827 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0004
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0001
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 827 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 827 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 827 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 833 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 833 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0034
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0119
============================================================


📊 Round 833 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 836 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 836 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0014
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0028
============================================================


📊 Round 836 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 839 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 839 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0021
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0003
============================================================


📊 Round 839 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 839 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 842 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 842 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0019
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0077
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 842 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 845 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 845 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0005
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0008
============================================================


📊 Round 845 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 845 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 845 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 852 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 852 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0012
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0044
============================================================


============================================================
🔄 Round 855 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 855 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0019
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0183
============================================================


📊 Round 855 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 855 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 855 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 860 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 860 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0001
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0004
============================================================


📊 Round 860 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

============================================================
🔄 Round 862 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 862 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0014
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0071
============================================================


📊 Round 862 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0042

📊 Round 862 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 865 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 865 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0000
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0006
============================================================


📊 Round 865 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

📊 Round 865 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2416, R²: 0.0043

============================================================
🔄 Round 867 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 867 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0030
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0056
============================================================


============================================================
🔄 Round 869 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 869 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0006
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0166
============================================================


============================================================
🔄 Round 872 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 872 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0008
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0014
============================================================


📊 Round 872 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 872 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 874 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 874 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0217
============================================================


============================================================
🔄 Round 875 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 875 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0015
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0080
============================================================


============================================================
🔄 Round 876 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 876 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0019
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0009
============================================================


📊 Round 876 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 877 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 877 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0028
============================================================


============================================================
🔄 Round 878 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 878 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0004
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0023
============================================================


============================================================
🔄 Round 880 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 880 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0380
============================================================


📊 Round 880 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 882 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 882 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0017
============================================================


============================================================
🔄 Round 883 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 883 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0016
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0367
============================================================


📊 Round 883 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 887 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 887 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0004
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0062
============================================================


============================================================
🔄 Round 888 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 888 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0007
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0136
============================================================


============================================================
🔄 Round 889 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 889 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0021
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0162
============================================================


============================================================
🔄 Round 890 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 890 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0010
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0033
============================================================


============================================================
🔄 Round 891 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 891 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0009
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0011
============================================================


📊 Round 891 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 891 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 893 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 893 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0017
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0068
============================================================


📊 Round 893 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 894 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 894 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0002
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0238
============================================================


📊 Round 894 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 894 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 894 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 901 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 901 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0043
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0046
============================================================


============================================================
🔄 Round 902 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 902 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0020
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0064
============================================================


============================================================
🔄 Round 905 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 905 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0014
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0070
============================================================


============================================================
🔄 Round 906 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 906 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0010
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0141
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 907 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 907 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0032
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0055
============================================================


📊 Round 907 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 907 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 911 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 911 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0003
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0006
============================================================


============================================================
🔄 Round 912 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 912 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0020
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0103
============================================================


============================================================
🔄 Round 913 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 913 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0024
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0098
============================================================


============================================================
🔄 Round 915 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 915 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0004
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0064
============================================================


============================================================
🔄 Round 917 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 917 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0040
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 922 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 922 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0019
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0097
============================================================


📊 Round 922 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 923 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 923 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0028
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0019
============================================================


============================================================
🔄 Round 924 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 924 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0011
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 925 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 925 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0033
============================================================


============================================================
🔄 Round 927 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 927 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0034
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0025
============================================================


============================================================
🔄 Round 928 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 928 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0008
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0015
============================================================


============================================================
🔄 Round 930 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 930 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0010
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0168
============================================================


📊 Round 930 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 934 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 934 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0029
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0123
============================================================


📊 Round 934 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 935 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 935 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0013
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0020
============================================================


📊 Round 935 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

============================================================
🔄 Round 936 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 936 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0024
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

📊 Round 936 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

============================================================
🔄 Round 943 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 943 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0016
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0030
============================================================


📊 Round 943 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0043

📊 Round 943 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2415, R²: 0.0044

❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
