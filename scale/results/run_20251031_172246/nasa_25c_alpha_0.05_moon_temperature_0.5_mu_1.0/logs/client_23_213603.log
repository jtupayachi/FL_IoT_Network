[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3799b70d-71ed-4d50-b280-120b4836a8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9c4f96-e309-4ea3-8f4b-413c27aeb297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9727f177-1e5b-47f8-b3ea-c9ac09521a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ca4d01-e959-4883-8f0a-b8309197e21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600b3b4f-8508-463d-8731-1d38fb454a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2947b589-f263-48bd-8956-cf4f66b75dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d6c3e4-8fdc-4e7c-9c03-5b1a53e715ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7fef9b-16f0-4285-b8ce-a5ab4e9b912e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c99a5b-b18a-4a39-a2f8-4d8424a5b8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cd19e3-1758-4be2-956d-e24ca613bda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415d0159-0be2-474b-aad1-970dfc3f3fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f46c84-074f-486d-a434-ab1cb01e48c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 385b944a-8d85-4c96-bf3e-fdc09513254e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04d2752-7686-4d22-827f-def49503a97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb62b337-85b1-4520-8fb7-33ff3e0ff43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba76fab-7662-425c-8c8d-93a97cd622bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a6005e-4039-4dcd-b753-2b24d17edd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baff9dc4-cb3f-4ea1-bba4-7825e2efe967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291d2c0a-c49c-46c7-b845-b10d2ee3bb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 220dce1c-85de-4ecf-8397-40898465b3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51bb6fa-6e6c-45bd-bfba-99bb895852a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934c07ff-7d9d-40b2-b5e1-1c76b9016381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea009e23-25a5-4c78-bce6-2d6bd993c2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7007cb5b-3b38-405a-b36a-7f2450eb0b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f275e82-871a-4e60-b304-80d7d64a8efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b5218d-2145-4244-8e43-92009f8ad2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e905905-cc24-4492-ae6d-5e032416773f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980f2620-b0a2-44d9-bb38-efc7b3c92c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a617cd67-e50f-4ff9-a5e6-9513f2de48c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa05e0b7-12cb-47dc-bad4-a94c6e3ffd7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fc2f23-9203-49eb-adb4-2e82a1d285bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b5bd1b-e99c-4b47-be6a-269ed664772c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee81a34-2e52-4fe7-80f6-7f7fefaa3d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2502527-5a23-4ec2-9672-e308e857b253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3034c90-e58f-46d5-80d0-a8b3760a5f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c91ab25-fcde-4dd5-9b17-05b6d1f36b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce3969e8-1add-4cf8-a1a5-1320bf70b90f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4824180b-5944-4e01-b3b4-dae0631a641f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0e2a890-dfa2-445c-b8cb-040b714e02c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 260ebf11-1632-4aed-8d74-8d1c1e9e56eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f5ed5e-a81b-47c8-958b-a83f5cd78956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd59ea0-c9b9-479d-a8ae-9df6077ed70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0beff7c0-49ac-4a3b-ae31-3119885d8a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1797aab9-7495-4a36-90e0-371955f6348b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf29ff5-ee10-4407-acbe-2297f4e1cb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f33c8c-79e2-4339-8e9c-da8e4f20b9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29147fcb-a6f9-4770-897c-9cde63898ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df4c5999-ee0b-4860-a83a-08c4b8a6bd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6980d8-1159-4dc1-84c9-ee0c5c85aeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce48af0-06b6-489a-9374-77f30a8e5154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7f3c29-fba1-4123-8b86-85cdb5786166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a335da9-b233-40a5-ab75-120dd323a319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f0337c-953f-480d-a0cf-47aae02328a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9351ee27-daf4-4874-8264-1fdbcbee0fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185695bb-97ab-4f87-a0cf-a6226109da52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcae54fc-e1c8-4185-ae98-dfdb337734e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413824cf-7fcd-4a0c-be22-6f061457ead9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7132bc2f-46e3-4f6b-8760-5ed9868d0041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba862c6-c199-45af-a5ba-c5133cf0bfe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082010d9-2e75-4606-acd3-74480904826e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a11375d-ac64-4393-8fba-16225fba8f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc72172b-a02e-43a0-923f-5211650c1c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef16bf30-ce81-4d62-bd67-cbb80966b9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404e1ebe-927e-43de-b470-2b10513afe0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c59875e-d4fc-423e-938f-ef9430b1eb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message decf5a6d-a8b6-42ed-83f3-05294b164205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb4f4b1-acd3-448d-993d-48c88b3a1ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192a3dab-7883-4697-baca-77ba5e73eb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41771149-9fee-4edc-b3bf-d921e32bd6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a875abc-97dc-43b2-8751-f37fa69dfb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b096c3f9-9d1f-4fee-af27-839f3f5731c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669feeb6-24a9-4154-992d-dac81b78c98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c5dfda-7eb0-4858-b51f-f9bb266f8694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676e99f8-9aea-4933-bff6-30b272cdd20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d780e5-dd55-447c-8e54-668c4b8de3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39eee09-a5a6-4c60-9b5b-bbcd0d9e0fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 327b5df5-02c3-45e7-aa1d-37be7b1c1727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd5bbb5f-5a1b-4199-8ebd-2e1920797071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6683cccb-5258-411c-b0e4-1f43c1f0923c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea80c00a-a050-47f9-b6c3-65dcdf84f3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177f54a2-34d8-476a-92bd-abb1246bc6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45fa4db-e099-4619-81b0-2ce46a3a1308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24bd9a1-b688-4194-87e9-30f00bd4bcf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050f5caf-e946-46b0-bcfe-11ccc5a96195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f213359-f4a7-4e45-80a7-eb7bcafa2515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd450f3-fa70-4dd0-bdef-62e190be3194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66226649-83f0-4abf-8b73-5c344bdb7c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11cdb9f-6695-40d8-8dfd-14af80403c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffa1245-edd4-4fd8-8719-a4e97dcd2212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b94318-8198-4886-adf3-e34dc2ca32fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afc3ef8-33ca-4648-9054-efea1c5efd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1bfb8aa-150e-4db0-97e2-aae54ef946a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a388e4c-6250-4ae8-997a-24071bffe0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6ef7e0-dc17-4ea3-9831-84860c899edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38697622-9ee4-4406-84a6-a0049b976994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62dff74c-41e4-473e-91c0-18c1c0c1bd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e1e064-b17c-41c1-8626-4bbd2708b9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49632aff-4d9d-4ac7-b7b8-6f0c86eab4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86f579a-b273-47e2-a548-09b6a73c78ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d4a9367-3c5c-42ea-acab-d905bbb98798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09c6862-16ad-4509-9c27-97056d14328d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f7840c-9318-4037-b89b-aa0284ae2eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e04cf97-7546-454a-9ce9-89c7dfa9321c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08366579-c836-469b-ab65-cccfabd256ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ea3e32-f6fe-43a7-b51b-c8f234a30da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c47188eb-eeff-429c-a7db-5784906a72ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f8b0c9-f0c6-490a-8e1c-2dff678dce06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd55872-2132-4a47-b938-7956a6d545c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb17c72-d150-4e2d-a98e-bf2cd78150f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667b89de-3798-4e82-b0dc-1d171d057bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec09ccd1-2bd8-48de-8084-bd81919afc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25aa5a96-eb47-4cd9-b461-0b1cb770936b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bac96a-9549-4807-8a88-22be547c913e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd84d81-a298-4362-a65b-28f5c3173eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b1e57c-9ba3-49b1-b123-0270d565f318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca6594e-8ce6-4f98-a9c1-fce6ff7637b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57781ea-f510-409c-a79c-52a10a624413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d48c1b-4a24-434c-839a-dbc9e533ae12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22d7361-7a55-423e-bf72-ee1573cc5b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65033565-8782-490d-8f69-525e857cec4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18407c7-cd88-4775-922a-f88147d3486a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed177ed-b2f7-440a-afe8-1afe89e32b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0a19b3-45e4-4a3b-99a5-9b5ad7456918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542e2a85-1277-4bf8-a563-89dad1b2abc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd318922-e129-43d1-9c7f-c3dcb9db04b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e31a12-58f4-4d1a-9c37-f4afe2df74a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc7aa94-e65e-45bc-a1e8-8052a8b2f308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b538982-81a9-44c3-bb6f-fea952bee70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63feeb25-121b-4829-b3af-3353c32b9edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1995a49a-4bfe-49a1-b372-b6f9af7b882d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82b251a-edff-435b-b921-14dd460df230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4494d3cd-0181-474b-a806-3f40e62a8a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d709d62-ae31-44cc-a9ea-a9d55a4e5f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a41170-5f2a-43ff-87f8-d6ca93a69a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f67312b-5e07-4704-aa28-90a1d8fd20d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6d51f1-0f45-41dd-bacd-3ed77a113c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede19df0-bf59-40a8-aa9c-3c39e18f83fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e82b201-c657-4ab2-a6ed-fe3305632048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33297d92-b1ef-42ab-bbb1-c92f693b64bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079978f4-8edb-4742-8da2-651d3403118b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2f9093-9c30-4daa-a7cc-840c066358a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a613e4e-e50a-41a0-b99d-930d1f586654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32520f3f-a0ef-4505-b446-b3226858db9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098721ef-327d-4f05-af11-3522cd2ef60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a752056f-e971-4ddc-9c1d-3d9ef7571cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc14672-a4f3-4b72-8f29-027a58972653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949ccc2a-328a-4cb7-b7ec-946eb33b5185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea3b26f-1a81-44b8-9e15-8658aa30b9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a00e33-a141-4e37-903e-ebfc9feeea04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ae4a82-b2b0-4eff-be70-cad4ee490a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85fd1d90-c66b-4c1f-9e88-fe05cff7a1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b63c251-bee9-42f4-9568-a7ff1856c3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cbaa289-80a9-40d2-b688-be82dfbd5515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd793f1-bef6-44bc-a6ac-a1370c128157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8ecd3c-ae25-4cf0-8d75-2bc83d77ed4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 991f867a-9af5-40a2-b7b8-d68666b4e91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1007581-d4b7-4bf7-b671-ac504747bc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112bb87f-41a8-46d0-a636-9018e799264f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b362645f-60fd-438c-b9f9-f2d1ff36257f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e30aba0-63ae-420c-be70-e80d7a05a0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17df46a4-108a-4f96-8e19-4ec6cbaa77ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49974011-89af-4693-9fdc-e4a9d0e96df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e3fa404-7da6-4745-85d9-cd640f84129c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62237162-a272-4f42-a28a-cf168b14a429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 284a6fac-61f0-4002-8cf4-5ac82191b3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6f0b41-bb81-4c59-894a-eed7fcd7fd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3681207-1789-4323-aa90-a4cb87738ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f48e697-794f-4e60-b65f-3d3ea8eb57d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01791ace-b9db-4891-9b6b-fd603136686a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9240f9a-2ea9-435a-8e05-1a0ccadf2b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a161ec5-59f8-4949-a636-ad2338f9a037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb536734-a2b4-4db4-ac83-174840170532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257f08ec-f642-4899-9580-726d4a854fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8b764e-f3df-4711-941e-f495d03d25a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d470576a-0991-4150-928f-b0a78158caba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884577c8-b407-4c08-836d-492201353c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456a5f4f-9236-48c7-a331-25ad1d2e873b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 620492b5-0658-4497-b2dc-8ca6179044d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c97451f-4b9b-491c-9858-d2e87d1eaacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3873e1e5-e4a3-49f7-9881-3a1c3f9ded74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8bb1866-8670-44e3-b429-75aaa4904bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d03a117-39c6-4f7e-9891-762d6ca5b2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee11ddde-addb-46e0-91b6-98501863e810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2548968d-2750-44e2-8781-6d2f52df0c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d29146e-0239-474a-88f3-2002dc817735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c6e4a36-1986-493e-827f-be5a6c4176aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d107b4-eed6-4071-a488-d9d548da668f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96006be-8649-4b40-a09a-4bfb8bf899d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe93d59-cd2f-46d7-a49c-d64dc89afda4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7992bcf7-e736-4e39-aab3-e1f04d0e2590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598cdc75-ebfe-48ca-b4c2-7944b4bbfb6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f607c16c-3daf-427a-9eda-1c2e5359a5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830dc6f4-8b0c-4b7a-9b4a-88322a9fb79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e84aeb7-aa0a-49de-bd5f-cc689f2e4d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c29a45dc-7e35-41e8-ad64-820c35c659b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3bdd31-aaa1-46da-a32f-adb0a3fadcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eaef383-ae9a-4afb-8696-0b578952ea5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e98cd47-4c12-4b29-91d8-20872f2a8651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afa4933-f3fa-4986-83b0-ed4051dd46c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d1262a-7681-456a-80f7-dc93e64410c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f46b74b-15fa-4385-baaa-10593e22a711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc40048a-6381-42a1-9d77-10c4e23de183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ac73fc-46cf-442b-922d-965db5d0057a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0f46eec-b786-4e9a-bb61-de7b7284cc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c4bd70c-8c98-4cf2-a01e-6258ef671c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfbba4c1-f2e7-49f0-a6d4-d35055a834ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33d7aab8-5556-418d-8f72-23b4617a5660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e313599c-1e57-4a5b-b558-b21faf49d364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c525ce45-a2ef-4acf-a0a3-94f909ad998e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 943d5e7a-70c8-48f4-ac48-b86b3106f392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d00f394-f59c-46d8-b4d9-efae50d89272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0432060-88b9-4c85-942f-8872006420a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57e9a79-ef97-430d-ac4c-d7462f5d44ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0230c76-c912-4586-892b-9c9923d7bc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2303d7b1-a3ef-4419-ae20-79b8f6270360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be8f5c8-1833-4e2f-9e75-e5ba31a2e0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1708c25c-d979-47a2-a173-6de4149532d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d38371-cabd-4e7a-af41-2663aca37929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc08c3ca-b8b6-4879-8e53-57b70b0b0950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c245d656-01a6-470a-b2e5-a83348f8bffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a90edb1-edcc-4ee1-86f4-968b155b30be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df4c17d-4d38-4fb5-b657-3719fe1bbacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a78eb81-ab27-4d13-9002-da169b6fb97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91485c51-3734-4a95-9d13-a69021957bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ff3c16-b3fa-4404-b122-a57e82c42740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c107e46a-84da-45bf-a570-b614497a3cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed185761-b8d0-4dc6-811e-5ac22faca182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a1d07f-3b44-41f7-8921-2aab2303b9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49199f6-7559-41b5-8e71-b78d560c6d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92b39be-7cfa-42f1-9718-aad742791a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eebfae17-cfb1-47c9-9e2f-ea48a861878e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e0048e-1f6c-4e15-b0f6-c888d848286f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc016f17-826e-4efe-aecb-1ec0262b1fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c60f58d-4dc3-4093-a2fd-aae099c0a08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fff5894-4630-4cca-a4d2-313e049c745b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3415fed-b6e5-4143-87bc-142bd5b06aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f83b93-330c-4750-a756-c3111f9c1dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b832368d-c0e6-4d4c-afb4-0b9d3b99b7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e4c4ad-22e0-422e-9162-681d113c69ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c00b0cf-5623-43b3-a377-56902e26546d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04786876-ac31-4907-bcc1-55e2f2f5855f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542ace8f-1e79-4ce2-b630-ad914f08f195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cf9915-8f8b-4cab-847e-3283d67de4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a9f9579-6ee3-44a3-aae8-f37f47d6d302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2885950b-de8e-4f51-ab88-3d1db733d7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23542bcd-4d55-4c49-bb1f-f4e8f2700823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbffd006-56a4-4568-9bdf-f7129b22dc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 557f75aa-922f-4c97-9f32-fd3c965a412c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466dd50a-8b0f-412a-8bbd-9107e4c4ddd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 535113ed-5548-4a0b-998c-eb056f677e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300f0143-42cc-4414-89ac-dceee75ffcc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2314d7c8-c281-4459-be17-834317843575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548bbcea-cc1b-439c-98f4-d9fb35e0d3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c342ca4-f2d3-48b3-9e21-9970c52eb1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b4eaef-5e0d-4c91-9074-1d558a5b4bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7953ea26-b284-482c-83d2-297d962903c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7628bf3f-bb41-490d-8fa6-2f8fcdc80ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8db48a0-e4a7-40e3-9b24-55408dbf84e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9629b5-99dc-44f9-a87c-89b234d33a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e022607-63d9-4c70-85fc-ab9758f98cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5c53b7-f219-4b54-88ea-e8128f41da39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 928c81c1-30bd-4ea8-a216-39b888d6a08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33f9d607-bb46-490c-b227-194ee2e70870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc81fed-02e8-4b12-98fb-035a36a67d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f41a56f-e313-49a8-97b7-77608857cc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317f6666-fc27-4a12-b5ab-afdcb619848d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfbbdb1c-232e-4b76-ad0a-5a3ac3d0e4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82feb60e-6a6e-45cd-ad54-22275decfd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905d2103-300c-4318-9be4-fd7dc87e9ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bf3ce9-a4de-4cca-979b-51d7b8e197fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de12c8b0-8df9-4f4d-a66f-ced368c21d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bc3701-18ff-47f2-acb7-23781703a317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3fd6348-a3bf-45b2-90d3-665eaf8e39ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470e86d6-8434-401b-880e-197b79909ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570bf56c-6253-4263-aa43-e5f7d4a9c7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56b984d1-c050-434b-9b7b-9484f9c41fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0edca2ea-e838-4fa2-b56d-c10811acfd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c3f8e9-c914-4b0d-8e4b-0d9b2eb14ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e0bc560-c060-4cc8-abb6-ef06725a5e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 722e3728-99a6-43e6-a9d2-d42b9e720ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9458341-2b02-4a1d-bd8d-376c21542a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f911647-8c31-4115-a94b-4fc5c3c4a89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d05889ac-3366-4efa-bef8-0daa19f1b57f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6f3699-5e3b-4dd9-9ec6-838f21d92872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f848b3-03bc-4efc-a65c-2c470dcb1b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89bb4fab-1bb9-4545-b129-2578ec93b62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e581a0b8-44ee-4214-b816-2bfb6728f28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b3c7a6-7a86-43f6-93ee-4fb1e1721410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea780635-e3e7-40d4-97ac-eb837bd66363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c336301c-26e8-4c2a-9acf-00515cc350e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786278f0-2f02-4f61-8193-dcff7752b9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7250aa3e-ff4a-433d-8eaa-a7652fbec9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6feba025-a7fc-42b7-a637-0fc51cd1c633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c91ec3d-3434-4386-8758-50f598752ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feefffff-6d44-4cea-91a6-820b9ebe41a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e23cdc3-c6b8-4b6c-80e3-09b3afb2a12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b50cc8-7aa8-4239-bcbc-62bc856ba556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ee077c-0fad-4e3d-b302-d34dadd70c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70528284-578a-493e-bd8a-b9452b0bcf43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a5731a-117e-47e8-81bd-cf827756b0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f79ee1-0ee6-4c20-af20-113fac24db9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0820df-4edd-497a-a13e-ae3dc7cfdf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a291957f-20dd-43cd-864b-ea88df0054a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 785f8e82-eaa6-4033-b1fa-c4fd1eeea0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1721343a-70a4-4963-acef-ca44b8fd310e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33206142-3766-4596-8ac5-38961858c3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7469a864-ba2f-4fbf-901e-a56f4ac4c625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c315749c-d68c-47a8-9ae5-c364a1606bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2e3925-3102-4896-be28-f845430c0f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b38bf3-603f-46b2-bc34-b260c0407d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ddbf905-4680-49de-a528-d20201aa82e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50c9b433-4202-4a35-880f-e628605fdf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2a9e51-1691-4a76-98f6-6651b95573ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa8ebc3-e9c1-493c-b616-6a8293fd289c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca49fb3a-70c2-4a1d-8296-35a551551cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5e20c96-2493-42b1-9e08-c91f874f1584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd3cc2d-7d6b-4a8b-986f-a3d94acb3e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 026e3868-1db7-4066-94b3-ea55b784a78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e73e210c-8791-4dee-b64d-95e89ca3695f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b07b0f-3213-431e-a0f3-4315126fd915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 729473c6-1796-4fdf-8f0d-40b76313725b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26af7ad-45ee-4ada-adae-bf3cc28a38f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf799435-e059-47e8-8cbe-ea3f1fa32f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee71ba1b-3657-45dd-8aaa-4f66cd3e6c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0311981c-1b64-4811-add6-98a59922c340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5247e90f-f70b-4046-9edf-50182a952cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64216488-db4a-4e90-8e01-eacc1fb6aa42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5cf784-1595-4093-aa60-277f0036152d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b39714-1f72-4e2d-a184-b9109ccb3129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d74980cf-4c8a-4682-b16f-6b62244a0efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4df40d-7f36-4a8c-af44-e85e14baf917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8394a385-5b52-48c7-bd77-0b5f446b9f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8171083e-86b3-48d2-bea8-63d7a4fc4bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe06cb0-646b-4eaa-aa8b-0d2f86b14a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 572d6320-5c95-4d05-9e54-d01de3cd0c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164c8fb4-afbb-4b88-b3aa-26e6cd06875d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2041319-7bdd-4d7e-a1d2-c9cf04fbd6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6502754c-5e5b-43fa-87a2-c6fafcf17795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b5770f-8742-407f-88e6-89f4abc65f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9242c691-7195-47da-8087-f23d9ef2f526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d22b0f1-8b32-40e8-97a7-d973e1ffd537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b833dc-1b2d-47d1-82d4-2807a4b360fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c84480-fde4-4bf2-9a67-719ed17b3baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582f5618-9159-4b57-adef-7c3b6bdcde89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9fe275-077b-46d4-9fba-eb56a9f7b84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e8b88d-63f7-4715-b749-f7eed6f4c043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a86ebf-2a40-489d-ac9f-b33d747b99bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbabfaea-4453-4077-a9a1-8e5c6d10d754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b01dd1-8a28-4a23-9d70-883c3e7a6578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d8d627-f585-41b2-8bbe-f5df4e782677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ac53f1-c1e3-4756-8964-183904717386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 333258fc-7fd9-40a6-b911-6b721b831601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1459aecd-0e5e-4f12-a0e2-f86e34f072f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c9558fe-a3f8-47d9-92c0-304cb5ab5d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e8f44f9-843e-41c2-854c-98a534ea7873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f4c19b-691f-4a92-a99e-3a5d8292719d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba4ac935-a163-481e-b872-17d276b35862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63669444-81ed-4c1f-b96f-325dc40103b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d5f525-fb71-4022-bec0-717b2c50db9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ca5f2b7-7c29-4c8c-acd6-41cd74d28bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efcc2d1-dfa6-4c14-bea5-173efaf66c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5128da3-28a1-489e-b689-6f1037806209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6715681c-5b4a-4772-b17e-fa6fd9bbe64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6684a99-f85b-462b-8fdc-93aa26b4521e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c469389-e6f5-4e73-be70-1a520264c922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e778834b-afb8-4014-96d1-6cb2972f1d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda29766-8f76-4430-85af-9a29a859679a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d3b78d-41b5-43f5-8235-1b1089b2a771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b3f73c-f693-4b5a-9246-3f2ed9fbc5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6beac0c-09d7-4420-9a2a-fbed79254319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b5ce75-e2fd-47fe-9e98-9041ae7ed1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d93568a-d44a-42ee-885a-b18268c2697b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24caef6-456d-4324-87f6-d5ce221632fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eb6a17b-f8c5-45b9-bee8-216488b9b216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d87c8b0-aec5-4155-bfcd-81f6860a2c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e990c13-ee02-4e81-aed4-6b4ff4fe012e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 225dc65a-1317-4561-97f6-87b93c3528ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5caa9d-fad2-4ea4-8a33-8716ebe47ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b355a371-8b9b-47d7-ad98-a495a120f81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c455fe-192a-4d73-b891-31ba336035e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5fbe2c5-f577-46b7-9030-4b1221b9d165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c6d6af-8267-40f7-824e-5d28556e9a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5674f41-5b08-4068-bc0a-1ab019ccf1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5d1ca07-a638-4923-97ec-e11282d88f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eece81b-cc44-4eff-8a46-afe1140bb178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f8e7ed-f791-4348-89ac-fcdb0bb2bbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74f6cada-37c4-4b86-9ab2-64fc7e91c702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37391581-933f-42ae-8af4-9dcfcd79e01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f580be4-6683-499a-8a0f-3afd8a3ae1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dabd7305-8918-4229-831e-9192eb2540dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84983fbc-386e-409b-af9f-456b96218b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d5d713-b1e7-4666-a099-ea453311a045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed8a798-4cf1-4190-88a3-ffeb0b829de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c08194c-2144-48f5-9f1e-54476d39d547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ec1cd8-6641-484a-b705-202cadf8657b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 258cb0ff-da0b-406d-b205-5a43415cdaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a1895a-10e9-4f4d-abb2-eae0a752d3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 260a45e7-03c8-4b9e-9e62-56c0e2e81409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0fe0914-c1e0-4874-a942-168ec2a94371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b121e1b-1f70-4a24-918c-17a5979741a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 776d195b-31d0-4a64-bb16-11f5badd18df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc19b90-f213-4f40-afe7-61eb91569398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301cb1fb-badb-454e-a29a-31096f3fd56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 710ce95c-58d5-4f61-977a-562513951ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a3b1e5-147f-4251-beca-b815d0fb5c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409b8f51-4c13-4230-87e9-600c460479b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60ada73-8677-43b1-acf1-3dc979422f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa882e00-60d6-41dd-bb7c-3895ff597bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4221ac88-b4be-4157-92fe-afbe9b0924ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37c9afb-9e6b-45f9-b663-53a8b8f44b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10e31e8-30cf-4395-8631-72ce55816d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9539f60-64de-445e-8820-918e5e9add7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2648b4e4-0682-430f-b448-4d8ab1654b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628f1e5e-a800-4521-8db9-f2c5d2c36861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddafe7e4-9add-47d1-8da8-9c94debb58cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cde258d-9fcd-4af6-9b0a-691057f058c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58eb5914-5fa4-42fa-971e-3710b4e5c0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6730f284-ebe0-4ccc-9c0a-b15b3051311b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3beb0008-a153-4c77-a458-7e13507d54f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f17954-e94f-4ee0-8832-ef44c962d01b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2608348d-0c30-4db1-8115-510c025654cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e67842cd-bcd1-4afb-9039-274dc511956e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6b116d-6bf2-44b2-8dfe-26db2e8999a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5741419-1a97-44d9-a358-54c0b86bffc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3a14a7-7699-4487-91d9-10937e3041aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d12dacb-0b88-48a2-973f-5cd7fa473cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e4ca74-93cd-45d7-82b5-e753d2e7c328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d3c2d3-19af-49ea-8d0a-939553567911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6145ff7e-9ca1-4627-8397-36a162dfb04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95188b53-6e01-4c7a-a8f0-2a4f90f1d260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e1c327-efcc-48bc-9a4a-3d312c266da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3bcd44b-efeb-4a25-8d75-d3f61f6aa95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75471870-fd33-41ce-b916-f6c2423d4043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e95225dc-5904-411c-bac5-e198f9fceaac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b6fe70-4d72-488f-b2ec-2025667e6be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00c3813-7b4e-472d-bce5-b9b6109f4e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b123955-4fa1-432e-9311-de775c5b5269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af15400a-96d5-45fa-8e03-d40d4d76bc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b72ffef-22ea-441d-8da8-83965ad9697f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13c2749-648c-48e2-a3f5-44fa9341ae80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bee84c8-cfdc-45f4-a6f3-18124ade017d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4ec926-8b55-4abf-a236-560ce35431f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e6d616-3456-4fa0-a0b9-3a8f7aaf6f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b19bf5-4a09-463b-8888-9fa9e194afb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ee0a0a-3bb7-41e2-943f-53ac4a234ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1480c348-1131-4c04-86bc-57c5630f0492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782a9759-52bd-4a55-89b4-343439b8c267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ba7755-711e-4d47-974f-f9ceb114437c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79c7332-39ae-4baf-a131-3d93534c6040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afebb7c5-3067-4814-8a82-6fe3e47f314b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b32d0f5-7a17-4af1-a68b-db3d6f8f0c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e3c80c-da7a-42cf-bc1b-cd68c70189b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eedbfb43-2702-408b-9a93-8e18c17b6ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e619b6e-3744-4aca-8b88-e0712a2a8f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389fd039-d1e6-42f0-9532-0041533c8ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197b7e8d-79d1-41de-92ee-ae3e7979e37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8696f491-d40e-4a39-8f20-08f9bde2894e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432ce37d-7833-4cd2-bb6b-63689dba3b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67591028-02d6-4a56-8d72-bda1498699b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ff2775-65e5-4a56-91e7-9de249dd4d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4871323f-6112-473b-b96e-5441eafb9467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27231d2d-29f0-4ba8-a956-6e11d8f0b4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ced9d5-2094-42a2-92a8-94a7f50d623a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176bb25b-4a28-4ebc-a544-1d330f7859c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad02ccf-10d2-49ef-8b43-6d94f90784ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0adc42c4-e17c-4be1-b3a6-3344dd22af05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e1ab772-09b0-4e7b-b684-6a90ca7b2db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f05b1dd-5aa8-461c-809e-f9856ad51de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d46c5aab-15b2-4fbf-81d6-93c89b96bd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93cb22f-13ea-4de5-9c76-e0a1cc7c07e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e24524c-f6ec-40f1-a3fd-eb44776d1e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8763cd07-3530-4e18-9026-9f286ba5edd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0204c065-aded-47a4-aeb3-a005c90647b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8bedd3-b3aa-4211-9e6f-723ab5960f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61ebff1-1316-4080-901f-99c3fa004209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbebfbb2-9135-4937-9b7d-65813ecd76e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d47703-23c7-4d4c-8429-591d7f5e139f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df93795a-2f05-4763-a9a5-4f5905e0cc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94073b0-3d95-47ca-9808-1503bde67222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a442687b-8b05-4ac0-b6b1-2111409881fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5074c5-d9fb-48f8-8896-222989a71818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86696448-1674-4c73-9335-dee50c3266a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae31640b-ec42-4a04-ad94-a303463a3db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb85610e-1c75-436c-939d-2b11da26e3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda08ec7-441f-454b-bb3e-6a5d29515b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a044b4e0-e728-42bb-be86-d354d3431203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed63a3e-3981-4464-90a2-9e9c955fd969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf62902-f487-4bb3-8c1e-699b4df14026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc593df0-e530-4319-9d71-bfef0a238923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c75d731-a066-4b36-a50d-d6277a7549be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3dedac-ff9c-4462-8a47-26603d203a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba915a0-0944-48cc-acdc-5918d3211141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3fdc89-8068-4226-b9c1-8367c87544a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c568ba63-148b-495f-9547-1f90d20f5ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b01c3d3-93f6-4a09-8592-bbce02f36d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb3aaa1-3863-4361-8736-59053ebf3770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddcbf863-26a0-4352-ac49-acfcb429bcc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056985ab-53f3-44ef-93c5-54025e577b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c728fcd-d61b-4c15-8c8f-a10556182c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b499a40-b41a-4d3a-94fd-0e78b10b8a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbfb9080-565b-43a4-ace4-f783a28434c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e2580ee-3d38-4c0b-b07a-2d3819098aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93eebf6b-25eb-42f4-80ff-374a9a8a250b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd051bfc-c662-4ccb-b797-407ea8bdeca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62169da3-4367-4f96-8ef8-38d5ad95453c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327ae2a4-b960-4c7f-9b23-c75e50f59952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dddf2dd9-d120-4ae3-a324-2cb149d32d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d55519-c422-4134-8312-18dcdc9971b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2faa60e-22b7-4110-95cb-556b7d117b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c5b5ee-65ca-4acf-9da2-5ca44d3853a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faefa74b-52a7-45c8-8574-730c9d465a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58407246-729e-4205-8ff2-4ade0a6ef73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d3c784-121c-4b4f-bb00-5ad23ba74370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95439d6-f7d4-44c8-8356-92fd7c611cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f27b63-e37b-4130-84f5-020fb5a2dca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33fada2-c8db-4eff-b79e-c55bfb3b1ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6a80e03-677f-452a-912f-c7d9f63a1c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96d90ee-1f93-4d83-914d-f35ddda69f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7df41e-a475-46ca-9e9a-e078500d3db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9bb6d1-9e69-433b-874d-ce010bccff39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 888775f1-ffdc-49a6-97e0-04a0b339375c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8206d7-66de-44e5-b53d-c14bb50fb91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a783c0a4-a25e-4362-afec-2a0785898369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1649f7-8f29-4ea7-85fa-b4b553d1a3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2933c3b9-aeca-4917-85ba-4ff5e1d0cafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47eb6721-a125-4f1f-a520-5dbc1c9c25c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ab8f50-6f0d-4587-82bc-a716cc5adb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46a6bf10-e179-43e7-8673-596e2448cdc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6549df24-2cf6-43aa-93e1-49695e8f04a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392f2dd2-0303-456a-a7e1-1f56e3e2655f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb732793-e66d-46db-83ca-3d26a6f5fea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb60e16-59f6-4882-a19c-c0dc12c8cb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9e5c4f-efb1-4a7c-bae1-8036e798aaa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba56d4fc-f22d-4e11-bffa-47f05f41892f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e397dc9-1067-410a-aaba-73439ae3ced7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97bf04bc-9a44-45d5-91e2-3748ff49dc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f81bc7f-b13e-48b0-9dbd-96c868908970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7abf9a-aad8-431d-8933-b761383158d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c6f935-68b0-4651-93ef-27db52d5db13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c356ce8-23b9-4f4d-b2c1-7cf5f5b781b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 552af346-77d0-4a27-ba17-47a9c49460f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b1226f9-c442-43a0-8fa9-d69ded5f5519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ceceb9-44e1-4ec0-8169-f924c4da1cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed78e19-88ed-4026-8a4a-5cb2e325a251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 662b70c7-7f0f-4e48-9a60-0612d081819a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f217076-16e9-4d82-bc6f-74547d9c4a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25646783-5a3b-438a-a30a-105d4c142493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23f8bc0-72c9-428e-9ad9-e9f2f7d519b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc5ff70-84d1-4c69-ab25-d9ba314b6d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef39ab1-a86b-47d7-9791-b60b2acc6b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce538363-b72b-45f6-a87a-0a285788634c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4800b42-088c-43a6-9d4f-810b21218954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea30068e-c779-440f-9514-9086d9fc33b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e4e677d-8c26-4b35-bf54-7ae378cfb46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c0a1402-b040-4afd-9dbc-26a2f2af3407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03cec571-caa8-45a7-9b0e-1384df32c559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350958c9-2b46-45ad-8335-8d4e8c50c584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d48161b-5604-4b3d-9011-277292496c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acbb4765-2a3e-49f1-8623-2323404893b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5377c67f-8b69-47ab-998f-95b3d2e9b816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad81b9b-5eea-4845-826d-dfba699ccfff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0cb137-dfe8-4e6a-b4de-eb21058e2f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89075964-9459-4c15-a656-9c06bc80a415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937702a5-82e5-4ea3-8b17-51fb3b44f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7244d97-1622-45d3-a5fc-c03a3635f9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3184a06e-c6ed-4efc-9017-b741d3d4b527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f539ec8-8ae5-452c-a9e5-1a68f95e540f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59393419-fd6e-45d6-94bf-e7879454429d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343fe1ac-8ddf-4073-8f8a-d7e2fc5081c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f2036a-179e-4454-b38e-481bd306eabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a5b37f-bd7d-421f-bd77-be1b78f22b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5147479a-79dc-4bcb-a8bb-12e11b77d1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83542575-4871-479f-9f62-b8ef885404cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936bdbc6-7388-4e97-8ae5-01f6928eb8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50561239-f981-4baa-914d-054fa37945c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6303c9e6-37bf-430d-bd55-66887b82a642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f690d64c-0b25-4a71-902b-5a096bf3aaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f911f95-a1c5-455e-9563-3890349f5755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c2207e-f1c3-471d-bbf5-a14b00468ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd3ac5c-88e8-4e8f-a53a-88f88e496002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e58015-6a2c-4605-a67d-6f16c84e1c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b48d8f2-1cb8-4729-9c54-b66a473e32e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd24c285-ced9-484a-afba-c6a39ed6f88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c385e83-a501-401d-a756-18bc619cbd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4887b42-dbb2-492e-8199-837a4527e64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2cbb19b-278a-4e28-b753-f5125e444021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adacdd88-91a1-4db6-955d-404c7b4a16af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01543a69-ca6d-4145-a911-d6710916daa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a198ed-1ca9-40f6-93c7-961101c6f915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7693218d-ab90-4a7f-9fe1-80328e435cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea56a29-3380-447f-aae0-c6f80ee6f4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce15a1f7-a0f1-4a59-8714-faa3a4d062ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbdb8775-b7b2-4ee5-bfaa-393ce435a70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d016ae9-ce1b-42c9-85c7-0abc37112bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7911788-e0f2-4402-9886-73608e96e7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a953c40e-757b-4d86-9c34-a84823cf9ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf31f739-d95d-4271-a95d-f996112dc3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a998dc-ff9f-420d-82fd-4f0a07f51da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f8cbeb-5a90-4e62-970d-8e280e103612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e70b57d-1148-4854-b1c4-f006ef3dae3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63de5105-6f9f-44cb-86b1-3a15014909c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 220bdf8f-dba6-44ea-bffe-bd8b262458ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a5b6b1-6c39-424a-bc79-d4483f723fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3458de50-349e-4630-a66a-564c3690a1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5818f6-7dc8-4515-9d4b-5943d9d1c353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f59694-1f9a-46f9-b36d-316f1eba579b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426a347e-aa15-4db1-ade1-604ddeb84790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e13741-50fb-4a78-b9f4-19cdf8ff5af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f74869-d363-4021-ae7c-a62447580bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52402744-f9d8-467b-a10e-69f7ab39e3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9516b537-4612-48a9-a59d-9ee9d5dd2ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5774c288-5e50-4106-b804-51f214a3abb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb154da-f745-4866-977f-22b1670cff75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8588f8b-0b72-4a06-8e6f-087a261bd178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93da6960-88e1-4056-93e2-1e9542e344ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1581a5-0d28-471f-b32d-09dd025f87ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cbd51dc-0691-4428-a981-08fb2e82c979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c390de8-e20e-4cc6-a07a-7d36a87979af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c63bb1d-2177-46af-9ef2-514b71a0dde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec149b4-f724-490d-99f3-9adc8b621222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c525d57-bdee-440d-82fc-06524b11c121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20c1b516-20ea-4437-b090-2b9e656c10a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9043f36-fc06-4c72-a6bc-21f698699544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd1fb7b-6cfa-4e48-a13b-2d537d49cec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b358723a-acf9-4b3a-a41d-83c667f0cffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ad18609-a02e-4ca4-85d4-d4258e3b774a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba5dbcc-d5fb-4826-82d2-24748bd9b8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a93c4b-86ca-44c1-b4e6-d984861ead9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1afd4af-6cb7-45dd-9ce3-40a6d7dba12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da08c32-bb4b-47c6-a549-31a9a8803473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 687f7fad-3ad0-458d-a64a-946bc3dcd4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afc387d2-4fd4-4c9d-9508-33cb09cb526c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7eea32-4162-449b-a1c0-84af7652d902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0075f20-9f84-42e9-9c7c-d431b27aab20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10f97b4-b634-4e1d-ba8d-aa7e35b62d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7adce98-5420-460e-9de4-dff8c9b37e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e959b4-b582-4857-8339-8ecb02aa071f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34a8a08-5a26-4cae-8a8b-1b759e03c1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25d551c-1a3c-4e02-877f-8694530ede8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d088aa-690f-4cfd-8965-fbef70d12727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e68344-4233-4884-9e59-c78b8d065c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2002a745-f9ec-49f4-8c6f-d61a10ee0893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0154c8-28b0-4a9e-bbeb-c6d43a7f3f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf366fd4-96bc-4857-86c3-dd266b5d25c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6afe75f-fa93-4d6d-aa82-ac2e8b4f1059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7b7d73-3cb1-45b0-8efd-cdf5a6c82827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc88c0c-95ea-4860-ab22-10a73d312686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841adfbc-1ede-4b29-8d7e-aac7841660ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119a2e71-1c8c-444c-94b2-1350bb18beac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebcd540b-edfc-48a3-8561-707436c71326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4966be94-ac7e-4717-bc86-488d91807f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8afdec8-14ec-49bd-9bbf-3b626be958be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33264842-9433-40d7-8fe5-7f5c1023f0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f36a04-5ef0-4412-992f-31ee38af4eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee767d8-9afc-42c2-b53b-1f722b7779da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be36a048-8913-4067-833c-4e8758535dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b730b02-8a06-4430-90ac-2321bdc18bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5093de7-5e78-48d0-9381-05e46364dbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b03e94b-8c77-4e56-808a-2fad057cb067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebb0973-20a2-4500-8e7e-3987d466dd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f4c744-b01e-46df-a708-bb6d6e9e8494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e4ed09-efcb-4355-804c-db97a6c4c485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0908e6-85d2-486b-960f-bd1508aaa958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb170fe-e4f7-4d4c-9248-2cfaaedf5068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c73c33-b15c-490a-8884-b67e7f9c698c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fedc375-f230-4d65-b41c-1daf04ea34ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc2850a-06ee-4a85-973f-a2d8f908144d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 401cd0d2-512e-4248-a5b9-c4915d64b34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9184089e-09a6-485e-8b4a-151e54847f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 670cb2bc-3a94-4a69-a798-79cd913b7d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fee9d40-4b07-4cfa-bffc-7e01ca6cc6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f07c47-d036-4b2f-8aa3-ba942b1c6fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03575cc-1304-4169-8179-aa30fe06f339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0483244c-cc1b-4093-90b7-705079b65961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e803651-b185-4b52-be50-223ac59f4d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da8b33f8-8374-4243-8671-d5452cb71ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f7216b8-877e-4451-84b0-b33e589bb7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e459302c-6da8-4de0-af89-a9a6f4e1b548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4f7ad5-9458-44cd-9299-31dda19e6dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 250abeb2-91a8-4e22-b059-f90899de00d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 993701dd-d442-4479-a635-9b6e0a4bf77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25122f09-7a50-44bd-a6e3-2117d914c145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a1bb666-9a8b-4621-82be-f16b6a6fec26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74f504d-4570-4648-9e5a-1cb78ab9d51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ba6903-7051-4cc4-88ba-80658d98ac99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2194e4-56a9-4faf-b65b-32a13153e421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f2401c-4e83-44af-b8a1-4b3eb04c4377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de3b73e-0d5b-438a-bbc5-0bab029972b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2ddbb9-432c-42ce-9578-aa649ee28d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7ce358-50a6-46ad-b5aa-b01815382a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb046e3-9e49-44b3-a226-0e9fe8cdba89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5aea54-dfba-454f-ad4a-368654852b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6335084-d0b8-48f2-8e07-40de55c6158e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f53a79-41ce-4abd-98c6-5066258ef0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edfe3a01-4e43-4789-8fd5-83c931c711f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee152db-a1a7-4bb1-abc6-696eaed93657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4cce9d0-42c2-4700-a10b-9d63877e5c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615ca6a1-4ad5-4f5b-96ca-01662a77add7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab4b1dd-9afe-47a4-8604-69641ff7d740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b4ff93-2777-4748-b322-b854d1a03c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0278b3ff-3c1c-42a4-a29c-5c02e894ce47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 160ab353-5cfc-4845-a125-656b49aa579f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6e2ed8-227f-4b07-94c6-e341a3971a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f399dfb9-516b-4d61-a7a0-717a16cb6b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c2b61d-199e-4748-be86-6b96430e50f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71675269-6879-48d1-952a-d3dfb0317765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2b5baf-5fb8-43d7-b7c4-627c7e9403a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4445d0-6e15-4f84-b17f-5db528e60400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274f03e7-6ecd-402f-8c12-73212f03892a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49229972-594d-44b3-b22f-dd34753db5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a68cb2-dc92-42d7-8ac5-51e3886e8040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d7590e-1451-4aac-bb2b-2d3848df31c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf147a2-b68a-4f15-87b2-da1b4a4da981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29665a87-ebe2-4688-9748-577f8bcf95ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81bfac9a-7efc-4407-ae8a-59ffb0aa9eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b4bd41-d3b8-4852-b11d-23653b1f0352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efe0fb2-8c8b-473b-b157-cf610604a5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e726be-b53e-4c7b-b98d-3acad4949cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695507d7-742c-47bc-ada7-9e3bd6bffb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1d0fbf-003e-40bb-9d3e-cb5e45f39b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a633aae-11a3-4b4e-abe4-96cdf51411b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f10431-11de-489c-8dd2-1418fef5c15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5278a769-04cd-47d7-9f09-88ebff9a359d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42a9a711-e45a-488a-8032-abc95ab9a2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd8a6b6-7d71-4a19-a588-0060d0cb1958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0eff658-e304-4dbf-acac-bcf610213dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695f5fd7-37c1-4831-8ff6-df8208bf971f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91534348-8ac4-4970-af14-b844d40460be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77227146-4c08-4915-8a18-3c94692e77c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa6c2a5-36c0-4a31-8863-3d85add4bafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cddca2ec-34d7-41dd-9077-234fca28df60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ab77a9-ba3f-48f9-947a-a24dff8d6477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d2a2718-41f9-40ad-8c11-b7071b84d7fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d629516f-45ef-49e6-aaef-aa814a1cafef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354bdf41-85c0-4af9-a197-a9da7f1b3829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b65aef8-818f-49a1-9c93-6f445b35d346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a97ee0-6347-44e3-a991-2d6512e8d01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510bf462-61f5-470f-bcb5-6006e3271718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a58506-0774-4a2f-b1c5-7f89709ab3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 385e425c-dfb0-4704-8c65-baf8e0b05526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227dd731-a8ef-43eb-86b6-06831c487303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e72ef52-bfd7-44a1-9fed-2f3b994bdd78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695f4f65-3e55-4ae1-9235-1eb4679eb9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda843ec-f1b0-4a84-b58c-753c42785019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ec4e7c-c53f-4209-a31b-a6d0650f9fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ee3072-2b46-438b-ba94-a7660709ca3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0746ec6-0eff-46ff-bbe6-22e42b3bef75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e35e46-9c65-4a67-86f5-bb89d8572052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94063575-cc90-4c3e-a936-c2ab69e8c3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0a449ca-d4ad-4c45-92c7-48abce49ac8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655939d7-15be-4c0d-8c3d-bf4cc6af8c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8db8ede-11cf-4cfb-ba8b-2a406cb14e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2fec22-bcaf-4c17-8b5b-96fe3d6248e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c39155a-0001-44f5-b126-672dd058c78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14dd647a-abb9-45ee-863b-6e70cb106ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc660315-a45d-4f1e-ab76-07db3e4988ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bd75a9-4abe-4c67-b847-d651b562c7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f95992-4089-4f81-ac19-4e79453df5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1ca7930-5cd4-4072-be7e-8c24047cafc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84dd0056-d1e1-48f8-aa79-1f5433107243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0761241c-48f4-4040-a8c9-625302ed823c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92e3e43-7508-4b22-8a1a-30ec0bb4788a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1d6ded-5e99-4cb9-bbde-b18867415b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0f4c37-c12b-4573-96a6-1f3bc80fcbae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1b08db-a121-4186-86ff-33a8a92b6f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 771c1632-8eab-44d4-b6a6-54b50a18fc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c96aed-fbd1-4c76-9a35-63e5d8affce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040b9865-d0c4-41a3-88f1-e2fd2dae253d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e557b2-9c87-4cb9-a5f9-85c2daaaa0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf7df35-ff6e-4fe8-bacf-04738cf01a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d6165c-6552-4f43-b760-ed2c6288225b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef17f4a7-9f0e-43a6-91d5-507c02fffada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3640f677-1518-4be2-a64d-fa8455220ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a87080-ea4c-48aa-aafa-b87f45b675b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebbd4dd-5edf-4465-871f-49eaa42c167d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4498512b-8079-4c73-9c48-61027aaac3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a79f75f-9e00-47d7-b52f-46e509233b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb8bf423-e290-442c-984e-5f3381b1086e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(7224, 24), y=(7224,)
   Test:  X=(1806, 24), y=(1806,)

⚠️  Limiting training data: 7224 → 800 samples
⚠️  Limiting test data: 1806 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2430, R²: -0.0022

============================================================
🔄 Round 2 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0893 (↓), lr=0.001000
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0893, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0892, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0828, val=0.0891, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0824, val=0.0887, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0808, val=0.0882, patience=3/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0761, val=0.0910, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 2 Summary - Client client_23
   Epochs: 33/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0195
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0098
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2443, R²: 0.0010

📊 Round 2 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2432, R²: 0.0014

============================================================
🔄 Round 5 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0820, val=0.0927 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0814, val=0.0919 (↓), lr=0.000250
   • Epoch   3/100: train=0.0814, val=0.0920, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0813, val=0.0920, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0812, val=0.0920, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0809, val=0.0918, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 5 Summary - Client client_23
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0039
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0100
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0047

📊 Round 5 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2432, R²: 0.0048

📊 Round 5 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2432, R²: 0.0048

============================================================
🔄 Round 9 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000063
   • Epoch   2/100: train=0.0850, val=0.0786, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0849, val=0.0786, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0849, val=0.0786, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0848, val=0.0787, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0847, val=0.0788, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 9 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0006
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0055
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2431, R²: 0.0054

============================================================
🔄 Round 11 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000016
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 11 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0027
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0022
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 11 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 16 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000004
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0845, val=0.0799, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0844, val=0.0799, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 16 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0024
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0003
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2428, R²: 0.0057

============================================================
🔄 Round 20 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 20 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0014
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0087
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2428, R²: 0.0057

============================================================
🔄 Round 21 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 21 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0029
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0119
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

📊 Round 21 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 27 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 27 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0051
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0300
============================================================


============================================================
🔄 Round 28 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 28 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0021
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0078
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 29 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 29 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0003
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0079
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 32 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 32 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0043
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0253
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

📊 Round 32 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 35 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 35 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0021
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0015
============================================================


============================================================
🔄 Round 37 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 37 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0025
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0202
============================================================


============================================================
🔄 Round 38 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 38 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0019
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0038
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 39 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 39 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0044
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0102
============================================================


============================================================
🔄 Round 40 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 40 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0011
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0205
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 41 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 41 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0028
   Val:   Loss=0.0693, RMSE=0.2633, R²=-0.0016
============================================================


============================================================
🔄 Round 42 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 42 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0005
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0044
============================================================


============================================================
🔄 Round 43 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 43 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0002
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0061
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 47 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 47 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0091
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 49 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 49 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0035
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0223
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 57 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 57 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0011
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0020
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 62 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 62 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0010
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0023
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 65 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 65 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0016
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0007
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 67 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 67 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0027
============================================================


============================================================
🔄 Round 68 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 68 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0022
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0240
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

📊 Round 68 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 70 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 70 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0003
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0157
============================================================


============================================================
🔄 Round 72 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 72 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0018
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0035
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 76 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 76 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0015
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0107
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 76 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 79 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 79 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0003
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0057
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 83 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 83 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0013
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 83 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 86 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 86 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0011
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0013
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 93 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 93 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0031
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0012
============================================================


============================================================
🔄 Round 96 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 96 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0042
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0012
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 96 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 96 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 103 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 103 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0003
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0073
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 104 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 104 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0025
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0145
============================================================


============================================================
🔄 Round 105 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 105 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0005
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0141
============================================================


============================================================
🔄 Round 107 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 107 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0034
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0082
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 107 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 107 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 110 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 110 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0021
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0043
============================================================


============================================================
🔄 Round 111 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 111 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0029
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0050
============================================================


============================================================
🔄 Round 112 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 112 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0017
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0013
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 112 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 116 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 116 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=-0.0023
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0001
============================================================


============================================================
🔄 Round 118 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 118 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0004
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0303
============================================================


============================================================
🔄 Round 120 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 120 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0030
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0010
============================================================


============================================================
🔄 Round 121 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 121 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0008
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0033
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 122 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 122 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0004
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0036
============================================================


============================================================
🔄 Round 124 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 124 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0006
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0119
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 125 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 125 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0010
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0013
============================================================


============================================================
🔄 Round 126 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 126 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0004
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0071
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 127 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 127 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0024
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0015
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 127 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 130 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 130 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0014
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0045
============================================================


============================================================
🔄 Round 131 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 131 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0003
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0054
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 132 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 132 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0001
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0051
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 139 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 139 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0014
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0062
============================================================


============================================================
🔄 Round 143 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 143 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0067
============================================================


============================================================
🔄 Round 144 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 144 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0039
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0001
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 145 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 145 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0025
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0043
============================================================


============================================================
🔄 Round 147 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 147 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0005
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0043
============================================================


============================================================
🔄 Round 148 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 148 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0009
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0139
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 148 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 150 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 150 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0287
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 150 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 150 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 150 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 157 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 157 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0005
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0141
============================================================


============================================================
🔄 Round 158 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 158 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0036
============================================================


============================================================
🔄 Round 161 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 161 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0011
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0112
============================================================


============================================================
🔄 Round 162 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 162 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0021
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0037
============================================================


============================================================
🔄 Round 164 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 164 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0289
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

📊 Round 164 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 164 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 168 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 168 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0007
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0077
============================================================


============================================================
🔄 Round 169 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 169 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0006
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0026
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0057

============================================================
🔄 Round 170 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 170 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0003
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0085
============================================================


============================================================
🔄 Round 171 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 171 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0010
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0120
============================================================


============================================================
🔄 Round 173 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 173 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0034
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0082
============================================================


============================================================
🔄 Round 174 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 174 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0024
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0152
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 177 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 177 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0041
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0092
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 181 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 181 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0017
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0007
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 187 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 187 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0017
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0122
============================================================


============================================================
🔄 Round 189 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 189 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0019
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0293
============================================================


============================================================
🔄 Round 191 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 191 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0008
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0198
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 196 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 196 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0007
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0101
============================================================


============================================================
🔄 Round 197 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 197 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0074
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 197 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 197 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 201 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 201 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0036
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0016
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 203 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 203 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0029
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0047
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 203 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 206 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 206 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0010
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0158
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 208 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 208 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0009
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.0144
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 208 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 218 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 218 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0014
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0212
============================================================


============================================================
🔄 Round 219 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 219 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0020
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0047
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 220 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 220 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0037
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0025
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 220 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 222 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 222 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0015
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 222 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 230 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 230 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0015
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0061
============================================================


============================================================
🔄 Round 234 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 234 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0007
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0115
============================================================


============================================================
🔄 Round 235 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 235 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0012
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0081
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 237 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 237 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0007
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0068
============================================================


============================================================
🔄 Round 238 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 238 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0049
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0163
============================================================


============================================================
🔄 Round 239 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 239 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0006
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0014
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 241 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 241 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0000
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0065
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 243 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 243 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0012
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0083
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 244 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 244 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0013
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0117
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 244 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 244 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 247 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 247 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0077
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 248 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 248 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0030
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.0083
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 248 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 248 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 248 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 255 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 255 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0014
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0016
============================================================


============================================================
🔄 Round 257 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 257 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0035
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0353
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 260 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 260 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0001
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0032
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 260 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 263 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 263 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0021
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0018
============================================================


============================================================
🔄 Round 265 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 265 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0033
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0021
============================================================


============================================================
🔄 Round 266 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 266 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0011
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0001
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 266 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 270 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 270 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0009
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0029
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 271 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 271 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0009
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 272 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 272 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0020
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0130
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 273 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 273 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0025
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0117
============================================================


============================================================
🔄 Round 276 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 276 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0019
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0115
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 277 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 277 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0036
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0105
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 277 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 282 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 282 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0099
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 286 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 286 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0030
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0083
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 286 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 286 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 292 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 292 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0029
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 294 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 294 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0003
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0041
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 294 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 297 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 297 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0021
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0019
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 298 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 298 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0012
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0086
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 298 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 303 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 303 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0021
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0016
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 306 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 306 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0024
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0170
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 306 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 306 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 312 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 312 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0035
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0287
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 313 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 313 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0003
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 315 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 315 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0029
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0063
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 316 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 316 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0016
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0008
============================================================


============================================================
🔄 Round 318 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 318 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0019
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0112
============================================================


============================================================
🔄 Round 319 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 319 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0252
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 319 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 319 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 325 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 325 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0004
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0064
============================================================


============================================================
🔄 Round 326 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 326 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0002
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 327 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 327 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0038
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0142
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 327 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 331 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 331 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0000
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0044
============================================================


============================================================
🔄 Round 337 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 337 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0012
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0183
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 340 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 340 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0006
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0083
============================================================


============================================================
🔄 Round 341 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 341 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0024
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0038
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 341 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 343 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 343 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0029
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0098
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 345 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 345 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0028
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0058
============================================================


============================================================
🔄 Round 347 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 347 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0010
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0012
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 347 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 349 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 349 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0073
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 351 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 351 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0006
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0092
============================================================


============================================================
🔄 Round 354 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 354 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0068
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0081
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 359 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 359 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0031
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0033
============================================================


============================================================
🔄 Round 363 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 363 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0011
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0142
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 363 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 366 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 366 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0011
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0131
============================================================


============================================================
🔄 Round 368 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 368 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0007
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0119
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 369 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 369 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0015
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0060
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 371 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 371 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0004
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0038
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 373 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 373 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0005
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0054
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 375 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 375 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0027
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0026
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 376 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 376 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0000
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0039
============================================================


============================================================
🔄 Round 378 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 378 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0006
   Val:   Loss=0.0757, RMSE=0.2750, R²=-0.0030
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 382 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 382 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0009
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0010
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 384 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 384 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0000
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0037
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 385 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 385 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0001
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0156
============================================================


============================================================
🔄 Round 386 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 386 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0009
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0113
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 390 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 390 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0002
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0046
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 391 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 391 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0003
============================================================


============================================================
🔄 Round 393 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 393 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0005
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0294
============================================================


============================================================
🔄 Round 394 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 394 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0001
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0033
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 395 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 395 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0023
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0074
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 399 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 399 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0002
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0051
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 400 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 400 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0007
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0065
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 400 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 406 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 406 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0021
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0007
============================================================


============================================================
🔄 Round 407 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 407 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0015
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0170
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 407 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 407 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 411 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 411 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0040
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0133
============================================================


============================================================
🔄 Round 412 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 412 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0024
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0054
============================================================


============================================================
🔄 Round 413 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 413 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0007
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0216
============================================================


============================================================
🔄 Round 414 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 414 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0023
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0022
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 415 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 415 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0001
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0030
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 415 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 415 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 420 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 420 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0000
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0062
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 421 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 421 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0016
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0032
============================================================


============================================================
🔄 Round 422 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 422 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0021
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0049
============================================================


============================================================
🔄 Round 424 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 424 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0024
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0015
============================================================


============================================================
🔄 Round 425 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 425 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0001
============================================================


============================================================
🔄 Round 427 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 427 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0008
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0034
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 428 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 428 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0013
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0006
============================================================


============================================================
🔄 Round 429 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 429 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0007
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0069
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 429 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 432 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 432 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0008
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0076
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 432 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 432 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 436 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 436 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0022
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0055
============================================================


============================================================
🔄 Round 438 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 438 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0004
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0129
============================================================


============================================================
🔄 Round 439 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 439 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0030
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0048
============================================================


============================================================
🔄 Round 441 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 441 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0000
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0030
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 442 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 442 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0006
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0012
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 442 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 444 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 444 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0003
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0045
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 444 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 448 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 448 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0002
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0025
============================================================


============================================================
🔄 Round 449 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 449 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0000
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0184
============================================================


============================================================
🔄 Round 451 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 451 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0031
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0200
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 451 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 453 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 453 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0006
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0112
============================================================


============================================================
🔄 Round 455 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 455 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0026
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0030
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 455 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 457 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 457 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0004
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0025
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 461 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 461 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0010
   Val:   Loss=0.0871, RMSE=0.2950, R²=-0.0082
============================================================


============================================================
🔄 Round 463 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 463 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0002
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0122
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 468 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 468 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0012
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0020
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 469 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 469 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0001
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0023
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 470 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 470 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0002
   Val:   Loss=0.0679, RMSE=0.2605, R²=-0.0116
============================================================


============================================================
🔄 Round 471 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 471 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0039
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0092
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 474 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 474 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0011
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0015
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 475 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 475 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0039
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0085
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 475 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 475 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 480 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 480 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0036
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0099
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 480 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 480 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 480 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 480 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 488 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 488 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0049
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0411
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 490 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 490 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0007
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0488
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 495 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 495 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0008
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0087
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 499 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 499 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0006
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0096
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 499 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 501 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 501 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0013
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0099
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 501 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 501 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 505 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 505 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0001
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0033
============================================================


============================================================
🔄 Round 508 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 508 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0016
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0031
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 508 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 511 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 511 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0010
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 512 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 512 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0031
   Val:   Loss=0.0948, RMSE=0.3078, R²=0.0053
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 514 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 514 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0014
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0037
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 515 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 515 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0001
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0034
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 516 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 516 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0020
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0204
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 516 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 518 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 518 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0003
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0038
============================================================


============================================================
🔄 Round 523 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 523 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0000
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0130
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 527 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 527 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0007
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0003
============================================================


============================================================
🔄 Round 528 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 528 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0027
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0068
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 532 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 532 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0015
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0080
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 532 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 534 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 534 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0015
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0022
============================================================


============================================================
🔄 Round 535 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 535 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0010
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0009
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 535 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 540 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 540 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0025
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0049
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 541 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 541 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0125
============================================================


============================================================
🔄 Round 542 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 542 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0008
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0080
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 542 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 542 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 542 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 547 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 547 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0012
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0309
============================================================


============================================================
🔄 Round 549 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 549 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0000
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0027
============================================================


============================================================
🔄 Round 550 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 550 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0027
   Val:   Loss=0.0987, RMSE=0.3141, R²=-0.0038
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 552 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 552 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0025
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0067
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 554 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 554 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0018
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0000
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 554 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 558 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 558 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0000
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0021
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 561 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 561 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0004
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0016
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 563 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 563 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0038
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0131
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 564 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 564 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0008
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0044
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 564 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 567 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 567 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0019
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0041
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 567 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 571 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 571 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0004
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0035
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 573 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 573 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0010
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0009
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 573 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 575 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 575 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0013
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0083
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 576 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 576 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0004
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0007
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 576 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 576 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 579 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 579 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0021
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0104
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 579 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 581 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 581 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0011
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0012
============================================================


============================================================
🔄 Round 582 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 582 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0005
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0060
============================================================


============================================================
🔄 Round 583 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 583 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0015
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0005
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 583 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 583 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 590 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 590 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0021
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0008
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 593 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 593 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0009
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0085
============================================================


============================================================
🔄 Round 595 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 595 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0018
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0010
============================================================


============================================================
🔄 Round 596 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 596 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0026
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0325
============================================================


============================================================
🔄 Round 597 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 597 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0002
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0028
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 598 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 598 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0031
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0080
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 602 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 602 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0040
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0133
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 602 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 607 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 607 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0002
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0209
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 607 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 609 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 609 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0018
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0002
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 610 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 610 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0004
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0002
============================================================


============================================================
🔄 Round 612 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 612 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0008
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0013
============================================================


============================================================
🔄 Round 613 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 613 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0026
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0041
============================================================


============================================================
🔄 Round 615 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 615 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0018
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0143
============================================================


============================================================
🔄 Round 617 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 617 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0026
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0067
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 618 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 618 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0014
   Val:   Loss=0.0890, RMSE=0.2982, R²=-0.0128
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 620 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 620 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0023
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0072
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 621 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 621 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0007
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0133
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 625 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 625 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0013
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0006
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 630 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 630 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0012
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0123
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 630 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 632 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 632 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0022
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0122
============================================================


============================================================
🔄 Round 637 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 637 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0029
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0119
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 637 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 639 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 639 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0022
   Val:   Loss=0.0931, RMSE=0.3050, R²=0.0060
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 643 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 643 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0004
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0066
============================================================


============================================================
🔄 Round 648 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 648 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0004
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0117
============================================================


============================================================
🔄 Round 649 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 649 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0048
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 651 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 651 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0007
============================================================


============================================================
🔄 Round 652 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 652 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0022
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0113
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 653 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 653 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0001
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0149
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 655 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 655 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0007
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0210
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 655 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 659 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 659 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0015
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0090
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 659 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 663 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 663 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0017
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0086
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 665 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 665 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0025
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0212
============================================================


============================================================
🔄 Round 666 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 666 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0000
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0015
============================================================


============================================================
🔄 Round 667 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 667 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0025
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0076
============================================================


============================================================
🔄 Round 668 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 668 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0019
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0157
============================================================


============================================================
🔄 Round 669 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 669 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0006
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0042
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 671 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 671 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0017
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0209
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 673 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 673 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0023
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0132
============================================================


============================================================
🔄 Round 674 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 674 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0030
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0025
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 679 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 679 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0014
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 680 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 680 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0005
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0034
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 680 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 684 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 684 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0022
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0131
============================================================


============================================================
🔄 Round 685 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 685 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0014
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0088
============================================================


============================================================
🔄 Round 686 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 686 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0008
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0048
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 686 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 690 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 690 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0016
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0002
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 690 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 690 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 695 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 695 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0019
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0036
============================================================


============================================================
🔄 Round 696 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 696 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0029
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0105
============================================================


============================================================
🔄 Round 697 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 697 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0001
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0016
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 699 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 699 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0009
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0148
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 701 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 701 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0007
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0014
============================================================


============================================================
🔄 Round 703 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 703 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0017
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0027
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 703 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 706 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 706 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0015
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0039
============================================================


============================================================
🔄 Round 707 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 707 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0007
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0011
============================================================


============================================================
🔄 Round 708 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 708 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0032
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0227
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 713 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 713 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0009
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0004
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 713 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 719 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 719 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0006
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0011
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 721 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 721 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0000
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0049
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 722 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 722 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0003
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0038
============================================================


============================================================
🔄 Round 724 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 724 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0018
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0007
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 728 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 728 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0002
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0047
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 729 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 729 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0010
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0035
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 732 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 732 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0021
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0015
============================================================


============================================================
🔄 Round 733 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 733 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0016
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0003
============================================================


============================================================
🔄 Round 735 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 735 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0016
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0019
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 736 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 736 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0018
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0081
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 737 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 737 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0018
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0008
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 737 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 737 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 737 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 745 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 745 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0029
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0112
============================================================


============================================================
🔄 Round 747 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 747 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0026
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0182
============================================================


============================================================
🔄 Round 749 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 749 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0031
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0038
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 749 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 752 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 752 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0024
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0088
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 755 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 755 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0008
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 756 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 756 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0017
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0112
============================================================


============================================================
🔄 Round 758 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 758 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0027
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0097
============================================================


============================================================
🔄 Round 759 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 759 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0011
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0065
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 759 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 764 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 764 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0024
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0043
============================================================


============================================================
🔄 Round 765 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 765 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0007
   Val:   Loss=0.0968, RMSE=0.3111, R²=0.0005
============================================================


============================================================
🔄 Round 766 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 766 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0032
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 766 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 769 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 769 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0020
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0026
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 769 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 772 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 772 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0017
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0052
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 774 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 774 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0012
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0037
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 775 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 775 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0020
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0096
============================================================


============================================================
🔄 Round 776 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 776 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0016
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0037
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 777 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 777 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0014
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0029
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 778 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 778 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0020
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0027
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 779 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 779 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0012
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0017
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 779 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 781 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 781 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0022
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0127
============================================================


============================================================
🔄 Round 783 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 783 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0023
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0025
============================================================


============================================================
🔄 Round 784 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 784 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0018
============================================================


============================================================
🔄 Round 785 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 785 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0002
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0016
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 786 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 786 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0010
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0053
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 786 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 790 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 790 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0014
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0032
============================================================


============================================================
🔄 Round 791 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 791 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0010
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0018
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 794 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 794 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0016
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0089
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 797 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 797 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0008
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0106
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 798 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 798 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0006
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0061
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 798 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 801 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 801 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0000
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0014
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 803 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 803 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0009
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0022
============================================================


============================================================
🔄 Round 805 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 805 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0022
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0051
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 806 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 806 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0003
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0024
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 806 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 806 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 810 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 810 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0012
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0014
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 812 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 812 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0008
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0048
============================================================


============================================================
🔄 Round 813 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 813 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0003
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0105
============================================================


============================================================
🔄 Round 814 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 814 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0003
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0152
============================================================


📊 Round 814 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 816 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 816 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0030
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0135
============================================================


📊 Round 816 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 816 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 818 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 818 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0010
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0082
============================================================


📊 Round 818 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 819 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 819 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0012
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0025
============================================================


============================================================
🔄 Round 821 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 821 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0033
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0158
============================================================


📊 Round 821 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 822 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 822 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0011
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0031
============================================================


📊 Round 822 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 826 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 826 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0031
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0105
============================================================


============================================================
🔄 Round 827 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 827 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0004
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0005
============================================================


📊 Round 827 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 829 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 829 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0027
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0060
============================================================


============================================================
🔄 Round 831 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 831 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0024
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0092
============================================================


============================================================
🔄 Round 832 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 832 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0016
   Val:   Loss=0.0986, RMSE=0.3140, R²=0.0005
============================================================


📊 Round 832 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 835 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 835 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0357
============================================================


📊 Round 835 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 835 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 837 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 837 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0020
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0041
============================================================


📊 Round 837 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 838 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 838 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0046
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0011
============================================================


📊 Round 838 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 839 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 839 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0022
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0083
============================================================


============================================================
🔄 Round 841 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 841 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0032
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0134
============================================================


============================================================
🔄 Round 844 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 844 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0032
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0003
============================================================


📊 Round 844 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 845 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 845 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0007
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0022
============================================================


📊 Round 845 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 845 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 850 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 850 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0010
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0046
============================================================


📊 Round 850 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 852 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 852 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0020
============================================================


============================================================
🔄 Round 853 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 853 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0001
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0320
============================================================


📊 Round 853 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 853 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 857 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 857 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0019
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0046
============================================================


📊 Round 857 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 860 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 860 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0013
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0043
============================================================


============================================================
🔄 Round 861 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 861 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0016
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0083
============================================================


📊 Round 861 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 865 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 865 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0017
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0212
============================================================


============================================================
🔄 Round 866 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 866 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0003
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0103
============================================================


📊 Round 866 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 866 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 866 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 866 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 872 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 872 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0002
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0160
============================================================


============================================================
🔄 Round 873 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 873 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0025
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0081
============================================================


📊 Round 873 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 874 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 874 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0002
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0584
============================================================


📊 Round 874 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 881 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 881 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0041
============================================================


============================================================
🔄 Round 885 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 885 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0028
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0098
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 885 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 888 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 888 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0029
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0236
============================================================


📊 Round 888 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 888 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 890 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 890 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0010
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0094
============================================================


📊 Round 890 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 890 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 890 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 890 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 897 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 897 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0010
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0060
============================================================


📊 Round 897 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 905 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 905 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0011
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0035
============================================================


============================================================
🔄 Round 906 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 906 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0004
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0300
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 909 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 909 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0013
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0065
============================================================


📊 Round 909 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 911 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 911 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0015
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0041
============================================================


📊 Round 911 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 913 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 913 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0012
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0210
============================================================


============================================================
🔄 Round 914 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 914 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0001
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0009
============================================================


📊 Round 914 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 917 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 917 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0035
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0151
============================================================


📊 Round 917 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 917 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 917 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 924 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 924 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0011
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0008
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 926 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 926 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0014
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0071
============================================================


📊 Round 926 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 928 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 928 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0039
============================================================


============================================================
🔄 Round 932 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 932 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0005
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0003
============================================================


============================================================
🔄 Round 933 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 933 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0026
============================================================


📊 Round 933 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 934 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 934 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0011
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0078
============================================================


📊 Round 934 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 936 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 936 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0020
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0033
============================================================


============================================================
🔄 Round 937 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 937 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0034
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0186
============================================================


📊 Round 937 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 937 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 937 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 937 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 937 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 943 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 943 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0000
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0005
============================================================


📊 Round 943 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

📊 Round 943 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0056

============================================================
🔄 Round 948 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 948 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0017
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0081
============================================================


❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_message:"Socket closed", grpc_status:14}"
>
