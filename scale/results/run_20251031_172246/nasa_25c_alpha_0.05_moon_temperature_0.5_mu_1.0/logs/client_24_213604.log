[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ca9a639-8fad-459b-a006-54b62b73d57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be52229f-ddf6-448c-aadc-1c14a910e50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a491865a-8823-47e2-b6cb-b33db98ea4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907ca4b8-68e0-4f65-a671-aadd9443c041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c88c61-c688-4b73-84ac-397710708a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8e6bec-654d-4872-bb89-e74ef408480f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1fe20f-9895-4e8d-acb3-230f3f4e4900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b703e3da-4384-4f4b-9ace-0fc1a9173c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3abb80-0305-4f4a-b58c-0f23950bfb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6dd07bb-e07a-4d36-a3e0-afba3bc09a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2564761e-2951-470d-847b-8bf9755aa805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17581b4e-46a7-40ec-9db0-6f27dd79dcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78417474-8751-46e1-8ff9-d60c52c6783b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c291d8ba-4171-4a39-ac88-31b6625524d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca306b1-08b8-4f23-a26a-3b02c592e1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29014a95-5e60-4f99-99bd-857e0d10df62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 839234d7-314e-4e2c-914f-0012c5ad3a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e041d043-be3a-4680-bb49-6c2a0bde4f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da89fed6-859a-46fb-a3ad-9679d88577db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2853570b-b8ad-4682-8db1-552a89b5c3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d508e86d-faeb-462f-9ccf-55b2464cde25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc62be1-e914-4651-be90-c788df62ead4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c45208c-5205-4f41-9ac4-0aab557e9b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff91ee0-e558-40ed-9f50-7218bafc92e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ccd67be-1f67-4dbb-90ae-5541f853a555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43138dca-1f0f-4a45-8ae9-5a1a566aa1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5c58b9-5d5a-4e64-a859-044fdfcc7d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e1b035-c9ec-403d-b390-104636cc9928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe0d7d4-1792-49fb-b194-387520e8d033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3751bf2e-3928-4869-a57b-5d3598d879a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a912fbf4-e616-4296-9846-fa1a8022fa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd09d2c3-769f-4d9c-90bb-f3090502d759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfb99e0-c4ea-4457-8723-cd9eb6064087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ab7519-5d64-44c5-9793-c91078e0dccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc6658cf-003a-4ef5-85af-f9b841196dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c7a48e-4f50-4aaa-8597-e989be14a6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c54d64-fc85-4ce3-a5d4-3afa5f246fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88c3463-71d5-4ecd-9f65-0a67b3e6a6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec60525-c42e-44ef-a82e-919156b15bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b525834b-c2b9-4fcf-a25f-4c123f2b7297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bf68cce-aaed-42fd-bc8c-50e985d849c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00cd1630-cf5b-4bc8-b95c-61db99a5f1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd9a303-3424-4240-aea8-c994d9061682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a44b012-7f99-4475-9e97-9f76f13f718a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f133cec-4e50-4750-925b-2556b428fb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676d039c-bca8-407c-973b-5e73f001f522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603e0c8c-6a66-439f-8a67-7c9284e3106d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9185d31f-ed07-47e0-9017-1a3db1dc5fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590e869e-4adf-444a-8e3b-8a9d9850c1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20d9e720-4557-4515-a059-0e9d3e943944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b30dc4-cf27-4a6c-94e2-d24d7617ea2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7adfc5b5-8cc3-4e1d-b0e9-c26230cff686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4135d01-4bb2-4250-bf23-7ad139a7698a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97bf1ff-927c-447f-8164-52a68a784a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa3577b-d9d8-4d22-9469-a3cff75ad4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4123ec-5e1a-4ae5-861c-b1a6b396939c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d7f682-6306-43e3-8d0e-bc12ff47c3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e10554e-8691-4138-98f8-21a33d250960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d60063-f46f-4bb6-94de-3bfdd8a12730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff1d4a7-a565-446a-958f-2e6e377370df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4953e1e-473e-49b7-b2a2-2ed05e422d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3718742-889f-4b57-94b2-52407e241613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b7ae37-2ca1-408f-95bf-0938d047f590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e57399bc-95de-4aae-a075-cbeb603491fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050e2eb4-5892-4db6-9d5d-deec0a4ece28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f861981-d8e9-40bb-a236-0c743312860b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe6c8a84-84b9-4c5f-bca3-c2186a8b4a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d94d82-a67c-49eb-92ba-0dda4d45d776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af14c8d-986a-423d-bea2-ffd7606cb9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b37ef7-c8e4-4976-83ac-fe02e59b058d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689e288b-ceeb-460e-8045-80fd0a5c6c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db5d0c5-3dc6-48c1-88a9-2d8a75303f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6adbf88e-2f28-4aa3-84fe-262058d2b8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7851c85f-4ca7-4374-842e-e2ba4c912ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10960469-5851-4844-80da-b96520b736b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5e83d4-5d6c-4193-8632-c8c961356f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8688b5b-2e04-4010-8ccb-a367da147ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad67f2f-2748-4c93-b7e1-caeb82c6d010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac93e7f-74ad-4b0d-a0f1-9c3640d6f2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc1c86ac-670b-4e15-924e-92677903f46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4411b03-bc0c-4635-ac21-82a91dee4d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ea1cca-f75d-442c-a478-b10739e8f590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d43c55-5eb3-4b08-b307-4e20cd1680f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b00ef2-ea7a-4323-91d1-57f12b2ff21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d513d4a-6285-47d6-b97f-4c6a370b97ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4bd6be-ff75-4cba-9981-356c2b174d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7975ab0-d48d-4761-bc88-e48015f3a855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db3790c-0948-4274-aede-6029da5a18f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4994a90-faa8-4e57-9de2-83b58254d8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d035d142-5e86-45b6-978e-5e4cdde1b1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76b7f4f-3433-44e7-a59b-c8ab0d477631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9661724-a441-499c-aaa5-d7e83c763b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c245536-de66-4dae-930c-1d6fade673ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ff5b9c-5b34-4088-982e-205bbab8c6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39d0c65-f64e-4047-b4e6-71b07940c57f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f4269a8-bf9c-4b76-aa7d-148231b91f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce11f51-155c-4010-9661-baae47f4d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e1da67-c84e-438d-a470-6548e3d92f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9076b3-ad93-44e3-b176-1c0b1a594643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95023560-eb9c-4329-8607-970199361b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df633088-747e-4882-9f74-1f3161fff208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823a4197-daf2-41ff-9a53-430b040b171d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094dd8b9-14fa-4858-8e4f-b96adc61cddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aefbca7-2ed0-456c-aef9-870d99b82776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e962bb6-75e5-4770-8ce2-c4d97c955a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad99e58c-dc9d-4b9c-96c8-d7cae999e08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bf09f0a-43dd-4b5b-9289-bca9cfd8904f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d72aeb1-9b0f-4985-a29c-d6ded98597c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ec29aa-fec4-4f41-aef8-9ed496fc68bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8579d28b-a8b4-4782-8124-55fc1702ac3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57dab2a2-368a-4f85-a5bb-6935630239f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb560cc-6672-4605-b379-85b89cd21e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7257c71-b081-41f1-9361-0e294a56a08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb156b99-3408-48c8-8b17-53cfa886627d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404d3686-eeb4-47e6-a1a2-05813e274a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0094fd03-281d-40d7-a930-2ae6e3b89b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a7bbfe-e346-48b7-a422-fdea61d21c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affaee3d-3c3a-4cc6-abf4-2f6574cbea7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0d777b-cf2f-41b1-bfc6-5796b7b871cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc9dace-955c-4e67-86b3-216a530ccbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad5fb65b-6acc-43ae-94fa-8229775f5455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020d8dab-c0a6-4842-8474-8e78b87e3e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c985010d-a750-451e-b097-608ad02f2ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1f5d72-2870-4e1c-855b-c9d9e921cfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e60bc5-5218-42cf-b561-35bcb4736a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2db72cf-40dc-4430-8d95-ba29d36647f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550eb98d-865e-4567-ab7d-f73ccd31efd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3902bf36-c28a-4ed7-972b-a1fc9ccbd8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2007d096-e3e8-49de-ba6b-9f48803c0fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38df90e-1129-44bf-b1d9-311fa7d2c065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c279c07a-f32b-4360-910c-3080e09a3640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7f4055-5777-4536-8e76-4d7bcdeef71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31cdb7f-4716-4244-8a11-e204cb336487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c97030-1124-4632-8b3d-91eb58a3a72c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1dee81-16fa-4b6f-89b2-805214a5e1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f279079-fb58-458d-a7a8-72edc25c5695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c99a15-8007-4166-bb39-96e9966f88f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac9ce2f-47f4-4ab1-aabc-c796c5c6bd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee20c1f6-3a0f-4c30-ace4-ff93d28a6266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbfd284-7692-4d53-993d-bb62387b84a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631617c6-b664-45de-a650-865577fec738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa3d5d0-539d-407a-981f-77186823888a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06495258-ec7c-447b-8e22-19bcf1ee813d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c29394-2d7e-46b9-bec1-4d3999d1e05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af5c9f5b-7e58-497a-b1c0-f957b6e6c627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0148d812-32b9-4cf1-8b4d-0fec41239a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc0da5c-1374-4956-a8d4-c51bf9b25168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1b31b3-d85a-43bc-a18a-6d866e75194e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d118f28-9ae2-4271-a643-e54bcda9b0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c2a21e-85df-4632-865e-59dd94230bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8176b46f-07f7-484b-8bb7-6ef139d004c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2ca85d-23bc-4ab0-87df-06290d3546f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af40f075-15c4-4680-b4cb-81efa9f870a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a79d722-b37b-4081-82f4-99fcfff3daa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a322a825-4c3c-42b3-a657-42faf2dd8776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b4535c-99cb-478c-b3a1-eaef1aaf3483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f787f1a8-de27-48c6-a602-97d0754366f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302936e3-4b9d-4dd5-974b-060d05212ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddab9e8d-a50b-449c-950f-993f75078102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceda11c0-0f23-4c6f-bb5b-35ea4a55a225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2add1f1-3669-4573-862d-6b6238a01df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97984c7-c8e1-4802-bc7c-3a0724863681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8458bbf-a764-4397-998a-031adf19bfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be00665-105b-4855-bdfd-9ea96c6284be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1544c8e-d26e-42cc-abf9-37a501909fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7782ee9-fe57-4473-a46b-ec5fea865f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39d02c0-f3e5-4945-a7ac-7400e3f2ecfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f92ad28-9e3f-4117-ae74-0e950bbed8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc4441a-c61e-4193-a8b0-ddc9e85a12ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e9046c-8573-4c9e-a082-2ee72a3412c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7910d7-1d2a-4a0a-b500-1d63cdbcdaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c88831c-c28f-4413-8a52-ef624c81a7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da768913-2dac-469e-b14c-4264afbbceca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fac3fd-39ef-4010-b741-31c985787c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d6bcc3-5ee5-4f1f-b0a3-34ca12ed23da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 343f6754-792d-4dc2-8936-e963166e2335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03ea3c5-1e62-4e85-b5b2-b05320f0e637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961dfa1d-dee5-438a-aa2b-374950c8411e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76d5eae8-17a8-45a7-bbde-5ef85cdecc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af72ea97-999a-4db1-9366-79a5483107ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5e603d-bf7f-4916-9904-7ca667e0bdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba4a6f5c-5976-4e36-8525-451b30f48af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee57343-bff9-480e-9e18-3f5f2be046b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35df54d4-597b-47c1-aaa3-f00eb87d6327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23a5b09-7293-4d47-93c2-e19809abe324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47777da0-9290-4d68-8249-fb261004f093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2059ad46-3203-4c7e-ae7a-58366c300bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41748516-9fc3-40b0-bc5c-9da127127f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e197063e-ae0a-4fb8-97ae-9ac8403b5043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483d7357-7e23-4d89-b5c5-52930688187b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93363d0-5da6-4af0-88ab-fd9c1463c1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545fa598-ec52-4d0e-8a25-b548039e2cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f0dc32-dcde-4531-b7d3-85723f8985b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90126ac7-b4c7-4e74-83d2-7400e3ff72ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0d197c-f5f7-48bf-85ef-e5a90eba87d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44fb64b-41f9-4693-a07e-b39f1247c3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e120e06e-c797-4ab3-8b68-0fbd81adae3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e2f83d-2ac6-46c0-883d-f6026ff467cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22326b0b-faef-40fd-a033-0db9d78dbb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede156a6-befa-4f8c-afb7-363dd1a6e58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98951025-3ee4-45b8-b7d2-b191fefa6f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c17e9f-7b73-4e61-963d-5c3c0d3fdd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef380e5e-cf4c-4d1b-b456-b0147b8efe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc12ad5-12e0-4a78-a39f-c9acaa6b409b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6873405-d490-404b-b294-b5248275daaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2597c69a-d33e-4ef7-bf9e-d746ffe0a9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fe9b2c-ba98-40e5-bcb3-81ae034aa7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b922b0af-2edc-4a71-80f2-de279b454099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e74ecf87-a527-4fac-8b37-3ac10d7e221c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c243a266-9660-4255-8965-6ec208df2752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d02a022-a90d-4e00-870c-0576728070df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234317b4-416f-4c3d-bb98-26885294763f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bad3a22-2b7c-4cea-bf18-93d179d0f68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311c4b0c-5def-4f33-98d5-bde9e38062e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db290cd-fa4e-437f-8112-ac299773e296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89448cf-1e7e-40e4-aff0-b10b8c1fc76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cacfc8dd-b045-4ac0-9df5-267a92d3e8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1fa0560-935b-474f-bbb9-243b58db2938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c420c3ed-036f-4f3f-b78a-b363fe145919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03854d68-5c52-407f-ab46-fecd5ce7a8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f34e29e-dd93-4c70-8f8e-0faaa20fa9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549b5ecd-5bf0-41f0-875c-f3f4fb82b864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc3655e-2714-45bb-be39-c9f95c6483e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2756005-3a60-4564-bef7-bbf3b704d6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 064feeab-35d8-4916-b951-640551be4f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc8adbb-77c9-418f-9992-6d856060864c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13710ced-d3cd-41af-b157-07712d57b79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe17c06-7e5d-42cc-89cf-80c25e67ea3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6486070-3a4b-47a4-aa29-de45b26550ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3487fe-bc7b-48a3-bb87-c4e97329e168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201122b1-4973-485b-8fb8-f89264ae9018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098398eb-ffc2-4d85-bf92-292574d57689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 878cad46-eec7-4e06-9209-27fd3f817150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d83a646-71e7-419b-bbaf-ae07ae9d0039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13b4891-a862-4bb9-9fee-0931dbbd2ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa487ea-3aac-4a22-8bc2-cfadbe1bff8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1648cc86-fa2b-4eb8-b2b0-d226d6ad289e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4776c09-1cba-4cc6-8ed7-e1c333b9fb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0d16ef-79c7-47f4-80cc-b15f43cbf03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a79095f-2436-41fe-9c11-f6e77dc8cccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b22d4a8-469d-4d33-9730-6c98c623250b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fb50f2-8506-492c-9b83-51704c807049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b578a4f-f58a-4858-a07f-ce2a3b99485b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2ef720-9e49-4545-b899-33548fc7d833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e27974-34e4-405e-8991-b786045079a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03d4977-9a32-47fc-bf4f-28cd08307a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0010ff-6655-4c21-a51c-eb53f711fc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8250d4-42e1-43ec-87d4-11bc4c41939a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8103f37-9d0a-4c50-b840-d41ea517cf03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce93e35-d3e6-4c03-899c-9eac7af25353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2230c0d-6218-4704-92a4-7d63a1014b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9f23c7-0185-4606-9f92-743dcf837f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521bca6e-0378-4bea-ab12-9ae427b9a9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8eb7312-060a-40e7-994e-ee016e1c87e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2eee5b-c99b-4d66-a349-a76064a89414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca767e4-896b-4a14-84fb-819e11ea7baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2af170e-060c-487c-a580-655231c6301b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de58371-bb1a-42c2-bb0f-9525ab889a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c989a11f-4fb3-46f7-88de-fd60f1b5f852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 785f425d-9429-4a7b-bc8d-a765d75fa129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba60771f-7940-4d98-9bf1-7e976121ee4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7dfffc-e63e-4a12-a137-54e4a5cb4b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d1cd3c-f18a-4f18-a771-d6776c307789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd328847-7dc3-4929-9b8c-66f7bd3487e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9793d927-4c5e-48c8-b243-a217dfaf6f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d5b92c-3ce8-47bd-95a9-40317220e7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4caa7f23-14a9-4b26-ace2-d67e833b4796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a6a24d-f12f-467e-892f-47075fa9a45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90237dce-0e13-4eb9-a8cb-b69217bb214c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0780a3b2-54b4-4ae7-8680-5e9b7d10ecbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e94b41-04c9-466b-bb9c-4081a8aa46d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f26e18-fa8f-451c-8f30-c0aa12634c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d8ca8ba-d984-4aa9-82b1-d158052d8462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66efa0af-c0e2-46eb-a102-7fa76a2755d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3320f0-7af5-49bf-89b8-5a1ebe427c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb722787-dafb-4b3c-b8af-3fd353b9625d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701aa5bd-8375-4f99-a951-9b87553d5474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b44946-5e9a-41e3-aae5-8074d79151f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdccfe46-d4bc-4ac3-985b-1663099de7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c337cdc-6edf-4e5d-982e-947ccaa90425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8d10e5-b051-4ecb-aeaf-ea89bfd06b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3e066a-363a-4f0b-86e6-4e35e41f4cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7665e3b3-b3ca-4332-ba4d-99b15ca8fffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7c54615-dddf-41e4-a568-852e38c4fb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10111fe-d058-4cb4-9b1c-fa0b3f1de37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c7353f-0e9b-4d39-97f3-a24949f1a248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1743dc-c398-4c22-96b5-0a81b23111c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12830b0f-0d2a-4135-81ec-2159f740371b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 914c1951-5077-4f97-9821-aaf548b8e56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c54ae53-79f5-4e02-9625-43e1eadd9e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7823f5bb-fc7a-4176-bda4-6aaee4a5bc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88d597e-a051-4b61-9a5c-1cd2bcc4a427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f0b050-fdad-40c2-9992-bf3a2bf86c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4c5460-3ffd-45dc-821e-65ebfd75355f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818240d0-536e-404e-93ee-7e1502da7ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181deeff-a854-42d7-815f-6ef72160744d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a742d9f-c758-42fb-bf5e-c2d486e9e8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d76eb01-4334-4d8b-b7a7-08869357008a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f87c36-caf7-4697-8eed-da5f1f2c8ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97844d29-debd-4315-8831-6d112a06b65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 800ea2e8-7b9f-4356-b67d-747f1bc0ff3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec83704a-d0ee-4711-ba18-e94b9860ec9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb5340e-161b-479b-8d14-588e0b81fe36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a5491b-d8e5-4d6b-ad9a-10daf930da48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8bf07ee-6b10-4d86-8ab8-8761cefea153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19457de6-56f4-4a19-8741-0e97c700a623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b937a08-498d-44ea-a139-c2eb128f4e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd51141-e79e-4683-a46d-e92ba90beb41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e6e0a9-24d3-4728-b7e6-2198d365c0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4d5f5b-d29c-449d-80fa-3689d53f5f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d819b003-3d82-4712-a780-b5e46139060e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 923d0c00-b3c2-4197-9ca4-f4481a68c6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36adcb3a-99c6-46a1-a4db-abb19ee7af45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f84743-2e67-4878-8b86-a20a8a6fb5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901f4092-76e1-4cf3-9837-8595ed8c54a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4caa5e47-d088-4687-b9b7-bd5c8bb9ac66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f900560a-5f41-4208-ad17-b422a8cd3f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5782d59-bb09-4458-939f-4e66a9a7162b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 386a6662-ba30-4ee1-8f01-5cc559a37844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339d5fbe-049f-4cb0-8197-aa5885895340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62ed45d7-5903-4c91-985c-72110d615d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f731627-d5ef-492c-a5e2-270ef9aec4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18dafd1-6fc6-40a4-87c0-9c5df0be7c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a069ab4b-9752-4705-b842-8b97da27b181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc119c73-e655-4926-b4fe-40495fe0e49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca8fab1-c052-47a1-997f-9e9b81b9ecf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5fa968e-b773-4e8b-8a56-bab1113166cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94a7b49-0b21-4e03-b2ee-4ec4595fb2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75059987-f07f-4a31-b376-09a8f029c5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b5c3aa-3a0b-4702-b499-4de153f68ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157c8d8b-c0fd-4932-b6a9-a258ebd07123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fe2dd8-f008-45d0-bb1c-5c3f2837b12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714d5984-30bf-427a-8e16-e7bbd0117cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf610fe-5aa4-4e01-be1c-a8d6e75ef433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20563f4c-189c-4733-b631-c009982b69ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c8d4a7-dc94-493a-83c5-a09974aba558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5313627e-5dc7-46ef-8b4a-3f5db38f522c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d11ab8-667a-4a24-b0ab-bfe1dfc1fbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78c02f84-59a9-446c-9537-da3acedb39e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d4ddf9-3338-4054-9ae6-643ac16fd3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81573792-175e-47af-9322-5a868a38fb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea1c090-f3e2-4118-80fa-04b5b5883a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772a0a41-30fc-4a4a-8e09-8ddb10696c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1f548d-0081-4f29-bcb4-59aae917e423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11d448a-2d22-4c7a-8646-5064c6e5f0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49494355-fe7e-40d9-b739-e2e4c6f9b23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654e73b9-6fbe-4597-a9de-48b0d3ffad80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 424ee44b-710c-461b-8d9d-3ee93bea5e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bec0e71-63d7-479b-86c3-e857a7a65870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0d819d-24a3-4f2e-befb-a394037c8645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f867d456-ec1a-4857-b69a-525c16b7085b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 577adb5c-230b-47e7-9d4e-6628be676ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8ca2727-254f-4501-860b-395a24861a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee623b0-6ad3-450e-b011-168c19d2f4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc83b47b-f51e-4ad3-b8e8-13488bdd80c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a907c63-2fe0-49ef-a581-6c868c9fd588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92f2d96-6747-40f8-9685-ebe0275f097e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 045fc593-3dd1-4516-a6b0-b1d6d815a64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22dc2d7c-1896-4832-8cf4-ab624c9ba263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502ac745-8e0c-45a4-b308-45a2eaaa6979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f145e808-7138-4164-a957-7d6c6aeb9011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e4660d-3210-447d-9aee-f80fc967b778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0de85d8-fc46-46c4-851c-6d9d7bd40f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c9e6f8-bf70-4a8b-b7ab-52d641af09d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d3ac7c-d7a3-4370-89b0-13cb7e25a958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4dbf06-e36a-4f8d-a60c-000d6fe62a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240e2ced-44a4-4c45-bc5f-5793306a8f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d16eaaa-b226-43ac-90ac-e605a7057601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9d7316-d47f-43fa-ba6d-020f9d1728ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905eb099-f38b-485b-841f-748684b91270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b814863-75da-4845-9052-75cb8c37b562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0620725-d8eb-4a70-9bc5-9375f610026f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da3259e-926b-4f17-aefc-2f9f515400ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64aeba7d-a4c2-4d03-9e66-44503efe05db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f89317c-8d7a-427f-9b34-22ea76a5c4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87856605-a543-4866-8188-395cadb7a1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b322467-ae52-46df-8806-986142034426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a5b48f-6752-480d-9312-6252c2a3be4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2017a732-be20-4c0e-80cd-8f1ca28130f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02610a59-15a5-4859-b6eb-adc6acdc63a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac58b27-f55c-47ae-afa2-5237be5b7e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad09e6e-21b4-4f96-a88c-9ea4475da659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8553c1dd-4208-4508-a862-ebb96924bc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef7e952-7449-48b3-b43a-45d675c54c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec418de-d142-4fc7-b9c2-a9334936ae3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c175db2-5e00-41f6-802c-87c8d544144e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f0ec0a-60f9-4c10-a3c8-cb7b0259f4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e69cd0-a6fa-49d8-99ce-ef6755c95d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18c6e37-d540-4c30-a12e-4149685cf961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66d226c-e0df-4caf-92dd-b9560aabea20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75841ae7-4b01-4f25-883c-76cd0e71fd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2d7c3b1-60b5-4510-bb1b-9e8ab4e3143e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2cc2d66-9761-4c42-8db4-032fc55282d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd473740-c209-4d43-a01b-eb9d677982b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9ceb3f-47ef-4ac9-a2fc-5eaf89011fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3db1e2-4c76-4cf8-b1e2-7ec35f8def34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ff9f4d-8b83-40ed-866c-84a4e12b64b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba71395-0368-4364-bda3-48c52d02a65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0149a837-598d-46f6-bf6a-0eb6396cad57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d05093-a80c-4ec4-9b8f-49da34a5cb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4eb2102-aaa6-4113-8383-fbdf0dda1199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f1ef975-3ef0-480a-b3b6-f1cec6902b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158259c5-bef2-4480-b302-b7532ea86d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 645415ee-507f-41f2-8dd7-811ae0f9cb8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124e4f6e-9c5e-4bde-924c-ed6fe17c8f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b91b8fee-223d-4233-87ff-dbd2235c382f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001412a6-b89b-47df-a4af-656a0bd5564d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da8573f5-6090-4e2a-b02b-2210b80ed0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 935a3748-8f58-4604-8481-1c5d8af36e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab132b1-68b0-4ac3-b084-78054f607519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0caa0b-639f-4092-b50a-79998037b9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e7ae214-67ee-430c-8e3e-09e8636ac735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f01cde-5ffe-45bf-b9e2-29d0673d54b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be76375b-4660-4078-af8c-9168ed117e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a220f551-c667-442b-8a43-5f2a209de7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ea26d6-8eca-46c8-8a16-4a6a84780bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1fb351b-9183-45aa-add1-0045a337e9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8243e51-160f-4fa8-a775-6df8c5a6b509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dd35a8-59ed-4d14-b461-6fb0fd262641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9413f842-e866-44c5-9925-282e91eaf6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8382bc07-3ef8-4f01-b470-3d39bec08603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb03e3e-bb95-4d40-97b2-7aff7e1614e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f634ef9-cbba-431d-92d4-10f9099077b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a321d5f9-cddb-4e62-b57e-879c82636542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9399a69-d1ef-4551-95c4-ded6952cb1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a4f61c-c6e1-4bcd-8be5-6b1cb95b22c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77288388-db02-42a7-9d8b-42a072709137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8105ed5-9e79-4028-800e-80dbe5f557c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 836182fd-22f5-4f42-aa24-35602960fdd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a11c352-005c-4091-a229-a6063477766e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b137f079-b38e-449e-a15b-160aa3fc5f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c994da9-540e-484f-982e-75ee9499cd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c081b63-5b99-446b-8ddd-2a810ff0cca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db42fb1-3946-4169-854b-b7623bf85871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c860864-346f-41c8-9d83-4ee8e6363eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33018ffd-5d82-485a-b9be-5a4faeb40ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07fbc48-fc7b-4c15-a257-449f97fa7ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891d0bef-1cf5-4a39-aeb9-bfb9986e6984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8d8923-a048-41d0-9461-ff71f74e2b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a494230d-70ab-404f-a055-0c3235aeb6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1a6ec24-bf38-420b-9110-1eb029125511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320fe047-716e-4f2e-9ab4-1c414c12c4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7974a2d8-83d1-4b97-aff6-ad152198333a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d940becf-d1cf-4e95-a6f5-568b1718a697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0a2b74-4def-4789-bf22-ff3f1f6eb34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05675340-4a28-4960-bf3d-54dc8491ce39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9b4586-8f19-4053-9194-2238c4c066f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2560ac-fe5f-43f2-8c99-6e4091a7617e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86281bb8-f358-4a99-92f0-096a9704b319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20fc2052-ce43-41dc-942f-bbffc74f01fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 900c2836-557b-4510-bd9c-4f24d138fbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a104018-639e-489e-97a7-dce5cf1e3e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ef5274-f49e-42ee-acff-838ec9f1a60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff4878f-f022-4054-a51d-2a406f6f2735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c669daa-5b96-4f45-8d52-39b6ad13a3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57dc622b-9e01-4b99-9952-c5f7db0601bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72168319-b11a-4a32-bfca-d2d90da83b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a6c4e7-2fa8-45c8-85fd-cfd0e20a7bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28848c21-d577-4ae8-8dda-4e9f3e1f77bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f211238-0e10-4883-b458-6382e84f42b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17ca9567-aa94-489a-8bf5-38dcb1294812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5071e6d6-b221-4534-9caa-e716614e8baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0177bba2-957d-4847-a768-8db388287597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12abdcba-5a27-4c5f-9517-3614f73a7e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7314f4-d286-47ca-b302-7618c2892f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db72fd15-ae69-4166-98f6-5e5656fbce02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8875c6c-b558-4dbd-8efe-2fc4933c14ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210ea0f2-8a81-411a-a449-2ba4c14fce4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faf9b604-90eb-49ff-94a3-1bc5b2559c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1068f4e1-97a7-46aa-a590-97a8afc33039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede8364c-41dd-44a3-8ed9-f27088c6df06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c34971c-c6f0-443b-baa9-f014d7236f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d42c01b8-97ff-4b56-b451-71bf650a18b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2164ede4-b45c-4a68-b554-8f8baa3bccef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b42b5f-90bb-4d79-b730-89253bd410d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955964c0-b89b-4966-b70b-5782c03a6408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea0aa13a-c58e-4159-abf3-a6be1e86bb32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661d7105-9991-49af-8c49-e0afd0890faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9081d0-5ce0-49c5-acd1-a1561f513e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f94b17e-425b-4ce5-b739-5bd173b2e35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7f328b-2e3f-4bca-ad54-c1509f20e47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec4be17-8bac-428f-b409-3d6e3bea34c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a692039-1907-4a15-94a9-7ecb7644194e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b85a89f9-4e47-40a2-888c-6b691bf0ad63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8fcd358-3088-4712-b123-76e5860ffc71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e49ef8e-302f-47a2-91a1-bc9ccadafdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f599487c-cf1d-4953-bac8-5cfea6b3c7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e65d23-985a-4c00-af76-f23265ed4b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0f9c0a-aa87-4053-9ede-5628762dea35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ab558d-5217-4f86-9baa-d24dd44553be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791fb580-1c59-4baa-91d6-2307be010918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b288df8-75ce-45e5-b844-823990ce4a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24fd6206-6e4a-47d7-8c45-3240cf751a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f80d9691-f342-4fa1-90b6-327a26ac565d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3961b4-3a8d-4807-9bd5-f8cfad1281fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4080401b-8975-4b23-ae45-727de1e2d134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8af772-b1e6-4940-ad93-41be26fb3ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3ba003-25b2-43b3-b676-1ce33ffcd1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49bb82f0-ebd1-4f2a-855d-2c799fc1e4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d6d538c-c834-4734-9aac-8c0d5db8780c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c14fd50-cabe-49b3-88aa-387ec2aa2637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721672a1-abe3-4fc3-b706-dc6ca6312f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2f3cc5-f226-4828-9ca9-ab62c47c5c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e95674-433f-4065-a078-48be050e21c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b1faeeb-36e9-4152-a7a4-410d2561b842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac9f5c2-f7ea-48fd-b6fd-8041da752e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db4e292-7ced-491e-8838-cabcbe4b086e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a53b5a5d-6e8e-47a7-9302-734856a25c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85514c4a-897e-4c87-9456-85643d6d5238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2046702-f44c-4b1a-8563-89ffcfaeba81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c2eb6f-2c65-499b-aba6-c039017458cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a17e4b2-56e3-45ac-ad7d-d6e85a852d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd9276c-7114-4caf-990c-4c2fbb26d496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d27256b-51a2-4d92-aba1-65bdaf0e3e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2139fc-5e80-48b2-b3f4-53cd68b91da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c417ee-a49e-40ec-893b-14467351b387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafff79b-8f02-46d7-8547-ee44707e24ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92467af-421a-48f1-b5e2-f1c37e7a7cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cd883b-ebbb-43ca-b101-195b927a3f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3beb93f1-375f-46a5-8294-c8a416ba2562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f6ffb7-b577-48bd-9c09-eecd67cf1e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1aa5bc-a1e3-464c-8a0f-acd8fff1c26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f06308-2454-4343-96fa-eb392db3ea29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ee0e13-86fb-487f-a086-316c38992025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a1c407-de8b-48cb-899d-f7929d158c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc768706-04e3-4c13-b7a0-6eaba12d12e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0004ccf3-b0fa-4720-9cd3-6b5d1fdf0a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40739e13-b703-4b9e-af72-4f170007d877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7262d4a2-6ff3-4d90-b7e3-6d8e276de00b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 503f8751-f2af-4c77-8b26-757be0625368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988321b2-ef44-4b7c-8679-265c6c48dba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c171f6fc-2242-4f00-93e5-7999dfc0e25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d69228-c8a2-4e87-923f-733583999799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ad382c-8f7a-4731-be45-a48f6a969293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff902f8-dc88-4fda-8738-fab3a7b1790f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcd25fed-13a4-43bc-89d9-21186da5a6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae51691f-ac02-484a-b3a4-fc44c2092ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3213a09-2efa-4872-bb12-495645f818c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8ae3a7-55db-4f45-8fed-876da09818c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4e89e5-fa4b-4fe2-a1df-1205ea65082b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a78ecb7-cf6a-4c63-ad0e-4f7198361412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6159b0b-50f5-4583-bf19-5cc3ab26f13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73af14d5-0543-4230-a4fd-d7f0d0e2bbd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8648167f-bc1f-4e7b-862f-ec92d3623953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6bce38-0116-4332-9dab-20b914952dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a7b5d0-316b-4a6d-83f7-ba4041be9754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 369a4032-8733-48f5-8d7f-05cba4a87c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01966819-5655-4223-93db-69dbd6fa485e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c642d56-b020-4848-ab23-c3cb8b04d128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1957f81-8980-459b-b07e-3700b1bd47b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b872ffe3-cbef-47f5-97ec-251c6f923e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ffa9c1-6d50-4830-9513-04e1ff88400c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc73268-112a-4266-9d01-1eb51ba8e237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6332b4ab-3399-46e2-988b-8075dc71916c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 536668d4-bb90-4a6e-af30-34393c722e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac484913-15d8-4cfe-8952-551564322251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9221212-47d2-493a-abc7-7764921bbef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df73f0e4-a033-45ad-9813-8cdb9862d55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae2a9e06-72ee-40ce-89e2-b2f31e421ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88124608-45f4-40b5-a060-aec9539ea875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a88d5ae-afad-45f9-8431-6f4dcd20a7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b9d43cc-0526-4f68-a4cd-e8da13c3b4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b4fbba-cbcd-4e5c-a5a9-e323db201527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05926257-8dee-4ba5-b646-db15f7a9957e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5bee8e-fc7d-415b-8243-1dd2b237af61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1200310f-e914-4c17-9e28-8f8c2068032c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b7cfab-0385-4753-a21e-a2295b207660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fa2f36-9433-4b37-bb25-76caea86e89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d47bcc-99e9-4503-92c3-0b1da29884dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f199bfb-b222-4fd2-896e-726a463f0b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99ff5fe-ae4c-475a-91d1-05a17e76cc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3948e7d3-2b5d-4f79-964e-9a44eee5b014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ee30ad-9916-47d4-9a52-2cf93b78cd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3ba49a-3497-43b7-b888-6817aa8442b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0bdc5f-f0b9-48c7-ba19-95d106572b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7c3172-17e9-4427-9eb5-b176889a3cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a586a678-ce7e-473a-999f-1005c4df4632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e08f90b-71b1-4556-bc5f-d1e24ef45160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 358c8277-2610-40da-a46f-a9f6d46f9a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e43ee54e-ad48-485e-94cd-3b9775b61496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cbf8108-3e7c-4f23-84de-a9b6a9ee33f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3519a52-431d-4a2d-b006-835911a30a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4844757-fcc9-473e-bcdb-550f2eba31fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86465916-d564-4876-8324-30efa592dd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 256ccc44-0b06-483d-a78d-acb9b7a31b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b1718da-99b2-4730-815f-a42898303b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1e4ae3-e8a0-46eb-ab93-2ecd7d836e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f46801c9-88ac-4bc3-8efe-2bafba9c9e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25272ab9-5dde-4eb6-84bb-24773c39c44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 381cb717-d036-4801-8f3f-f5e9c3b2b064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df9dd68d-7f76-4838-8c98-00a5f09fcdac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9f229e-7261-49db-8907-905183b6d0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e07faa0-9cd4-41cc-a5a9-84489cdbaa29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17b57c3-7358-45df-b8d3-cb74b7cc8dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7c8303-70f1-4638-87e6-cd93c07d0213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773f615c-50ba-401d-869a-2af5fa28ff79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064703a2-791b-4429-9b57-1b4780b8ba63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b806fa25-de39-4df2-8304-95a5bbcff60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088a1f6a-5b27-4c92-8737-3db53080919d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad736947-864a-45fa-83ab-89f1dc8ac1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fc5492-da06-4a6e-a336-c84dbbe6c4e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b4fc1f-f3c2-4492-9762-7a00aae1629a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73de6dce-3ef4-460e-8ad3-e4f1dc9c5362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d482f2-ec80-4599-8472-e61866bcf61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f725312b-4475-4333-9f41-1b55ff6fe34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8024f1c-0335-4dee-99cd-ccbbeed683dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c9e77f-fee7-455c-b975-08964b7a2313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f5bdaf-860e-4448-9b13-25bc882199c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340ef842-ce59-4ef4-9504-daed3618106b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432f6e09-6a0a-4046-861d-6edded466a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84368e98-8ce2-4bb1-a716-ea2140256c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f61583f6-cbac-49dc-9552-f4003a721774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8850ce85-b5f9-41d1-ac8e-95f6ef16a89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d958a904-8d73-4882-9a4a-ff6ac65848c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53729a87-9c5e-4c43-ac60-9cb0cdee4c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 513fc088-8f2c-465f-a18f-1e7cb23dfd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b144683-c892-464a-bfe9-ebe8ae1a05ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31dc2d51-0a0f-46be-ab90-2852e63c6fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22b22a0b-2ff4-4488-a33b-2862f5fbb875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04193b7c-4395-4ac3-8f0e-bc79d1b9531c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56e38ab4-833c-4291-8b81-19133e9bbb37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5003f9a1-4996-4b9e-854d-0748a4a3e2fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68bd49cd-e307-4042-bbe4-306784e07bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5758ea-573b-4f7e-8ee1-d22a8ba8519e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c22f27b-9d4b-4ae4-a915-b0517e4b89d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b1615f-00d3-4cb6-b851-97f8bd529a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50b852e-6fd7-4275-878d-cbaee65a8c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df170636-e547-4c36-96d9-961640fc704e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f533dc49-5bba-4555-b87e-686d97ab7afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eec6d9c-bbe9-4a50-bd10-8a11a0f85e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3fe517-f0a3-4b77-9a59-95ce826cc544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1741aec8-4c3f-4aef-904a-44a02d8a8449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 421f219b-df91-4afe-a655-b51973990e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd135a3-2506-4697-9f1a-dbdcdbcc393e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d68216-5c60-475a-b185-a051d23127b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e73c431-b83e-4c78-a6b6-1d6cbe76f36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2fd881-4703-48b8-b864-fb31321c52e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a209ab-9a86-4797-a11f-46cb81bcc5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f3b5f7-a7de-4dda-8c5e-cf9a3c891135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c9d97c-dc03-4156-86c9-5af78b835584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a034726e-ef98-436c-966a-503536f534af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca8def7-1dd0-4605-a035-d3d10bfdf469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d872989-fdb6-4e1b-a29f-ef8a632ae75d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f208007-3fb2-49f3-99e9-154dbe9e7d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e88a03-e5ec-485e-9ce2-38f03f5f3f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2816750-5768-4f62-96ff-0517437fcf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850d6049-414a-4608-9d30-5aeb48faf9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f264c659-ca99-47c0-9468-45c47485ea5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c61b684-5293-443f-88f4-d2728fdeea22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a601f2b5-90fb-4ca8-85b3-3dee65bd10c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788a917c-a30f-4c2d-b1a6-43218383d5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e3bd7e-d70d-4be5-9e83-20385a359e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a91dc22-c9f4-4a52-a406-0077d8aca039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeab8519-d051-4c7e-ba97-9474a011d318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a70f73f-3f59-426e-864a-80af667c4ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b029e79-9928-48b6-b65b-43491a2eb2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9e8030-d6c4-4790-99f2-3d76c87335a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d9c3c1a-1aab-4b52-a01b-d186ebc05fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d0a78d-2e7a-475e-83b6-cd8a84a27892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb831e7-d8d2-4417-811e-a92f6dee4b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbae85eb-11e6-4e26-84cf-9491bcad055d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf1d7b0-1820-4142-ada6-b8ec0ba2470e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e984d1-f02b-4f95-bfa6-481ce299396a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7428be1-70f0-4b71-8260-f518bb25b021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4846f292-759d-4b16-9d20-a7260b6090ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26ab91e-339d-4c78-a51f-ddaccbb5213d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080d1182-1e34-4a70-8f56-621f2979f7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e1347f-c5f5-407c-8d6f-abe4d5e5f41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a92f11-498b-4d69-909b-dbc06c275a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2242e857-6e68-403a-af27-4b76691b2b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e255dc-e0c0-41e1-87ae-a2a341063fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e44ad24b-515b-4cb1-b43d-0e200518d96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8e98e7-4e67-4925-be13-b81b948a4e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c800ad13-3e16-4afd-8d20-b780db1a68f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12339e44-1cc3-4d2d-82fc-2a7bdbee0aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b071c5b7-8c67-47fb-b202-a220347db6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8401cff-19fc-4920-9b22-7034bf45da2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a7cc9b-2a0a-4348-87a4-16e6b5e0a034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58cf59df-e0a0-4a4f-99f7-5e78eeb0a669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c11766-06f8-411f-9c1d-13324739bd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22815a32-f516-47b9-890a-1b2f2a567878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8316b7-f073-4422-b5a3-941b193cef8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9b9360-1dc3-4410-8a01-0fe8978372fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fe01dc-c30d-4b1b-9819-5842b5747f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d55eb7-917f-480d-8af1-a36f1ac8f6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a91d7ea0-47fc-405f-bce9-7b9ba88b5026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48167993-ebc6-4e0c-89b9-c30847846b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5701f1ae-9e54-4622-96fc-734957381378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c446ee-2427-453b-a3f9-bad06ca23e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f36cea9f-b41b-465d-bfdd-7476533732f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab5dd21-5ff2-4eaf-b360-02086f63e6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f57da13-8786-455d-a565-80c85f1c78c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08bb4c3-a2e9-409a-b564-ea7b6f405fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 394852d5-1c41-4287-8740-6160b1704e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 233ce4c9-f304-4f45-9baa-8309fd3879fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae7ba97-1189-4b9c-9c6f-724a1a8a5ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8c6241-1e5c-49f1-93c0-4ad81493207a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26332d1f-a097-4e09-9a3c-b676aaa0ed48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b63b897-ad84-433a-80df-2ce8c30b5c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4da0ff-34eb-4914-b7b3-59136674eb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2225ff-2201-4456-a2fb-21964586bd0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ecb7dc-27a2-44cd-9095-7ed394eaa4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c1ddb0f-63c8-43fc-aa55-24e99c70b152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0a7655-8234-480a-a71b-fa7beb659cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac7197fa-26be-43bf-801d-55a853db7450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2188598b-df58-4dc1-b3d8-1bcf5e3b1871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1c3b67-d908-42bd-9ff1-49a0fe9335ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddfb442a-e733-4662-b962-fa85b9ccbdc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc902859-3d25-408d-a4b7-3ba71c5279d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade181ba-de5c-4e4f-a844-2f78d1101522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641f66d5-8eb6-4ce4-a39f-a384f4c4c58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d17eb10e-a83e-4238-9543-0a738c640d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc300742-aac1-4dc5-82d3-812219a449fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9fbbe06-1d37-4192-a833-ee7f75055b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18fbf41e-c671-4a4b-90fc-b2cbe987484b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c712a772-17d6-464e-a40b-4cfe0909de09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877133f9-f7a5-4811-a181-50c937dc6e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c44469-2e08-4c8f-88b2-7ca28b188165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0222cd5c-a5ec-4f23-8c65-18c5d9d18bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c8ea87-9d8e-42cb-bad6-decbd82228e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc6389e-439b-4b41-8ae4-8f59303335b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0556fbd-26f4-43c7-83d7-54f4bbefa662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa187796-3d27-4922-a777-ef34c65c0d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65cac2e8-95eb-40ad-86a5-b851fdf41242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3a0709a-f6d4-4373-9a79-829393a3a795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32929a9d-8848-4fa7-9288-0f8f8b2cb98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c924691-8928-4320-b714-9893bd8cf69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad054f61-8bf3-47c6-b74c-a548f14f864f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4811f237-a3ba-4025-a5e0-c57e6b42cb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0907ea54-31b3-412a-8235-aecc7556b5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e96d52c-44c8-4f88-8fbe-7f0847978c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f423a535-6b73-401d-9967-35844caec9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275156d6-f918-45e2-a055-dd11391654b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df6d70e-d1d5-4e97-a642-895f03d91a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899022ba-314e-4fc8-ac3d-4704ee41368f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5983fb60-7155-4ab8-b14f-ed6f5e33332a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e81544c-9641-4f81-9f31-695270babf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9855e02f-8ed3-412f-b334-bc398d7a3abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bc1c57c-b6bd-49a0-bcba-4e8cb7f80518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0702bce9-e400-4d09-90ab-1a23ab35ed8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd23848c-30de-4aab-a779-20c47b5fc8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3a6934-99e7-400c-a090-f841ac6ef588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b8db61b-b51f-4a4a-a69d-76d6d6f4666a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf35e8e-cc98-4294-8a18-005c76330193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9524f0-dcf4-4c24-a15a-4cc46fcbbbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f03fac-d2b9-4a6e-846f-9f2f0520f9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23be9d6d-af9f-4ed7-9c75-7d614fd44d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8059f10-d616-42f4-bb48-171e8637bbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795b31f4-f22b-4f7e-a016-bf8489f39d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddfa6ae-e5e8-44a3-a6e8-d5e4e069e26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3713b1-a5c0-40d1-9b3d-472d23dc85b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a17052d-c627-46b6-a157-708e01a6e8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931d8dbc-c53f-46ad-8ae4-6728f2f47b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4e0ec4-6d80-4333-9baf-4a663abfda29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1494e2c4-fe96-46f2-9d76-648c4a9c1810
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8694
Algorithm: MOON
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(3897, 24), y=(3897,)
   Test:  X=(975, 24), y=(975,)

⚠️  Limiting training data: 3897 → 800 samples
⚠️  Limiting test data: 975 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2482, R²: 0.0015

📊 Round 0 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2480, R²: 0.0033

============================================================
🔄 Round 6 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0912 (↓), lr=0.001000
   • Epoch   2/100: train=0.0884, val=0.0910, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0884, val=0.0913, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0878, val=0.0915, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0871, val=0.0911, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0834, val=0.0895, patience=3/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0744, val=0.0949, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 6 Summary - Client client_24
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0597
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0297
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 6 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 9 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0862 (↓), lr=0.000500
   • Epoch   2/100: train=0.0899, val=0.0859, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0895, val=0.0857, patience=2/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0893, val=0.0856 (↓), lr=0.000500
   • Epoch   5/100: train=0.0891, val=0.0855, patience=1/15, lr=0.000500
   • Epoch  11/100: train=0.0881, val=0.0854, patience=7/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 9 Summary - Client client_24
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0234
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0256
============================================================


============================================================
🔄 Round 10 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0995 (↓), lr=0.000250
   • Epoch   2/100: train=0.0859, val=0.0995, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0857, val=0.0994, patience=2/15, lr=0.000250
   📉 Epoch 4: LR reduced 0.000250 → 0.000125
   • Epoch   4/100: train=0.0856, val=0.0993, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0853, val=0.0993, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0850, val=0.0992, patience=10/15, lr=0.000125
   📉 Epoch 12: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 10 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0169
   Val:   Loss=0.0995, RMSE=0.3155, R²=0.0026
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: 0.0024

📊 Round 10 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: 0.0026

📊 Round 10 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0021

============================================================
🔄 Round 16 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0915 (↓), lr=0.000063
   • Epoch   2/100: train=0.0880, val=0.0914, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0878, val=0.0914, patience=2/15, lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   • Epoch   4/100: train=0.0877, val=0.0914, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0877, val=0.0914, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0874, val=0.0916, patience=10/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 16 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0152
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0017
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2485, R²: 0.0018

📊 Round 16 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0018

============================================================
🔄 Round 19 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0922 (↓), lr=0.000016
   • Epoch   2/100: train=0.0879, val=0.0922, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0878, val=0.0922, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0878, val=0.0921, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0878, val=0.0921, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0877, val=0.0920, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 19 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0139
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0088
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0019

============================================================
🔄 Round 22 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0906 (↓), lr=0.000004
   • Epoch   2/100: train=0.0885, val=0.0906, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0885, val=0.0906, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0885, val=0.0906, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0884, val=0.0906, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0884, val=0.0906, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 22 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0150
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0003
============================================================


============================================================
🔄 Round 25 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 25 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0140
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0136
============================================================


============================================================
🔄 Round 26 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0923, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 26 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3041, R²=0.0148
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0027
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0020

============================================================
🔄 Round 28 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 28 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0151
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0104
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0021

============================================================
🔄 Round 30 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 30 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0137
   Val:   Loss=0.0934, RMSE=0.3057, R²=0.0099
============================================================


============================================================
🔄 Round 34 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 34 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0171
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0030
============================================================


============================================================
🔄 Round 36 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 36 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0149
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0072
============================================================


============================================================
🔄 Round 41 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 41 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0161
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0021
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: 0.0023

============================================================
🔄 Round 42 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 42 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0136
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0166
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: 0.0023

============================================================
🔄 Round 44 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 44 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0132
   Val:   Loss=0.0981, RMSE=0.3132, R²=0.0006
============================================================


============================================================
🔄 Round 45 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 45 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3024, R²=0.0141
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0138
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: 0.0024

📊 Round 45 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2484, R²: 0.0026

============================================================
🔄 Round 54 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 54 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0145
   Val:   Loss=0.0994, RMSE=0.3152, R²=0.0124
============================================================


============================================================
🔄 Round 57 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 57 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0136
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0138
============================================================


============================================================
🔄 Round 58 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.1006, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 58 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0125
   Val:   Loss=0.1006, RMSE=0.3172, R²=0.0134
============================================================


============================================================
🔄 Round 60 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 60 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3029, R²=0.0117
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0048
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0027

📊 Round 60 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 63 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 63 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0119
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0236
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0027

📊 Round 63 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0027

============================================================
🔄 Round 68 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 68 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0161
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0056
============================================================


============================================================
🔄 Round 69 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 69 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0159
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0087
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0028

📊 Round 69 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0028

📊 Round 69 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0029

============================================================
🔄 Round 76 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 76 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0140
   Val:   Loss=0.0973, RMSE=0.3119, R²=0.0137
============================================================


============================================================
🔄 Round 77 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 77 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0150
   Val:   Loss=0.0992, RMSE=0.3149, R²=0.0112
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0028

📊 Round 77 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 81 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 81 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0165
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0018
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0028

============================================================
🔄 Round 82 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 82 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0132
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0196
============================================================


============================================================
🔄 Round 83 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 83 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0155
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0074
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0029

📊 Round 83 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0029

📊 Round 83 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0029

============================================================
🔄 Round 89 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 89 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0154
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0023
============================================================


============================================================
🔄 Round 91 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 91 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0139
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0155
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0029

============================================================
🔄 Round 94 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 94 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0130
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0185
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 96 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 96 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0140
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0095
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 98 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 98 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0141
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0147
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0030

📊 Round 98 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 101 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 101 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0148
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0100
============================================================


============================================================
🔄 Round 104 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1008 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1008, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1008, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1008, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.1009, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 104 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0150
   Val:   Loss=0.1008, RMSE=0.3175, R²=-0.0029
============================================================


============================================================
🔄 Round 105 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 105 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0121
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0222
============================================================


============================================================
🔄 Round 106 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 106 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0128
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0205
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 107 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 107 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0130
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0027
============================================================


============================================================
🔄 Round 108 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 108 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0139
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0171
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 115 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 115 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0137
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0115
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 115 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 119 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 119 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0128
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0172
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 127 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 127 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0142
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0079
============================================================


============================================================
🔄 Round 128 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 128 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0100
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0229
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

📊 Round 128 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 135 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 135 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0149
   Val:   Loss=0.0982, RMSE=0.3134, R²=0.0125
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 137 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 137 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0146
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0095
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 138 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 138 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0157
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0097
============================================================


============================================================
🔄 Round 139 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 139 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=0.0149
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0031
============================================================


============================================================
🔄 Round 140 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 140 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0136
   Val:   Loss=0.0948, RMSE=0.3080, R²=0.0181
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 143 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 143 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0127
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0214
============================================================


============================================================
🔄 Round 144 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 144 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0154
   Val:   Loss=0.1006, RMSE=0.3171, R²=0.0073
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 145 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 145 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0146
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0109
============================================================


============================================================
🔄 Round 146 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 146 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=0.0139
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0168
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

📊 Round 146 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 149 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 149 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0160
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0054
============================================================


============================================================
🔄 Round 151 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 151 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0164
   Val:   Loss=0.0965, RMSE=0.3107, R²=0.0077
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

📊 Round 151 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0120
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0202
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

📊 Round 157 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

📊 Round 157 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 161 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 161 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0121
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0097
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 167 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 167 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0124
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0056
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 169 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 169 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0137
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0050
============================================================


============================================================
🔄 Round 170 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 170 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0129
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0198
============================================================


============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0129
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0123
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

📊 Round 171 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 173 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 173 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0162
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0013
============================================================


============================================================
🔄 Round 175 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.1047 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.1047, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.1047, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.1047, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.1047, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.1047, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1047)

============================================================
📊 Round 175 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0169
   Val:   Loss=0.1047, RMSE=0.3236, R²=0.0066
============================================================


============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0176
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0050
============================================================


============================================================
🔄 Round 177 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 177 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0141
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0147
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 178 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 178 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0107
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0209
============================================================


============================================================
🔄 Round 179 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 179 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0118
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0192
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 180 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 180 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0127
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0161
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 181 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 181 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0130
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0187
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 183 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 183 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0125
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0227
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 184 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 184 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0147
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0124
============================================================


============================================================
🔄 Round 185 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 185 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0133
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0129
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2483, R²: 0.0034

📊 Round 185 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 190 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 190 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0157
   Val:   Loss=0.0998, RMSE=0.3160, R²=0.0102
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 194 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 194 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0125
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0086
============================================================


============================================================
🔄 Round 195 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 195 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0133
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0158
============================================================


============================================================
🔄 Round 199 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 199 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0155
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0071
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 202 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 202 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0132
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0198
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 207 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 207 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0149
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0132
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 208 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 208 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0143
   Val:   Loss=0.0974, RMSE=0.3122, R²=0.0155
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 209 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 209 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0143
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0009
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 211 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 211 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=0.0165
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0030
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 216 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 216 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0135
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0089
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 216 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 218 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 218 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0124
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0089
============================================================


============================================================
🔄 Round 219 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 219 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0151
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0122
============================================================


============================================================
🔄 Round 221 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 221 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0125
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0001
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 221 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

============================================================
🔄 Round 226 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 226 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0152
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0122
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0034

📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 232 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 232 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0131
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0204
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 232 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 235 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 235 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0177
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0136
============================================================


============================================================
🔄 Round 236 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 236 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0173
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0009
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 238 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 238 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0140
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0036
============================================================


============================================================
🔄 Round 239 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 239 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0119
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0250
============================================================


============================================================
🔄 Round 240 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 240 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0132
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0117
============================================================


============================================================
🔄 Round 241 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 241 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0164
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0070
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 241 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 244 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 244 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0134
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0188
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 244 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 248 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 248 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0123
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0315
============================================================


============================================================
🔄 Round 249 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 249 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0163
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0073
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 251 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 251 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0134
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0096
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 252 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 252 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0143
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0149
============================================================


============================================================
🔄 Round 255 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 255 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0112
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0069
============================================================


============================================================
🔄 Round 257 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 257 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0150
   Val:   Loss=0.0970, RMSE=0.3114, R²=0.0128
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 257 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 263 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 263 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0144
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0125
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 263 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 267 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 267 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0133
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0168
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 267 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 270 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 270 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0146
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0077
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

📊 Round 270 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 275 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 275 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0134
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0154
============================================================


============================================================
🔄 Round 278 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 278 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0151
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0120
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 278 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 278 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 281 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 281 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=0.0160
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0026
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 283 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 283 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0155
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0102
============================================================


============================================================
🔄 Round 284 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 284 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0168
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0030
============================================================


============================================================
🔄 Round 287 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 287 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3019, R²=0.0128
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0201
============================================================


============================================================
🔄 Round 289 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 289 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0110
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0222
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 289 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 291 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 291 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0139
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0161
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 293 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 293 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0125
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0213
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 294 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 294 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0145
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0137
============================================================


============================================================
🔄 Round 295 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 295 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0123
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0201
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 295 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 299 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 299 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0143
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0145
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 299 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 302 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 302 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0147
   Val:   Loss=0.0970, RMSE=0.3115, R²=0.0118
============================================================


============================================================
🔄 Round 303 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 303 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0166
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0010
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 304 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 304 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0133
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0156
============================================================


============================================================
🔄 Round 305 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 305 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0128
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0217
============================================================


============================================================
🔄 Round 306 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 306 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0167
   Val:   Loss=0.0990, RMSE=0.3147, R²=0.0016
============================================================


============================================================
🔄 Round 309 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 309 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0148
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0121
============================================================


============================================================
🔄 Round 310 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.1024 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.1024, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.1024, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.1024, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.1024, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.1024, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1024)

============================================================
📊 Round 310 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0131
   Val:   Loss=0.1024, RMSE=0.3201, R²=0.0193
============================================================


============================================================
🔄 Round 313 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 313 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0153
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0054
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 313 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 315 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 315 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0142
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0111
============================================================


============================================================
🔄 Round 318 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 318 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3041, R²=0.0140
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0146
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 318 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 320 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 320 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0121
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0237
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 320 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 320 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 327 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 327 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0142
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0139
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

📊 Round 327 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 327 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 331 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 331 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=0.0136
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0152
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 332 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 332 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0138
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0094
============================================================


============================================================
🔄 Round 333 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 333 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0159
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0088
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 333 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 339 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 339 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0158
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0042
============================================================


============================================================
🔄 Round 340 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 340 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0148
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0117
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

📊 Round 340 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 344 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 344 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0133
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0192
============================================================


============================================================
🔄 Round 345 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 345 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0145
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0145
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 347 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 347 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0155
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0048
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 349 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 349 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0146
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0138
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 351 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 351 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0143
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0115
============================================================


============================================================
🔄 Round 352 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 352 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3038, R²=0.0146
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0121
============================================================


============================================================
🔄 Round 353 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 353 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0144
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0090
============================================================


============================================================
🔄 Round 354 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 354 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0144
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0010
============================================================


============================================================
🔄 Round 355 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 355 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0144
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0078
============================================================


============================================================
🔄 Round 359 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 359 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0138
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0143
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 360 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 360 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0140
   Val:   Loss=0.0969, RMSE=0.3113, R²=0.0159
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 364 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 364 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0149
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0127
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 364 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 364 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 370 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 370 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0126
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0025
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 373 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 373 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0138
   Val:   Loss=0.0912, RMSE=0.3021, R²=0.0051
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 375 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 375 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0137
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0075
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 377 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 377 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0157
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0093
============================================================


============================================================
🔄 Round 378 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 378 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0161
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0019
============================================================


============================================================
🔄 Round 379 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 379 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0136
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0174
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 379 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 383 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 383 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0136
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0175
============================================================


============================================================
🔄 Round 387 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 387 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0111
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0270
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 387 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 389 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 389 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0164
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0082
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 389 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 389 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 389 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 396 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 396 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0129
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0151
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

📊 Round 396 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 402 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 402 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0151
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0063
============================================================


============================================================
🔄 Round 403 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 403 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3029, R²=0.0151
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0097
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 405 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 405 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0168
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0044
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 409 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 409 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0144
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0125
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0036

============================================================
🔄 Round 411 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 411 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0146
   Val:   Loss=0.0974, RMSE=0.3121, R²=0.0055
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 413 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 413 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0142
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0153
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

📊 Round 413 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 413 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2482, R²: 0.0037

📊 Round 413 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 419 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 419 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0115
   Val:   Loss=0.1003, RMSE=0.3167, R²=0.0215
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 420 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 420 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0149
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0114
============================================================


============================================================
🔄 Round 422 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 422 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0139
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0134
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 424 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 424 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0163
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0003
============================================================


============================================================
🔄 Round 425 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 425 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0153
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0028
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 425 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 425 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 429 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 429 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0164
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0055
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 429 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 429 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 429 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 436 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 436 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0152
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0106
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 438 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 438 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0151
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0051
============================================================


============================================================
🔄 Round 440 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 440 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0145
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0138
============================================================


============================================================
🔄 Round 442 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 442 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0169
   Val:   Loss=0.0937, RMSE=0.3060, R²=0.0050
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 442 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 445 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 445 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3029, R²=0.0137
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0114
============================================================


============================================================
🔄 Round 446 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 446 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0149
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0123
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 450 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 450 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0150
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0019
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 451 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 451 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0142
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0147
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 454 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 454 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0158
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0069
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 456 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 456 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0133
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0100
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 459 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 459 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0121
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0242
============================================================


============================================================
🔄 Round 462 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 462 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0139
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0087
============================================================


============================================================
🔄 Round 467 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 467 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0150
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0121
============================================================


============================================================
🔄 Round 469 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 469 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0139
   Val:   Loss=0.0965, RMSE=0.3107, R²=0.0132
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 471 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 471 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=0.0141
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0098
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 473 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 473 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0147
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0123
============================================================


============================================================
🔄 Round 474 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 474 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0149
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0124
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 474 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 477 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 477 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0147
   Val:   Loss=0.0942, RMSE=0.3068, R²=0.0113
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 478 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 478 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0162
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0068
============================================================


============================================================
🔄 Round 480 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 480 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0125
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0209
============================================================


============================================================
🔄 Round 482 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 482 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0126
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0026
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 483 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 483 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0131
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0159
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 483 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 489 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 489 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0143
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0059
============================================================


============================================================
🔄 Round 491 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 491 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0150
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0122
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 492 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 492 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0141
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0154
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 496 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 496 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0127
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0071
============================================================


============================================================
🔄 Round 498 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 498 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0145
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0021
============================================================


============================================================
🔄 Round 499 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 499 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0151
   Val:   Loss=0.0959, RMSE=0.3096, R²=0.0116
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 499 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 503 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 503 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0132
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0138
============================================================


============================================================
🔄 Round 504 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 504 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0138
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0109
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 508 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 508 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0139
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0066
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 508 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 512 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 512 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0136
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0148
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 513 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 513 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0166
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0148
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 513 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

📊 Round 513 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 522 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 522 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0148
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0126
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 522 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0037

============================================================
🔄 Round 527 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 527 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0140
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0056
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 527 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 530 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 530 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0127
   Val:   Loss=0.0961, RMSE=0.3099, R²=-0.0092
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 530 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 530 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 538 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 538 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0160
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0021
============================================================


============================================================
🔄 Round 539 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 539 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0166
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0055
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 540 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 540 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0136
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0169
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 540 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 543 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 543 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0134
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0083
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 543 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 543 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 543 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 543 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 552 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 552 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0153
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0102
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

📊 Round 552 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 557 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 557 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0155
   Val:   Loss=0.0969, RMSE=0.3112, R²=0.0086
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 558 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 558 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0127
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0152
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 560 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 560 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0154
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0097
============================================================


============================================================
🔄 Round 561 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 561 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0145
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0039
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 561 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 563 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 563 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0156
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0063
============================================================


============================================================
🔄 Round 566 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 566 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=0.0134
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0009
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 567 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 567 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0131
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0193
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 569 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 569 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0122
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0227
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0038

============================================================
🔄 Round 571 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 571 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0144
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0057
============================================================


============================================================
🔄 Round 572 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 572 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0128
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0169
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 573 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 573 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0135
   Val:   Loss=0.0952, RMSE=0.3086, R²=0.0175
============================================================


============================================================
🔄 Round 574 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 574 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0121
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0186
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 574 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 574 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 580 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 580 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0121
   Val:   Loss=0.0964, RMSE=0.3105, R²=0.0076
============================================================


============================================================
🔄 Round 581 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 581 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0147
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0079
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 581 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 586 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 586 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0151
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0095
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 587 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 587 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0116
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0028
============================================================


============================================================
🔄 Round 588 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 588 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0133
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0169
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 592 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 592 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0122
   Val:   Loss=0.0964, RMSE=0.3104, R²=0.0207
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 593 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 593 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0154
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0010
============================================================


============================================================
🔄 Round 594 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 594 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0146
   Val:   Loss=0.0960, RMSE=0.3098, R²=0.0126
============================================================


============================================================
🔄 Round 596 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 596 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0155
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0075
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 598 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 598 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0113
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0082
============================================================


============================================================
🔄 Round 599 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 599 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0139
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0161
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 601 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 601 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0133
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0084
============================================================


============================================================
🔄 Round 602 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 602 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0127
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0160
============================================================


============================================================
🔄 Round 603 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 603 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0151
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0018
============================================================


============================================================
🔄 Round 604 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 604 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0138
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0127
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 606 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 606 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0132
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0197
============================================================


============================================================
🔄 Round 607 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 607 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0128
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0145
============================================================


============================================================
🔄 Round 610 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 610 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0142
   Val:   Loss=0.0977, RMSE=0.3126, R²=-0.0012
============================================================


============================================================
🔄 Round 611 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 611 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0116
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0121
============================================================


============================================================
🔄 Round 612 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 612 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=0.0134
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0187
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 614 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 614 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0136
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0119
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 614 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 617 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 617 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0142
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0008
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 617 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 619 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 619 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0085
   Val:   Loss=0.1009, RMSE=0.3176, R²=0.0146
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 619 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 621 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 621 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0131
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0021
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 623 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 623 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=0.0133
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0172
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 623 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 623 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 627 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 627 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0125
   Val:   Loss=0.0944, RMSE=0.3073, R²=0.0129
============================================================


============================================================
🔄 Round 628 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 628 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0160
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0077
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 630 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 630 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0125
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0109
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 630 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 633 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 633 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0149
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0099
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 635 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 635 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0122
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0233
============================================================


============================================================
🔄 Round 637 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 637 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0110
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0266
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 638 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 638 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0175
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0042
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 640 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 640 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0137
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0166
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 640 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 642 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 642 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0144
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0073
============================================================


============================================================
🔄 Round 643 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 643 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0136
   Val:   Loss=0.0992, RMSE=0.3150, R²=0.0162
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 643 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

📊 Round 643 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 649 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 649 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0129
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0178
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 649 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 654 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 654 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0135
   Val:   Loss=0.0942, RMSE=0.3070, R²=0.0158
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 656 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 656 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0144
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0140
============================================================


============================================================
🔄 Round 657 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 657 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0127
   Val:   Loss=0.0974, RMSE=0.3120, R²=-0.0016
============================================================


============================================================
🔄 Round 658 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 658 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0127
   Val:   Loss=0.0876, RMSE=0.2961, R²=0.0178
============================================================


============================================================
🔄 Round 663 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 663 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0162
   Val:   Loss=0.0978, RMSE=0.3127, R²=0.0055
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 664 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 664 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0167
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0030
============================================================


============================================================
🔄 Round 666 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 666 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=0.0121
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0208
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 666 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 666 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 671 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 671 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=0.0122
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0148
============================================================


============================================================
🔄 Round 673 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 673 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0152
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0024
============================================================


============================================================
🔄 Round 674 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 674 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0165
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0047
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 677 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 677 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0124
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0214
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 677 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 684 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 684 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0125
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0028
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 685 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 685 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0131
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0343
============================================================


============================================================
🔄 Round 686 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 686 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0159
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0021
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 686 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 689 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 689 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0116
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0217
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2482, R²: 0.0039

============================================================
🔄 Round 691 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 691 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0150
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0016
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 692 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 692 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0134
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0148
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 692 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 694 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 694 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0149
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0077
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 699 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 699 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0152
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0049
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 701 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 701 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0132
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0177
============================================================


============================================================
🔄 Round 702 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 702 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0136
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0123
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 703 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0925, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 703 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3041, R²=0.0133
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0123
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 703 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 706 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 706 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0154
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0045
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 706 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 710 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 710 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0107
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0128
============================================================


============================================================
🔄 Round 711 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 711 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0133
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0175
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 711 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 711 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 718 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 718 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0126
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0215
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 718 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 724 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 724 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=0.0147
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0065
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 724 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 727 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 727 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0143
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0096
============================================================


============================================================
🔄 Round 729 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 729 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0164
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0038
============================================================


============================================================
🔄 Round 730 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 730 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0143
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0147
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 731 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 731 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0171
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0021
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 732 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 732 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0159
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0053
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 732 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 732 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 738 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 738 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0135
   Val:   Loss=0.0966, RMSE=0.3108, R²=0.0174
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 739 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 739 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0147
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0129
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 739 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 741 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 741 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0144
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0117
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 742 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 742 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0158
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0073
============================================================


============================================================
🔄 Round 744 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 744 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0142
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0117
============================================================


============================================================
🔄 Round 745 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 745 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0137
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0171
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 747 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 747 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0154
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0090
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 747 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 752 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 752 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0123
   Val:   Loss=0.0981, RMSE=0.3132, R²=0.0212
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 754 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 754 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0145
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0093
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 755 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 755 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0127
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0084
============================================================


============================================================
🔄 Round 756 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 756 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0166
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0039
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 759 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 759 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0103
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0305
============================================================


============================================================
🔄 Round 762 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 762 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0137
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0001
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 762 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 765 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 765 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0125
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0089
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 767 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 767 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0146
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0128
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

📊 Round 767 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0039

============================================================
🔄 Round 769 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 769 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0111
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0029
============================================================


============================================================
🔄 Round 770 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 770 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0142
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0010
============================================================


============================================================
🔄 Round 771 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 771 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0134
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0082
============================================================


============================================================
🔄 Round 773 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 773 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0164
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0056
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 776 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 776 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0168
   Val:   Loss=0.1010, RMSE=0.3177, R²=0.0002
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 777 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 777 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0151
   Val:   Loss=0.0996, RMSE=0.3155, R²=0.0115
============================================================


============================================================
🔄 Round 778 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 778 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0145
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0124
============================================================


============================================================
🔄 Round 782 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 782 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0134
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0177
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 790 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 790 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0148
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0072
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 790 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 790 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 795 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 795 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0123
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0124
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 796 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 796 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0119
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0076
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 799 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 799 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0134
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0128
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 799 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 804 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 804 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0134
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0178
============================================================


============================================================
🔄 Round 805 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 805 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0131
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0009
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 805 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 805 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 810 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 810 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0093
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0066
============================================================


📊 Round 810 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 811 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 811 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0147
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0097
============================================================


============================================================
🔄 Round 812 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 812 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0149
   Val:   Loss=0.0973, RMSE=0.3119, R²=0.0118
============================================================


📊 Round 812 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 812 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 815 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 815 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0145
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0061
============================================================


============================================================
🔄 Round 816 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 816 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0150
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0116
============================================================


============================================================
🔄 Round 817 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 817 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0146
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0008
============================================================


============================================================
🔄 Round 820 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 820 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0139
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0158
============================================================


============================================================
🔄 Round 826 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 826 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0161
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0047
============================================================


============================================================
🔄 Round 828 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 828 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0129
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0034
============================================================


============================================================
🔄 Round 829 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 829 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0155
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0091
============================================================


📊 Round 829 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 830 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 830 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0153
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0098
============================================================


📊 Round 830 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 831 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 831 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0159
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0017
============================================================


📊 Round 831 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 833 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 833 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0144
   Val:   Loss=0.0879, RMSE=0.2966, R²=0.0053
============================================================


============================================================
🔄 Round 835 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 835 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0136
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0050
============================================================


📊 Round 835 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 835 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 835 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 835 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 839 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 839 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0150
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0079
============================================================


============================================================
🔄 Round 840 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 840 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0142
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0102
============================================================


📊 Round 840 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 841 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 841 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=0.0131
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0194
============================================================


============================================================
🔄 Round 842 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 842 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0144
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0101
============================================================


📊 Round 842 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 842 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 842 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 845 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 845 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0158
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0059
============================================================


============================================================
🔄 Round 846 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 846 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0135
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0130
============================================================


📊 Round 846 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 848 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 848 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=0.0135
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0148
============================================================


============================================================
🔄 Round 849 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 849 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0156
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0091
============================================================


📊 Round 849 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 850 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 850 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0104
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0271
============================================================


============================================================
🔄 Round 851 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 851 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0149
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0109
============================================================


📊 Round 851 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 851 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 854 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 854 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0162
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0065
============================================================


📊 Round 854 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 854 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 858 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 858 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0147
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0106
============================================================


📊 Round 858 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 858 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 862 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 862 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0134
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0112
============================================================


============================================================
🔄 Round 863 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 863 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0159
   Val:   Loss=0.0953, RMSE=0.3088, R²=0.0063
============================================================


============================================================
🔄 Round 864 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 864 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0138
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0164
============================================================


📊 Round 864 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

📊 Round 864 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0040

============================================================
🔄 Round 868 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 868 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0162
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0040
============================================================


============================================================
🔄 Round 870 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 870 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0141
   Val:   Loss=0.0968, RMSE=0.3111, R²=0.0130
============================================================


📊 Round 870 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 870 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 870 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 870 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 876 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 876 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0119
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0198
============================================================


📊 Round 876 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 877 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 877 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0130
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0184
============================================================


📊 Round 877 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 878 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 878 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0127
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0201
============================================================


📊 Round 878 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 878 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 880 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 880 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0150
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0113
============================================================


============================================================
🔄 Round 881 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 881 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0143
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0142
============================================================


============================================================
🔄 Round 882 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.1050 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.1050, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.1050, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.1050, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.1050, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.1050, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1050)

============================================================
📊 Round 882 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0116
   Val:   Loss=0.1050, RMSE=0.3241, R²=0.0177
============================================================


📊 Round 882 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 883 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 883 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0157
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0071
============================================================


============================================================
🔄 Round 884 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 884 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0124
   Val:   Loss=0.0948, RMSE=0.3078, R²=0.0110
============================================================


📊 Round 884 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 885 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 885 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0143
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0076
============================================================


📊 Round 885 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 885 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 885 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 892 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 892 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0142
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0148
============================================================


📊 Round 892 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 892 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 900 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 900 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3014, R²=0.0140
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0161
============================================================


============================================================
🔄 Round 901 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 901 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0161
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0073
============================================================


📊 Round 901 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 903 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 903 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0172
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0023
============================================================


============================================================
🔄 Round 904 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 904 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0120
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0231
============================================================


📊 Round 904 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 905 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 905 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0160
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0070
============================================================


============================================================
🔄 Round 906 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 906 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0139
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0157
============================================================


📊 Round 906 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 907 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 907 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0133
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0128
============================================================


============================================================
🔄 Round 908 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 908 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0156
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0092
============================================================


📊 Round 908 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 908 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 911 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 911 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0150
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0120
============================================================


📊 Round 911 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 911 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 920 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 920 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0130
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0090
============================================================


📊 Round 920 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 920 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 922 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 922 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0107
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0400
============================================================


============================================================
🔄 Round 923 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 923 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0172
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0016
============================================================


============================================================
🔄 Round 924 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 924 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0150
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0003
============================================================


📊 Round 924 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 925 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 925 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0133
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0188
============================================================


📊 Round 925 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 925 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 928 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 928 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0155
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0097
============================================================


📊 Round 928 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 928 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 933 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 933 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0104
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0305
============================================================


============================================================
🔄 Round 934 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 934 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0155
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0100
============================================================


📊 Round 934 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 935 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 935 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0151
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0114
============================================================


============================================================
🔄 Round 936 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 936 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0153
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0080
============================================================


📊 Round 936 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0042

============================================================
🔄 Round 939 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 939 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0138
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0019
============================================================


📊 Round 939 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0042

📊 Round 939 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 942 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 942 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0141
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0125
============================================================


📊 Round 942 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

📊 Round 942 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0041

============================================================
🔄 Round 944 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 944 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0134
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0141
============================================================


📊 Round 944 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2481, R²: 0.0042

❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8694 {grpc_status:14, grpc_message:"Socket closed"}"
>
